{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RA-KL Research Notebook\n",
        "\n",
        "## Regime-Aware KL Budget Control for PPO in Portfolio Optimization\n",
        "\n",
        "This notebook is a paper-ready research workflow to:\n",
        "- define the RA-KL method and claims,\n",
        "- run ablations,\n",
        "- compute training stability diagnostics,\n",
        "- evaluate out-of-sample performance,\n",
        "- generate publication tables/figures.\n",
        "\n",
        "Use this notebook as your primary write-up workspace for the KL-management contribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Study Scope and Contribution Claims\n",
        "\n",
        "### Problem\n",
        "Static PPO KL thresholds are fragile in non-stationary markets. They can either:\n",
        "- allow policy over-jumps (instability), or\n",
        "- trigger frequent early-stops (under-updating).\n",
        "\n",
        "### Proposed Method\n",
        "**RA-KL (Regime-Aware KL Budget Controller)**: an online controller that adapts PPO aggressiveness using update-level feedback.\n",
        "\n",
        "### Main Contribution Statement\n",
        "RA-KL transforms PPO trust-region control from static hyperparameters to a closed-loop, regime-aware budgeting mechanism.\n",
        "\n",
        "### Testable Hypotheses\n",
        "1. RA-KL reduces KL overshoot rate and early-stop frequency.\n",
        "2. RA-KL improves stability-adjusted performance (Sharpe/Sortino/Calmar).\n",
        "3. RA-KL lowers unnecessary turnover without collapsing responsiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Method Specification (Paper Draft)\n",
        "\n",
        "### 2.1 Controller Inputs\n",
        "At update $t$, define:\n",
        "- $k_t$: observed approximate KL,\n",
        "- $c_t$: clip fraction,\n",
        "- $s_t$: early-stop indicator,\n",
        "- $a_t$: alpha-dispersion proxy (Dirichlet alpha std),\n",
        "- $r_t$: regime/stress proxy (e.g., volatility bucket).\n",
        "\n",
        "Use exponential moving averages (EMA):\n",
        "\\[\n",
        "\\bar{k}_t = (1-\\lambda_k)\\bar{k}_{t-1} + \\lambda_k k_t\n",
        "\\]\n",
        "(similarly for $\\bar{c}_t, \\bar{s}_t, \\bar{a}_t$).\n",
        "\n",
        "### 2.2 KL Tracking Error\n",
        "\\[\n",
        "e_t = \\frac{\\bar{k}_t}{k^{\\text{base}}} - 1\n",
        "\\]\n",
        "where $k^{\\text{base}}$ is baseline KL target.\n",
        "\n",
        "### 2.3 Adaptive Controls\n",
        "\\[\n",
        "\\eta_t = \\text{clip}(\\eta_{t-1} \\exp(-\\kappa_\\eta e_t^+), \\eta_{\\min}, \\eta_{\\max})\n",
        "\\]\n",
        "\\[\n",
        "\\epsilon_t = \\text{clip}(\\epsilon_{t-1}(1-\\kappa_\\epsilon e_t^+), \\epsilon_{\\min}, \\epsilon_{\\max})\n",
        "\\]\n",
        "\\[\n",
        "k_t^{\\text{target}} = \\text{clip}(k^{\\text{base}} \\exp(-\\kappa_k e_t^+ + \\kappa_{\\text{relax}} e_t^-), k_{\\min}, k_{\\max})\n",
        "\\]\n",
        "\n",
        "where $e_t^+ = \\max(e_t,0)$ and $e_t^- = \\max(-e_t,0)$.\n",
        "\n",
        "### 2.4 Regime Gate\n",
        "During stress regimes, tighten KL budget via multiplier $\\rho_t \\in (0,1]$:\n",
        "\\[\n",
        "k_t^{\\text{target}} \\leftarrow \\rho_t k_t^{\\text{target}}\n",
        "\\]\n",
        "Example: $\\rho_t=0.8$ in high-vol regime.\n",
        "\n",
        "### 2.5 Dirichlet-aware Dampening\n",
        "If KL is high and alpha dispersion changes abruptly, apply temporary cooldown (N updates) to actor LR and clip.\n",
        "\n",
        "### 2.6 Expected Effect\n",
        "- fewer over-aggressive updates,\n",
        "- fewer repetitive early-stops,\n",
        "- smoother portfolio reallocation path,\n",
        "- better train-to-test robustness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 3) Imports and plotting defaults\n",
        "from pathlib import Path\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.width', 160)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 4) Configure run paths\n",
        "# Set this to your run folder that contains logs/*episodes*.csv, *step_diagnostics*.csv, *summary*.csv\n",
        "RESULTS_ROOT = Path('/content/adaptive_portfolio_rl/tcn_fusion_results')\n",
        "LOGS_DIR = RESULTS_ROOT / 'logs'\n",
        "\n",
        "# Optional fixed timestamp suffix (example: '20260221_071837').\n",
        "# If None, notebook auto-picks latest files by mtime.\n",
        "RUN_TAG = None\n",
        "\n",
        "print('RESULTS_ROOT:', RESULTS_ROOT)\n",
        "print('LOGS_DIR:', LOGS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 5) File loader helpers\n",
        "\n",
        "def _pick_latest(pattern: str, logs_dir: Path, run_tag: str | None = None):\n",
        "    files = sorted(logs_dir.glob(pattern), key=lambda p: p.stat().st_mtime)\n",
        "    if run_tag:\n",
        "        tagged = [p for p in files if run_tag in p.name]\n",
        "        if tagged:\n",
        "            return tagged[-1]\n",
        "    return files[-1] if files else None\n",
        "\n",
        "\n",
        "def load_run_artifacts(logs_dir: Path, run_tag: str | None = None):\n",
        "    episodes_p = _pick_latest('*episodes*.csv', logs_dir, run_tag)\n",
        "    steps_p = _pick_latest('*step_diagnostics*.csv', logs_dir, run_tag)\n",
        "    summary_p = _pick_latest('*summary*.csv', logs_dir, run_tag)\n",
        "    meta_p = _pick_latest('*_metadata.json', logs_dir, run_tag)\n",
        "    manifest_p = _pick_latest('*active_feature_manifest.json', logs_dir, run_tag)\n",
        "\n",
        "    out = {\n",
        "        'episodes_path': episodes_p,\n",
        "        'steps_path': steps_p,\n",
        "        'summary_path': summary_p,\n",
        "        'metadata_path': meta_p,\n",
        "        'manifest_path': manifest_p,\n",
        "        'episodes': pd.read_csv(episodes_p) if episodes_p else None,\n",
        "        'steps': pd.read_csv(steps_p) if steps_p else None,\n",
        "        'summary': pd.read_csv(summary_p) if summary_p else None,\n",
        "        'metadata': json.loads(meta_p.read_text(encoding='utf-8')) if meta_p else None,\n",
        "        'manifest': json.loads(manifest_p.read_text(encoding='utf-8')) if manifest_p else None,\n",
        "    }\n",
        "    return out\n",
        "\n",
        "art = load_run_artifacts(LOGS_DIR, RUN_TAG)\n",
        "for k in ['episodes_path','steps_path','summary_path','metadata_path','manifest_path']:\n",
        "    print(f'{k}:', art[k])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 6) Quick schema inspection\n",
        "\n",
        "def show_schema(df: pd.DataFrame | None, name: str, n=40):\n",
        "    if df is None:\n",
        "        print(f'{name}: None')\n",
        "        return\n",
        "    print(f'\n",
        "{name}: shape={df.shape}')\n",
        "    print('columns:', list(df.columns[:n]))\n",
        "    if len(df.columns) > n:\n",
        "        print(f'... (+{len(df.columns)-n} more)')\n",
        "\n",
        "show_schema(art['episodes'], 'episodes')\n",
        "show_schema(art['steps'], 'step_diagnostics')\n",
        "show_schema(art['summary'], 'summary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Ablation Plan (state in paper)\n",
        "\n",
        "### Baselines\n",
        "1. **Static PPO-KL**: fixed target_kl and fixed clip.\n",
        "2. **Scheduled PPO**: hand-crafted rollout/batch/LR schedule only.\n",
        "\n",
        "### Proposed Variants\n",
        "3. **Adaptive-KL only**: closed-loop KL controller without regime gate.\n",
        "4. **Adaptive-KL + Dirichlet Dampening**.\n",
        "5. **Full RA-KL**: Adaptive-KL + regime gate + Dirichlet dampening.\n",
        "\n",
        "### Controlled Factors\n",
        "- same seed set, data split, feature set,\n",
        "- same architecture (TCN_FUSION),\n",
        "- same reward system (TAPE) unless in reward ablation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 7) Register experiment runs for cross-run ablation comparison\n",
        "# Fill with your available runs (paths or log files).\n",
        "\n",
        "EXPERIMENTS = [\n",
        "    {\n",
        "        'label': 'static_kl',\n",
        "        'group': 'baseline',\n",
        "        'logs_dir': LOGS_DIR,\n",
        "        'run_tag': None,  # put explicit tag for this run\n",
        "        'method': 'Static PPO-KL',\n",
        "    },\n",
        "    # Add more runs here:\n",
        "    # {'label': 'ra_kl_full', 'group': 'proposed', 'logs_dir': Path(...), 'run_tag': '2026....', 'method': 'RA-KL Full'},\n",
        "]\n",
        "\n",
        "print('Experiments configured:', len(EXPERIMENTS))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 8) Metric extractor utilities (robust to column naming differences)\n",
        "\n",
        "def pick_col(df, candidates, default=None):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return default\n",
        "\n",
        "\n",
        "def compute_training_stability(episodes: pd.DataFrame | None, steps: pd.DataFrame | None):\n",
        "    res = {}\n",
        "\n",
        "    if steps is not None and len(steps) > 0:\n",
        "        kl_col = pick_col(steps, ['approx_kl', 'kl', 'ppo_approx_kl'])\n",
        "        clip_col = pick_col(steps, ['clip_fraction', 'ppo_clip_fraction'])\n",
        "        early_col = pick_col(steps, ['early_stop_kl_triggered', 'kl_early_stop', 'early_stop'])\n",
        "        turn_col = pick_col(steps, ['turnover', 'episode_turnover', 'turnover_pct'])\n",
        "\n",
        "        if kl_col:\n",
        "            res['kl_mean'] = float(steps[kl_col].mean())\n",
        "            res['kl_p95'] = float(steps[kl_col].quantile(0.95))\n",
        "            res['kl_max'] = float(steps[kl_col].max())\n",
        "        if clip_col:\n",
        "            res['clip_fraction_mean'] = float(steps[clip_col].mean())\n",
        "        if early_col:\n",
        "            res['early_stop_rate'] = float((steps[early_col] > 0).mean())\n",
        "        if turn_col:\n",
        "            res['turnover_mean'] = float(steps[turn_col].mean())\n",
        "\n",
        "    if episodes is not None and len(episodes) > 0:\n",
        "        shp_col = pick_col(episodes, ['Sharpe', 'sharpe', 'sharpe_ratio'])\n",
        "        ret_col = pick_col(episodes, ['Return', 'total_return', 'episode_return'])\n",
        "        dd_col = pick_col(episodes, ['Max_Drawdown', 'max_drawdown', 'MDD'])\n",
        "\n",
        "        if shp_col:\n",
        "            res['episode_sharpe_mean'] = float(episodes[shp_col].mean())\n",
        "            res['episode_sharpe_p75'] = float(episodes[shp_col].quantile(0.75))\n",
        "        if ret_col:\n",
        "            res['episode_return_mean'] = float(episodes[ret_col].mean())\n",
        "        if dd_col:\n",
        "            res['episode_mdd_mean'] = float(episodes[dd_col].mean())\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 9) Build ablation table\n",
        "\n",
        "def load_one_experiment(exp):\n",
        "    art = load_run_artifacts(exp['logs_dir'], exp.get('run_tag'))\n",
        "    stab = compute_training_stability(art['episodes'], art['steps'])\n",
        "\n",
        "    row = {\n",
        "        'label': exp['label'],\n",
        "        'group': exp.get('group'),\n",
        "        'method': exp.get('method'),\n",
        "        'run_tag': exp.get('run_tag'),\n",
        "    }\n",
        "    row.update(stab)\n",
        "    return row, art\n",
        "\n",
        "rows = []\n",
        "loaded = {}\n",
        "for exp in EXPERIMENTS:\n",
        "    row, loaded_art = load_one_experiment(exp)\n",
        "    rows.append(row)\n",
        "    loaded[exp['label']] = loaded_art\n",
        "\n",
        "ablation_df = pd.DataFrame(rows)\n",
        "ablation_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 10) KL diagnostics plots for one selected run\n",
        "SELECT_LABEL = EXPERIMENTS[0]['label'] if EXPERIMENTS else None\n",
        "sel = loaded.get(SELECT_LABEL, {})\n",
        "steps_df = sel.get('steps')\n",
        "\n",
        "if steps_df is None or steps_df.empty:\n",
        "    print('No step_diagnostics loaded for selected run.')\n",
        "else:\n",
        "    kl_col = pick_col(steps_df, ['approx_kl', 'kl', 'ppo_approx_kl'])\n",
        "    clip_col = pick_col(steps_df, ['clip_fraction', 'ppo_clip_fraction'])\n",
        "    early_col = pick_col(steps_df, ['early_stop_kl_triggered', 'kl_early_stop', 'early_stop'])\n",
        "    x_col = pick_col(steps_df, ['update', 'update_count', 'step', 'timesteps'])\n",
        "\n",
        "    x = steps_df[x_col] if x_col else np.arange(len(steps_df))\n",
        "\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "    if kl_col:\n",
        "        axes[0].plot(x, steps_df[kl_col], lw=1.2)\n",
        "        axes[0].set_title('Approx KL over training updates')\n",
        "        axes[0].set_ylabel('KL')\n",
        "\n",
        "    if clip_col:\n",
        "        axes[1].plot(x, steps_df[clip_col], lw=1.2, color='tab:orange')\n",
        "        axes[1].set_title('Clip fraction over updates')\n",
        "        axes[1].set_ylabel('clip_fraction')\n",
        "\n",
        "    if early_col:\n",
        "        axes[2].plot(x, steps_df[early_col], lw=1.0, color='tab:red')\n",
        "        axes[2].set_title('KL early-stop trigger indicator')\n",
        "        axes[2].set_ylabel('trigger')\n",
        "\n",
        "    axes[2].set_xlabel('update index')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 11) Performance plots (return, sharpe, drawdown, turnover)\n",
        "\n",
        "sel = loaded.get(SELECT_LABEL, {})\n",
        "ep_df = sel.get('episodes')\n",
        "\n",
        "if ep_df is None or ep_df.empty:\n",
        "    print('No episodes file loaded for selected run.')\n",
        "else:\n",
        "    idx = np.arange(len(ep_df))\n",
        "    cols = {\n",
        "        'return': pick_col(ep_df, ['Return', 'total_return', 'episode_return']),\n",
        "        'sharpe': pick_col(ep_df, ['Sharpe', 'sharpe', 'sharpe_ratio']),\n",
        "        'drawdown': pick_col(ep_df, ['Max_Drawdown', 'max_drawdown', 'MDD']),\n",
        "        'turnover': pick_col(ep_df, ['Turnover', 'turnover', 'turnover_pct']),\n",
        "    }\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(13, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for ax, (name, col) in zip(axes, cols.items()):\n",
        "        if col:\n",
        "            ax.plot(idx, ep_df[col], lw=1.2)\n",
        "            ax.set_title(f'{name} ({col})')\n",
        "            ax.set_xlabel('episode')\n",
        "        else:\n",
        "            ax.set_title(f'{name}: column not found')\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 12) Paper-ready summary table with ranking\n",
        "rank_cols = [c for c in [\n",
        "    'episode_sharpe_mean',\n",
        "    'episode_return_mean',\n",
        "    'episode_mdd_mean',\n",
        "    'turnover_mean',\n",
        "    'kl_mean',\n",
        "    'early_stop_rate',\n",
        "] if c in ablation_df.columns]\n",
        "\n",
        "summary_table = ablation_df.copy()\n",
        "if 'episode_sharpe_mean' in summary_table:\n",
        "    summary_table = summary_table.sort_values('episode_sharpe_mean', ascending=False)\n",
        "\n",
        "summary_table.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 13) Export publication assets (CSV + LaTeX)\n",
        "OUT_DIR = Path('./paper_outputs_ra_kl')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ablation_csv = OUT_DIR / 'ablation_summary.csv'\n",
        "ablation_df.to_csv(ablation_csv, index=False)\n",
        "print('Saved:', ablation_csv)\n",
        "\n",
        "# LaTeX table for paper\n",
        "latex_path = OUT_DIR / 'ablation_summary.tex'\n",
        "with open(latex_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(ablation_df.to_latex(index=False, float_format=lambda x: f'{x:0.4f}' if isinstance(x, float) else str(x)))\n",
        "print('Saved:', latex_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Write-up Blocks You Can Paste into Paper\n",
        "\n",
        "### Method paragraph (short)\n",
        "We introduce Regime-Aware KL Budgeting (RA-KL), a closed-loop PPO controller that adapts target KL, actor learning rate, and clip range from update-level feedback (approximate KL, clipping pressure, and early-stop incidence), with additional regime-conditioned tightening during market stress and Dirichlet-policy dampening when concentration dynamics become unstable.\n",
        "\n",
        "### Experimental protocol paragraph\n",
        "All ablations use the same data split, architecture (TCN_FUSION), reward design (TAPE), and seed protocol. We compare static PPO trust-region settings against adaptive variants, and report both optimization diagnostics (KL overshoot, clip fraction, early-stop rate) and portfolio performance metrics (Sharpe, Sortino, drawdown, turnover, return).\n",
        "\n",
        "### Main finding template\n",
        "RA-KL reduced KL overshoot frequency by [X%], reduced early-stop rate by [Y%], and improved out-of-sample Sharpe by [Z], while maintaining lower turnover and comparable drawdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Reporting Checklist\n",
        "\n",
        "- Include exact hyperparameter bounds for dynamic controls.\n",
        "- Report mean and variance over multiple seeds.\n",
        "- Separate training stability metrics from test performance metrics.\n",
        "- Add failure-case analysis (when RA-KL underperforms).\n",
        "- Provide compute-cost comparison (time/update and wall-clock).\n",
        "- Include robustness checks across benchmark and stress windows."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}