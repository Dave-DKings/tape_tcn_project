{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Final Evaluation Notebook\n",
    "\n",
    "This notebook is evaluation-only and designed for final model selection, ablations, and benchmarking.\n",
    "All runtime variables are isolated with the `eval_` prefix to avoid conflicts with training notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Connect to Colab VM and sync repository\n",
    "Run this first in a fresh Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "HEAD is now at 72fd098 Enforce feature-audit allowlist across training and evaluation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "EVAL_REPO_URL = \"https://github.com/Dave-DKings/tape_tcn_project.git\"\n",
    "EVAL_REPO_DIR = \"/content/adaptive_portfolio_rl\"\n",
    "\n",
    "if not os.path.exists(f\"{EVAL_REPO_DIR}/.git\"):\n",
    "    !git clone {EVAL_REPO_URL} {EVAL_REPO_DIR}\n",
    "\n",
    "%cd /content/adaptive_portfolio_rl\n",
    "!git fetch origin\n",
    "!git reset --hard origin/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Optional: mount Drive and restore saved results zip\n",
    "Set `EVAL_RESTORE_FROM_ZIP=True` only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "âœ… Restored results from zip\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "EVAL_RESTORE_FROM_ZIP = True\n",
    "EVAL_ZIP_PATH = \"/content/drive/MyDrive/tcn_fusion_results_run4.zip\"\n",
    "\n",
    "if EVAL_RESTORE_FROM_ZIP:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    zip_path = Path(EVAL_ZIP_PATH)\n",
    "    if not zip_path.exists():\n",
    "        raise FileNotFoundError(f\"Zip not found: {zip_path}\")\n",
    "\n",
    "    !mkdir -p /content/adaptive_portfolio_rl\n",
    "    !unzip -q -o {zip_path} -d /content/adaptive_portfolio_rl\n",
    "    print(\"âœ… Restored results from zip\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ EVAL_RESTORE_FROM_ZIP=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d075602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip exists: True\n",
      "Archive:  /content/drive/MyDrive/tcn_fusion_results_run4.zip\n",
      "  Length      Date    Time    Name\n",
      "---------  ---------- -----   ----\n",
      "        0  2026-02-23 03:54   tcn_fusion_results/\n",
      "        0  2026-02-23 07:28   tcn_fusion_results/high_watermark_checkpoints/\n",
      "  1878320  2026-02-23 06:59   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00053_shp0p824_critic.weights.h5\n",
      "  1878320  2026-02-23 06:46   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00050_shp0p822_critic.weights.h5\n",
      "  1878320  2026-02-23 03:54   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p819_critic.weights.h5\n",
      "  1881904  2026-02-23 07:07   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00055_shp0p824_actor.weights.h5\n",
      "  1881904  2026-02-23 04:18   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00008_shp0p820_actor.weights.h5\n",
      "  1878320  2026-02-23 07:15   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00057_shp0p825_critic.weights.h5\n",
      "  1881904  2026-02-23 04:05   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p820_actor.weights.h5\n",
      "  1881904  2026-02-23 06:42   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00049_shp0p821_actor.weights.h5\n",
      "  1878320  2026-02-23 04:18   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00008_shp0p820_critic.weights.h5\n",
      "  1881904  2026-02-23 07:03   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00054_shp0p824_actor.weights.h5\n",
      "  1878320  2026-02-23 04:28   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp0p820_critic.weights.h5\n",
      "  1878320  2026-02-23 07:11   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00056_shp0p825_critic.weights.h5\n",
      "  1881904  2026-02-23 06:46   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00050_shp0p822_actor.weights.h5\n",
      "  1878320  2026-02-23 06:54   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00052_shp0p824_critic.weights.h5\n",
      "  1881904  2026-02-23 04:15   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00007_shp0p820_actor.weights.h5\n",
      "  1881904  2026-02-23 06:59   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00053_shp0p824_actor.weights.h5\n",
      "  1878320  2026-02-23 04:25   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00010_shp0p820_critic.weights.h5\n",
      "  1881904  2026-02-23 06:54   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00052_shp0p824_actor.weights.h5\n",
      "  1878320  2026-02-23 04:05   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p820_critic.weights.h5\n",
      "  1878320  2026-02-23 06:42   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00049_shp0p821_critic.weights.h5\n",
      "  1881904  2026-02-23 07:11   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00056_shp0p825_actor.weights.h5\n",
      "  1881904  2026-02-23 07:15   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00057_shp0p825_actor.weights.h5\n",
      "  1878320  2026-02-23 07:03   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00054_shp0p824_critic.weights.h5\n",
      "  1881904  2026-02-23 04:25   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00010_shp0p820_actor.weights.h5\n",
      "  1878320  2026-02-23 06:50   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00051_shp0p822_critic.weights.h5\n",
      "  1881904  2026-02-23 03:58   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp0p819_actor.weights.h5\n",
      "  1881904  2026-02-23 07:28   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p280_actor.weights.h5\n",
      "  1881904  2026-02-23 04:28   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp0p820_actor.weights.h5\n",
      "  1878320  2026-02-23 04:15   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00007_shp0p820_critic.weights.h5\n",
      "  1878320  2026-02-23 07:28   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p280_critic.weights.h5\n",
      "  1878320  2026-02-23 03:58   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp0p819_critic.weights.h5\n",
      "  1878320  2026-02-23 07:07   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00055_shp0p824_critic.weights.h5\n",
      "  1881904  2026-02-23 06:50   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00051_shp0p822_actor.weights.h5\n",
      "  1881904  2026-02-23 03:54   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p819_actor.weights.h5\n",
      "        0  2026-02-23 07:28   tcn_fusion_results/logs/\n",
      "/content/eval_restore/tcn_fusion_results logs: True actors: 17\n",
      "/content/eval_restore/tcn_fusion_results_run4/tcn_fusion_results logs: False actors: 0\n",
      "/content/eval_restore/tcn_fusion_results_run4 logs: False actors: 0\n",
      "âœ… EVAL_RESULTS_ROOT = /content/eval_restore/tcn_fusion_results\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "EVAL_ZIP_PATH = Path(\"/content/drive/MyDrive/tcn_fusion_results_run4.zip\")\n",
    "\n",
    "# 1) Verify zip exists\n",
    "print(\"zip exists:\", EVAL_ZIP_PATH.exists())\n",
    "if not EVAL_ZIP_PATH.exists():\n",
    "    raise FileNotFoundError(EVAL_ZIP_PATH)\n",
    "\n",
    "# 2) Inspect zip top-level structure\n",
    "!unzip -l \"{EVAL_ZIP_PATH}\" | head -n 40\n",
    "\n",
    "# 3) Extract to /content (clean target)\n",
    "!mkdir -p /content/eval_restore\n",
    "!unzip -q -o \"{EVAL_ZIP_PATH}\" -d /content/eval_restore\n",
    "\n",
    "# 4) Auto-detect correct results root\n",
    "candidates = [\n",
    "    Path(\"/content/eval_restore/tcn_fusion_results\"),\n",
    "    Path(\"/content/eval_restore/tcn_fusion_results_run4/tcn_fusion_results\"),\n",
    "    Path(\"/content/eval_restore/tcn_fusion_results_run4\"),\n",
    "]\n",
    "for c in candidates:\n",
    "    print(c, \"logs:\", (c / \"logs\").exists(), \"actors:\", len(list(c.rglob(\"*_actor.weights.h5\"))))\n",
    "\n",
    "EVAL_RESULTS_ROOT = next(\n",
    "    c for c in candidates\n",
    "    if (c / \"logs\").exists() and len(list(c.rglob(\"*_actor.weights.h5\"))) > 0\n",
    ")\n",
    "print(\"âœ… EVAL_RESULTS_ROOT =\", EVAL_RESULTS_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a0432ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python: /usr/bin/python3\n",
      "âœ… Requirements installed\n"
     ]
    }
   ],
   "source": [
    "# Install project requirements in Colab VM\n",
    "import subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
    "REQ_FILE = REPO_DIR / \"requirements.txt\"\n",
    "\n",
    "if not REQ_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Missing requirements file: {REQ_FILE}\")\n",
    "\n",
    "print(\"Using python:\", sys.executable)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"], check=True)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REQ_FILE)], check=True)\n",
    "\n",
    "print(\"âœ… Requirements installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d78dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DTypePolicy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.mixed_precision.set_global_policy(\"float32\")\n",
    "print(tf.keras.mixed_precision.global_policy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import re\n",
    "from dataclasses import replace\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import get_active_config\n",
    "from src.data_utils import DataProcessor\n",
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    prepare_phase1_dataset,\n",
    "    create_experiment6_result_stub,\n",
    "    evaluate_experiment6_checkpoint,\n",
    "    load_training_metadata_into_config,\n",
    "    build_evaluation_track_summary,\n",
    "    build_ablation_table,\n",
    "    compare_agent_vs_baseline,\n",
    "    Phase1Dataset,\n",
    "    split_dataset_by_date,\n",
    "    identify_covariance_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Evaluation run settings\n",
    "Adjust once here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_RANDOM_SEED = 42\n",
    "EVAL_RESULTS_ROOT = Path(\"/content/eval_restore/tcn_fusion_results\")\n",
    "\n",
    "# Deterministic policy mode: 'mean' is recommended for stable ranking.\n",
    "EVAL_DETERMINISTIC_MODE = 'mean'\n",
    "EVAL_STOCHASTIC_MODE = \"sample\"\n",
    "\n",
    "# Stochastic robustness checks per checkpoint.\n",
    "EVAL_NUM_STOCHASTIC_RUNS = 10\n",
    "EVAL_STOCHASTIC_EPISODE_LIMIT = 756\n",
    "\n",
    "# Selection for ablation basket\n",
    "EVAL_TOP_HW = 8         # high-watermark checkpoints by filename Sharpe tag\n",
    "EVAL_TOP_PERIODIC = 4   # periodic step checkpoints by most recent step\n",
    "EVAL_INCLUDE_ROOT = True\n",
    "EVAL_INCLUDE_RARE = False\n",
    "\n",
    "# Save outputs\n",
    "EVAL_SAVE_LOGS = True\n",
    "EVAL_SAVE_ARTIFACTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4b53d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print((EVAL_RESULTS_ROOT / \"logs\").exists())\n",
    "print(len(list(EVAL_RESULTS_ROOT.rglob(\"*_actor.weights.h5\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815ad1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root exists: True\n",
      "logs exists: True\n",
      "actor ckpts: 17\n"
     ]
    }
   ],
   "source": [
    "print(\"root exists:\", EVAL_RESULTS_ROOT.exists())\n",
    "print(\"logs exists:\", (EVAL_RESULTS_ROOT / \"logs\").exists())\n",
    "print(\"actor ckpts:\", len(list(EVAL_RESULTS_ROOT.rglob(\"*_actor.weights.h5\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Build evaluation dataset and load latest metadata config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c774d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_phase1_data\" in globals():\n",
    "    del eval_phase1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.data_utils:âš ï¸ Allowlist columns missing from runtime feature pool (25): ['Regime_Volatility_Ratio', 'Regime_Price_vs_SMA_Short', 'Regime_SMA_Short_Slope', 'Regime_SMA_Long_Slope', 'Regime_Momentum_Short', 'Regime_Momentum_Long', 'Regime_Corr_to_Market', 'Regime_Breadth_Positive', 'CrossSectional_ZScore_LogReturn_1d', 'Residual_Momentum_21', 'Volume_Percentile_63', 'ShortTerm_Reversal_5', 'VolOfVol_63', 'Beta_to_Market', 'OBV_Delta_Norm_21', 'YieldCurve_Spread', 'YieldCurve_Inverted_Flag', 'Fundamental_FCFE_Delta', 'Fundamental_Revenue_Delta', 'Fundamental_NCFO_Delta']\n",
      "WARNING:src.data_utils:âš ï¸ Feature-audit expected count mismatch: expected=53 got=28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Using metadata: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260223_035133_metadata.json\n",
      "âœ… Applied training metadata to config\n",
      "   Metadata: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260223_035133_metadata.json\n",
      "   Run timestamp: 20260223_035133\n",
      "   Architecture: TCN_FUSION\n",
      "   Turnover target: 0.35\n",
      "   DSR scalar: 2.0\n",
      "   PPO update timesteps: scheduled\n",
      "   Episode length curriculum: True\n",
      "   RA-KL enabled: True\n",
      "   Profile override loaded: True\n",
      "   Credit assignment mode: step_reward_plus_terminal_bonus\n",
      "   Retroactive episode scaling: False\n",
      "   Actuarial columns detected: 4\n",
      "   configured audit allowlist: 53\n",
      "   overlap(trained vs allowlist): 53\n",
      "âœ… Eval metadata feature lock applied\n",
      "   trained active_feature_columns: 53\n",
      "   trained actuarial columns: 4 ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "   core feature_columns (+runtime groups): 53\n",
      "   disabled_features: 69\n",
      "   expected active after lock: -16\n",
      "   state_layout asset/global dims: 32 21\n",
      "ðŸ“¦ Loading normalized master from: /content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\n",
      "================================================================================\n",
      "âœ‚ï¸  TIME-BASED TRAIN/TEST SPLIT (80/20 split)\n",
      "   Train: 2003-10-01 â†’ 2021-04-09 (4411 days, 17.5 years, 43867 rows)\n",
      "   Test:  2021-04-12 â†’ 2025-08-29 (1103 days, 4.4 years, 11030 rows)\n",
      "================================================================================\n",
      "âœ… Built eval_phase1_data from saved normalized master\n",
      "   Train shape: (43867, 109)\n",
      "   Test shape: (11030, 109)\n",
      "   Covariance cols: 3\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVAL CONFIG + FEATURE LOCK (metadata-trained layout) + DATASET BUILD\n",
    "# ============================================================================\n",
    "\n",
    "from src.config import get_active_config\n",
    "from src.data_utils import DataProcessor\n",
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    load_training_metadata_into_config,\n",
    "    Phase1Dataset,\n",
    "    prepare_phase1_dataset,\n",
    "    split_dataset_by_date,\n",
    "    identify_covariance_columns,\n",
    ")\n",
    "\n",
    "if not EVAL_RESULTS_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Missing results root: {EVAL_RESULTS_ROOT}\")\n",
    "\n",
    "\n",
    "def eval_extract_trained_state_layout(metadata_dict: dict):\n",
    "    arch = metadata_dict.get(\"Architecture_Settings\", {}) or {}\n",
    "\n",
    "    # Try effective first, then template\n",
    "    effective = arch.get(\"agent_params_effective\", {}) or {}\n",
    "    template = arch.get(\"agent_params_template\", {}) or {}\n",
    "\n",
    "    layout = effective.get(\"state_layout\")\n",
    "    if not isinstance(layout, dict) or not layout:\n",
    "        layout = template.get(\"state_layout\")\n",
    "\n",
    "    if not isinstance(layout, dict) or not layout:\n",
    "        raise ValueError(\"Could not find state_layout in metadata (agent_params_effective/template).\")\n",
    "\n",
    "    active_cols = layout.get(\"active_feature_columns\")\n",
    "    if not isinstance(active_cols, list) or not active_cols:\n",
    "        raise ValueError(\"state_layout.active_feature_columns missing/empty in metadata.\")\n",
    "\n",
    "    return layout, list(dict.fromkeys(active_cols))\n",
    "\n",
    "\n",
    "def eval_apply_metadata_feature_lock(cfg, trained_active_feature_columns):\n",
    "    \"\"\"\n",
    "    Lock feature selection to the trained layout while preserving project-level drops.\n",
    "\n",
    "    Important: include trained-only runtime groups (e.g., Actuarial_*) in the\n",
    "    candidate universe so counts and lock math stay aligned with training.\n",
    "    \"\"\"\n",
    "    probe_cfg = copy.deepcopy(cfg)\n",
    "    probe_fp = probe_cfg.setdefault(\"feature_params\", {})\n",
    "    probe_fs = probe_fp.setdefault(\"feature_selection\", {})\n",
    "    probe_fs[\"disable_features\"] = False\n",
    "    probe_fs[\"disabled_features\"] = []\n",
    "\n",
    "    probe = DataProcessor(probe_cfg)\n",
    "    core_all_cols = list(dict.fromkeys(probe.get_feature_columns(\"phase1\")))\n",
    "\n",
    "    # Ensure runtime-only trained columns are represented in lock universe.\n",
    "    for col in trained_active_feature_columns:\n",
    "        if col not in core_all_cols:\n",
    "            core_all_cols.append(col)\n",
    "\n",
    "    trained_set = set(trained_active_feature_columns)\n",
    "    from_core_gap = {c for c in core_all_cols if c not in trained_set}\n",
    "\n",
    "    # Preserve preconfigured drops (audit + curated disables).\n",
    "    existing_disabled = set(\n",
    "        cfg.get(\"feature_params\", {})\n",
    "        .get(\"feature_selection\", {})\n",
    "        .get(\"disabled_features\", [])\n",
    "    )\n",
    "    disabled = sorted(existing_disabled.union(from_core_gap))\n",
    "\n",
    "    fp = cfg.setdefault(\"feature_params\", {})\n",
    "    fs = fp.setdefault(\"feature_selection\", {})\n",
    "    fs[\"disable_features\"] = True\n",
    "    fs[\"disabled_features\"] = disabled\n",
    "\n",
    "    return core_all_cols, disabled\n",
    "\n",
    "\n",
    "def eval_bind_trained_feature_layout(processor, trained_active_feature_columns):\n",
    "    \"\"\"\n",
    "    Force eval-time feature list to match the exact trained state layout.\n",
    "    This prevents runtime-family omissions (e.g., actuarial) when loading\n",
    "    from a pre-normalized CSV without re-running full feature engineering.\n",
    "    \"\"\"\n",
    "    trained_cols = list(dict.fromkeys(trained_active_feature_columns))\n",
    "    base_get_feature_columns = processor.get_feature_columns\n",
    "\n",
    "    def _locked_get_feature_columns(phase='phase1'):\n",
    "        if str(phase).lower() == 'phase1':\n",
    "            return list(trained_cols)\n",
    "        return base_get_feature_columns(phase)\n",
    "\n",
    "    processor.get_feature_columns = _locked_get_feature_columns\n",
    "    return processor\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Build eval config from latest metadata\n",
    "# ------------------------------------------------------------------\n",
    "eval_config = copy.deepcopy(get_active_config(\"phase1\"))\n",
    "\n",
    "eval_logs_dir = EVAL_RESULTS_ROOT / \"logs\"\n",
    "meta_files = sorted(eval_logs_dir.glob(\"*_metadata.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not meta_files:\n",
    "    raise FileNotFoundError(f\"No metadata JSON in {eval_logs_dir}\")\n",
    "\n",
    "EVAL_METADATA_PATH = meta_files[0]\n",
    "print(\"ðŸ“„ Using metadata:\", EVAL_METADATA_PATH)\n",
    "\n",
    "with open(EVAL_METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_metadata = json.load(f)\n",
    "\n",
    "eval_config = load_training_metadata_into_config(\n",
    "    EVAL_METADATA_PATH,\n",
    "    copy.deepcopy(eval_config),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Enforce architecture family used by checkpoints\n",
    "eval_config[\"agent_params\"][\"actor_critic_type\"] = \"TCN_FUSION\"\n",
    "eval_config[\"agent_params\"][\"use_fusion\"] = True\n",
    "eval_config[\"agent_params\"][\"use_attention\"] = False\n",
    "\n",
    "# A2/A3/A4 compatibility defaults (legacy runs remain loadable)\n",
    "eval_config[\"agent_params\"].setdefault(\"fusion_cross_asset_mixer_enabled\", False)\n",
    "eval_config[\"agent_params\"].setdefault(\"fusion_cross_asset_mixer_layers\", 1)\n",
    "eval_config[\"agent_params\"].setdefault(\"fusion_cross_asset_mixer_expansion\", 2.0)\n",
    "eval_config[\"agent_params\"].setdefault(\"fusion_cross_asset_mixer_dropout\", 0.1)\n",
    "eval_config[\"agent_params\"].setdefault(\"fusion_alpha_head_hidden_dims\", [])\n",
    "eval_config[\"agent_params\"].setdefault(\"fusion_alpha_head_dropout\", 0.1)\n",
    "\n",
    "print(\"   Fusion mixer cfg:\", {k: eval_config[\"agent_params\"][k] for k in [\n",
    "    \"fusion_cross_asset_mixer_enabled\",\n",
    "    \"fusion_cross_asset_mixer_layers\",\n",
    "    \"fusion_cross_asset_mixer_expansion\",\n",
    "    \"fusion_cross_asset_mixer_dropout\",\n",
    "]})\n",
    "print(\"   Fusion alpha head cfg:\", eval_config[\"agent_params\"][\"fusion_alpha_head_hidden_dims\"],\n",
    "      \"| dropout:\", eval_config[\"agent_params\"][\"fusion_alpha_head_dropout\"])\n",
    "\n",
    "# Extract trained state layout and lock features to it\n",
    "trained_state_layout, trained_active_feature_columns = eval_extract_trained_state_layout(eval_metadata)\n",
    "\n",
    "# Keep layout in config for agent reconstruction compatibility\n",
    "eval_config[\"agent_params\"][\"state_layout\"] = copy.deepcopy(trained_state_layout)\n",
    "eval_config[\"agent_params\"][\"asset_feature_dim\"] = int(trained_state_layout.get(\"asset_feature_dim\", 0) or 0)\n",
    "eval_config[\"agent_params\"][\"global_feature_dim\"] = int(trained_state_layout.get(\"global_feature_dim\", 0) or 0)\n",
    "eval_config[\"agent_params\"][\"num_assets\"] = int(trained_state_layout.get(\"num_assets\", 10) or 10)\n",
    "\n",
    "core_all_cols, eval_disabled_features = eval_apply_metadata_feature_lock(\n",
    "    eval_config, trained_active_feature_columns\n",
    ")\n",
    "\n",
    "act_trained = [c for c in trained_active_feature_columns if c.startswith(\"Actuarial_\")]\n",
    "configured_allowlist = list(dict.fromkeys(\n",
    "    eval_config.get(\"feature_params\", {}).get(\"feature_selection\", {}).get(\"active_features_allowlist\", []) or []\n",
    "))\n",
    "if configured_allowlist:\n",
    "    overlap = len(set(trained_active_feature_columns) & set(configured_allowlist))\n",
    "    print(\"   configured audit allowlist:\", len(configured_allowlist))\n",
    "    print(\"   overlap(trained vs allowlist):\", overlap)\n",
    "    if overlap != len(trained_active_feature_columns):\n",
    "        print(\"   âš ï¸ Metadata-trained layout differs from configured allowlist (expected for legacy runs).\")\n",
    "print(\"âœ… Eval metadata feature lock applied\")\n",
    "print(\"   trained active_feature_columns:\", len(trained_active_feature_columns))\n",
    "print(\"   trained actuarial columns:\", len(act_trained), act_trained)\n",
    "print(\"   core feature_columns (+runtime groups):\", len(core_all_cols))\n",
    "print(\"   disabled_features:\", len(eval_disabled_features))\n",
    "print(\"   expected active after lock:\", len(core_all_cols) - len(eval_disabled_features))\n",
    "print(\"   state_layout asset/global dims:\",\n",
    "      trained_state_layout.get(\"asset_feature_dim\"),\n",
    "      trained_state_layout.get(\"global_feature_dim\"))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Build eval dataset from SAVED normalized master features (no rebuild)\n",
    "# ------------------------------------------------------------------\n",
    "EVAL_USE_SAVED_NORMALIZED = True\n",
    "EVAL_FORCE_REBUILD_PHASE1 = True  # IMPORTANT: avoid stale globals from prior runs\n",
    "\n",
    "if EVAL_FORCE_REBUILD_PHASE1 and \"eval_phase1_data\" in globals():\n",
    "    del eval_phase1_data\n",
    "    print(\"ðŸ§¹ Cleared stale eval_phase1_data from runtime\")\n",
    "\n",
    "if \"eval_phase1_data\" in globals():\n",
    "    print(\"â„¹ï¸ Reusing eval_phase1_data from current runtime\")\n",
    "else:\n",
    "    if not EVAL_USE_SAVED_NORMALIZED:\n",
    "        eval_phase1_data = prepare_phase1_dataset(eval_config, force_download=False)\n",
    "        eval_phase1_data.data_processor = eval_bind_trained_feature_layout(\n",
    "            eval_phase1_data.data_processor,\n",
    "            trained_active_feature_columns,\n",
    "        )\n",
    "    else:\n",
    "        normalized_candidates = [\n",
    "            EVAL_RESULTS_ROOT / \"data\" / \"master_features_NORMALIZED.csv\",\n",
    "            Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results_run4/data/master_features_NORMALIZED.csv\"),\n",
    "            Path(eval_config.get(\"BASE_DATA_PATH\", \"/content/adaptive_portfolio_rl/data\")) / \"master_features_NORMALIZED.csv\",\n",
    "            Path(\"/content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\"),\n",
    "        ]\n",
    "        normalized_path = next((p for p in normalized_candidates if p.exists()), None)\n",
    "        if normalized_path is None:\n",
    "            raise FileNotFoundError(\n",
    "                \"Could not find master_features_NORMALIZED.csv in expected locations:\\n\"\n",
    "                + \"\\n\".join(str(p) for p in normalized_candidates)\n",
    "            )\n",
    "\n",
    "        print(\"ðŸ“¦ Loading normalized master from:\", normalized_path)\n",
    "        master_df_norm = pd.read_csv(normalized_path)\n",
    "\n",
    "        if \"Date\" not in master_df_norm.columns:\n",
    "            raise ValueError(\"Normalized CSV missing required 'Date' column\")\n",
    "        if \"Ticker\" not in master_df_norm.columns:\n",
    "            raise ValueError(\"Normalized CSV missing required 'Ticker' column\")\n",
    "\n",
    "        master_df_norm[\"Date\"] = pd.to_datetime(\n",
    "            master_df_norm[\"Date\"], utc=True, errors=\"coerce\"\n",
    "        ).dt.tz_localize(None)\n",
    "        master_df_norm = master_df_norm.dropna(subset=[\"Date\"]).sort_values([\"Date\", \"Ticker\"]).reset_index(drop=True)\n",
    "\n",
    "        analysis_start = pd.to_datetime(eval_config.get(\"ANALYSIS_START_DATE\", \"2003-09-02\"))\n",
    "        analysis_end = pd.to_datetime(eval_config.get(\"ANALYSIS_END_DATE\", \"2025-09-01\"))\n",
    "        master_df_norm = master_df_norm[\n",
    "            (master_df_norm[\"Date\"] >= analysis_start) &\n",
    "            (master_df_norm[\"Date\"] <= analysis_end)\n",
    "        ].copy()\n",
    "\n",
    "        missing_trained = [c for c in trained_active_feature_columns if c not in master_df_norm.columns]\n",
    "        if missing_trained:\n",
    "            raise ValueError(\n",
    "                f\"Saved normalized CSV missing {len(missing_trained)} trained active columns. \"\n",
    "                f\"Sample: {missing_trained[:10]}\"\n",
    "            )\n",
    "\n",
    "        eval_processor = DataProcessor(eval_config)\n",
    "        eval_processor = eval_bind_trained_feature_layout(eval_processor, trained_active_feature_columns)\n",
    "\n",
    "        split_date = eval_config.get(\"TRAIN_TEST_SPLIT_DATE\")\n",
    "        if split_date:\n",
    "            train_df, test_df, train_end_date, test_start_date = split_dataset_by_date(\n",
    "                master_df_norm, date_column=\"Date\", split_date=split_date\n",
    "            )\n",
    "        else:\n",
    "            train_df, test_df, train_end_date, test_start_date = split_dataset_by_date(\n",
    "                master_df_norm, date_column=\"Date\", train_fraction=0.8\n",
    "            )\n",
    "\n",
    "        eval_phase1_data = Phase1Dataset(\n",
    "            master_df=master_df_norm,\n",
    "            train_df=train_df,\n",
    "            test_df=test_df,\n",
    "            scalers={},\n",
    "            train_end_date=train_end_date,\n",
    "            test_start_date=test_start_date,\n",
    "            covariance_columns=identify_covariance_columns(master_df_norm.columns),\n",
    "            data_processor=eval_processor,\n",
    "        )\n",
    "\n",
    "        print(\"âœ… Built eval_phase1_data from saved normalized master\")\n",
    "        print(\"   Train shape:\", eval_phase1_data.train_df.shape)\n",
    "        print(\"   Test shape:\", eval_phase1_data.test_df.shape)\n",
    "        print(\"   Covariance cols:\", len(eval_phase1_data.covariance_columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40c64cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43867, 109) (11030, 109)\n",
      "Date min/max test: 2021-04-12 00:00:00 2025-08-29 00:00:00\n",
      "Eval phase1 feature count: 53\n",
      "Eval actuarial features: 4 ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n"
     ]
    }
   ],
   "source": [
    "print(eval_phase1_data.train_df.shape, eval_phase1_data.test_df.shape)\n",
    "print(\"Date min/max test:\", eval_phase1_data.test_df[\"Date\"].min(), eval_phase1_data.test_df[\"Date\"].max())\n",
    "\n",
    "_eval_used = list(dict.fromkeys(eval_phase1_data.data_processor.get_feature_columns(\"phase1\")))\n",
    "_eval_act = [c for c in _eval_used if c.startswith(\"Actuarial_\")]\n",
    "print(\"Eval phase1 feature count:\", len(_eval_used))\n",
    "print(\"Eval actuarial features:\", len(_eval_act), _eval_act)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Inspect latest training CSV logs (for diagnostics context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260223_035133_episodes.csv\n",
      "step diagnostics: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260223_035133_step_diagnostics.csv\n",
      "summary: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260223_035133_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bbfc4783-9a90-40e9-9579-e9f8d0592a1a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>update</th>\n",
       "      <th>timestep</th>\n",
       "      <th>episode</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>episode_return_pct</th>\n",
       "      <th>episode_sharpe</th>\n",
       "      <th>episode_sortino</th>\n",
       "      <th>episode_max_dd</th>\n",
       "      <th>episode_volatility</th>\n",
       "      <th>episode_win_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>actor_grad_norm</th>\n",
       "      <th>critic_grad_norm</th>\n",
       "      <th>alpha_min</th>\n",
       "      <th>alpha_max</th>\n",
       "      <th>alpha_mean</th>\n",
       "      <th>ratio_mean</th>\n",
       "      <th>ratio_std</th>\n",
       "      <th>drawdown_lambda_peak</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>termination_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>13440</td>\n",
       "      <td>47</td>\n",
       "      <td>9803.141590</td>\n",
       "      <td>27.957519</td>\n",
       "      <td>1.096592</td>\n",
       "      <td>1.603439</td>\n",
       "      <td>7.024921</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>55.069583</td>\n",
       "      <td>...</td>\n",
       "      <td>1.944204</td>\n",
       "      <td>2.408474</td>\n",
       "      <td>1.172852</td>\n",
       "      <td>2.873698</td>\n",
       "      <td>1.921875</td>\n",
       "      <td>1.000203</td>\n",
       "      <td>0.156306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>15360</td>\n",
       "      <td>51</td>\n",
       "      <td>10768.436391</td>\n",
       "      <td>32.318040</td>\n",
       "      <td>1.065081</td>\n",
       "      <td>1.484673</td>\n",
       "      <td>10.131881</td>\n",
       "      <td>0.119907</td>\n",
       "      <td>51.292247</td>\n",
       "      <td>...</td>\n",
       "      <td>2.808472</td>\n",
       "      <td>3.468325</td>\n",
       "      <td>1.196289</td>\n",
       "      <td>2.725260</td>\n",
       "      <td>1.910807</td>\n",
       "      <td>1.001841</td>\n",
       "      <td>0.151260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>17280</td>\n",
       "      <td>54</td>\n",
       "      <td>11572.609205</td>\n",
       "      <td>31.595754</td>\n",
       "      <td>1.040988</td>\n",
       "      <td>1.313027</td>\n",
       "      <td>12.562912</td>\n",
       "      <td>0.120075</td>\n",
       "      <td>54.274354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.409888</td>\n",
       "      <td>2.124740</td>\n",
       "      <td>1.345215</td>\n",
       "      <td>3.104492</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>1.001803</td>\n",
       "      <td>0.406095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>19200</td>\n",
       "      <td>58</td>\n",
       "      <td>12542.397630</td>\n",
       "      <td>42.403897</td>\n",
       "      <td>1.577045</td>\n",
       "      <td>2.496833</td>\n",
       "      <td>4.884333</td>\n",
       "      <td>0.103146</td>\n",
       "      <td>57.256461</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>2.976378</td>\n",
       "      <td>1.274414</td>\n",
       "      <td>2.796875</td>\n",
       "      <td>1.984863</td>\n",
       "      <td>1.003672</td>\n",
       "      <td>0.184058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53</td>\n",
       "      <td>20000</td>\n",
       "      <td>60</td>\n",
       "      <td>13012.389113</td>\n",
       "      <td>33.635945</td>\n",
       "      <td>1.280029</td>\n",
       "      <td>1.558131</td>\n",
       "      <td>10.789747</td>\n",
       "      <td>0.102126</td>\n",
       "      <td>55.467197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359510</td>\n",
       "      <td>3.147861</td>\n",
       "      <td>1.360352</td>\n",
       "      <td>2.587891</td>\n",
       "      <td>1.994141</td>\n",
       "      <td>0.995335</td>\n",
       "      <td>0.143635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbfc4783-9a90-40e9-9579-e9f8d0592a1a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bbfc4783-9a90-40e9-9579-e9f8d0592a1a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bbfc4783-9a90-40e9-9579-e9f8d0592a1a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    update  timestep  episode  elapsed_time  episode_return_pct  \\\n",
       "6       35     13440       47   9803.141590           27.957519   \n",
       "7       40     15360       51  10768.436391           32.318040   \n",
       "8       45     17280       54  11572.609205           31.595754   \n",
       "9       50     19200       58  12542.397630           42.403897   \n",
       "10      53     20000       60  13012.389113           33.635945   \n",
       "\n",
       "    episode_sharpe  episode_sortino  episode_max_dd  episode_volatility  \\\n",
       "6         1.096592         1.603439        7.024921            0.099068   \n",
       "7         1.065081         1.484673       10.131881            0.119907   \n",
       "8         1.040988         1.313027       12.562912            0.120075   \n",
       "9         1.577045         2.496833        4.884333            0.103146   \n",
       "10        1.280029         1.558131       10.789747            0.102126   \n",
       "\n",
       "    episode_win_rate  ...  actor_grad_norm  critic_grad_norm  alpha_min  \\\n",
       "6          55.069583  ...         1.944204          2.408474   1.172852   \n",
       "7          51.292247  ...         2.808472          3.468325   1.196289   \n",
       "8          54.274354  ...         1.409888          2.124740   1.345215   \n",
       "9          57.256461  ...         1.428403          2.976378   1.274414   \n",
       "10         55.467197  ...         1.359510          3.147861   1.360352   \n",
       "\n",
       "    alpha_max  alpha_mean  ratio_mean  ratio_std drawdown_lambda_peak  \\\n",
       "6    2.873698    1.921875    1.000203   0.156306                  0.0   \n",
       "7    2.725260    1.910807    1.001841   0.151260                  0.0   \n",
       "8    3.104492    2.070312    1.001803   0.406095                  0.0   \n",
       "9    2.796875    1.984863    1.003672   0.184058                  0.0   \n",
       "10   2.587891    1.994141    0.995335   0.143635                  0.0   \n",
       "\n",
       "    episode_length  termination_reason  \n",
       "6            504.0       episode_limit  \n",
       "7            504.0       episode_limit  \n",
       "8            504.0       episode_limit  \n",
       "9            504.0       episode_limit  \n",
       "10           504.0       episode_limit  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not eval_logs_dir.exists():\n",
    "    raise FileNotFoundError(f\"Missing logs dir: {eval_logs_dir}\")\n",
    "\n",
    "def eval_latest_csv(pattern):\n",
    "    files = sorted(eval_logs_dir.glob(pattern), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    return files[0] if files else None\n",
    "\n",
    "eval_latest_episodes_csv = eval_latest_csv('*episodes*.csv')\n",
    "eval_latest_step_diag_csv = eval_latest_csv('*step_diagnostics*.csv')\n",
    "eval_latest_summary_csv = eval_latest_csv('*summary*.csv')\n",
    "\n",
    "print('episodes:', eval_latest_episodes_csv)\n",
    "print('step diagnostics:', eval_latest_step_diag_csv)\n",
    "print('summary:', eval_latest_summary_csv)\n",
    "\n",
    "if eval_latest_episodes_csv:\n",
    "    eval_episodes_df = pd.read_csv(eval_latest_episodes_csv)\n",
    "    display(eval_episodes_df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Checkpoint discovery and ablation basket construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checkpoint pairs: 17\n",
      "By kind: {'high_watermark': 17}\n",
      "Selected for ablation: 8\n",
      "Forced requested: [90, 102, 106, 118, 134, 144, 162, 166]\n",
      "Forced found: []\n",
      "Forced missing: [90, 102, 106, 118, 134, 144, 162, 166]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-791d572c-0527-41b2-a39c-b7b39448b9cf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_kind</th>\n",
       "      <th>episode</th>\n",
       "      <th>step</th>\n",
       "      <th>sharpe_tag</th>\n",
       "      <th>actor_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>51</td>\n",
       "      <td>None</td>\n",
       "      <td>0.822</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>52</td>\n",
       "      <td>None</td>\n",
       "      <td>0.824</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>0.824</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>54</td>\n",
       "      <td>None</td>\n",
       "      <td>0.824</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>55</td>\n",
       "      <td>None</td>\n",
       "      <td>0.824</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.825</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>57</td>\n",
       "      <td>None</td>\n",
       "      <td>0.825</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>1.280</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-791d572c-0527-41b2-a39c-b7b39448b9cf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-791d572c-0527-41b2-a39c-b7b39448b9cf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-791d572c-0527-41b2-a39c-b7b39448b9cf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  checkpoint_kind  episode  step  sharpe_tag  \\\n",
       "0  high_watermark       51  None       0.822   \n",
       "1  high_watermark       52  None       0.824   \n",
       "2  high_watermark       53  None       0.824   \n",
       "3  high_watermark       54  None       0.824   \n",
       "4  high_watermark       55  None       0.824   \n",
       "5  high_watermark       56  None       0.825   \n",
       "6  high_watermark       57  None       0.825   \n",
       "7  high_watermark       60  None       1.280   \n",
       "\n",
       "                                          actor_path  \n",
       "0  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "1  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "2  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "3  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "4  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "5  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "6  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "7  /content/eval_restore/tcn_fusion_results/high_...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CHECKPOINT DISCOVERY + ABLATION BASKET (with forced episode includes)\n",
    "# ============================================================================\n",
    "\n",
    "#import re\n",
    "#from pathlib import Path\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# Config knobs\n",
    "# -----------------------\n",
    "EVAL_TOP_ROOT = globals().get(\"EVAL_TOP_ROOT\", 2)\n",
    "EVAL_TOP_HW = globals().get(\"EVAL_TOP_HW\", 8)\n",
    "EVAL_TOP_PERIODIC = globals().get(\"EVAL_TOP_PERIODIC\", 4)\n",
    "EVAL_TOP_RARE = globals().get(\"EVAL_TOP_RARE\", 3)\n",
    "\n",
    "EVAL_INCLUDE_ROOT = globals().get(\"EVAL_INCLUDE_ROOT\", True)\n",
    "EVAL_INCLUDE_RARE = globals().get(\"EVAL_INCLUDE_RARE\", False)\n",
    "\n",
    "# Force-include these episodes even if they are not in top-sharpe basket\n",
    "# Hard-set forced episodes for this run\n",
    "EVAL_FORCE_EPISODES = [90, 102, 106, 118, 134, 144, 162, 166]\n",
    "EVAL_FORCE_EPISODES = sorted({int(x) for x in EVAL_FORCE_EPISODES})\n",
    "\n",
    "if \"EVAL_RESULTS_ROOT\" not in globals():\n",
    "    raise NameError(\"EVAL_RESULTS_ROOT is not defined\")\n",
    "\n",
    "EVAL_RESULTS_ROOT = Path(EVAL_RESULTS_ROOT)\n",
    "if not EVAL_RESULTS_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Missing results root: {EVAL_RESULTS_ROOT}\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Parse helpers\n",
    "# -----------------------\n",
    "def _ckpt_name(x) -> str:\n",
    "    return x.name if isinstance(x, Path) else str(x)\n",
    "\n",
    "\n",
    "def eval_parse_sharpe_from_name(x):\n",
    "    # Supports: ..._shp1p234... and ..._shm0p456...\n",
    "    name = _ckpt_name(x)\n",
    "    m = re.search(r\"_sh([pm])(\\d+)p(\\d+)\", name)\n",
    "    if not m:\n",
    "        return None\n",
    "    sign = 1.0 if m.group(1) == \"p\" else -1.0\n",
    "    return sign * float(f\"{m.group(2)}.{m.group(3)}\")\n",
    "\n",
    "\n",
    "def eval_parse_episode(x):\n",
    "    name = _ckpt_name(x)\n",
    "    m = re.search(r\"_ep(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "def eval_parse_step(x):\n",
    "    name = _ckpt_name(x)\n",
    "    m = re.search(r\"_step(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Discovery\n",
    "# -----------------------\n",
    "def eval_discover_actor_files(results_root: Path) -> pd.DataFrame:\n",
    "    actors = sorted(results_root.rglob(\"*_actor.weights.h5\"))\n",
    "    rows = []\n",
    "\n",
    "    for actor in actors:\n",
    "        prefix = str(actor).replace(\"_actor.weights.h5\", \"\")\n",
    "        critic = Path(prefix + \"_critic.weights.h5\")\n",
    "        if not critic.exists():\n",
    "            continue\n",
    "\n",
    "        parent_name = actor.parent.name\n",
    "        if parent_name == \"high_watermark_checkpoints\":\n",
    "            kind = \"high_watermark\"\n",
    "        elif parent_name == \"step_sharpe_checkpoints\":\n",
    "            kind = \"step_sharpe\"\n",
    "        elif parent_name == \"rare_models\":\n",
    "            kind = \"rare\"\n",
    "        elif eval_parse_step(actor) is not None:\n",
    "            kind = \"periodic_step\"\n",
    "        else:\n",
    "            kind = \"root\"\n",
    "\n",
    "        rows.append({\n",
    "            \"actor_path\": str(actor),\n",
    "            \"critic_path\": str(critic),\n",
    "            \"checkpoint_prefix\": prefix,\n",
    "            \"checkpoint_kind\": kind,\n",
    "            \"episode\": eval_parse_episode(actor),\n",
    "            \"step\": eval_parse_step(actor),\n",
    "            \"sharpe_tag\": eval_parse_sharpe_from_name(actor),\n",
    "            \"mtime\": actor.stat().st_mtime,\n",
    "        })\n",
    "\n",
    "    cols = [\n",
    "        \"actor_path\", \"critic_path\", \"checkpoint_prefix\",\n",
    "        \"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"mtime\"\n",
    "    ]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Basket selection\n",
    "# -----------------------\n",
    "def eval_select_ablation_basket(df_ckpt: pd.DataFrame) -> pd.DataFrame:\n",
    "    picks = []\n",
    "\n",
    "    if EVAL_INCLUDE_ROOT:\n",
    "        root_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"root\"].copy()\n",
    "        if not root_df.empty:\n",
    "            picks.append(root_df.sort_values(\"mtime\", ascending=False).head(EVAL_TOP_ROOT))\n",
    "\n",
    "    hw_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"high_watermark\"].copy()\n",
    "    if not hw_df.empty:\n",
    "        hw_df[\"sharpe_rank_key\"] = hw_df[\"sharpe_tag\"].fillna(-np.inf)\n",
    "        picks.append(\n",
    "            hw_df.sort_values(\n",
    "                [\"sharpe_rank_key\", \"episode\", \"mtime\"],\n",
    "                ascending=[False, False, False]\n",
    "            ).head(EVAL_TOP_HW)\n",
    "        )\n",
    "\n",
    "    periodic_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"periodic_step\"].copy()\n",
    "    if not periodic_df.empty:\n",
    "        picks.append(\n",
    "            periodic_df.sort_values([\"step\", \"mtime\"], ascending=[False, False]).head(EVAL_TOP_PERIODIC)\n",
    "        )\n",
    "\n",
    "    if EVAL_INCLUDE_RARE:\n",
    "        rare_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"rare\"].copy()\n",
    "        if not rare_df.empty:\n",
    "            rare_df[\"sharpe_rank_key\"] = rare_df[\"sharpe_tag\"].fillna(-np.inf)\n",
    "            picks.append(\n",
    "                rare_df.sort_values(\n",
    "                    [\"sharpe_rank_key\", \"episode\", \"mtime\"],\n",
    "                    ascending=[False, False, False]\n",
    "                ).head(EVAL_TOP_RARE)\n",
    "            )\n",
    "\n",
    "    out = pd.concat(picks, ignore_index=True) if picks else pd.DataFrame(columns=df_ckpt.columns)\n",
    "\n",
    "    # Force include specific episodes (prefer high_watermark/root)\n",
    "    if EVAL_FORCE_EPISODES:\n",
    "        forced = df_ckpt[\n",
    "            (df_ckpt[\"episode\"].isin(EVAL_FORCE_EPISODES)) &\n",
    "            (df_ckpt[\"checkpoint_kind\"].isin([\"high_watermark\", \"root\"]))\n",
    "        ].copy()\n",
    "        if not forced.empty:\n",
    "            out = pd.concat([out, forced], ignore_index=True)\n",
    "\n",
    "    out = out.drop_duplicates(subset=[\"checkpoint_prefix\"]).reset_index(drop=True)\n",
    "    out = out.sort_values(\n",
    "        [\"checkpoint_kind\", \"episode\", \"sharpe_tag\", \"step\", \"mtime\"],\n",
    "        ascending=[True, True, False, False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Run\n",
    "# -----------------------\n",
    "eval_ckpt_df = eval_discover_actor_files(EVAL_RESULTS_ROOT)\n",
    "if eval_ckpt_df.empty:\n",
    "    raise RuntimeError(f\"No valid actor+critic checkpoint pairs found under {EVAL_RESULTS_ROOT}\")\n",
    "\n",
    "print(\"All checkpoint pairs:\", len(eval_ckpt_df))\n",
    "print(\"By kind:\", eval_ckpt_df[\"checkpoint_kind\"].value_counts().to_dict())\n",
    "\n",
    "eval_ablation_ckpts = eval_select_ablation_basket(eval_ckpt_df)\n",
    "\n",
    "found_forced = sorted(\n",
    "    set(eval_ablation_ckpts[\"episode\"].dropna().astype(int).tolist()) & set(EVAL_FORCE_EPISODES)\n",
    ")\n",
    "missing_forced = sorted(set(EVAL_FORCE_EPISODES) - set(found_forced))\n",
    "\n",
    "print(\"Selected for ablation:\", len(eval_ablation_ckpts))\n",
    "print(\"Forced requested:\", EVAL_FORCE_EPISODES)\n",
    "print(\"Forced found:\", found_forced)\n",
    "print(\"Forced missing:\", missing_forced)\n",
    "\n",
    "display(\n",
    "    eval_ablation_ckpts[\n",
    "        [\"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"actor_path\"]\n",
    "    ].head(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Evaluate ablation basket (deterministic + stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    load_run_checkpoint_prefixes_from_metadata,\n",
    "    preflight_checkpoint_loadability,\n",
    ")\n",
    "\n",
    "run_prefixes = load_run_checkpoint_prefixes_from_metadata(\n",
    "    EVAL_METADATA_PATH,\n",
    "    results_root=EVAL_RESULTS_ROOT,\n",
    "    allowed_types={\"high_watermark\", \"deterministic_validation_high_watermark\", \"final_high_watermark_style\"},\n",
    "    require_both_files=True,\n",
    ")\n",
    "\n",
    "# Fallback for older metadata\n",
    "if not run_prefixes:\n",
    "    print(\"â„¹ï¸ No run-scoped checkpoint records in metadata; falling back to discovered checkpoints.\")\n",
    "    if \"eval_ckpt_df\" not in globals() or eval_ckpt_df is None or len(eval_ckpt_df) == 0:\n",
    "        eval_ckpt_df = eval_discover_actor_files(EVAL_RESULTS_ROOT)\n",
    "\n",
    "    fallback_df = eval_ckpt_df[eval_ckpt_df[\"checkpoint_kind\"].isin([\"high_watermark\", \"root\"])].copy()\n",
    "    run_prefixes = fallback_df[\"checkpoint_prefix\"].dropna().unique().tolist()\n",
    "\n",
    "print(\"run checkpoints:\", len(run_prefixes))\n",
    "\n",
    "preflight_df = preflight_checkpoint_loadability(\n",
    "    checkpoint_prefixes=run_prefixes,\n",
    "    phase1_data=eval_phase1_data,\n",
    "    config=eval_config,\n",
    "    random_seed=EVAL_RANDOM_SEED,\n",
    "    use_covariance=True,\n",
    "    architecture=eval_config[\"agent_params\"][\"actor_critic_type\"],\n",
    ")\n",
    "\n",
    "if preflight_df is None or preflight_df.empty:\n",
    "    print(\"âš ï¸ preflight returned empty; keeping current eval_ablation_ckpts\")\n",
    "else:\n",
    "    display(preflight_df.head())\n",
    "    if \"compatible\" in preflight_df.columns and \"checkpoint_prefix\" in preflight_df.columns:\n",
    "        compatible_prefixes = set(preflight_df.loc[preflight_df[\"compatible\"], \"checkpoint_prefix\"])\n",
    "        eval_ablation_ckpts = eval_ablation_ckpts[\n",
    "            eval_ablation_ckpts[\"checkpoint_prefix\"].isin(compatible_prefixes)\n",
    "        ].reset_index(drop=True)\n",
    "        print(\"compatible selected:\", len(eval_ablation_ckpts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    eval_ablation_ckpts[[\"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"checkpoint_prefix\"]]\n",
    "    .sort_values([\"episode\", \"step\"], na_position=\"last\")\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7695d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running evaluate loop\n",
    "eval_config[\"training_params\"][\"evaluation_action_execution_beta\"] = 0.25\n",
    "eval_config[\"training_params\"][\"evaluation_turnover_penalty_scalar\"] = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_run_one_checkpoint(eval_cfg, phase1_data, ckpt_prefix, seed=42):\n",
    "    stub = create_experiment6_result_stub(\n",
    "        random_seed=seed,\n",
    "        use_covariance=True,\n",
    "        architecture=eval_cfg[\"agent_params\"][\"actor_critic_type\"],\n",
    "        checkpoint_path=ckpt_prefix,\n",
    "        agent_config=copy.deepcopy(eval_cfg[\"agent_params\"]),  # important\n",
    "        base_agent_params=None,\n",
    "    )\n",
    "\n",
    "\n",
    "    return evaluate_experiment6_checkpoint(\n",
    "        experiment6=stub,\n",
    "        phase1_data=phase1_data,\n",
    "        config=eval_cfg,\n",
    "        random_seed=seed,\n",
    "        checkpoint_path_override=ckpt_prefix,\n",
    "        deterministic_eval_mode=EVAL_DETERMINISTIC_MODE,\n",
    "        num_eval_runs=EVAL_NUM_STOCHASTIC_RUNS,\n",
    "        stochastic_eval_mode = EVAL_STOCHASTIC_MODE,\n",
    "        stochastic_episode_length_limit=EVAL_STOCHASTIC_EPISODE_LIMIT,\n",
    "        save_eval_logs=EVAL_SAVE_LOGS,\n",
    "        save_eval_artifacts=EVAL_SAVE_ARTIFACTS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9593cd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: episode_list\n",
      "Selected checkpoints: 1 / 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0dc9d35f-d3ca-4acb-a96c-eb3eb0cb6007\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_kind</th>\n",
       "      <th>episode</th>\n",
       "      <th>step</th>\n",
       "      <th>sharpe_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>57</td>\n",
       "      <td>None</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dc9d35f-d3ca-4acb-a96c-eb3eb0cb6007')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0dc9d35f-d3ca-4acb-a96c-eb3eb0cb6007 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0dc9d35f-d3ca-4acb-a96c-eb3eb0cb6007');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  checkpoint_kind  episode  step  sharpe_tag\n",
       "0  high_watermark       57  None       0.825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/1] Evaluating: high_watermark__ep0057__step-00001\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00057_shp0p825\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00057_shp0p825_actor.weights.h5\n",
      "âœ… Found critic weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00057_shp0p825_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "   âœ… Weights loaded successfully\n",
      "   ðŸŽ¯ Deterministic eval policy modes: ['mean']\n",
      "   ðŸŽ¯ Stochastic eval policy mode:     sample\n",
      "\n",
      "================================================================================\n",
      "DETERMINISTIC EVALUATION (det_mean)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š DETERMINISTIC TEST RESULTS:\n",
      "   Eval Track: det_mean\n",
      "   Start Date: 2021-04-12\n",
      "   Market Regime: Post-Pandemic Rally (2021)\n",
      "   Episode Length: 1103 days (4.38 years)\n",
      "   Final Portfolio Value: $169,219.95\n",
      "   Total Return: +69.22%\n",
      "   Annualized Return: +12.77%\n",
      "   Sharpe Ratio: 0.8223 (annualized)\n",
      "   Sortino Ratio: 1.1998 (annualized)\n",
      "   Max Drawdown: 13.88%\n",
      "   Volatility (Ann.): 13.30%\n",
      "   Turnover: 0.26%\n",
      "   Win Rate: 53.27%\n",
      "   Diagnostics: action_uniques=1103, alpha<=1 frac=0.000, argmax_alpha_uniques=3\n",
      "\n",
      "================================================================================\n",
      "STOCHASTIC EVALUATIONS (Random Start = True, 10 Runs)\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ² Run 1/10 (Seed=142):\n",
      "   Start Date: 2021-05-19 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -18.52%\n",
      "   Annualized Return: -6.60%\n",
      "   Sharpe: -0.5408\n",
      "   Max DD: 24.77%\n",
      "   Turnover (episode): 65.81%\n",
      "   Turnover (step): mean=65.806% | p95=90.320% | max=121.341%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=99.5% | mean_excess=30.854%\n",
      "   Raw/Executed turnover: raw_mean=65.806% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 2/10 (Seed=143):\n",
      "   Start Date: 2021-04-21 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -18.24%\n",
      "   Annualized Return: -6.49%\n",
      "   Sharpe: -0.5567\n",
      "   Max DD: 28.18%\n",
      "   Turnover (episode): 66.05%\n",
      "   Turnover (step): mean=66.047% | p95=92.484% | max=111.944%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=99.2% | mean_excess=31.072%\n",
      "   Raw/Executed turnover: raw_mean=66.047% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 3/10 (Seed=144):\n",
      "   Start Date: 2021-05-11 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -20.38%\n",
      "   Annualized Return: -7.32%\n",
      "   Sharpe: -0.6261\n",
      "   Max DD: 27.74%\n",
      "   Turnover (episode): 66.46%\n",
      "   Turnover (step): mean=66.455% | p95=91.903% | max=110.774%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=98.4% | mean_excess=31.543%\n",
      "   Raw/Executed turnover: raw_mean=66.455% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 4/10 (Seed=145):\n",
      "   Start Date: 2021-04-15 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -6.52%\n",
      "   Annualized Return: -2.22%\n",
      "   Sharpe: -0.2211\n",
      "   Max DD: 21.78%\n",
      "   Turnover (episode): 66.33%\n",
      "   Turnover (step): mean=66.333% | p95=92.761% | max=116.589%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=97.9% | mean_excess=31.452%\n",
      "   Raw/Executed turnover: raw_mean=66.333% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 5/10 (Seed=146):\n",
      "   Start Date: 2021-05-17 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -2.90%\n",
      "   Annualized Return: -0.98%\n",
      "   Sharpe: -0.1326\n",
      "   Max DD: 19.58%\n",
      "   Turnover (episode): 66.86%\n",
      "   Turnover (step): mean=66.856% | p95=93.124% | max=124.916%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=98.1% | mean_excess=31.947%\n",
      "   Raw/Executed turnover: raw_mean=66.856% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 6/10 (Seed=147):\n",
      "   Start Date: 2021-05-11 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -5.69%\n",
      "   Annualized Return: -1.94%\n",
      "   Sharpe: -0.2117\n",
      "   Max DD: 19.52%\n",
      "   Turnover (episode): 66.20%\n",
      "   Turnover (step): mean=66.197% | p95=92.048% | max=114.855%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=98.1% | mean_excess=31.301%\n",
      "   Raw/Executed turnover: raw_mean=66.197% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 7/10 (Seed=148):\n",
      "   Start Date: 2021-04-22 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -12.30%\n",
      "   Annualized Return: -4.28%\n",
      "   Sharpe: -0.3886\n",
      "   Max DD: 27.39%\n",
      "   Turnover (episode): 65.25%\n",
      "   Turnover (step): mean=65.252% | p95=89.546% | max=130.665%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=98.4% | mean_excess=30.287%\n",
      "   Raw/Executed turnover: raw_mean=65.252% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 8/10 (Seed=149):\n",
      "   Start Date: 2021-05-24 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -6.60%\n",
      "   Annualized Return: -2.25%\n",
      "   Sharpe: -0.2409\n",
      "   Max DD: 21.43%\n",
      "   Turnover (episode): 66.83%\n",
      "   Turnover (step): mean=66.828% | p95=93.469% | max=122.128%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=98.7% | mean_excess=31.885%\n",
      "   Raw/Executed turnover: raw_mean=66.828% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 9/10 (Seed=150):\n",
      "   Start Date: 2021-05-12 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -21.77%\n",
      "   Annualized Return: -7.86%\n",
      "   Sharpe: -0.6808\n",
      "   Max DD: 26.54%\n",
      "   Turnover (episode): 66.92%\n",
      "   Turnover (step): mean=66.922% | p95=90.881% | max=112.067%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=99.1% | mean_excess=31.944%\n",
      "   Raw/Executed turnover: raw_mean=66.922% | executed/raw=1.000\n",
      "\n",
      "ðŸŽ² Run 10/10 (Seed=151):\n",
      "   Start Date: 2021-05-11 | Regime: Post-Pandemic Rally (2021)\n",
      "   Days Traded: 756 (3.00 years)\n",
      "   Total Return: -13.07%\n",
      "   Annualized Return: -4.56%\n",
      "   Sharpe: -0.4090\n",
      "   Max DD: 20.30%\n",
      "   Turnover (episode): 66.59%\n",
      "   Turnover (step): mean=66.587% | p95=91.725% | max=118.716%\n",
      "   Turnover vs target: target=35.000% | exceed_rate=99.1% | mean_excess=31.619%\n",
      "   Raw/Executed turnover: raw_mean=66.587% | executed/raw=1.000\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: STOCHASTIC EVALUATION STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total Return (%):\n",
      "   Mean: -12.60%\n",
      "   Std:  6.88%\n",
      "   Min:  -21.77%\n",
      "   Max:  -2.90%\n",
      "\n",
      "Annualized Return (%):\n",
      "   Mean: -4.45%\n",
      "   Std:  2.51%\n",
      "   Min:  -7.86%\n",
      "   Max:  -0.98%\n",
      "\n",
      "Sharpe Ratio (annualized):\n",
      "   Mean: -0.4008\n",
      "   Std:  0.1940\n",
      "   Min:  -0.6808\n",
      "   Max:  -0.1326\n",
      "\n",
      "Max Drawdown (%):\n",
      "   Mean: 23.72%\n",
      "   Std:  3.56%\n",
      "   Min:  19.52%\n",
      "   Max:  28.18%\n",
      "\n",
      "Turnover (%):\n",
      "   Mean: 66.33%\n",
      "   Std:  0.53%\n",
      "\n",
      "Turnover Step Detail (%):\n",
      "   Mean(step mean): 66.328%\n",
      "   Mean(step p95):  91.826%\n",
      "   Mean(step max):  118.399%\n",
      "   Mean exceed rate: 98.6%\n",
      "   Mean excess over target: 31.390%\n",
      "   Mean executed/raw ratio: 1.000\n",
      "\n",
      "ðŸ’¾ Evaluation results saved: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/logs/exp6_custom_eval_20260223_085336.csv\n",
      "ðŸ’¾ Per-track artifacts saved in: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/logs\n",
      "âœ… Completed evaluations: 1\n",
      "âš ï¸ Failed evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Evaluation subset controls\n",
    "# -----------------------------------------------------------------------------\n",
    "# Modes:\n",
    "# - \"all\": run full eval_ablation_ckpts\n",
    "# - \"index_range\": run by row index range in eval_ablation_ckpts\n",
    "# - \"episode_range\": run checkpoints with episode in [min_ep, max_ep]\n",
    "# - \"episode_list\": run only specific episodes\n",
    "EVAL_RUN_MODE = \"episode_list\"\n",
    "\n",
    "EVAL_INDEX_RANGE = (0, 9999)      # used when mode=\"index_range\" (inclusive)\n",
    "EVAL_EPISODE_RANGE = (1, 9999)    # used when mode=\"episode_range\" (inclusive)\n",
    "EVAL_EPISODE_LIST = [57]  # used when mode=\"episode_list\"\n",
    "\n",
    "# Optional: clear previous results each run\n",
    "EVAL_RESET_RESULTS = True\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build selected checkpoint frame\n",
    "# -----------------------------------------------------------------------------\n",
    "eval_evaluations = {}\n",
    "eval_failures = {}\n",
    "\n",
    "if EVAL_RUN_MODE == \"all\":\n",
    "    eval_run_ckpts = eval_ablation_ckpts.copy()\n",
    "\n",
    "elif EVAL_RUN_MODE == \"index_range\":\n",
    "    i0, i1 = EVAL_INDEX_RANGE\n",
    "    eval_run_ckpts = eval_ablation_ckpts.iloc[i0:i1 + 1].copy()\n",
    "\n",
    "elif EVAL_RUN_MODE == \"episode_range\":\n",
    "    ep0, ep1 = EVAL_EPISODE_RANGE\n",
    "    tmp = eval_ablation_ckpts.copy()\n",
    "    tmp[\"_ep_int\"] = pd.to_numeric(tmp[\"episode\"], errors=\"coerce\")\n",
    "    eval_run_ckpts = tmp[(tmp[\"_ep_int\"] >= ep0) & (tmp[\"_ep_int\"] <= ep1)].drop(columns=[\"_ep_int\"]).copy()\n",
    "\n",
    "elif EVAL_RUN_MODE == \"episode_list\":\n",
    "    want = set(int(x) for x in EVAL_EPISODE_LIST)\n",
    "    tmp = eval_ablation_ckpts.copy()\n",
    "    tmp[\"_ep_int\"] = pd.to_numeric(tmp[\"episode\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    eval_run_ckpts = tmp[tmp[\"_ep_int\"].isin(want)].drop(columns=[\"_ep_int\"]).copy()\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown EVAL_RUN_MODE: {EVAL_RUN_MODE}\")\n",
    "\n",
    "eval_run_ckpts = eval_run_ckpts.reset_index(drop=True)\n",
    "\n",
    "print(f\"Mode: {EVAL_RUN_MODE}\")\n",
    "print(f\"Selected checkpoints: {len(eval_run_ckpts)} / {len(eval_ablation_ckpts)}\")\n",
    "display(eval_run_ckpts[[\"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\"]].head(20))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "if EVAL_RESET_RESULTS or \"eval_evaluations\" not in globals():\n",
    "    eval_evaluations = {}\n",
    "if EVAL_RESET_RESULTS or \"eval_failures\" not in globals():\n",
    "    eval_failures = {}\n",
    "\n",
    "for i, row in eval_run_ckpts.iterrows():\n",
    "    ep = int(row[\"episode\"]) if pd.notna(row[\"episode\"]) else -1\n",
    "    st = int(row[\"step\"]) if pd.notna(row[\"step\"]) else -1\n",
    "    label = f\"{row['checkpoint_kind']}__ep{ep:04d}__step{st:06d}\"\n",
    "    prefix = row[\"checkpoint_prefix\"]\n",
    "\n",
    "    print(f\"\\n[{i+1}/{len(eval_run_ckpts)}] Evaluating: {label}\")\n",
    "    try:\n",
    "        ev = eval_run_one_checkpoint(eval_config, eval_phase1_data, prefix, seed=EVAL_RANDOM_SEED)\n",
    "        eval_evaluations[label] = ev\n",
    "    except Exception as e:\n",
    "        eval_failures[label] = f\"{type(e).__name__}: {e}\"\n",
    "        print(f\"âŒ Failed {label}: {eval_failures[label]}\")\n",
    "\n",
    "print(\"âœ… Completed evaluations:\", len(eval_evaluations))\n",
    "print(\"âš ï¸ Failed evaluations:\", len(eval_failures))\n",
    "\n",
    "if eval_failures:\n",
    "    print(\"\\nFailure samples:\")\n",
    "    for k, v in list(eval_failures.items())[:10]:\n",
    "        print(\" -\", k, \"->\", v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Ablation table and leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval_evaluations:\n",
    "    raise RuntimeError('No successful evaluations to summarize.')\n",
    "\n",
    "eval_ablation_table = build_ablation_table(eval_evaluations)\n",
    "\n",
    "display(eval_ablation_table.head(30))\n",
    "\n",
    "# Deterministic-first leaderboard view\n",
    "eval_leaderboard = eval_ablation_table.copy()\n",
    "eval_leaderboard['risk_adjusted_score'] = (\n",
    "    eval_leaderboard['det_sharpe'].fillna(-999)\n",
    "    - 0.5 * eval_leaderboard['det_max_drawdown'].fillna(1.0)\n",
    "    - 0.1 * eval_leaderboard['det_turnover'].fillna(1.0)\n",
    ")\n",
    "eval_leaderboard = eval_leaderboard.sort_values(['risk_adjusted_score', 'det_sharpe'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "print('Top by risk-adjusted score:')\n",
    "display(eval_leaderboard.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Build industry baseline returns (equal-weight and cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_identify_asset_column(df: pd.DataFrame):\n",
    "    candidates = ['Ticker', 'ticker', 'tic', 'asset', 'Asset', 'symbol', 'Symbol']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def eval_identify_return_column(df: pd.DataFrame):\n",
    "    candidates = ['LogReturn_1d', 'log_return_1d', 'Return_1d', 'return_1d', 'daily_return']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def eval_fetch_sp500_returns(start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fetch S&P500 daily simple returns for benchmark comparison.\n",
    "    Primary source: yfinance '^GSPC'.\n",
    "    Fallback: empty series if fetch fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception:\n",
    "        try:\n",
    "            !pip -q install yfinance\n",
    "            import yfinance as yf\n",
    "        except Exception:\n",
    "            print('âš ï¸ Could not install/import yfinance; SP500 benchmark disabled.')\n",
    "            return pd.Series(dtype=float)\n",
    "\n",
    "    try:\n",
    "        df = yf.download('^GSPC', start=str(start_date.date()), end=str((end_date + pd.Timedelta(days=1)).date()), auto_adjust=True, progress=False)\n",
    "        if df is None or df.empty or 'Close' not in df.columns:\n",
    "            print('âš ï¸ SP500 download returned empty data.')\n",
    "            return pd.Series(dtype=float)\n",
    "        close = pd.Series(df['Close']).dropna()\n",
    "        ret = close.pct_change().dropna().astype(float)\n",
    "        ret.index = pd.to_datetime(ret.index)\n",
    "        return ret\n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸ SP500 fetch failed: {type(e).__name__}: {e}')\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "\n",
    "def eval_build_baselines_from_phase1(phase1_data):\n",
    "    test_df = phase1_data.test_df.copy()\n",
    "    if 'Date' not in test_df.columns:\n",
    "        raise ValueError('test_df must contain Date column')\n",
    "\n",
    "    ret_col = eval_identify_return_column(test_df)\n",
    "    if ret_col is None:\n",
    "        raise ValueError('Could not identify return column in test_df')\n",
    "\n",
    "    if 'LogReturn' in ret_col or 'log' in ret_col.lower():\n",
    "        test_df['_simple_ret'] = np.expm1(test_df[ret_col].astype(float))\n",
    "    else:\n",
    "        test_df['_simple_ret'] = test_df[ret_col].astype(float)\n",
    "\n",
    "    # Industry baseline 1: equal-weight over available assets each day\n",
    "    eqw = (\n",
    "        test_df.groupby('Date')['_simple_ret']\n",
    "        .mean()\n",
    "        .sort_index()\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # Industry baseline 2: cash (0% daily return)\n",
    "    cash = pd.Series(np.zeros(len(eqw)), index=pd.to_datetime(eqw.index), name='cash')\n",
    "\n",
    "    # Industry baseline 3: S&P 500 (^GSPC)\n",
    "    dt_index = pd.to_datetime(eqw.index)\n",
    "    sp500_ret = eval_fetch_sp500_returns(dt_index.min(), dt_index.max())\n",
    "    if not sp500_ret.empty:\n",
    "        # align to model dates; missing market holidays become 0 return for alignment stability\n",
    "        sp500_ret = sp500_ret.reindex(dt_index).fillna(0.0)\n",
    "    else:\n",
    "        sp500_ret = pd.Series(dtype=float)\n",
    "\n",
    "    # reset to plain 0..n index for compare_agent_vs_baseline\n",
    "    eqw = eqw.reset_index(drop=True)\n",
    "    cash = cash.reset_index(drop=True)\n",
    "    sp500 = sp500_ret.reset_index(drop=True) if not sp500_ret.empty else pd.Series(dtype=float)\n",
    "    return eqw, cash, sp500\n",
    "\n",
    "\n",
    "eval_baseline_eqw, eval_baseline_cash, eval_baseline_sp500 = eval_build_baselines_from_phase1(eval_phase1_data)\n",
    "print('Baseline lengths | EQW:', len(eval_baseline_eqw), 'Cash:', len(eval_baseline_cash), 'SP500:', len(eval_baseline_sp500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Benchmark each evaluated checkpoint vs baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_rows = []\n",
    "for label, ev in eval_evaluations.items():\n",
    "    try:\n",
    "        cmp_eqw = compare_agent_vs_baseline(ev, eval_baseline_eqw)\n",
    "    except Exception as e:\n",
    "        cmp_eqw = {'error': str(e)}\n",
    "\n",
    "    try:\n",
    "        cmp_cash = compare_agent_vs_baseline(ev, eval_baseline_cash)\n",
    "    except Exception as e:\n",
    "        cmp_cash = {'error': str(e)}\n",
    "\n",
    "    try:\n",
    "        if len(eval_baseline_sp500) > 0:\n",
    "            cmp_sp500 = compare_agent_vs_baseline(ev, eval_baseline_sp500)\n",
    "        else:\n",
    "            cmp_sp500 = {'error': 'SP500 baseline unavailable'}\n",
    "    except Exception as e:\n",
    "        cmp_sp500 = {'error': str(e)}\n",
    "\n",
    "    row = {\n",
    "        'label': label,\n",
    "        'det_sharpe': (ev.deterministic_metrics or {}).get('sharpe_ratio', np.nan),\n",
    "        'det_return': (ev.deterministic_metrics or {}).get('annualized_return', np.nan),\n",
    "        'det_mdd': (ev.deterministic_metrics or {}).get('max_drawdown_abs', np.nan),\n",
    "        'det_turnover': (ev.deterministic_metrics or {}).get('turnover', np.nan),\n",
    "    }\n",
    "\n",
    "    for prefix, comp in [('eqw', cmp_eqw), ('cash', cmp_cash), ('sp500', cmp_sp500)]:\n",
    "        if isinstance(comp, dict) and 'error' not in comp:\n",
    "            for k, v in comp.items():\n",
    "                row[f'{prefix}_{k}'] = v\n",
    "        else:\n",
    "            row[f'{prefix}_error'] = comp.get('error', 'unknown') if isinstance(comp, dict) else 'unknown'\n",
    "\n",
    "    benchmark_rows.append(row)\n",
    "\n",
    "eval_benchmark_df = pd.DataFrame(benchmark_rows)\n",
    "\n",
    "display(eval_benchmark_df.sort_values('det_sharpe', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Champion selection (production candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_benchmark_df.empty:\n",
    "    raise RuntimeError('No benchmark rows available.')\n",
    "\n",
    "# Balanced production-style objective: reward risk-adjusted return, penalize drawdown/turnover.\n",
    "eval_benchmark_df['selection_score'] = (\n",
    "    eval_benchmark_df['det_sharpe'].fillna(-999)\n",
    "    + 0.2 * eval_benchmark_df['det_return'].fillna(0.0)\n",
    "    - 0.7 * eval_benchmark_df['det_mdd'].fillna(1.0)\n",
    "    - 0.1 * eval_benchmark_df['det_turnover'].fillna(1.0)\n",
    ")\n",
    "\n",
    "champion_row = eval_benchmark_df.sort_values('selection_score', ascending=False).iloc[0]\n",
    "EVAL_CHAMPION_LABEL = champion_row['label']\n",
    "EVAL_CHAMPION = eval_evaluations[EVAL_CHAMPION_LABEL]\n",
    "\n",
    "print('ðŸ† Champion label:', EVAL_CHAMPION_LABEL)\n",
    "print(champion_row[['det_sharpe', 'det_return', 'det_mdd', 'det_turnover', 'selection_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Regime-sliced performance (champion vs equal-weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regime_tag(dates: pd.Series):\n",
    "    d = pd.to_datetime(dates)\n",
    "    conds = [\n",
    "        (d <= pd.Timestamp('2020-02-19')),\n",
    "        (d >= pd.Timestamp('2020-02-20')) & (d <= pd.Timestamp('2020-06-30')),\n",
    "        (d >= pd.Timestamp('2020-07-01')) & (d <= pd.Timestamp('2021-12-31')),\n",
    "        (d >= pd.Timestamp('2022-01-01')) & (d <= pd.Timestamp('2023-12-31')),\n",
    "        (d >= pd.Timestamp('2024-01-01')),\n",
    "    ]\n",
    "    labels = ['pre_covid', 'covid_crash', 'post_covid_recovery', 'inflation_rates', 'recent']\n",
    "    out = np.select(conds, labels, default='other')\n",
    "    return pd.Series(out)\n",
    "\n",
    "\n",
    "def eval_sharpe(x):\n",
    "    x = pd.Series(x).dropna()\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "    std = x.std(ddof=1)\n",
    "    if std <= 1e-12:\n",
    "        return np.nan\n",
    "    return np.sqrt(252.0) * x.mean() / std\n",
    "\n",
    "# Build aligned daily return series for champion and baselines\n",
    "champ_port = np.array(EVAL_CHAMPION.deterministic_portfolio)\n",
    "champ_ret = pd.Series(np.diff(champ_port) / champ_port[:-1]).reset_index(drop=True)\n",
    "eqw_ret = eval_baseline_eqw.reset_index(drop=True)\n",
    "sp500_ret = eval_baseline_sp500.reset_index(drop=True) if len(eval_baseline_sp500) > 0 else pd.Series(dtype=float)\n",
    "\n",
    "n_core = min(len(champ_ret), len(eqw_ret), len(eval_phase1_data.test_df['Date'].drop_duplicates()) - 1)\n",
    "if len(sp500_ret) > 0:\n",
    "    n = min(n_core, len(sp500_ret))\n",
    "else:\n",
    "    n = n_core\n",
    "\n",
    "dates = pd.to_datetime(eval_phase1_data.test_df['Date'].drop_duplicates().sort_values()).reset_index(drop=True).iloc[1:n+1]\n",
    "\n",
    "reg_df = pd.DataFrame({\n",
    "    'Date': dates.reset_index(drop=True),\n",
    "    'champion_ret': champ_ret.iloc[:n].reset_index(drop=True),\n",
    "    'eqw_ret': eqw_ret.iloc[:n].reset_index(drop=True),\n",
    "})\n",
    "if len(sp500_ret) > 0:\n",
    "    reg_df['sp500_ret'] = sp500_ret.iloc[:n].reset_index(drop=True)\n",
    "else:\n",
    "    reg_df['sp500_ret'] = np.nan\n",
    "\n",
    "reg_df['regime'] = eval_regime_tag(reg_df['Date'])\n",
    "\n",
    "regime_rows = []\n",
    "for regime, g in reg_df.groupby('regime'):\n",
    "    row = {\n",
    "        'regime': regime,\n",
    "        'n_days': len(g),\n",
    "        'champion_sharpe': eval_sharpe(g['champion_ret']),\n",
    "        'eqw_sharpe': eval_sharpe(g['eqw_ret']),\n",
    "        'champion_total_return': float((1.0 + g['champion_ret']).prod() - 1.0),\n",
    "        'eqw_total_return': float((1.0 + g['eqw_ret']).prod() - 1.0),\n",
    "    }\n",
    "    if g['sp500_ret'].notna().any():\n",
    "        row['sp500_sharpe'] = eval_sharpe(g['sp500_ret'])\n",
    "        row['sp500_total_return'] = float((1.0 + g['sp500_ret'].fillna(0.0)).prod() - 1.0)\n",
    "    else:\n",
    "        row['sp500_sharpe'] = np.nan\n",
    "        row['sp500_total_return'] = np.nan\n",
    "    regime_rows.append(row)\n",
    "\n",
    "eval_regime_df = pd.DataFrame(regime_rows).sort_values('regime').reset_index(drop=True)\n",
    "display(eval_regime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Statistical confidence: bootstrap Sharpe difference (champion - equal-weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_block_bootstrap_sharpe_diff(agent_ret, base_ret, n_boot=2000, block=20, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    a = np.asarray(agent_ret, dtype=float)\n",
    "    b = np.asarray(base_ret, dtype=float)\n",
    "    n = min(len(a), len(b))\n",
    "    a = a[:n]\n",
    "    b = b[:n]\n",
    "\n",
    "    def _sharpe(x):\n",
    "        x = pd.Series(x).dropna()\n",
    "        if len(x) < 2:\n",
    "            return np.nan\n",
    "        s = x.std(ddof=1)\n",
    "        if s <= 1e-12:\n",
    "            return np.nan\n",
    "        return np.sqrt(252.0) * x.mean() / s\n",
    "\n",
    "    diffs = []\n",
    "    n_blocks = int(np.ceil(n / block))\n",
    "    max_start = max(1, n - block + 1)\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = []\n",
    "        for __ in range(n_blocks):\n",
    "            st = int(rng.integers(0, max_start))\n",
    "            idx.extend(range(st, min(st + block, n)))\n",
    "        idx = np.asarray(idx[:n])\n",
    "        d = _sharpe(a[idx]) - _sharpe(b[idx])\n",
    "        if np.isfinite(d):\n",
    "            diffs.append(float(d))\n",
    "\n",
    "    if not diffs:\n",
    "        return {'n_boot_eff': 0, 'mean': np.nan, 'ci_low': np.nan, 'ci_high': np.nan, 'p_le_zero': np.nan}\n",
    "\n",
    "    diffs = np.asarray(diffs)\n",
    "    return {\n",
    "        'n_boot_eff': int(len(diffs)),\n",
    "        'mean': float(np.mean(diffs)),\n",
    "        'ci_low': float(np.quantile(diffs, 0.025)),\n",
    "        'ci_high': float(np.quantile(diffs, 0.975)),\n",
    "        'p_le_zero': float(np.mean(diffs <= 0.0)),\n",
    "    }\n",
    "\n",
    "bootstrap_eqw = eval_block_bootstrap_sharpe_diff(\n",
    "    reg_df['champion_ret'].values,\n",
    "    reg_df['eqw_ret'].values,\n",
    "    n_boot=2000,\n",
    "    block=20,\n",
    "    seed=EVAL_RANDOM_SEED,\n",
    ")\n",
    "\n",
    "if reg_df['sp500_ret'].notna().any():\n",
    "    bootstrap_sp500 = eval_block_bootstrap_sharpe_diff(\n",
    "        reg_df['champion_ret'].values,\n",
    "        reg_df['sp500_ret'].fillna(0.0).values,\n",
    "        n_boot=2000,\n",
    "        block=20,\n",
    "        seed=EVAL_RANDOM_SEED,\n",
    "    )\n",
    "else:\n",
    "    bootstrap_sp500 = {'n_boot_eff': 0, 'mean': np.nan, 'ci_low': np.nan, 'ci_high': np.nan, 'p_le_zero': np.nan}\n",
    "\n",
    "print('Bootstrap Sharpe diff (Champion - EQW):')\n",
    "print(bootstrap_eqw)\n",
    "print('Bootstrap Sharpe diff (Champion - SP500):')\n",
    "print(bootstrap_sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Training-diagnostics quality checks from CSV metrics\n",
    "Uses saved CSVs to report KL stability, turnover drivers, and execution quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_report = {}\n",
    "\n",
    "if eval_latest_episodes_csv and Path(eval_latest_episodes_csv).exists():\n",
    "    ep = pd.read_csv(eval_latest_episodes_csv)\n",
    "    diag_report['episodes_rows'] = len(ep)\n",
    "\n",
    "    if 'approx_kl' in ep.columns:\n",
    "        kl = pd.to_numeric(ep['approx_kl'], errors='coerce').dropna()\n",
    "        if len(kl):\n",
    "            diag_report['approx_kl_mean'] = float(kl.mean())\n",
    "            diag_report['approx_kl_p50'] = float(kl.quantile(0.50))\n",
    "            diag_report['approx_kl_p90'] = float(kl.quantile(0.90))\n",
    "\n",
    "    if {'episode_turnover_pct', 'approx_kl'}.issubset(ep.columns):\n",
    "        x = pd.to_numeric(ep['episode_turnover_pct'], errors='coerce')\n",
    "        y = pd.to_numeric(ep['approx_kl'], errors='coerce')\n",
    "        valid = x.notna() & y.notna()\n",
    "        if valid.any():\n",
    "            diag_report['corr_turnoverpct_kl'] = float(np.corrcoef(x[valid], y[valid])[0, 1])\n",
    "\n",
    "if eval_latest_step_diag_csv and Path(eval_latest_step_diag_csv).exists():\n",
    "    sd = pd.read_csv(eval_latest_step_diag_csv)\n",
    "    diag_report['step_diag_rows'] = len(sd)\n",
    "\n",
    "    for col in ['l1_w_delta', 'turnover_penalty_contrib', 'tx_cost_contrib_reward_pts', 'action_realization_l1']:\n",
    "        if col in sd.columns:\n",
    "            s = pd.to_numeric(sd[col], errors='coerce').dropna()\n",
    "            if len(s):\n",
    "                diag_report[f'{col}_mean'] = float(s.mean())\n",
    "                diag_report[f'{col}_p90'] = float(s.quantile(0.90))\n",
    "\n",
    "print(json.dumps(diag_report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Save final evaluation package\n",
    "Exports leaderboard, benchmark table, regime table, diagnostics, and champion metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out_dir = EVAL_RESULTS_ROOT / 'logs'\n",
    "eval_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "eval_ablation_path = eval_out_dir / f'final_eval_ablation_{ts}.csv'\n",
    "eval_benchmark_path = eval_out_dir / f'final_eval_benchmark_{ts}.csv'\n",
    "eval_regime_path = eval_out_dir / f'final_eval_regime_{ts}.csv'\n",
    "eval_diag_path = eval_out_dir / f'final_eval_diagnostics_{ts}.json'\n",
    "eval_meta_path = eval_out_dir / f'final_eval_champion_{ts}.json'\n",
    "\n",
    "eval_ablation_table.to_csv(eval_ablation_path, index=False)\n",
    "eval_benchmark_df.to_csv(eval_benchmark_path, index=False)\n",
    "eval_regime_df.to_csv(eval_regime_path, index=False)\n",
    "\n",
    "with open(eval_diag_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'bootstrap_sharpe_diff_eqw': bootstrap_eqw,\n",
    "        'bootstrap_sharpe_diff_sp500': bootstrap_sp500,\n",
    "        'diagnostics': diag_report,\n",
    "        'metadata_path': str(EVAL_METADATA_PATH),\n",
    "    }, f, indent=2)\n",
    "\n",
    "with open(eval_meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'champion_label': EVAL_CHAMPION_LABEL,\n",
    "        'selection_row': champion_row.to_dict(),\n",
    "        'deterministic_metrics': EVAL_CHAMPION.deterministic_metrics,\n",
    "        'checkpoint_description': EVAL_CHAMPION.checkpoint_description,\n",
    "    }, f, indent=2, default=str)\n",
    "\n",
    "print('âœ… Saved evaluation package:')\n",
    "print('-', eval_ablation_path)\n",
    "print('-', eval_benchmark_path)\n",
    "print('-', eval_regime_path)\n",
    "print('-', eval_diag_path)\n",
    "print('-', eval_meta_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}