{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TCN Final Evaluation Notebook\n",
        "\n",
        "This notebook is evaluation-only and designed for final model selection, ablations, and benchmarking.\n",
        "All runtime variables are isolated with the `eval_` prefix to avoid conflicts with training notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Connect to Colab VM and sync repository\n",
        "Run this first in a fresh Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/adaptive_portfolio_rl\n",
            "HEAD is now at a092792 Add configurable alpha-diversity logging and sync notebook updates\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "EVAL_REPO_URL = \"https://github.com/Dave-DKings/tape_tcn_project.git\"\n",
        "EVAL_REPO_DIR = \"/content/adaptive_portfolio_rl\"\n",
        "\n",
        "if not os.path.exists(f\"{EVAL_REPO_DIR}/.git\"):\n",
        "    !git clone {EVAL_REPO_URL} {EVAL_REPO_DIR}\n",
        "\n",
        "%cd /content/adaptive_portfolio_rl\n",
        "!git fetch origin\n",
        "!git reset --hard origin/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Optional: mount Drive and restore saved results zip\n",
        "Set `EVAL_RESTORE_FROM_ZIP=True` only when needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Restored results from zip\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "EVAL_RESTORE_FROM_ZIP = True\n",
        "EVAL_ZIP_PATH = \"/content/drive/MyDrive/tcn_fusion_results_export.zip\"\n",
        "\n",
        "if EVAL_RESTORE_FROM_ZIP:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    zip_path = Path(EVAL_ZIP_PATH)\n",
        "    if not zip_path.exists():\n",
        "        raise FileNotFoundError(f\"Zip not found: {zip_path}\")\n",
        "\n",
        "    !mkdir -p /content/adaptive_portfolio_rl\n",
        "    !unzip -q -o {zip_path} -d /content/adaptive_portfolio_rl\n",
        "    print(\"âœ… Restored results from zip\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ EVAL_RESTORE_FROM_ZIP=False\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5d075602",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zip exists: True\n",
            "Archive:  /content/drive/MyDrive/tcn_fusion_results_export.zip\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "        0  2026-02-21 07:45   tcn_fusion_results/\n",
            "        0  2026-02-21 11:36   tcn_fusion_results/high_watermark_checkpoints/\n",
            "  1897264  2026-02-21 08:48   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00073_shp0p760_actor.weights.h5\n",
            "  1893680  2026-02-21 08:48   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00073_shp0p760_critic.weights.h5\n",
            "  1897264  2026-02-21 08:03   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00031_shp2p546_actor.weights.h5\n",
            "  1893680  2026-02-21 07:45   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p682_critic.weights.h5\n",
            "  1897264  2026-02-21 10:40   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00104_shp0p556_actor.weights.h5\n",
            "  1897264  2026-02-21 07:47   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp1p406_actor.weights.h5\n",
            "  1893680  2026-02-21 09:13   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00087_shp0p675_critic.weights.h5\n",
            "  1893680  2026-02-21 07:59   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00024_shp0p828_critic.weights.h5\n",
            "  1893680  2026-02-21 08:06   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00037_shp0p504_critic.weights.h5\n",
            "  1893680  2026-02-21 07:48   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p251_critic.weights.h5\n",
            "  1893680  2026-02-21 09:31   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00093_shp0p566_critic.weights.h5\n",
            "  1893680  2026-02-21 08:18   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00049_shp1p567_critic.weights.h5\n",
            "  1893680  2026-02-21 08:00   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p929_critic.weights.h5\n",
            "  1893680  2026-02-21 07:51   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp1p233_critic.weights.h5\n",
            "  1897264  2026-02-21 08:21   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00052_shp0p837_actor.weights.h5\n",
            "  1897264  2026-02-21 08:32   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00061_shp1p229_actor.weights.h5\n",
            "  1893680  2026-02-21 07:58   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00023_shp0p659_critic.weights.h5\n",
            "  1897264  2026-02-21 11:39   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00115_shp0p702_actor.weights.h5\n",
            "  1893680  2026-02-21 10:16   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00100_shp0p654_critic.weights.h5\n",
            "  1893680  2026-02-21 11:06   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00109_shp0p807_critic.weights.h5\n",
            "  1897264  2026-02-21 10:35   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00103_shp0p591_actor.weights.h5\n",
            "  1897264  2026-02-21 08:30   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00059_shp0p621_actor.weights.h5\n",
            "  1897264  2026-02-21 10:32   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00102_shp0p633_actor.weights.h5\n",
            "  1893680  2026-02-21 08:17   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00048_shp1p565_critic.weights.h5\n",
            "  1893680  2026-02-21 07:46   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p209_critic.weights.h5\n",
            "  1897264  2026-02-21 09:59   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00097_shp0p533_actor.weights.h5\n",
            "  1897264  2026-02-21 07:48   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00007_shp0p778_actor.weights.h5\n",
            "  1893680  2026-02-21 10:52   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00106_shp0p630_critic.weights.h5\n",
            "  1897264  2026-02-21 08:53   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00076_shp0p534_actor.weights.h5\n",
            "  1893680  2026-02-21 08:50   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00074_shp0p553_critic.weights.h5\n",
            "  1893680  2026-02-21 11:11   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00110_shp0p561_critic.weights.h5\n",
            "  1893680  2026-02-21 07:47   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp1p406_critic.weights.h5\n",
            "  1897264  2026-02-21 08:13   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00045_shp0p674_actor.weights.h5\n",
            "  1893680  2026-02-21 08:16   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00047_shp1p076_critic.weights.h5\n",
            "  1893680  2026-02-21 08:03   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00032_shp1p156_critic.weights.h5\n",
            "/content/eval_restore/tcn_fusion_results logs: True actors: 73\n",
            "/content/eval_restore/tcn_fusion_results_export/tcn_fusion_results logs: False actors: 0\n",
            "/content/eval_restore/tcn_fusion_results_export logs: False actors: 0\n",
            "âœ… EVAL_RESULTS_ROOT = /content/eval_restore/tcn_fusion_results\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "EVAL_ZIP_PATH = Path(\"/content/drive/MyDrive/tcn_fusion_results_export.zip\")\n",
        "\n",
        "# 1) Verify zip exists\n",
        "print(\"zip exists:\", EVAL_ZIP_PATH.exists())\n",
        "if not EVAL_ZIP_PATH.exists():\n",
        "    raise FileNotFoundError(EVAL_ZIP_PATH)\n",
        "\n",
        "# 2) Inspect zip top-level structure\n",
        "!unzip -l \"{EVAL_ZIP_PATH}\" | head -n 40\n",
        "\n",
        "# 3) Extract to /content (clean target)\n",
        "!mkdir -p /content/eval_restore\n",
        "!unzip -q -o \"{EVAL_ZIP_PATH}\" -d /content/eval_restore\n",
        "\n",
        "# 4) Auto-detect correct results root\n",
        "candidates = [\n",
        "    Path(\"/content/eval_restore/tcn_fusion_results\"),\n",
        "    Path(\"/content/eval_restore/tcn_fusion_results_export/tcn_fusion_results\"),\n",
        "    Path(\"/content/eval_restore/tcn_fusion_results_export\"),\n",
        "]\n",
        "for c in candidates:\n",
        "    print(c, \"logs:\", (c / \"logs\").exists(), \"actors:\", len(list(c.rglob(\"*_actor.weights.h5\"))))\n",
        "\n",
        "EVAL_RESULTS_ROOT = next(\n",
        "    c for c in candidates\n",
        "    if (c / \"logs\").exists() and len(list(c.rglob(\"*_actor.weights.h5\"))) > 0\n",
        ")\n",
        "print(\"âœ… EVAL_RESULTS_ROOT =\", EVAL_RESULTS_ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import json\n",
        "import re\n",
        "from dataclasses import replace\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from src.config import get_active_config\n",
        "from src.data_utils import DataProcessor\n",
        "from src.notebook_helpers.tcn_phase1 import (\n",
        "    prepare_phase1_dataset,\n",
        "    create_experiment6_result_stub,\n",
        "    evaluate_experiment6_checkpoint,\n",
        "    load_training_metadata_into_config,\n",
        "    build_evaluation_track_summary,\n",
        "    build_ablation_table,\n",
        "    compare_agent_vs_baseline,\n",
        "    Phase1Dataset,\n",
        "    split_dataset_by_date,\n",
        "    identify_covariance_columns,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Evaluation run settings\n",
        "Adjust once here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "EVAL_RANDOM_SEED = 42\n",
        "EVAL_RESULTS_ROOT = Path(\"/content/eval_restore/tcn_fusion_results\")\n",
        "\n",
        "# Deterministic policy mode: 'mean' is recommended for stable ranking.\n",
        "EVAL_DETERMINISTIC_MODE = 'mean'\n",
        "\n",
        "# Stochastic robustness checks per checkpoint.\n",
        "EVAL_NUM_STOCHASTIC_RUNS = 5\n",
        "EVAL_STOCHASTIC_EPISODE_LIMIT = 252\n",
        "\n",
        "# Selection for ablation basket\n",
        "EVAL_TOP_HW = 8         # high-watermark checkpoints by filename Sharpe tag\n",
        "EVAL_TOP_PERIODIC = 4   # periodic step checkpoints by most recent step\n",
        "EVAL_INCLUDE_ROOT = True\n",
        "EVAL_INCLUDE_RARE = False\n",
        "\n",
        "# Save outputs\n",
        "EVAL_SAVE_LOGS = True\n",
        "EVAL_SAVE_ARTIFACTS = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c4b53d03",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "73\n"
          ]
        }
      ],
      "source": [
        "print((EVAL_RESULTS_ROOT / \"logs\").exists())\n",
        "print(len(list(EVAL_RESULTS_ROOT.rglob(\"*_actor.weights.h5\"))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "815ad1c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root exists: True\n",
            "logs exists: True\n",
            "actor ckpts: 73\n"
          ]
        }
      ],
      "source": [
        "print(\"root exists:\", EVAL_RESULTS_ROOT.exists())\n",
        "print(\"logs exists:\", (EVAL_RESULTS_ROOT / \"logs\").exists())\n",
        "print(\"actor ckpts:\", len(list(EVAL_RESULTS_ROOT.rglob(\"*_actor.weights.h5\"))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Build evaluation dataset and load latest metadata config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c774d4d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"eval_phase1_data\" in globals():\n",
        "    del eval_phase1_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“„ Using metadata: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_metadata.json\n",
            "âœ… Applied training metadata to config\n",
            "   Metadata: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_metadata.json\n",
            "   Run timestamp: 20260221_074438\n",
            "   Architecture: TCN_FUSION\n",
            "   Turnover target: 0.35\n",
            "   DSR scalar: 2.0\n",
            "   PPO update timesteps: scheduled\n",
            "   Episode length curriculum: True\n",
            "   Profile override loaded: True\n",
            "   Credit assignment mode: step_reward_plus_terminal_bonus\n",
            "   Retroactive episode scaling: False\n",
            "âœ… Eval core feature lock applied\n",
            "   active_feature_columns: 50\n",
            "   disabled_features: 25\n",
            "ðŸ“¦ Loading normalized master from: /content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\n",
            "================================================================================\n",
            "âœ‚ï¸  TIME-BASED TRAIN/TEST SPLIT (80/20 split)\n",
            "   Train: 2003-10-01 â†’ 2021-04-09 (4411 days, 17.5 years, 43867 rows)\n",
            "   Test:  2021-04-12 â†’ 2025-08-29 (1103 days, 4.4 years, 11030 rows)\n",
            "================================================================================\n",
            "âœ… Built eval_phase1_data from saved normalized master\n",
            "   Train shape: (43867, 105)\n",
            "   Test shape: (11030, 105)\n",
            "   Covariance cols: ['Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1', 'Covariance_Eigenvalue_2']\n"
          ]
        }
      ],
      "source": [
        "if not EVAL_RESULTS_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Missing results root: {EVAL_RESULTS_ROOT}\")\n",
        "\n",
        "\n",
        "def eval_build_core_active_feature_columns(cfg):\n",
        "    from src.data_utils import DataProcessor\n",
        "\n",
        "    probe = DataProcessor(cfg)\n",
        "    return list(dict.fromkeys(probe.get_feature_columns(\"phase1\")))\n",
        "\n",
        "\n",
        "def eval_apply_core_feature_lock(cfg, active_feature_columns):\n",
        "    from src.data_utils import DataProcessor\n",
        "\n",
        "    probe_cfg = copy.deepcopy(cfg)\n",
        "    probe_fp = probe_cfg.setdefault(\"feature_params\", {})\n",
        "    probe_fs = probe_fp.setdefault(\"feature_selection\", {})\n",
        "    probe_fs[\"disable_features\"] = False\n",
        "    probe_fs[\"disabled_features\"] = []\n",
        "\n",
        "    probe = DataProcessor(probe_cfg)\n",
        "    core_all_cols = list(dict.fromkeys(probe.get_feature_columns(\"phase1\")))\n",
        "\n",
        "    active_set = set(active_feature_columns)\n",
        "    disabled = sorted([c for c in core_all_cols if c not in active_set])\n",
        "\n",
        "    fp = cfg.setdefault(\"feature_params\", {})\n",
        "    fs = fp.setdefault(\"feature_selection\", {})\n",
        "    fs[\"disable_features\"] = True\n",
        "    fs[\"disabled_features\"] = disabled\n",
        "\n",
        "    return core_all_cols, disabled\n",
        "\n",
        "\n",
        "eval_config = copy.deepcopy(get_active_config('phase1'))\n",
        "\n",
        "eval_logs_dir = EVAL_RESULTS_ROOT / 'logs'\n",
        "meta_files = sorted(eval_logs_dir.glob('*_metadata.json'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "if not meta_files:\n",
        "    raise FileNotFoundError(f\"No metadata JSON in {eval_logs_dir}\")\n",
        "\n",
        "EVAL_METADATA_PATH = meta_files[0]\n",
        "print('ðŸ“„ Using metadata:', EVAL_METADATA_PATH)\n",
        "\n",
        "# Apply run-time training settings (architecture/reward/etc.) from metadata.\n",
        "eval_config = load_training_metadata_into_config(\n",
        "    EVAL_METADATA_PATH,\n",
        "    copy.deepcopy(eval_config),\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Enforce architecture family used by checkpoints\n",
        "eval_config['agent_params']['actor_critic_type'] = 'TCN_FUSION'\n",
        "eval_config['agent_params']['use_fusion'] = True\n",
        "eval_config['agent_params']['use_attention'] = False\n",
        "\n",
        "# IMPORTANT: feature list is derived from core project pipeline, not manifest.\n",
        "eval_active_feature_columns = eval_build_core_active_feature_columns(eval_config)\n",
        "_, eval_disabled_features = eval_apply_core_feature_lock(eval_config, eval_active_feature_columns)\n",
        "\n",
        "print('âœ… Eval core feature lock applied')\n",
        "print('   active_feature_columns:', len(eval_active_feature_columns))\n",
        "print('   disabled_features:', len(eval_disabled_features))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Build eval dataset from SAVED normalized master features (no rebuild)\n",
        "# ------------------------------------------------------------------\n",
        "EVAL_USE_SAVED_NORMALIZED = True\n",
        "\n",
        "if \"eval_phase1_data\" in globals():\n",
        "    print(\"â„¹ï¸ Reusing eval_phase1_data from current runtime\")\n",
        "else:\n",
        "    if not EVAL_USE_SAVED_NORMALIZED:\n",
        "        # fallback if you ever want full pipeline rebuild\n",
        "        eval_phase1_data = prepare_phase1_dataset(eval_config, force_download=False)\n",
        "    else:\n",
        "        # Candidate locations (zip-restore + normal project path)\n",
        "        normalized_candidates = [\n",
        "            EVAL_RESULTS_ROOT / \"data\" / \"master_features_NORMALIZED.csv\",\n",
        "            Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results_export/data/master_features_NORMALIZED.csv\"),\n",
        "            Path(eval_config.get(\"BASE_DATA_PATH\", \"/content/adaptive_portfolio_rl/data\")) / \"master_features_NORMALIZED.csv\",\n",
        "            Path(\"/content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\"),\n",
        "        ]\n",
        "        normalized_path = next((p for p in normalized_candidates if p.exists()), None)\n",
        "        if normalized_path is None:\n",
        "            raise FileNotFoundError(\n",
        "                \"Could not find master_features_NORMALIZED.csv in expected locations:\\n\"\n",
        "                + \"\\n\".join(str(p) for p in normalized_candidates)\n",
        "            )\n",
        "\n",
        "        print(\"ðŸ“¦ Loading normalized master from:\", normalized_path)\n",
        "        master_df_norm = pd.read_csv(normalized_path)\n",
        "\n",
        "        if \"Date\" not in master_df_norm.columns:\n",
        "            raise ValueError(\"Normalized CSV missing required 'Date' column\")\n",
        "        if \"Ticker\" not in master_df_norm.columns:\n",
        "            raise ValueError(\"Normalized CSV missing required 'Ticker' column\")\n",
        "\n",
        "        # Ensure datetime consistency\n",
        "        master_df_norm[\"Date\"] = pd.to_datetime(master_df_norm[\"Date\"], utc=True, errors=\"coerce\").dt.tz_localize(None)\n",
        "        master_df_norm = master_df_norm.dropna(subset=[\"Date\"]).sort_values([\"Date\", \"Ticker\"]).reset_index(drop=True)\n",
        "\n",
        "        # Apply analysis window from eval config\n",
        "        analysis_start = pd.to_datetime(eval_config.get(\"ANALYSIS_START_DATE\", \"2003-09-02\"))\n",
        "        analysis_end = pd.to_datetime(eval_config.get(\"ANALYSIS_END_DATE\", \"2025-09-01\"))\n",
        "        master_df_norm = master_df_norm[\n",
        "            (master_df_norm[\"Date\"] >= analysis_start) &\n",
        "            (master_df_norm[\"Date\"] <= analysis_end)\n",
        "        ].copy()\n",
        "\n",
        "        # Build processor from current eval config (feature definitions, env expectations)\n",
        "        eval_processor = DataProcessor(eval_config)\n",
        "\n",
        "        # Optional sanity check\n",
        "        expected_feature_cols = eval_processor.get_feature_columns(\"phase1\")\n",
        "        missing = [c for c in expected_feature_cols if c not in master_df_norm.columns]\n",
        "        if missing:\n",
        "            print(f\"âš ï¸ Missing expected feature columns in saved normalized CSV: {len(missing)}\")\n",
        "            print(\"   Sample:\", missing[:10])\n",
        "\n",
        "        # Split using eval config split rule (already loaded from metadata if present)\n",
        "        split_date = eval_config.get(\"TRAIN_TEST_SPLIT_DATE\")\n",
        "        if split_date:\n",
        "            train_df, test_df, train_end_date, test_start_date = split_dataset_by_date(\n",
        "                master_df_norm, date_column=\"Date\", split_date=split_date\n",
        "            )\n",
        "        else:\n",
        "            train_df, test_df, train_end_date, test_start_date = split_dataset_by_date(\n",
        "                master_df_norm, date_column=\"Date\", train_fraction=0.8\n",
        "            )\n",
        "\n",
        "        eval_phase1_data = Phase1Dataset(\n",
        "            master_df=master_df_norm,\n",
        "            train_df=train_df,\n",
        "            test_df=test_df,\n",
        "            scalers={},  # not needed for eval-only checkpoint loading\n",
        "            train_end_date=train_end_date,\n",
        "            test_start_date=test_start_date,\n",
        "            covariance_columns=identify_covariance_columns(master_df_norm.columns),\n",
        "            data_processor=eval_processor,\n",
        "        )\n",
        "\n",
        "        print(\"âœ… Built eval_phase1_data from saved normalized master\")\n",
        "        print(\"   Train shape:\", eval_phase1_data.train_df.shape)\n",
        "        print(\"   Test shape:\", eval_phase1_data.test_df.shape)\n",
        "        print(\"   Covariance cols:\", eval_phase1_data.covariance_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "40c64cd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(43867, 105) (11030, 105)\n",
            "Date min/max test: 2021-04-12 00:00:00 2025-08-29 00:00:00\n"
          ]
        }
      ],
      "source": [
        "print(eval_phase1_data.train_df.shape, eval_phase1_data.test_df.shape)\n",
        "print(\"Date min/max test:\", eval_phase1_data.test_df[\"Date\"].min(), eval_phase1_data.test_df[\"Date\"].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Inspect latest training CSV logs (for diagnostics context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episodes: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_episodes.csv\n",
            "step diagnostics: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_step_diagnostics.csv\n",
            "summary: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_summary.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a7ef7af1-eef7-459b-b105-710052397da7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>update</th>\n",
              "      <th>timestep</th>\n",
              "      <th>episode</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>episode_return_pct</th>\n",
              "      <th>episode_sharpe</th>\n",
              "      <th>episode_sortino</th>\n",
              "      <th>episode_max_dd</th>\n",
              "      <th>episode_volatility</th>\n",
              "      <th>episode_win_rate</th>\n",
              "      <th>...</th>\n",
              "      <th>actor_grad_norm</th>\n",
              "      <th>critic_grad_norm</th>\n",
              "      <th>alpha_min</th>\n",
              "      <th>alpha_max</th>\n",
              "      <th>alpha_mean</th>\n",
              "      <th>ratio_mean</th>\n",
              "      <th>ratio_std</th>\n",
              "      <th>drawdown_lambda_peak</th>\n",
              "      <th>episode_length</th>\n",
              "      <th>termination_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>200</td>\n",
              "      <td>92288</td>\n",
              "      <td>112</td>\n",
              "      <td>12984.339746</td>\n",
              "      <td>160.172362</td>\n",
              "      <td>0.698085</td>\n",
              "      <td>0.866149</td>\n",
              "      <td>30.670430</td>\n",
              "      <td>0.152975</td>\n",
              "      <td>52.907531</td>\n",
              "      <td>...</td>\n",
              "      <td>1.145636</td>\n",
              "      <td>0.870696</td>\n",
              "      <td>0.416976</td>\n",
              "      <td>2.490606</td>\n",
              "      <td>1.454391</td>\n",
              "      <td>1.014433</td>\n",
              "      <td>0.329495</td>\n",
              "      <td>0.104402</td>\n",
              "      <td>2099.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>205</td>\n",
              "      <td>94848</td>\n",
              "      <td>113</td>\n",
              "      <td>13342.201170</td>\n",
              "      <td>144.682331</td>\n",
              "      <td>0.602021</td>\n",
              "      <td>0.745132</td>\n",
              "      <td>31.341508</td>\n",
              "      <td>0.153894</td>\n",
              "      <td>52.854594</td>\n",
              "      <td>...</td>\n",
              "      <td>1.130851</td>\n",
              "      <td>0.504859</td>\n",
              "      <td>0.358140</td>\n",
              "      <td>2.738815</td>\n",
              "      <td>1.541263</td>\n",
              "      <td>1.003132</td>\n",
              "      <td>0.482642</td>\n",
              "      <td>0.108881</td>\n",
              "      <td>2243.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>210</td>\n",
              "      <td>97408</td>\n",
              "      <td>113</td>\n",
              "      <td>13701.259389</td>\n",
              "      <td>93.120311</td>\n",
              "      <td>0.304018</td>\n",
              "      <td>0.392391</td>\n",
              "      <td>39.369065</td>\n",
              "      <td>0.172854</td>\n",
              "      <td>52.252252</td>\n",
              "      <td>...</td>\n",
              "      <td>1.224620</td>\n",
              "      <td>1.182268</td>\n",
              "      <td>0.810124</td>\n",
              "      <td>1.960325</td>\n",
              "      <td>1.430809</td>\n",
              "      <td>1.004731</td>\n",
              "      <td>0.192864</td>\n",
              "      <td>0.108881</td>\n",
              "      <td>2243.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>215</td>\n",
              "      <td>99968</td>\n",
              "      <td>115</td>\n",
              "      <td>14058.239728</td>\n",
              "      <td>68.148983</td>\n",
              "      <td>0.702017</td>\n",
              "      <td>0.835756</td>\n",
              "      <td>30.053439</td>\n",
              "      <td>0.193406</td>\n",
              "      <td>54.963427</td>\n",
              "      <td>...</td>\n",
              "      <td>1.300989</td>\n",
              "      <td>2.885931</td>\n",
              "      <td>0.415817</td>\n",
              "      <td>2.477985</td>\n",
              "      <td>1.466220</td>\n",
              "      <td>1.009898</td>\n",
              "      <td>0.325248</td>\n",
              "      <td>0.089567</td>\n",
              "      <td>958.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>216</td>\n",
              "      <td>100000</td>\n",
              "      <td>115</td>\n",
              "      <td>14066.485792</td>\n",
              "      <td>78.524055</td>\n",
              "      <td>0.649932</td>\n",
              "      <td>0.755351</td>\n",
              "      <td>30.247986</td>\n",
              "      <td>0.173939</td>\n",
              "      <td>55.036261</td>\n",
              "      <td>...</td>\n",
              "      <td>2.661150</td>\n",
              "      <td>2.511589</td>\n",
              "      <td>0.728522</td>\n",
              "      <td>1.970628</td>\n",
              "      <td>1.455702</td>\n",
              "      <td>1.007613</td>\n",
              "      <td>0.257829</td>\n",
              "      <td>0.089567</td>\n",
              "      <td>958.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 78 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7ef7af1-eef7-459b-b105-710052397da7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7ef7af1-eef7-459b-b105-710052397da7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7ef7af1-eef7-459b-b105-710052397da7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    update  timestep  episode  elapsed_time  episode_return_pct  \\\n",
              "39     200     92288      112  12984.339746          160.172362   \n",
              "40     205     94848      113  13342.201170          144.682331   \n",
              "41     210     97408      113  13701.259389           93.120311   \n",
              "42     215     99968      115  14058.239728           68.148983   \n",
              "43     216    100000      115  14066.485792           78.524055   \n",
              "\n",
              "    episode_sharpe  episode_sortino  episode_max_dd  episode_volatility  \\\n",
              "39        0.698085         0.866149       30.670430            0.152975   \n",
              "40        0.602021         0.745132       31.341508            0.153894   \n",
              "41        0.304018         0.392391       39.369065            0.172854   \n",
              "42        0.702017         0.835756       30.053439            0.193406   \n",
              "43        0.649932         0.755351       30.247986            0.173939   \n",
              "\n",
              "    episode_win_rate  ...  actor_grad_norm  critic_grad_norm  alpha_min  \\\n",
              "39         52.907531  ...         1.145636          0.870696   0.416976   \n",
              "40         52.854594  ...         1.130851          0.504859   0.358140   \n",
              "41         52.252252  ...         1.224620          1.182268   0.810124   \n",
              "42         54.963427  ...         1.300989          2.885931   0.415817   \n",
              "43         55.036261  ...         2.661150          2.511589   0.728522   \n",
              "\n",
              "    alpha_max  alpha_mean  ratio_mean  ratio_std drawdown_lambda_peak  \\\n",
              "39   2.490606    1.454391    1.014433   0.329495             0.104402   \n",
              "40   2.738815    1.541263    1.003132   0.482642             0.108881   \n",
              "41   1.960325    1.430809    1.004731   0.192864             0.108881   \n",
              "42   2.477985    1.466220    1.009898   0.325248             0.089567   \n",
              "43   1.970628    1.455702    1.007613   0.257829             0.089567   \n",
              "\n",
              "    episode_length  termination_reason  \n",
              "39          2099.0      data_exhausted  \n",
              "40          2243.0      data_exhausted  \n",
              "41          2243.0      data_exhausted  \n",
              "42           958.0      data_exhausted  \n",
              "43           958.0      data_exhausted  \n",
              "\n",
              "[5 rows x 78 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if not eval_logs_dir.exists():\n",
        "    raise FileNotFoundError(f\"Missing logs dir: {eval_logs_dir}\")\n",
        "\n",
        "def eval_latest_csv(pattern):\n",
        "    files = sorted(eval_logs_dir.glob(pattern), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return files[0] if files else None\n",
        "\n",
        "eval_latest_episodes_csv = eval_latest_csv('*episodes*.csv')\n",
        "eval_latest_step_diag_csv = eval_latest_csv('*step_diagnostics*.csv')\n",
        "eval_latest_summary_csv = eval_latest_csv('*summary*.csv')\n",
        "\n",
        "print('episodes:', eval_latest_episodes_csv)\n",
        "print('step diagnostics:', eval_latest_step_diag_csv)\n",
        "print('summary:', eval_latest_summary_csv)\n",
        "\n",
        "if eval_latest_episodes_csv:\n",
        "    eval_episodes_df = pd.read_csv(eval_latest_episodes_csv)\n",
        "    display(eval_episodes_df.tail(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Checkpoint discovery and ablation basket construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All checkpoint pairs: 73\n",
            "By kind: {'high_watermark': 73}\n",
            "Selected for ablation: 15\n",
            "Forced requested: [60, 62, 69, 73, 75, 90, 100]\n",
            "Forced found: [60, 62, 69, 73, 75, 90, 100]\n",
            "Forced missing: []\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bea12fbf-241f-4120-896f-49b87bf71b5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>checkpoint_kind</th>\n",
              "      <th>episode</th>\n",
              "      <th>step</th>\n",
              "      <th>sharpe_tag</th>\n",
              "      <th>actor_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>1.822</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>3.251</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>15</td>\n",
              "      <td>None</td>\n",
              "      <td>1.810</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>26</td>\n",
              "      <td>None</td>\n",
              "      <td>1.929</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>31</td>\n",
              "      <td>None</td>\n",
              "      <td>2.546</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>36</td>\n",
              "      <td>None</td>\n",
              "      <td>1.798</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>49</td>\n",
              "      <td>None</td>\n",
              "      <td>1.567</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>58</td>\n",
              "      <td>None</td>\n",
              "      <td>1.893</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>60</td>\n",
              "      <td>None</td>\n",
              "      <td>1.303</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>62</td>\n",
              "      <td>None</td>\n",
              "      <td>0.598</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>69</td>\n",
              "      <td>None</td>\n",
              "      <td>1.099</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>73</td>\n",
              "      <td>None</td>\n",
              "      <td>0.760</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>75</td>\n",
              "      <td>None</td>\n",
              "      <td>0.595</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>90</td>\n",
              "      <td>None</td>\n",
              "      <td>1.494</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>high_watermark</td>\n",
              "      <td>100</td>\n",
              "      <td>None</td>\n",
              "      <td>0.654</td>\n",
              "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bea12fbf-241f-4120-896f-49b87bf71b5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bea12fbf-241f-4120-896f-49b87bf71b5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bea12fbf-241f-4120-896f-49b87bf71b5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   checkpoint_kind  episode  step  sharpe_tag  \\\n",
              "0   high_watermark        3  None       1.822   \n",
              "1   high_watermark        6  None       3.251   \n",
              "2   high_watermark       15  None       1.810   \n",
              "3   high_watermark       26  None       1.929   \n",
              "4   high_watermark       31  None       2.546   \n",
              "5   high_watermark       36  None       1.798   \n",
              "6   high_watermark       49  None       1.567   \n",
              "7   high_watermark       58  None       1.893   \n",
              "8   high_watermark       60  None       1.303   \n",
              "9   high_watermark       62  None       0.598   \n",
              "10  high_watermark       69  None       1.099   \n",
              "11  high_watermark       73  None       0.760   \n",
              "12  high_watermark       75  None       0.595   \n",
              "13  high_watermark       90  None       1.494   \n",
              "14  high_watermark      100  None       0.654   \n",
              "\n",
              "                                           actor_path  \n",
              "0   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "1   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "2   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "3   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "4   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "5   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "6   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "7   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "8   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "9   /content/eval_restore/tcn_fusion_results/high_...  \n",
              "10  /content/eval_restore/tcn_fusion_results/high_...  \n",
              "11  /content/eval_restore/tcn_fusion_results/high_...  \n",
              "12  /content/eval_restore/tcn_fusion_results/high_...  \n",
              "13  /content/eval_restore/tcn_fusion_results/high_...  \n",
              "14  /content/eval_restore/tcn_fusion_results/high_...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CHECKPOINT DISCOVERY + ABLATION BASKET (with forced episode includes)\n",
        "# ============================================================================\n",
        "\n",
        "#import re\n",
        "#from pathlib import Path\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "\n",
        "# -----------------------\n",
        "# Config knobs\n",
        "# -----------------------\n",
        "EVAL_TOP_ROOT = globals().get(\"EVAL_TOP_ROOT\", 2)\n",
        "EVAL_TOP_HW = globals().get(\"EVAL_TOP_HW\", 8)\n",
        "EVAL_TOP_PERIODIC = globals().get(\"EVAL_TOP_PERIODIC\", 4)\n",
        "EVAL_TOP_RARE = globals().get(\"EVAL_TOP_RARE\", 3)\n",
        "\n",
        "EVAL_INCLUDE_ROOT = globals().get(\"EVAL_INCLUDE_ROOT\", True)\n",
        "EVAL_INCLUDE_RARE = globals().get(\"EVAL_INCLUDE_RARE\", False)\n",
        "\n",
        "# Force-include these episodes even if they are not in top-sharpe basket\n",
        "EVAL_FORCE_EPISODES = globals().get(\"EVAL_FORCE_EPISODES\", [60, 62, 69, 73, 75, 90, 100])\n",
        "\n",
        "if \"EVAL_RESULTS_ROOT\" not in globals():\n",
        "    raise NameError(\"EVAL_RESULTS_ROOT is not defined\")\n",
        "\n",
        "EVAL_RESULTS_ROOT = Path(EVAL_RESULTS_ROOT)\n",
        "if not EVAL_RESULTS_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Missing results root: {EVAL_RESULTS_ROOT}\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Parse helpers\n",
        "# -----------------------\n",
        "def _ckpt_name(x) -> str:\n",
        "    return x.name if isinstance(x, Path) else str(x)\n",
        "\n",
        "\n",
        "def eval_parse_sharpe_from_name(x):\n",
        "    # Supports: ..._shp1p234... and ..._shm0p456...\n",
        "    name = _ckpt_name(x)\n",
        "    m = re.search(r\"_sh([pm])(\\d+)p(\\d+)\", name)\n",
        "    if not m:\n",
        "        return None\n",
        "    sign = 1.0 if m.group(1) == \"p\" else -1.0\n",
        "    return sign * float(f\"{m.group(2)}.{m.group(3)}\")\n",
        "\n",
        "\n",
        "def eval_parse_episode(x):\n",
        "    name = _ckpt_name(x)\n",
        "    m = re.search(r\"_ep(\\d+)\", name)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "\n",
        "def eval_parse_step(x):\n",
        "    name = _ckpt_name(x)\n",
        "    m = re.search(r\"_step(\\d+)\", name)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Discovery\n",
        "# -----------------------\n",
        "def eval_discover_actor_files(results_root: Path) -> pd.DataFrame:\n",
        "    actors = sorted(results_root.rglob(\"*_actor.weights.h5\"))\n",
        "    rows = []\n",
        "\n",
        "    for actor in actors:\n",
        "        prefix = str(actor).replace(\"_actor.weights.h5\", \"\")\n",
        "        critic = Path(prefix + \"_critic.weights.h5\")\n",
        "        if not critic.exists():\n",
        "            continue\n",
        "\n",
        "        parent_name = actor.parent.name\n",
        "        if parent_name == \"high_watermark_checkpoints\":\n",
        "            kind = \"high_watermark\"\n",
        "        elif parent_name == \"step_sharpe_checkpoints\":\n",
        "            kind = \"step_sharpe\"\n",
        "        elif parent_name == \"rare_models\":\n",
        "            kind = \"rare\"\n",
        "        elif eval_parse_step(actor) is not None:\n",
        "            kind = \"periodic_step\"\n",
        "        else:\n",
        "            kind = \"root\"\n",
        "\n",
        "        rows.append({\n",
        "            \"actor_path\": str(actor),\n",
        "            \"critic_path\": str(critic),\n",
        "            \"checkpoint_prefix\": prefix,\n",
        "            \"checkpoint_kind\": kind,\n",
        "            \"episode\": eval_parse_episode(actor),\n",
        "            \"step\": eval_parse_step(actor),\n",
        "            \"sharpe_tag\": eval_parse_sharpe_from_name(actor),\n",
        "            \"mtime\": actor.stat().st_mtime,\n",
        "        })\n",
        "\n",
        "    cols = [\n",
        "        \"actor_path\", \"critic_path\", \"checkpoint_prefix\",\n",
        "        \"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"mtime\"\n",
        "    ]\n",
        "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Basket selection\n",
        "# -----------------------\n",
        "def eval_select_ablation_basket(df_ckpt: pd.DataFrame) -> pd.DataFrame:\n",
        "    picks = []\n",
        "\n",
        "    if EVAL_INCLUDE_ROOT:\n",
        "        root_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"root\"].copy()\n",
        "        if not root_df.empty:\n",
        "            picks.append(root_df.sort_values(\"mtime\", ascending=False).head(EVAL_TOP_ROOT))\n",
        "\n",
        "    hw_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"high_watermark\"].copy()\n",
        "    if not hw_df.empty:\n",
        "        hw_df[\"sharpe_rank_key\"] = hw_df[\"sharpe_tag\"].fillna(-np.inf)\n",
        "        picks.append(\n",
        "            hw_df.sort_values(\n",
        "                [\"sharpe_rank_key\", \"episode\", \"mtime\"],\n",
        "                ascending=[False, False, False]\n",
        "            ).head(EVAL_TOP_HW)\n",
        "        )\n",
        "\n",
        "    periodic_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"periodic_step\"].copy()\n",
        "    if not periodic_df.empty:\n",
        "        picks.append(\n",
        "            periodic_df.sort_values([\"step\", \"mtime\"], ascending=[False, False]).head(EVAL_TOP_PERIODIC)\n",
        "        )\n",
        "\n",
        "    if EVAL_INCLUDE_RARE:\n",
        "        rare_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"rare\"].copy()\n",
        "        if not rare_df.empty:\n",
        "            rare_df[\"sharpe_rank_key\"] = rare_df[\"sharpe_tag\"].fillna(-np.inf)\n",
        "            picks.append(\n",
        "                rare_df.sort_values(\n",
        "                    [\"sharpe_rank_key\", \"episode\", \"mtime\"],\n",
        "                    ascending=[False, False, False]\n",
        "                ).head(EVAL_TOP_RARE)\n",
        "            )\n",
        "\n",
        "    out = pd.concat(picks, ignore_index=True) if picks else pd.DataFrame(columns=df_ckpt.columns)\n",
        "\n",
        "    # Force include specific episodes (prefer high_watermark/root)\n",
        "    if EVAL_FORCE_EPISODES:\n",
        "        forced = df_ckpt[\n",
        "            (df_ckpt[\"episode\"].isin(EVAL_FORCE_EPISODES)) &\n",
        "            (df_ckpt[\"checkpoint_kind\"].isin([\"high_watermark\", \"root\"]))\n",
        "        ].copy()\n",
        "        if not forced.empty:\n",
        "            out = pd.concat([out, forced], ignore_index=True)\n",
        "\n",
        "    out = out.drop_duplicates(subset=[\"checkpoint_prefix\"]).reset_index(drop=True)\n",
        "    out = out.sort_values(\n",
        "        [\"checkpoint_kind\", \"episode\", \"sharpe_tag\", \"step\", \"mtime\"],\n",
        "        ascending=[True, True, False, False, False]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Run\n",
        "# -----------------------\n",
        "eval_ckpt_df = eval_discover_actor_files(EVAL_RESULTS_ROOT)\n",
        "if eval_ckpt_df.empty:\n",
        "    raise RuntimeError(f\"No valid actor+critic checkpoint pairs found under {EVAL_RESULTS_ROOT}\")\n",
        "\n",
        "print(\"All checkpoint pairs:\", len(eval_ckpt_df))\n",
        "print(\"By kind:\", eval_ckpt_df[\"checkpoint_kind\"].value_counts().to_dict())\n",
        "\n",
        "eval_ablation_ckpts = eval_select_ablation_basket(eval_ckpt_df)\n",
        "\n",
        "found_forced = sorted(\n",
        "    set(eval_ablation_ckpts[\"episode\"].dropna().astype(int).tolist()) & set(EVAL_FORCE_EPISODES)\n",
        ")\n",
        "missing_forced = sorted(set(EVAL_FORCE_EPISODES) - set(found_forced))\n",
        "\n",
        "print(\"Selected for ablation:\", len(eval_ablation_ckpts))\n",
        "print(\"Forced requested:\", EVAL_FORCE_EPISODES)\n",
        "print(\"Forced found:\", found_forced)\n",
        "print(\"Forced missing:\", missing_forced)\n",
        "\n",
        "display(\n",
        "    eval_ablation_ckpts[\n",
        "        [\"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"actor_path\"]\n",
        "    ].head(100)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Evaluate ablation basket (deterministic + stochastic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1/15] Evaluating: high_watermark__ep0003__step-00001\n",
            "\n",
            "================================================================================\n",
            "LOADING CUSTOM CHECKPOINT: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p822\n",
            "================================================================================\n",
            "âœ… Found actor weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p822_actor.weights.h5\n",
            "âœ… Found critic weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p822_critic.weights.h5\n",
            "ðŸ—ï¸ Recreating evaluation environments...\n",
            "ðŸ”§ Building models before loading weights...\n",
            "   âœ… Models built successfully\n",
            "ðŸ“‚ Loading checkpoint weights...\n",
            "âŒ Failed high_watermark__ep0003__step-00001: ValueError: A total of 10 objects could not be loaded. Example error message for object <Dense name=tcn_fusion_actor_asset_projection, built=True>:\n",
            "\n",
            "Layer 'tcn_fusion_actor_asset_projection' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n",
            "\n",
            "List of objects that could not be loaded:\n",
            "[<Dense name=tcn_fusion_actor_asset_projection, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_0_conv1, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_0_conv2, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_0_downsample, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_1_conv1, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_1_conv2, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_1_downsample, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_2_conv1, built=True>, <Conv1D name=tcn_fusion_actor_asset_tcn_2_conv2, built=True>, <Dense name=tcn_fusion_actor_global_projection, built=True>]\n",
            "\n",
            "[2/15] Evaluating: high_watermark__ep0006__step-00001\n",
            "\n",
            "================================================================================\n",
            "LOADING CUSTOM CHECKPOINT: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p251\n",
            "================================================================================\n",
            "âœ… Found actor weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p251_actor.weights.h5\n",
            "âœ… Found critic weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p251_critic.weights.h5\n",
            "ðŸ—ï¸ Recreating evaluation environments...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3082204645.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[{i+1}/{len(eval_ablation_ckpts)}] Evaluating: {label}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_run_one_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_phase1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEVAL_RANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0meval_evaluations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3082204645.py\u001b[0m in \u001b[0;36meval_run_one_checkpoint\u001b[0;34m(eval_cfg, phase1_data, ckpt_prefix, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     return evaluate_experiment6_checkpoint(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mexperiment6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mphase1_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphase1_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/adaptive_portfolio_rl/src/notebook_helpers/tcn_phase1.py\u001b[0m in \u001b[0;36mevaluate_experiment6_checkpoint\u001b[0;34m(experiment6, phase1_data, config, random_seed, use_final_model, use_rare_model, checkpoint_episode, use_clip_checkpoint, clip_episode, model_family, normal_model_strategy, rare_model_strategy, num_eval_runs, stochastic_episode_length_limit, sample_actions, sample_actions_deterministic, sample_actions_stochastic, deterministic_eval_mode, compare_deterministic_modes, stochastic_eval_mode, checkpoint_path_override, save_eval_logs, save_eval_artifacts)\u001b[0m\n\u001b[1;32m   3525\u001b[0m     )\n\u001b[1;32m   3526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3527\u001b[0;31m     env_test_random = PortfolioEnvTAPE(\n\u001b[0m\u001b[1;32m   3528\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3529\u001b[0m         \u001b[0mdata_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/adaptive_portfolio_rl/src/environment_tape_rl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, data_processor, processed_data, mode, start_idx, end_idx, action_normalization, exclude_covariance, random_start, episode_length_limit, terminal_reward_metric, reward_system, tape_profile, tape_terminal_scalar, tape_terminal_clip, tape_terminal_bonus_mode, tape_terminal_baseline, tape_terminal_neutral_band_enabled, tape_terminal_neutral_band_halfwidth, tape_terminal_gate_a_enabled, tape_terminal_gate_a_sharpe_threshold, tape_terminal_gate_a_max_drawdown, dsr_window, dsr_scalar, target_turnover, turnover_penalty_scalar, turnover_target_band, action_execution_beta, gamma, enable_base_reward, drawdown_constraint)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;31m# Build feature matrix: (days, features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Define action space: continuous weights for N assets + cash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/adaptive_portfolio_rl/src/environment_tape_rl.py\u001b[0m in \u001b[0;36m_build_feature_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mday_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0mday_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_day_data_by_ticker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4093\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4147\u001b[0m         \u001b[0;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4149\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0;31m# key might be object-dtype bool, check_array_indexer needs bool array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m         \u001b[0;31m# GH 33924\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m         \u001b[0;31m# key may contain nan elements, check_array_indexer needs bool array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/inference.py\u001b[0m in \u001b[0;36mis_array_like\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \"\"\"\n\u001b[1;32m    197\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def eval_run_one_checkpoint(eval_cfg, phase1_data, ckpt_prefix, seed=42):\n",
        "    stub = create_experiment6_result_stub(\n",
        "        random_seed=seed,\n",
        "        use_covariance=True,\n",
        "        architecture=eval_cfg[\"agent_params\"][\"actor_critic_type\"],\n",
        "        checkpoint_path=ckpt_prefix,\n",
        "        agent_config=copy.deepcopy(eval_cfg[\"agent_params\"]),  # important\n",
        "        base_agent_params=None,\n",
        "    )\n",
        "\n",
        "\n",
        "    return evaluate_experiment6_checkpoint(\n",
        "        experiment6=stub,\n",
        "        phase1_data=phase1_data,\n",
        "        config=eval_cfg,\n",
        "        random_seed=seed,\n",
        "        checkpoint_path_override=ckpt_prefix,\n",
        "        deterministic_eval_mode=EVAL_DETERMINISTIC_MODE,\n",
        "        num_eval_runs=EVAL_NUM_STOCHASTIC_RUNS,\n",
        "        stochastic_episode_length_limit=EVAL_STOCHASTIC_EPISODE_LIMIT,\n",
        "        save_eval_logs=EVAL_SAVE_LOGS,\n",
        "        save_eval_artifacts=EVAL_SAVE_ARTIFACTS,\n",
        "    )\n",
        "\n",
        "\n",
        "eval_evaluations = {}\n",
        "eval_failures = {}\n",
        "\n",
        "for i, row in eval_ablation_ckpts.iterrows():\n",
        "    ep = int(row[\"episode\"]) if pd.notna(row[\"episode\"]) else -1\n",
        "    st = int(row[\"step\"]) if pd.notna(row[\"step\"]) else -1\n",
        "    label = f\"{row['checkpoint_kind']}__ep{ep:04d}__step{st:06d}\"\n",
        "    prefix = row[\"checkpoint_prefix\"]\n",
        "\n",
        "    print(f\"\\n[{i+1}/{len(eval_ablation_ckpts)}] Evaluating: {label}\")\n",
        "    try:\n",
        "        ev = eval_run_one_checkpoint(eval_config, eval_phase1_data, prefix, seed=EVAL_RANDOM_SEED)\n",
        "        eval_evaluations[label] = ev\n",
        "    except Exception as e:\n",
        "        eval_failures[label] = f\"{type(e).__name__}: {e}\"\n",
        "        print(f\"âŒ Failed {label}: {eval_failures[label]}\")\n",
        "\n",
        "print(\"âœ… Completed evaluations:\", len(eval_evaluations))\n",
        "print(\"âš ï¸ Failed evaluations:\", len(eval_failures))\n",
        "\n",
        "if eval_failures:\n",
        "    print(\"\\nFailure samples:\")\n",
        "    for k, v in list(eval_failures.items())[:10]:\n",
        "        print(\" -\", k, \"->\", v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Ablation table and leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not eval_evaluations:\n",
        "    raise RuntimeError('No successful evaluations to summarize.')\n",
        "\n",
        "eval_ablation_table = build_ablation_table(eval_evaluations)\n",
        "\n",
        "display(eval_ablation_table.head(30))\n",
        "\n",
        "# Deterministic-first leaderboard view\n",
        "eval_leaderboard = eval_ablation_table.copy()\n",
        "eval_leaderboard['risk_adjusted_score'] = (\n",
        "    eval_leaderboard['det_sharpe'].fillna(-999)\n",
        "    - 0.5 * eval_leaderboard['det_max_drawdown'].fillna(1.0)\n",
        "    - 0.1 * eval_leaderboard['det_turnover'].fillna(1.0)\n",
        ")\n",
        "eval_leaderboard = eval_leaderboard.sort_values(['risk_adjusted_score', 'det_sharpe'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "print('Top by risk-adjusted score:')\n",
        "display(eval_leaderboard.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Build industry baseline returns (equal-weight and cash)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_identify_asset_column(df: pd.DataFrame):\n",
        "    candidates = ['Ticker', 'ticker', 'tic', 'asset', 'Asset', 'symbol', 'Symbol']\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "\n",
        "def eval_identify_return_column(df: pd.DataFrame):\n",
        "    candidates = ['LogReturn_1d', 'log_return_1d', 'Return_1d', 'return_1d', 'daily_return']\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "\n",
        "def eval_fetch_sp500_returns(start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Fetch S&P500 daily simple returns for benchmark comparison.\n",
        "    Primary source: yfinance '^GSPC'.\n",
        "    Fallback: empty series if fetch fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import yfinance as yf\n",
        "    except Exception:\n",
        "        try:\n",
        "            !pip -q install yfinance\n",
        "            import yfinance as yf\n",
        "        except Exception:\n",
        "            print('âš ï¸ Could not install/import yfinance; SP500 benchmark disabled.')\n",
        "            return pd.Series(dtype=float)\n",
        "\n",
        "    try:\n",
        "        df = yf.download('^GSPC', start=str(start_date.date()), end=str((end_date + pd.Timedelta(days=1)).date()), auto_adjust=True, progress=False)\n",
        "        if df is None or df.empty or 'Close' not in df.columns:\n",
        "            print('âš ï¸ SP500 download returned empty data.')\n",
        "            return pd.Series(dtype=float)\n",
        "        close = pd.Series(df['Close']).dropna()\n",
        "        ret = close.pct_change().dropna().astype(float)\n",
        "        ret.index = pd.to_datetime(ret.index)\n",
        "        return ret\n",
        "    except Exception as e:\n",
        "        print(f'âš ï¸ SP500 fetch failed: {type(e).__name__}: {e}')\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "\n",
        "def eval_build_baselines_from_phase1(phase1_data):\n",
        "    test_df = phase1_data.test_df.copy()\n",
        "    if 'Date' not in test_df.columns:\n",
        "        raise ValueError('test_df must contain Date column')\n",
        "\n",
        "    ret_col = eval_identify_return_column(test_df)\n",
        "    if ret_col is None:\n",
        "        raise ValueError('Could not identify return column in test_df')\n",
        "\n",
        "    if 'LogReturn' in ret_col or 'log' in ret_col.lower():\n",
        "        test_df['_simple_ret'] = np.expm1(test_df[ret_col].astype(float))\n",
        "    else:\n",
        "        test_df['_simple_ret'] = test_df[ret_col].astype(float)\n",
        "\n",
        "    # Industry baseline 1: equal-weight over available assets each day\n",
        "    eqw = (\n",
        "        test_df.groupby('Date')['_simple_ret']\n",
        "        .mean()\n",
        "        .sort_index()\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    # Industry baseline 2: cash (0% daily return)\n",
        "    cash = pd.Series(np.zeros(len(eqw)), index=pd.to_datetime(eqw.index), name='cash')\n",
        "\n",
        "    # Industry baseline 3: S&P 500 (^GSPC)\n",
        "    dt_index = pd.to_datetime(eqw.index)\n",
        "    sp500_ret = eval_fetch_sp500_returns(dt_index.min(), dt_index.max())\n",
        "    if not sp500_ret.empty:\n",
        "        # align to model dates; missing market holidays become 0 return for alignment stability\n",
        "        sp500_ret = sp500_ret.reindex(dt_index).fillna(0.0)\n",
        "    else:\n",
        "        sp500_ret = pd.Series(dtype=float)\n",
        "\n",
        "    # reset to plain 0..n index for compare_agent_vs_baseline\n",
        "    eqw = eqw.reset_index(drop=True)\n",
        "    cash = cash.reset_index(drop=True)\n",
        "    sp500 = sp500_ret.reset_index(drop=True) if not sp500_ret.empty else pd.Series(dtype=float)\n",
        "    return eqw, cash, sp500\n",
        "\n",
        "\n",
        "eval_baseline_eqw, eval_baseline_cash, eval_baseline_sp500 = eval_build_baselines_from_phase1(eval_phase1_data)\n",
        "print('Baseline lengths | EQW:', len(eval_baseline_eqw), 'Cash:', len(eval_baseline_cash), 'SP500:', len(eval_baseline_sp500))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Benchmark each evaluated checkpoint vs baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "benchmark_rows = []\n",
        "for label, ev in eval_evaluations.items():\n",
        "    try:\n",
        "        cmp_eqw = compare_agent_vs_baseline(ev, eval_baseline_eqw)\n",
        "    except Exception as e:\n",
        "        cmp_eqw = {'error': str(e)}\n",
        "\n",
        "    try:\n",
        "        cmp_cash = compare_agent_vs_baseline(ev, eval_baseline_cash)\n",
        "    except Exception as e:\n",
        "        cmp_cash = {'error': str(e)}\n",
        "\n",
        "    try:\n",
        "        if len(eval_baseline_sp500) > 0:\n",
        "            cmp_sp500 = compare_agent_vs_baseline(ev, eval_baseline_sp500)\n",
        "        else:\n",
        "            cmp_sp500 = {'error': 'SP500 baseline unavailable'}\n",
        "    except Exception as e:\n",
        "        cmp_sp500 = {'error': str(e)}\n",
        "\n",
        "    row = {\n",
        "        'label': label,\n",
        "        'det_sharpe': (ev.deterministic_metrics or {}).get('sharpe_ratio', np.nan),\n",
        "        'det_return': (ev.deterministic_metrics or {}).get('annualized_return', np.nan),\n",
        "        'det_mdd': (ev.deterministic_metrics or {}).get('max_drawdown_abs', np.nan),\n",
        "        'det_turnover': (ev.deterministic_metrics or {}).get('turnover', np.nan),\n",
        "    }\n",
        "\n",
        "    for prefix, comp in [('eqw', cmp_eqw), ('cash', cmp_cash), ('sp500', cmp_sp500)]:\n",
        "        if isinstance(comp, dict) and 'error' not in comp:\n",
        "            for k, v in comp.items():\n",
        "                row[f'{prefix}_{k}'] = v\n",
        "        else:\n",
        "            row[f'{prefix}_error'] = comp.get('error', 'unknown') if isinstance(comp, dict) else 'unknown'\n",
        "\n",
        "    benchmark_rows.append(row)\n",
        "\n",
        "eval_benchmark_df = pd.DataFrame(benchmark_rows)\n",
        "\n",
        "display(eval_benchmark_df.sort_values('det_sharpe', ascending=False).head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Champion selection (production candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if eval_benchmark_df.empty:\n",
        "    raise RuntimeError('No benchmark rows available.')\n",
        "\n",
        "# Balanced production-style objective: reward risk-adjusted return, penalize drawdown/turnover.\n",
        "eval_benchmark_df['selection_score'] = (\n",
        "    eval_benchmark_df['det_sharpe'].fillna(-999)\n",
        "    + 0.2 * eval_benchmark_df['det_return'].fillna(0.0)\n",
        "    - 0.7 * eval_benchmark_df['det_mdd'].fillna(1.0)\n",
        "    - 0.1 * eval_benchmark_df['det_turnover'].fillna(1.0)\n",
        ")\n",
        "\n",
        "champion_row = eval_benchmark_df.sort_values('selection_score', ascending=False).iloc[0]\n",
        "EVAL_CHAMPION_LABEL = champion_row['label']\n",
        "EVAL_CHAMPION = eval_evaluations[EVAL_CHAMPION_LABEL]\n",
        "\n",
        "print('ðŸ† Champion label:', EVAL_CHAMPION_LABEL)\n",
        "print(champion_row[['det_sharpe', 'det_return', 'det_mdd', 'det_turnover', 'selection_score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13) Regime-sliced performance (champion vs equal-weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_regime_tag(dates: pd.Series):\n",
        "    d = pd.to_datetime(dates)\n",
        "    conds = [\n",
        "        (d <= pd.Timestamp('2020-02-19')),\n",
        "        (d >= pd.Timestamp('2020-02-20')) & (d <= pd.Timestamp('2020-06-30')),\n",
        "        (d >= pd.Timestamp('2020-07-01')) & (d <= pd.Timestamp('2021-12-31')),\n",
        "        (d >= pd.Timestamp('2022-01-01')) & (d <= pd.Timestamp('2023-12-31')),\n",
        "        (d >= pd.Timestamp('2024-01-01')),\n",
        "    ]\n",
        "    labels = ['pre_covid', 'covid_crash', 'post_covid_recovery', 'inflation_rates', 'recent']\n",
        "    out = np.select(conds, labels, default='other')\n",
        "    return pd.Series(out)\n",
        "\n",
        "\n",
        "def eval_sharpe(x):\n",
        "    x = pd.Series(x).dropna()\n",
        "    if len(x) < 2:\n",
        "        return np.nan\n",
        "    std = x.std(ddof=1)\n",
        "    if std <= 1e-12:\n",
        "        return np.nan\n",
        "    return np.sqrt(252.0) * x.mean() / std\n",
        "\n",
        "# Build aligned daily return series for champion and baselines\n",
        "champ_port = np.array(EVAL_CHAMPION.deterministic_portfolio)\n",
        "champ_ret = pd.Series(np.diff(champ_port) / champ_port[:-1]).reset_index(drop=True)\n",
        "eqw_ret = eval_baseline_eqw.reset_index(drop=True)\n",
        "sp500_ret = eval_baseline_sp500.reset_index(drop=True) if len(eval_baseline_sp500) > 0 else pd.Series(dtype=float)\n",
        "\n",
        "n_core = min(len(champ_ret), len(eqw_ret), len(eval_phase1_data.test_df['Date'].drop_duplicates()) - 1)\n",
        "if len(sp500_ret) > 0:\n",
        "    n = min(n_core, len(sp500_ret))\n",
        "else:\n",
        "    n = n_core\n",
        "\n",
        "dates = pd.to_datetime(eval_phase1_data.test_df['Date'].drop_duplicates().sort_values()).reset_index(drop=True).iloc[1:n+1]\n",
        "\n",
        "reg_df = pd.DataFrame({\n",
        "    'Date': dates.reset_index(drop=True),\n",
        "    'champion_ret': champ_ret.iloc[:n].reset_index(drop=True),\n",
        "    'eqw_ret': eqw_ret.iloc[:n].reset_index(drop=True),\n",
        "})\n",
        "if len(sp500_ret) > 0:\n",
        "    reg_df['sp500_ret'] = sp500_ret.iloc[:n].reset_index(drop=True)\n",
        "else:\n",
        "    reg_df['sp500_ret'] = np.nan\n",
        "\n",
        "reg_df['regime'] = eval_regime_tag(reg_df['Date'])\n",
        "\n",
        "regime_rows = []\n",
        "for regime, g in reg_df.groupby('regime'):\n",
        "    row = {\n",
        "        'regime': regime,\n",
        "        'n_days': len(g),\n",
        "        'champion_sharpe': eval_sharpe(g['champion_ret']),\n",
        "        'eqw_sharpe': eval_sharpe(g['eqw_ret']),\n",
        "        'champion_total_return': float((1.0 + g['champion_ret']).prod() - 1.0),\n",
        "        'eqw_total_return': float((1.0 + g['eqw_ret']).prod() - 1.0),\n",
        "    }\n",
        "    if g['sp500_ret'].notna().any():\n",
        "        row['sp500_sharpe'] = eval_sharpe(g['sp500_ret'])\n",
        "        row['sp500_total_return'] = float((1.0 + g['sp500_ret'].fillna(0.0)).prod() - 1.0)\n",
        "    else:\n",
        "        row['sp500_sharpe'] = np.nan\n",
        "        row['sp500_total_return'] = np.nan\n",
        "    regime_rows.append(row)\n",
        "\n",
        "eval_regime_df = pd.DataFrame(regime_rows).sort_values('regime').reset_index(drop=True)\n",
        "display(eval_regime_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14) Statistical confidence: bootstrap Sharpe difference (champion - equal-weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_block_bootstrap_sharpe_diff(agent_ret, base_ret, n_boot=2000, block=20, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    a = np.asarray(agent_ret, dtype=float)\n",
        "    b = np.asarray(base_ret, dtype=float)\n",
        "    n = min(len(a), len(b))\n",
        "    a = a[:n]\n",
        "    b = b[:n]\n",
        "\n",
        "    def _sharpe(x):\n",
        "        x = pd.Series(x).dropna()\n",
        "        if len(x) < 2:\n",
        "            return np.nan\n",
        "        s = x.std(ddof=1)\n",
        "        if s <= 1e-12:\n",
        "            return np.nan\n",
        "        return np.sqrt(252.0) * x.mean() / s\n",
        "\n",
        "    diffs = []\n",
        "    n_blocks = int(np.ceil(n / block))\n",
        "    max_start = max(1, n - block + 1)\n",
        "\n",
        "    for _ in range(n_boot):\n",
        "        idx = []\n",
        "        for __ in range(n_blocks):\n",
        "            st = int(rng.integers(0, max_start))\n",
        "            idx.extend(range(st, min(st + block, n)))\n",
        "        idx = np.asarray(idx[:n])\n",
        "        d = _sharpe(a[idx]) - _sharpe(b[idx])\n",
        "        if np.isfinite(d):\n",
        "            diffs.append(float(d))\n",
        "\n",
        "    if not diffs:\n",
        "        return {'n_boot_eff': 0, 'mean': np.nan, 'ci_low': np.nan, 'ci_high': np.nan, 'p_le_zero': np.nan}\n",
        "\n",
        "    diffs = np.asarray(diffs)\n",
        "    return {\n",
        "        'n_boot_eff': int(len(diffs)),\n",
        "        'mean': float(np.mean(diffs)),\n",
        "        'ci_low': float(np.quantile(diffs, 0.025)),\n",
        "        'ci_high': float(np.quantile(diffs, 0.975)),\n",
        "        'p_le_zero': float(np.mean(diffs <= 0.0)),\n",
        "    }\n",
        "\n",
        "bootstrap_eqw = eval_block_bootstrap_sharpe_diff(\n",
        "    reg_df['champion_ret'].values,\n",
        "    reg_df['eqw_ret'].values,\n",
        "    n_boot=2000,\n",
        "    block=20,\n",
        "    seed=EVAL_RANDOM_SEED,\n",
        ")\n",
        "\n",
        "if reg_df['sp500_ret'].notna().any():\n",
        "    bootstrap_sp500 = eval_block_bootstrap_sharpe_diff(\n",
        "        reg_df['champion_ret'].values,\n",
        "        reg_df['sp500_ret'].fillna(0.0).values,\n",
        "        n_boot=2000,\n",
        "        block=20,\n",
        "        seed=EVAL_RANDOM_SEED,\n",
        "    )\n",
        "else:\n",
        "    bootstrap_sp500 = {'n_boot_eff': 0, 'mean': np.nan, 'ci_low': np.nan, 'ci_high': np.nan, 'p_le_zero': np.nan}\n",
        "\n",
        "print('Bootstrap Sharpe diff (Champion - EQW):')\n",
        "print(bootstrap_eqw)\n",
        "print('Bootstrap Sharpe diff (Champion - SP500):')\n",
        "print(bootstrap_sp500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15) Training-diagnostics quality checks from CSV metrics\n",
        "Uses saved CSVs to report KL stability, turnover drivers, and execution quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diag_report = {}\n",
        "\n",
        "if eval_latest_episodes_csv and Path(eval_latest_episodes_csv).exists():\n",
        "    ep = pd.read_csv(eval_latest_episodes_csv)\n",
        "    diag_report['episodes_rows'] = len(ep)\n",
        "\n",
        "    if 'approx_kl' in ep.columns:\n",
        "        kl = pd.to_numeric(ep['approx_kl'], errors='coerce').dropna()\n",
        "        if len(kl):\n",
        "            diag_report['approx_kl_mean'] = float(kl.mean())\n",
        "            diag_report['approx_kl_p50'] = float(kl.quantile(0.50))\n",
        "            diag_report['approx_kl_p90'] = float(kl.quantile(0.90))\n",
        "\n",
        "    if {'episode_turnover_pct', 'approx_kl'}.issubset(ep.columns):\n",
        "        x = pd.to_numeric(ep['episode_turnover_pct'], errors='coerce')\n",
        "        y = pd.to_numeric(ep['approx_kl'], errors='coerce')\n",
        "        valid = x.notna() & y.notna()\n",
        "        if valid.any():\n",
        "            diag_report['corr_turnoverpct_kl'] = float(np.corrcoef(x[valid], y[valid])[0, 1])\n",
        "\n",
        "if eval_latest_step_diag_csv and Path(eval_latest_step_diag_csv).exists():\n",
        "    sd = pd.read_csv(eval_latest_step_diag_csv)\n",
        "    diag_report['step_diag_rows'] = len(sd)\n",
        "\n",
        "    for col in ['l1_w_delta', 'turnover_penalty_contrib', 'tx_cost_contrib_reward_pts', 'action_realization_l1']:\n",
        "        if col in sd.columns:\n",
        "            s = pd.to_numeric(sd[col], errors='coerce').dropna()\n",
        "            if len(s):\n",
        "                diag_report[f'{col}_mean'] = float(s.mean())\n",
        "                diag_report[f'{col}_p90'] = float(s.quantile(0.90))\n",
        "\n",
        "print(json.dumps(diag_report, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16) Save final evaluation package\n",
        "Exports leaderboard, benchmark table, regime table, diagnostics, and champion metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_out_dir = EVAL_RESULTS_ROOT / 'logs'\n",
        "eval_out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "eval_ablation_path = eval_out_dir / f'final_eval_ablation_{ts}.csv'\n",
        "eval_benchmark_path = eval_out_dir / f'final_eval_benchmark_{ts}.csv'\n",
        "eval_regime_path = eval_out_dir / f'final_eval_regime_{ts}.csv'\n",
        "eval_diag_path = eval_out_dir / f'final_eval_diagnostics_{ts}.json'\n",
        "eval_meta_path = eval_out_dir / f'final_eval_champion_{ts}.json'\n",
        "\n",
        "eval_ablation_table.to_csv(eval_ablation_path, index=False)\n",
        "eval_benchmark_df.to_csv(eval_benchmark_path, index=False)\n",
        "eval_regime_df.to_csv(eval_regime_path, index=False)\n",
        "\n",
        "with open(eval_diag_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump({\n",
        "        'bootstrap_sharpe_diff_eqw': bootstrap_eqw,\n",
        "        'bootstrap_sharpe_diff_sp500': bootstrap_sp500,\n",
        "        'diagnostics': diag_report,\n",
        "        'metadata_path': str(EVAL_METADATA_PATH),\n",
        "    }, f, indent=2)\n",
        "\n",
        "with open(eval_meta_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump({\n",
        "        'champion_label': EVAL_CHAMPION_LABEL,\n",
        "        'selection_row': champion_row.to_dict(),\n",
        "        'deterministic_metrics': EVAL_CHAMPION.deterministic_metrics,\n",
        "        'checkpoint_description': EVAL_CHAMPION.checkpoint_description,\n",
        "    }, f, indent=2, default=str)\n",
        "\n",
        "print('âœ… Saved evaluation package:')\n",
        "print('-', eval_ablation_path)\n",
        "print('-', eval_benchmark_path)\n",
        "print('-', eval_regime_path)\n",
        "print('-', eval_diag_path)\n",
        "print('-', eval_meta_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
