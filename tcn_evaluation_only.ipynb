{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Final Evaluation Notebook\n",
    "\n",
    "This notebook is evaluation-only and designed for final model selection, ablations, and benchmarking.\n",
    "All runtime variables are isolated with the `eval_` prefix to avoid conflicts with training notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Connect to Colab VM and sync repository\n",
    "Run this first in a fresh Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/adaptive_portfolio_rl\n",
      "HEAD is now at d9e114c Add RA-KL controller and enhance evaluation turnover diagnostics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "EVAL_REPO_URL = \"https://github.com/Dave-DKings/tape_tcn_project.git\"\n",
    "EVAL_REPO_DIR = \"/content/adaptive_portfolio_rl\"\n",
    "\n",
    "if not os.path.exists(f\"{EVAL_REPO_DIR}/.git\"):\n",
    "    !git clone {EVAL_REPO_URL} {EVAL_REPO_DIR}\n",
    "\n",
    "%cd /content/adaptive_portfolio_rl\n",
    "!git fetch origin\n",
    "!git reset --hard origin/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Optional: mount Drive and restore saved results zip\n",
    "Set `EVAL_RESTORE_FROM_ZIP=True` only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "âœ… Restored results from zip\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "EVAL_RESTORE_FROM_ZIP = True\n",
    "EVAL_ZIP_PATH = \"/content/drive/MyDrive/tcn_fusion_results_export2.zip\"\n",
    "\n",
    "if EVAL_RESTORE_FROM_ZIP:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    zip_path = Path(EVAL_ZIP_PATH)\n",
    "    if not zip_path.exists():\n",
    "        raise FileNotFoundError(f\"Zip not found: {zip_path}\")\n",
    "\n",
    "    !mkdir -p /content/adaptive_portfolio_rl\n",
    "    !unzip -q -o {zip_path} -d /content/adaptive_portfolio_rl\n",
    "    print(\"âœ… Restored results from zip\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ EVAL_RESTORE_FROM_ZIP=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d075602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip exists: True\n",
      "Archive:  /content/drive/MyDrive/tcn_fusion_results_export2.zip\n",
      "  Length      Date    Time    Name\n",
      "---------  ---------- -----   ----\n",
      "        0  2026-02-22 06:23   tcn_fusion_results/\n",
      "        0  2026-02-22 10:21   tcn_fusion_results/high_watermark_checkpoints/\n",
      "  1897264  2026-02-22 06:25   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp1p324_actor.weights.h5\n",
      "  1897264  2026-02-22 08:49   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00118_shp0p642_actor.weights.h5\n",
      "  1897264  2026-02-22 06:48   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00043_shp0p589_actor.weights.h5\n",
      "  1897264  2026-02-22 06:24   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp0p855_actor.weights.h5\n",
      "  1897264  2026-02-22 06:29   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00013_shp0p549_actor.weights.h5\n",
      "  1893680  2026-02-22 06:37   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p202_critic.weights.h5\n",
      "  1893680  2026-02-22 06:24   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp0p855_critic.weights.h5\n",
      "  1893680  2026-02-22 06:29   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00013_shp0p549_critic.weights.h5\n",
      "  1893680  2026-02-22 10:21   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00166_shp0p126_critic.weights.h5\n",
      "  1897264  2026-02-22 09:35   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00144_shp0p544_actor.weights.h5\n",
      "  1893680  2026-02-22 07:57   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00090_shp0p743_critic.weights.h5\n",
      "  1897264  2026-02-22 06:56   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00049_shp0p775_actor.weights.h5\n",
      "  1893680  2026-02-22 09:18   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00134_shp0p611_critic.weights.h5\n",
      "  1897264  2026-02-22 09:18   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00134_shp0p611_actor.weights.h5\n",
      "  1897264  2026-02-22 10:21   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00166_shp0p126_actor.weights.h5\n",
      "  1893680  2026-02-22 07:07   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00058_shp0p746_critic.weights.h5\n",
      "  1893680  2026-02-22 08:27   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00106_shp0p724_critic.weights.h5\n",
      "  1897264  2026-02-22 07:07   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00058_shp0p746_actor.weights.h5\n",
      "  1893680  2026-02-22 06:40   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00031_shp1p630_critic.weights.h5\n",
      "  1893680  2026-02-22 06:56   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00049_shp0p775_critic.weights.h5\n",
      "  1897264  2026-02-22 08:27   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00106_shp0p724_actor.weights.h5\n",
      "  1897264  2026-02-22 06:23   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p951_actor.weights.h5\n",
      "  1893680  2026-02-22 06:23   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p951_critic.weights.h5\n",
      "  1893680  2026-02-22 09:35   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00144_shp0p544_critic.weights.h5\n",
      "  1893680  2026-02-22 09:27   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00139_shp0p555_critic.weights.h5\n",
      "  1897264  2026-02-22 06:37   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p202_actor.weights.h5\n",
      "  1897264  2026-02-22 09:27   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00139_shp0p555_actor.weights.h5\n",
      "  1897264  2026-02-22 06:40   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00031_shp1p630_actor.weights.h5\n",
      "  1897264  2026-02-22 07:57   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00090_shp0p743_actor.weights.h5\n",
      "  1893680  2026-02-22 06:48   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00043_shp0p589_critic.weights.h5\n",
      "  1893680  2026-02-22 08:49   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00118_shp0p642_critic.weights.h5\n",
      "  1893680  2026-02-22 06:25   tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp1p324_critic.weights.h5\n",
      "        0  2026-02-22 10:21   tcn_fusion_results/logs/\n",
      "    16858  2026-02-22 10:21   tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_episodes.csv\n",
      "    31302  2026-02-22 10:21   tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_metadata.json\n",
      "/content/eval_restore/tcn_fusion_results logs: True actors: 16\n",
      "/content/eval_restore/tcn_fusion_results_export2/tcn_fusion_results logs: False actors: 0\n",
      "/content/eval_restore/tcn_fusion_results_export2 logs: False actors: 0\n",
      "âœ… EVAL_RESULTS_ROOT = /content/eval_restore/tcn_fusion_results\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "EVAL_ZIP_PATH = Path(\"/content/drive/MyDrive/tcn_fusion_results_export2.zip\")\n",
    "\n",
    "# 1) Verify zip exists\n",
    "print(\"zip exists:\", EVAL_ZIP_PATH.exists())\n",
    "if not EVAL_ZIP_PATH.exists():\n",
    "    raise FileNotFoundError(EVAL_ZIP_PATH)\n",
    "\n",
    "# 2) Inspect zip top-level structure\n",
    "!unzip -l \"{EVAL_ZIP_PATH}\" | head -n 40\n",
    "\n",
    "# 3) Extract to /content (clean target)\n",
    "!mkdir -p /content/eval_restore\n",
    "!unzip -q -o \"{EVAL_ZIP_PATH}\" -d /content/eval_restore\n",
    "\n",
    "# 4) Auto-detect correct results root\n",
    "candidates = [\n",
    "    Path(\"/content/eval_restore/tcn_fusion_results\"),\n",
    "    Path(\"/content/eval_restore/tcn_fusion_results_export2/tcn_fusion_results\"),\n",
    "    Path(\"/content/eval_restore/tcn_fusion_results_export2\"),\n",
    "]\n",
    "for c in candidates:\n",
    "    print(c, \"logs:\", (c / \"logs\").exists(), \"actors:\", len(list(c.rglob(\"*_actor.weights.h5\"))))\n",
    "\n",
    "EVAL_RESULTS_ROOT = next(\n",
    "    c for c in candidates\n",
    "    if (c / \"logs\").exists() and len(list(c.rglob(\"*_actor.weights.h5\"))) > 0\n",
    ")\n",
    "print(\"âœ… EVAL_RESULTS_ROOT =\", EVAL_RESULTS_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0432ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python: /usr/bin/python3\n",
      "âœ… Requirements installed\n"
     ]
    }
   ],
   "source": [
    "# Install project requirements in Colab VM\n",
    "import subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
    "REQ_FILE = REPO_DIR / \"requirements.txt\"\n",
    "\n",
    "if not REQ_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Missing requirements file: {REQ_FILE}\")\n",
    "\n",
    "print(\"Using python:\", sys.executable)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"], check=True)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REQ_FILE)], check=True)\n",
    "\n",
    "print(\"âœ… Requirements installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import re\n",
    "from dataclasses import replace\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import get_active_config\n",
    "from src.data_utils import DataProcessor\n",
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    prepare_phase1_dataset,\n",
    "    create_experiment6_result_stub,\n",
    "    evaluate_experiment6_checkpoint,\n",
    "    load_training_metadata_into_config,\n",
    "    build_evaluation_track_summary,\n",
    "    build_ablation_table,\n",
    "    compare_agent_vs_baseline,\n",
    "    Phase1Dataset,\n",
    "    split_dataset_by_date,\n",
    "    identify_covariance_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Evaluation run settings\n",
    "Adjust once here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_RANDOM_SEED = 42\n",
    "EVAL_RESULTS_ROOT = Path(\"/content/eval_restore/tcn_fusion_results\")\n",
    "\n",
    "# Deterministic policy mode: 'mean' is recommended for stable ranking.\n",
    "EVAL_DETERMINISTIC_MODE = 'mean'\n",
    "EVAL_STOCHASTIC_MODE = \"sample\"\n",
    "\n",
    "# Stochastic robustness checks per checkpoint.\n",
    "EVAL_NUM_STOCHASTIC_RUNS = 3\n",
    "EVAL_STOCHASTIC_EPISODE_LIMIT = 252\n",
    "\n",
    "# Selection for ablation basket\n",
    "EVAL_TOP_HW = 8         # high-watermark checkpoints by filename Sharpe tag\n",
    "EVAL_TOP_PERIODIC = 4   # periodic step checkpoints by most recent step\n",
    "EVAL_INCLUDE_ROOT = True\n",
    "EVAL_INCLUDE_RARE = False\n",
    "\n",
    "# Save outputs\n",
    "EVAL_SAVE_LOGS = True\n",
    "EVAL_SAVE_ARTIFACTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b53d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print((EVAL_RESULTS_ROOT / \"logs\").exists())\n",
    "print(len(list(EVAL_RESULTS_ROOT.rglob(\"*_actor.weights.h5\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815ad1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root exists: True\n",
      "logs exists: True\n",
      "actor ckpts: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"root exists:\", EVAL_RESULTS_ROOT.exists())\n",
    "print(\"logs exists:\", (EVAL_RESULTS_ROOT / \"logs\").exists())\n",
    "print(\"actor ckpts:\", len(list(EVAL_RESULTS_ROOT.rglob(\"*_actor.weights.h5\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Build evaluation dataset and load latest metadata config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c774d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval_phase1_data\" in globals():\n",
    "    del eval_phase1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Using metadata: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_metadata.json\n",
      "âœ… Applied training metadata to config\n",
      "   Metadata: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_metadata.json\n",
      "   Run timestamp: 20260222_062113\n",
      "   Architecture: TCN_FUSION\n",
      "   Turnover target: 0.35\n",
      "   DSR scalar: 2.0\n",
      "   PPO update timesteps: scheduled\n",
      "   Episode length curriculum: True\n",
      "   RA-KL enabled: True\n",
      "   Profile override loaded: True\n",
      "   Credit assignment mode: step_reward_plus_terminal_bonus\n",
      "   Retroactive episode scaling: False\n",
      "âœ… Eval metadata feature lock applied\n",
      "   trained active_feature_columns: 73\n",
      "   core feature_columns: 75\n",
      "   disabled_features: 25\n",
      "   expected active after lock: 50\n",
      "   state_layout asset/global dims: 37 36\n",
      "ðŸ“¦ Loading normalized master from: /content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\n",
      "================================================================================\n",
      "âœ‚ï¸  TIME-BASED TRAIN/TEST SPLIT (80/20 split)\n",
      "   Train: 2003-10-01 â†’ 2021-04-09 (4411 days, 17.5 years, 43867 rows)\n",
      "   Test:  2021-04-12 â†’ 2025-08-29 (1103 days, 4.4 years, 11030 rows)\n",
      "================================================================================\n",
      "âœ… Built eval_phase1_data from saved normalized master\n",
      "   Train shape: (43867, 105)\n",
      "   Test shape: (11030, 105)\n",
      "   Covariance cols: 3\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVAL CONFIG + FEATURE LOCK (metadata-trained layout) + DATASET BUILD\n",
    "# ============================================================================\n",
    "\n",
    "from src.config import get_active_config\n",
    "from src.data_utils import DataProcessor\n",
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    load_training_metadata_into_config,\n",
    "    Phase1Dataset,\n",
    "    prepare_phase1_dataset,\n",
    "    split_dataset_by_date,          # moved here\n",
    "    identify_covariance_columns,    # moved here\n",
    ")\n",
    "\n",
    "\n",
    "if not EVAL_RESULTS_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Missing results root: {EVAL_RESULTS_ROOT}\")\n",
    "\n",
    "\n",
    "def eval_extract_trained_state_layout(metadata_dict: dict):\n",
    "    arch = metadata_dict.get(\"Architecture_Settings\", {}) or {}\n",
    "\n",
    "    # Try effective first, then template\n",
    "    effective = arch.get(\"agent_params_effective\", {}) or {}\n",
    "    template = arch.get(\"agent_params_template\", {}) or {}\n",
    "\n",
    "    layout = effective.get(\"state_layout\")\n",
    "    if not isinstance(layout, dict) or not layout:\n",
    "        layout = template.get(\"state_layout\")\n",
    "\n",
    "    if not isinstance(layout, dict) or not layout:\n",
    "        raise ValueError(\"Could not find state_layout in metadata (agent_params_effective/template).\")\n",
    "\n",
    "    active_cols = layout.get(\"active_feature_columns\")\n",
    "    if not isinstance(active_cols, list) or not active_cols:\n",
    "        raise ValueError(\"state_layout.active_feature_columns missing/empty in metadata.\")\n",
    "\n",
    "    return layout, list(dict.fromkeys(active_cols))\n",
    "\n",
    "\n",
    "def eval_apply_metadata_feature_lock(cfg, trained_active_feature_columns):\n",
    "    probe_cfg = copy.deepcopy(cfg)\n",
    "    probe_fp = probe_cfg.setdefault(\"feature_params\", {})\n",
    "    probe_fs = probe_fp.setdefault(\"feature_selection\", {})\n",
    "    probe_fs[\"disable_features\"] = False\n",
    "    probe_fs[\"disabled_features\"] = []\n",
    "\n",
    "    probe = DataProcessor(probe_cfg)\n",
    "    core_all_cols = list(dict.fromkeys(probe.get_feature_columns(\"phase1\")))\n",
    "\n",
    "    trained_set = set(trained_active_feature_columns)\n",
    "    disabled = sorted([c for c in core_all_cols if c not in trained_set])\n",
    "\n",
    "    fp = cfg.setdefault(\"feature_params\", {})\n",
    "    fs = fp.setdefault(\"feature_selection\", {})\n",
    "    fs[\"disable_features\"] = True\n",
    "    fs[\"disabled_features\"] = disabled\n",
    "\n",
    "    return core_all_cols, disabled\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Build eval config from latest metadata\n",
    "# ------------------------------------------------------------------\n",
    "eval_config = copy.deepcopy(get_active_config(\"phase1\"))\n",
    "\n",
    "eval_logs_dir = EVAL_RESULTS_ROOT / \"logs\"\n",
    "meta_files = sorted(eval_logs_dir.glob(\"*_metadata.json\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not meta_files:\n",
    "    raise FileNotFoundError(f\"No metadata JSON in {eval_logs_dir}\")\n",
    "\n",
    "EVAL_METADATA_PATH = meta_files[0]\n",
    "print(\"ðŸ“„ Using metadata:\", EVAL_METADATA_PATH)\n",
    "\n",
    "with open(EVAL_METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_metadata = json.load(f)\n",
    "\n",
    "eval_config = load_training_metadata_into_config(\n",
    "    EVAL_METADATA_PATH,\n",
    "    copy.deepcopy(eval_config),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Enforce architecture family used by checkpoints\n",
    "eval_config[\"agent_params\"][\"actor_critic_type\"] = \"TCN_FUSION\"\n",
    "eval_config[\"agent_params\"][\"use_fusion\"] = True\n",
    "eval_config[\"agent_params\"][\"use_attention\"] = False\n",
    "\n",
    "# Extract trained state layout and lock features to it\n",
    "trained_state_layout, trained_active_feature_columns = eval_extract_trained_state_layout(eval_metadata)\n",
    "\n",
    "# Keep layout in config for agent reconstruction compatibility\n",
    "eval_config[\"agent_params\"][\"state_layout\"] = copy.deepcopy(trained_state_layout)\n",
    "eval_config[\"agent_params\"][\"asset_feature_dim\"] = int(trained_state_layout.get(\"asset_feature_dim\", 0) or 0)\n",
    "eval_config[\"agent_params\"][\"global_feature_dim\"] = int(trained_state_layout.get(\"global_feature_dim\", 0) or 0)\n",
    "eval_config[\"agent_params\"][\"num_assets\"] = int(trained_state_layout.get(\"num_assets\", 10) or 10)\n",
    "\n",
    "core_all_cols, eval_disabled_features = eval_apply_metadata_feature_lock(\n",
    "    eval_config, trained_active_feature_columns\n",
    ")\n",
    "\n",
    "print(\"âœ… Eval metadata feature lock applied\")\n",
    "print(\"   trained active_feature_columns:\", len(trained_active_feature_columns))\n",
    "print(\"   core feature_columns:\", len(core_all_cols))\n",
    "print(\"   disabled_features:\", len(eval_disabled_features))\n",
    "print(\"   expected active after lock:\", len(core_all_cols) - len(eval_disabled_features))\n",
    "print(\"   state_layout asset/global dims:\",\n",
    "      trained_state_layout.get(\"asset_feature_dim\"),\n",
    "      trained_state_layout.get(\"global_feature_dim\"))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Build eval dataset from SAVED normalized master features (no rebuild)\n",
    "# ------------------------------------------------------------------\n",
    "EVAL_USE_SAVED_NORMALIZED = True\n",
    "EVAL_FORCE_REBUILD_PHASE1 = True  # IMPORTANT: avoid stale globals from prior runs\n",
    "\n",
    "if EVAL_FORCE_REBUILD_PHASE1 and \"eval_phase1_data\" in globals():\n",
    "    del eval_phase1_data\n",
    "    print(\"ðŸ§¹ Cleared stale eval_phase1_data from runtime\")\n",
    "\n",
    "if \"eval_phase1_data\" in globals():\n",
    "    print(\"â„¹ï¸ Reusing eval_phase1_data from current runtime\")\n",
    "else:\n",
    "    if not EVAL_USE_SAVED_NORMALIZED:\n",
    "        eval_phase1_data = prepare_phase1_dataset(eval_config, force_download=False)\n",
    "    else:\n",
    "        normalized_candidates = [\n",
    "            EVAL_RESULTS_ROOT / \"data\" / \"master_features_NORMALIZED.csv\",\n",
    "            Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results_export2/data/master_features_NORMALIZED.csv\"),\n",
    "            Path(eval_config.get(\"BASE_DATA_PATH\", \"/content/adaptive_portfolio_rl/data\")) / \"master_features_NORMALIZED.csv\",\n",
    "            Path(\"/content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\"),\n",
    "        ]\n",
    "        normalized_path = next((p for p in normalized_candidates if p.exists()), None)\n",
    "        if normalized_path is None:\n",
    "            raise FileNotFoundError(\n",
    "                \"Could not find master_features_NORMALIZED.csv in expected locations:\\n\"\n",
    "                + \"\\n\".join(str(p) for p in normalized_candidates)\n",
    "            )\n",
    "\n",
    "        print(\"ðŸ“¦ Loading normalized master from:\", normalized_path)\n",
    "        master_df_norm = pd.read_csv(normalized_path)\n",
    "\n",
    "        if \"Date\" not in master_df_norm.columns:\n",
    "            raise ValueError(\"Normalized CSV missing required 'Date' column\")\n",
    "        if \"Ticker\" not in master_df_norm.columns:\n",
    "            raise ValueError(\"Normalized CSV missing required 'Ticker' column\")\n",
    "\n",
    "        master_df_norm[\"Date\"] = pd.to_datetime(\n",
    "            master_df_norm[\"Date\"], utc=True, errors=\"coerce\"\n",
    "        ).dt.tz_localize(None)\n",
    "        master_df_norm = master_df_norm.dropna(subset=[\"Date\"]).sort_values([\"Date\", \"Ticker\"]).reset_index(drop=True)\n",
    "\n",
    "        analysis_start = pd.to_datetime(eval_config.get(\"ANALYSIS_START_DATE\", \"2003-09-02\"))\n",
    "        analysis_end = pd.to_datetime(eval_config.get(\"ANALYSIS_END_DATE\", \"2025-09-01\"))\n",
    "        master_df_norm = master_df_norm[\n",
    "            (master_df_norm[\"Date\"] >= analysis_start) &\n",
    "            (master_df_norm[\"Date\"] <= analysis_end)\n",
    "        ].copy()\n",
    "\n",
    "        eval_processor = DataProcessor(eval_config)\n",
    "        expected_feature_cols = eval_processor.get_feature_columns(\"phase1\")\n",
    "        missing = [c for c in expected_feature_cols if c not in master_df_norm.columns]\n",
    "        if missing:\n",
    "            print(f\"âš ï¸ Missing expected feature columns in saved normalized CSV: {len(missing)}\")\n",
    "            print(\"   Sample:\", missing[:10])\n",
    "\n",
    "        split_date = eval_config.get(\"TRAIN_TEST_SPLIT_DATE\")\n",
    "        if split_date:\n",
    "            train_df, test_df, train_end_date, test_start_date = split_dataset_by_date(\n",
    "                master_df_norm, date_column=\"Date\", split_date=split_date\n",
    "            )\n",
    "        else:\n",
    "            train_df, test_df, train_end_date, test_start_date = split_dataset_by_date(\n",
    "                master_df_norm, date_column=\"Date\", train_fraction=0.8\n",
    "            )\n",
    "\n",
    "        eval_phase1_data = Phase1Dataset(\n",
    "            master_df=master_df_norm,\n",
    "            train_df=train_df,\n",
    "            test_df=test_df,\n",
    "            scalers={},\n",
    "            train_end_date=train_end_date,\n",
    "            test_start_date=test_start_date,\n",
    "            covariance_columns=identify_covariance_columns(master_df_norm.columns),\n",
    "            data_processor=eval_processor,\n",
    "        )\n",
    "\n",
    "        print(\"âœ… Built eval_phase1_data from saved normalized master\")\n",
    "        print(\"   Train shape:\", eval_phase1_data.train_df.shape)\n",
    "        print(\"   Test shape:\", eval_phase1_data.test_df.shape)\n",
    "        print(\"   Covariance cols:\", len(eval_phase1_data.covariance_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c64cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43867, 105) (11030, 105)\n",
      "Date min/max test: 2021-04-12 00:00:00 2025-08-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(eval_phase1_data.train_df.shape, eval_phase1_data.test_df.shape)\n",
    "print(\"Date min/max test:\", eval_phase1_data.test_df[\"Date\"].min(), eval_phase1_data.test_df[\"Date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Inspect latest training CSV logs (for diagnostics context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_episodes.csv\n",
      "step diagnostics: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_step_diagnostics.csv\n",
      "summary: /content/eval_restore/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260222_062113_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-42c8543c-b8de-4238-9322-99954115ed89\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>update</th>\n",
       "      <th>timestep</th>\n",
       "      <th>episode</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>episode_return_pct</th>\n",
       "      <th>episode_sharpe</th>\n",
       "      <th>episode_sortino</th>\n",
       "      <th>episode_max_dd</th>\n",
       "      <th>episode_volatility</th>\n",
       "      <th>episode_win_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>actor_grad_norm</th>\n",
       "      <th>critic_grad_norm</th>\n",
       "      <th>alpha_min</th>\n",
       "      <th>alpha_max</th>\n",
       "      <th>alpha_mean</th>\n",
       "      <th>ratio_mean</th>\n",
       "      <th>ratio_std</th>\n",
       "      <th>drawdown_lambda_peak</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>termination_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>180</td>\n",
       "      <td>72256</td>\n",
       "      <td>132</td>\n",
       "      <td>10471.297643</td>\n",
       "      <td>6.504814</td>\n",
       "      <td>0.078591</td>\n",
       "      <td>0.100861</td>\n",
       "      <td>18.612846</td>\n",
       "      <td>0.139238</td>\n",
       "      <td>51.655629</td>\n",
       "      <td>...</td>\n",
       "      <td>1.988872</td>\n",
       "      <td>0.224274</td>\n",
       "      <td>1.046454</td>\n",
       "      <td>3.156558</td>\n",
       "      <td>2.082150</td>\n",
       "      <td>1.000443</td>\n",
       "      <td>0.240029</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>756.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>81216</td>\n",
       "      <td>144</td>\n",
       "      <td>11743.819913</td>\n",
       "      <td>25.649109</td>\n",
       "      <td>0.543708</td>\n",
       "      <td>0.826669</td>\n",
       "      <td>15.613754</td>\n",
       "      <td>0.116102</td>\n",
       "      <td>52.980132</td>\n",
       "      <td>...</td>\n",
       "      <td>2.266486</td>\n",
       "      <td>0.117776</td>\n",
       "      <td>1.132757</td>\n",
       "      <td>3.103621</td>\n",
       "      <td>2.109309</td>\n",
       "      <td>0.986040</td>\n",
       "      <td>0.186952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>756.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>220</td>\n",
       "      <td>90176</td>\n",
       "      <td>156</td>\n",
       "      <td>13025.927910</td>\n",
       "      <td>7.450575</td>\n",
       "      <td>0.093699</td>\n",
       "      <td>0.129008</td>\n",
       "      <td>14.852449</td>\n",
       "      <td>0.114165</td>\n",
       "      <td>51.125828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.382765</td>\n",
       "      <td>0.115853</td>\n",
       "      <td>1.076166</td>\n",
       "      <td>3.175422</td>\n",
       "      <td>2.177220</td>\n",
       "      <td>0.965313</td>\n",
       "      <td>0.158254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>756.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>240</td>\n",
       "      <td>99136</td>\n",
       "      <td>165</td>\n",
       "      <td>14318.098720</td>\n",
       "      <td>11.466424</td>\n",
       "      <td>0.124307</td>\n",
       "      <td>0.167125</td>\n",
       "      <td>17.788045</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>52.730884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757308</td>\n",
       "      <td>0.043773</td>\n",
       "      <td>1.405392</td>\n",
       "      <td>3.048145</td>\n",
       "      <td>2.260119</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.153357</td>\n",
       "      <td>0.140682</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>242</td>\n",
       "      <td>100000</td>\n",
       "      <td>166</td>\n",
       "      <td>14442.332821</td>\n",
       "      <td>11.738086</td>\n",
       "      <td>0.126447</td>\n",
       "      <td>0.191022</td>\n",
       "      <td>19.116556</td>\n",
       "      <td>0.118607</td>\n",
       "      <td>50.148957</td>\n",
       "      <td>...</td>\n",
       "      <td>1.679471</td>\n",
       "      <td>0.102187</td>\n",
       "      <td>1.192190</td>\n",
       "      <td>3.092397</td>\n",
       "      <td>2.220290</td>\n",
       "      <td>1.000755</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>0.012580</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>episode_limit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42c8543c-b8de-4238-9322-99954115ed89')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-42c8543c-b8de-4238-9322-99954115ed89 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-42c8543c-b8de-4238-9322-99954115ed89');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    update  timestep  episode  elapsed_time  episode_return_pct  \\\n",
       "8      180     72256      132  10471.297643            6.504814   \n",
       "9      200     81216      144  11743.819913           25.649109   \n",
       "10     220     90176      156  13025.927910            7.450575   \n",
       "11     240     99136      165  14318.098720           11.466424   \n",
       "12     242    100000      166  14442.332821           11.738086   \n",
       "\n",
       "    episode_sharpe  episode_sortino  episode_max_dd  episode_volatility  \\\n",
       "8         0.078591         0.100861       18.612846            0.139238   \n",
       "9         0.543708         0.826669       15.613754            0.116102   \n",
       "10        0.093699         0.129008       14.852449            0.114165   \n",
       "11        0.124307         0.167125       17.788045            0.150664   \n",
       "12        0.126447         0.191022       19.116556            0.118607   \n",
       "\n",
       "    episode_win_rate  ...  actor_grad_norm  critic_grad_norm  alpha_min  \\\n",
       "8          51.655629  ...         1.988872          0.224274   1.046454   \n",
       "9          52.980132  ...         2.266486          0.117776   1.132757   \n",
       "10         51.125828  ...         1.382765          0.115853   1.076166   \n",
       "11         52.730884  ...         1.757308          0.043773   1.405392   \n",
       "12         50.148957  ...         1.679471          0.102187   1.192190   \n",
       "\n",
       "    alpha_max  alpha_mean  ratio_mean  ratio_std drawdown_lambda_peak  \\\n",
       "8    3.156558    2.082150    1.000443   0.240029             0.003053   \n",
       "9    3.103621    2.109309    0.986040   0.186952             0.000000   \n",
       "10   3.175422    2.177220    0.965313   0.158254             0.000000   \n",
       "11   3.048145    2.260119    0.996447   0.153357             0.140682   \n",
       "12   3.092397    2.220290    1.000755   0.176697             0.012580   \n",
       "\n",
       "    episode_length  termination_reason  \n",
       "8            756.0       episode_limit  \n",
       "9            756.0       episode_limit  \n",
       "10           756.0       episode_limit  \n",
       "11          1008.0       episode_limit  \n",
       "12          1008.0       episode_limit  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not eval_logs_dir.exists():\n",
    "    raise FileNotFoundError(f\"Missing logs dir: {eval_logs_dir}\")\n",
    "\n",
    "def eval_latest_csv(pattern):\n",
    "    files = sorted(eval_logs_dir.glob(pattern), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    return files[0] if files else None\n",
    "\n",
    "eval_latest_episodes_csv = eval_latest_csv('*episodes*.csv')\n",
    "eval_latest_step_diag_csv = eval_latest_csv('*step_diagnostics*.csv')\n",
    "eval_latest_summary_csv = eval_latest_csv('*summary*.csv')\n",
    "\n",
    "print('episodes:', eval_latest_episodes_csv)\n",
    "print('step diagnostics:', eval_latest_step_diag_csv)\n",
    "print('summary:', eval_latest_summary_csv)\n",
    "\n",
    "if eval_latest_episodes_csv:\n",
    "    eval_episodes_df = pd.read_csv(eval_latest_episodes_csv)\n",
    "    display(eval_episodes_df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Checkpoint discovery and ablation basket construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checkpoint pairs: 16\n",
      "By kind: {'high_watermark': 16}\n",
      "Selected for ablation: 8\n",
      "Forced requested: [60, 62, 69, 73, 75, 90, 100]\n",
      "Forced found: [90]\n",
      "Forced missing: [60, 62, 69, 73, 75, 100]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-490dd9e5-a7fa-4e35-ab4e-c50c662cde26\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint_kind</th>\n",
       "      <th>episode</th>\n",
       "      <th>step</th>\n",
       "      <th>sharpe_tag</th>\n",
       "      <th>actor_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0.951</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.855</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>1.324</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>1.202</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>1.630</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>49</td>\n",
       "      <td>None</td>\n",
       "      <td>0.775</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>58</td>\n",
       "      <td>None</td>\n",
       "      <td>0.746</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high_watermark</td>\n",
       "      <td>90</td>\n",
       "      <td>None</td>\n",
       "      <td>0.743</td>\n",
       "      <td>/content/eval_restore/tcn_fusion_results/high_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-490dd9e5-a7fa-4e35-ab4e-c50c662cde26')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-490dd9e5-a7fa-4e35-ab4e-c50c662cde26 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-490dd9e5-a7fa-4e35-ab4e-c50c662cde26');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  checkpoint_kind  episode  step  sharpe_tag  \\\n",
       "0  high_watermark        3  None       0.951   \n",
       "1  high_watermark        5  None       0.855   \n",
       "2  high_watermark        6  None       1.324   \n",
       "3  high_watermark       26  None       1.202   \n",
       "4  high_watermark       31  None       1.630   \n",
       "5  high_watermark       49  None       0.775   \n",
       "6  high_watermark       58  None       0.746   \n",
       "7  high_watermark       90  None       0.743   \n",
       "\n",
       "                                          actor_path  \n",
       "0  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "1  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "2  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "3  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "4  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "5  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "6  /content/eval_restore/tcn_fusion_results/high_...  \n",
       "7  /content/eval_restore/tcn_fusion_results/high_...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CHECKPOINT DISCOVERY + ABLATION BASKET (with forced episode includes)\n",
    "# ============================================================================\n",
    "\n",
    "#import re\n",
    "#from pathlib import Path\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# Config knobs\n",
    "# -----------------------\n",
    "EVAL_TOP_ROOT = globals().get(\"EVAL_TOP_ROOT\", 2)\n",
    "EVAL_TOP_HW = globals().get(\"EVAL_TOP_HW\", 8)\n",
    "EVAL_TOP_PERIODIC = globals().get(\"EVAL_TOP_PERIODIC\", 4)\n",
    "EVAL_TOP_RARE = globals().get(\"EVAL_TOP_RARE\", 3)\n",
    "\n",
    "EVAL_INCLUDE_ROOT = globals().get(\"EVAL_INCLUDE_ROOT\", True)\n",
    "EVAL_INCLUDE_RARE = globals().get(\"EVAL_INCLUDE_RARE\", False)\n",
    "\n",
    "# Force-include these episodes even if they are not in top-sharpe basket\n",
    "EVAL_FORCE_EPISODES = globals().get(\"EVAL_FORCE_EPISODES\", [60, 62, 69, 73, 75, 90, 100])\n",
    "\n",
    "if \"EVAL_RESULTS_ROOT\" not in globals():\n",
    "    raise NameError(\"EVAL_RESULTS_ROOT is not defined\")\n",
    "\n",
    "EVAL_RESULTS_ROOT = Path(EVAL_RESULTS_ROOT)\n",
    "if not EVAL_RESULTS_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Missing results root: {EVAL_RESULTS_ROOT}\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Parse helpers\n",
    "# -----------------------\n",
    "def _ckpt_name(x) -> str:\n",
    "    return x.name if isinstance(x, Path) else str(x)\n",
    "\n",
    "\n",
    "def eval_parse_sharpe_from_name(x):\n",
    "    # Supports: ..._shp1p234... and ..._shm0p456...\n",
    "    name = _ckpt_name(x)\n",
    "    m = re.search(r\"_sh([pm])(\\d+)p(\\d+)\", name)\n",
    "    if not m:\n",
    "        return None\n",
    "    sign = 1.0 if m.group(1) == \"p\" else -1.0\n",
    "    return sign * float(f\"{m.group(2)}.{m.group(3)}\")\n",
    "\n",
    "\n",
    "def eval_parse_episode(x):\n",
    "    name = _ckpt_name(x)\n",
    "    m = re.search(r\"_ep(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "def eval_parse_step(x):\n",
    "    name = _ckpt_name(x)\n",
    "    m = re.search(r\"_step(\\d+)\", name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Discovery\n",
    "# -----------------------\n",
    "def eval_discover_actor_files(results_root: Path) -> pd.DataFrame:\n",
    "    actors = sorted(results_root.rglob(\"*_actor.weights.h5\"))\n",
    "    rows = []\n",
    "\n",
    "    for actor in actors:\n",
    "        prefix = str(actor).replace(\"_actor.weights.h5\", \"\")\n",
    "        critic = Path(prefix + \"_critic.weights.h5\")\n",
    "        if not critic.exists():\n",
    "            continue\n",
    "\n",
    "        parent_name = actor.parent.name\n",
    "        if parent_name == \"high_watermark_checkpoints\":\n",
    "            kind = \"high_watermark\"\n",
    "        elif parent_name == \"step_sharpe_checkpoints\":\n",
    "            kind = \"step_sharpe\"\n",
    "        elif parent_name == \"rare_models\":\n",
    "            kind = \"rare\"\n",
    "        elif eval_parse_step(actor) is not None:\n",
    "            kind = \"periodic_step\"\n",
    "        else:\n",
    "            kind = \"root\"\n",
    "\n",
    "        rows.append({\n",
    "            \"actor_path\": str(actor),\n",
    "            \"critic_path\": str(critic),\n",
    "            \"checkpoint_prefix\": prefix,\n",
    "            \"checkpoint_kind\": kind,\n",
    "            \"episode\": eval_parse_episode(actor),\n",
    "            \"step\": eval_parse_step(actor),\n",
    "            \"sharpe_tag\": eval_parse_sharpe_from_name(actor),\n",
    "            \"mtime\": actor.stat().st_mtime,\n",
    "        })\n",
    "\n",
    "    cols = [\n",
    "        \"actor_path\", \"critic_path\", \"checkpoint_prefix\",\n",
    "        \"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"mtime\"\n",
    "    ]\n",
    "    return pd.DataFrame(rows, columns=cols) if rows else pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Basket selection\n",
    "# -----------------------\n",
    "def eval_select_ablation_basket(df_ckpt: pd.DataFrame) -> pd.DataFrame:\n",
    "    picks = []\n",
    "\n",
    "    if EVAL_INCLUDE_ROOT:\n",
    "        root_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"root\"].copy()\n",
    "        if not root_df.empty:\n",
    "            picks.append(root_df.sort_values(\"mtime\", ascending=False).head(EVAL_TOP_ROOT))\n",
    "\n",
    "    hw_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"high_watermark\"].copy()\n",
    "    if not hw_df.empty:\n",
    "        hw_df[\"sharpe_rank_key\"] = hw_df[\"sharpe_tag\"].fillna(-np.inf)\n",
    "        picks.append(\n",
    "            hw_df.sort_values(\n",
    "                [\"sharpe_rank_key\", \"episode\", \"mtime\"],\n",
    "                ascending=[False, False, False]\n",
    "            ).head(EVAL_TOP_HW)\n",
    "        )\n",
    "\n",
    "    periodic_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"periodic_step\"].copy()\n",
    "    if not periodic_df.empty:\n",
    "        picks.append(\n",
    "            periodic_df.sort_values([\"step\", \"mtime\"], ascending=[False, False]).head(EVAL_TOP_PERIODIC)\n",
    "        )\n",
    "\n",
    "    if EVAL_INCLUDE_RARE:\n",
    "        rare_df = df_ckpt[df_ckpt[\"checkpoint_kind\"] == \"rare\"].copy()\n",
    "        if not rare_df.empty:\n",
    "            rare_df[\"sharpe_rank_key\"] = rare_df[\"sharpe_tag\"].fillna(-np.inf)\n",
    "            picks.append(\n",
    "                rare_df.sort_values(\n",
    "                    [\"sharpe_rank_key\", \"episode\", \"mtime\"],\n",
    "                    ascending=[False, False, False]\n",
    "                ).head(EVAL_TOP_RARE)\n",
    "            )\n",
    "\n",
    "    out = pd.concat(picks, ignore_index=True) if picks else pd.DataFrame(columns=df_ckpt.columns)\n",
    "\n",
    "    # Force include specific episodes (prefer high_watermark/root)\n",
    "    if EVAL_FORCE_EPISODES:\n",
    "        forced = df_ckpt[\n",
    "            (df_ckpt[\"episode\"].isin(EVAL_FORCE_EPISODES)) &\n",
    "            (df_ckpt[\"checkpoint_kind\"].isin([\"high_watermark\", \"root\"]))\n",
    "        ].copy()\n",
    "        if not forced.empty:\n",
    "            out = pd.concat([out, forced], ignore_index=True)\n",
    "\n",
    "    out = out.drop_duplicates(subset=[\"checkpoint_prefix\"]).reset_index(drop=True)\n",
    "    out = out.sort_values(\n",
    "        [\"checkpoint_kind\", \"episode\", \"sharpe_tag\", \"step\", \"mtime\"],\n",
    "        ascending=[True, True, False, False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Run\n",
    "# -----------------------\n",
    "eval_ckpt_df = eval_discover_actor_files(EVAL_RESULTS_ROOT)\n",
    "if eval_ckpt_df.empty:\n",
    "    raise RuntimeError(f\"No valid actor+critic checkpoint pairs found under {EVAL_RESULTS_ROOT}\")\n",
    "\n",
    "print(\"All checkpoint pairs:\", len(eval_ckpt_df))\n",
    "print(\"By kind:\", eval_ckpt_df[\"checkpoint_kind\"].value_counts().to_dict())\n",
    "\n",
    "eval_ablation_ckpts = eval_select_ablation_basket(eval_ckpt_df)\n",
    "\n",
    "found_forced = sorted(\n",
    "    set(eval_ablation_ckpts[\"episode\"].dropna().astype(int).tolist()) & set(EVAL_FORCE_EPISODES)\n",
    ")\n",
    "missing_forced = sorted(set(EVAL_FORCE_EPISODES) - set(found_forced))\n",
    "\n",
    "print(\"Selected for ablation:\", len(eval_ablation_ckpts))\n",
    "print(\"Forced requested:\", EVAL_FORCE_EPISODES)\n",
    "print(\"Forced found:\", found_forced)\n",
    "print(\"Forced missing:\", missing_forced)\n",
    "\n",
    "display(\n",
    "    eval_ablation_ckpts[\n",
    "        [\"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"actor_path\"]\n",
    "    ].head(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Evaluate ablation basket (deterministic + stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    load_run_checkpoint_prefixes_from_metadata,\n",
    "    preflight_checkpoint_loadability,\n",
    ")\n",
    "\n",
    "run_prefixes = load_run_checkpoint_prefixes_from_metadata(\n",
    "    EVAL_METADATA_PATH,\n",
    "    results_root=EVAL_RESULTS_ROOT,\n",
    "    allowed_types={\"high_watermark\", \"final_high_watermark_style\"},\n",
    "    require_both_files=True,\n",
    ")\n",
    "\n",
    "# Fallback for older metadata\n",
    "if not run_prefixes:\n",
    "    print(\"â„¹ï¸ No run-scoped checkpoint records in metadata; falling back to discovered checkpoints.\")\n",
    "    if \"eval_ckpt_df\" not in globals() or eval_ckpt_df is None or len(eval_ckpt_df) == 0:\n",
    "        eval_ckpt_df = eval_discover_actor_files(EVAL_RESULTS_ROOT)\n",
    "\n",
    "    fallback_df = eval_ckpt_df[eval_ckpt_df[\"checkpoint_kind\"].isin([\"high_watermark\", \"root\"])].copy()\n",
    "    run_prefixes = fallback_df[\"checkpoint_prefix\"].dropna().unique().tolist()\n",
    "\n",
    "print(\"run checkpoints:\", len(run_prefixes))\n",
    "\n",
    "preflight_df = preflight_checkpoint_loadability(\n",
    "    checkpoint_prefixes=run_prefixes,\n",
    "    phase1_data=eval_phase1_data,\n",
    "    config=eval_config,\n",
    "    random_seed=EVAL_RANDOM_SEED,\n",
    "    use_covariance=True,\n",
    "    architecture=eval_config[\"agent_params\"][\"actor_critic_type\"],\n",
    ")\n",
    "\n",
    "if preflight_df is None or preflight_df.empty:\n",
    "    print(\"âš ï¸ preflight returned empty; keeping current eval_ablation_ckpts\")\n",
    "else:\n",
    "    display(preflight_df.head())\n",
    "    if \"compatible\" in preflight_df.columns and \"checkpoint_prefix\" in preflight_df.columns:\n",
    "        compatible_prefixes = set(preflight_df.loc[preflight_df[\"compatible\"], \"checkpoint_prefix\"])\n",
    "        eval_ablation_ckpts = eval_ablation_ckpts[\n",
    "            eval_ablation_ckpts[\"checkpoint_prefix\"].isin(compatible_prefixes)\n",
    "        ].reset_index(drop=True)\n",
    "        print(\"compatible selected:\", len(eval_ablation_ckpts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    eval_ablation_ckpts[[\"checkpoint_kind\", \"episode\", \"step\", \"sharpe_tag\", \"checkpoint_prefix\"]]\n",
    "    .sort_values([\"episode\", \"step\"], na_position=\"last\")\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f539b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Temporary patch applied: stochastic_eval_mode now respected\n"
     ]
    }
   ],
   "source": [
    "# TEMP PATCH: force stochastic_eval_mode to win over legacy sample_actions defaults\n",
    "import src.notebook_helpers.tcn_phase1 as tcn_phase1\n",
    "\n",
    "_orig_eval_ckpt = tcn_phase1.evaluate_experiment6_checkpoint\n",
    "\n",
    "def _patched_evaluate_experiment6_checkpoint(*args, **kwargs):\n",
    "    # Neutralize legacy fallback unless caller explicitly sets them\n",
    "    kwargs.setdefault(\"sample_actions\", None)\n",
    "    kwargs.setdefault(\"sample_actions_stochastic\", None)\n",
    "    kwargs.setdefault(\"sample_actions_deterministic\", None)\n",
    "\n",
    "    # Ensure stochastic path uses your requested mode\n",
    "    kwargs.setdefault(\"stochastic_eval_mode\", \"sample\")\n",
    "    return _orig_eval_ckpt(*args, **kwargs)\n",
    "\n",
    "tcn_phase1.evaluate_experiment6_checkpoint = _patched_evaluate_experiment6_checkpoint\n",
    "print(\"âœ… Temporary patch applied: stochastic_eval_mode now respected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/8] Evaluating: high_watermark__ep0003__step-00001\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p951\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p951_actor.weights.h5\n",
      "âœ… Found critic weights: /content/eval_restore/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p951_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "   âœ… Weights loaded successfully\n",
      "   ðŸŽ¯ Deterministic eval policy modes: ['mean']\n",
      "   ðŸŽ¯ Stochastic eval policy mode:     mean\n",
      "\n",
      "================================================================================\n",
      "DETERMINISTIC EVALUATION (det_mean)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def eval_run_one_checkpoint(eval_cfg, phase1_data, ckpt_prefix, seed=42):\n",
    "    stub = create_experiment6_result_stub(\n",
    "        random_seed=seed,\n",
    "        use_covariance=True,\n",
    "        architecture=eval_cfg[\"agent_params\"][\"actor_critic_type\"],\n",
    "        checkpoint_path=ckpt_prefix,\n",
    "        agent_config=copy.deepcopy(eval_cfg[\"agent_params\"]),  # important\n",
    "        base_agent_params=None,\n",
    "    )\n",
    "\n",
    "\n",
    "    return evaluate_experiment6_checkpoint(\n",
    "        experiment6=stub,\n",
    "        phase1_data=phase1_data,\n",
    "        config=eval_cfg,\n",
    "        random_seed=seed,\n",
    "        checkpoint_path_override=ckpt_prefix,\n",
    "        deterministic_eval_mode=EVAL_DETERMINISTIC_MODE,\n",
    "        num_eval_runs=EVAL_NUM_STOCHASTIC_RUNS,\n",
    "        stochastic_eval_mode = EVAL_STOCHASTIC_MODE,\n",
    "        stochastic_episode_length_limit=EVAL_STOCHASTIC_EPISODE_LIMIT,\n",
    "        save_eval_logs=EVAL_SAVE_LOGS,\n",
    "        save_eval_artifacts=EVAL_SAVE_ARTIFACTS,\n",
    "    )\n",
    "\n",
    "\n",
    "eval_evaluations = {}\n",
    "eval_failures = {}\n",
    "\n",
    "for i, row in eval_ablation_ckpts.iterrows():\n",
    "    ep = int(row[\"episode\"]) if pd.notna(row[\"episode\"]) else -1\n",
    "    st = int(row[\"step\"]) if pd.notna(row[\"step\"]) else -1\n",
    "    label = f\"{row['checkpoint_kind']}__ep{ep:04d}__step{st:06d}\"\n",
    "    prefix = row[\"checkpoint_prefix\"]\n",
    "\n",
    "    print(f\"\\n[{i+1}/{len(eval_ablation_ckpts)}] Evaluating: {label}\")\n",
    "    try:\n",
    "        ev = eval_run_one_checkpoint(eval_config, eval_phase1_data, prefix, seed=EVAL_RANDOM_SEED)\n",
    "        eval_evaluations[label] = ev\n",
    "    except Exception as e:\n",
    "        eval_failures[label] = f\"{type(e).__name__}: {e}\"\n",
    "        print(f\"âŒ Failed {label}: {eval_failures[label]}\")\n",
    "\n",
    "print(\"âœ… Completed evaluations:\", len(eval_evaluations))\n",
    "print(\"âš ï¸ Failed evaluations:\", len(eval_failures))\n",
    "\n",
    "if eval_failures:\n",
    "    print(\"\\nFailure samples:\")\n",
    "    for k, v in list(eval_failures.items())[:10]:\n",
    "        print(\" -\", k, \"->\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Ablation table and leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not eval_evaluations:\n",
    "    raise RuntimeError('No successful evaluations to summarize.')\n",
    "\n",
    "eval_ablation_table = build_ablation_table(eval_evaluations)\n",
    "\n",
    "display(eval_ablation_table.head(30))\n",
    "\n",
    "# Deterministic-first leaderboard view\n",
    "eval_leaderboard = eval_ablation_table.copy()\n",
    "eval_leaderboard['risk_adjusted_score'] = (\n",
    "    eval_leaderboard['det_sharpe'].fillna(-999)\n",
    "    - 0.5 * eval_leaderboard['det_max_drawdown'].fillna(1.0)\n",
    "    - 0.1 * eval_leaderboard['det_turnover'].fillna(1.0)\n",
    ")\n",
    "eval_leaderboard = eval_leaderboard.sort_values(['risk_adjusted_score', 'det_sharpe'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "print('Top by risk-adjusted score:')\n",
    "display(eval_leaderboard.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Build industry baseline returns (equal-weight and cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_identify_asset_column(df: pd.DataFrame):\n",
    "    candidates = ['Ticker', 'ticker', 'tic', 'asset', 'Asset', 'symbol', 'Symbol']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def eval_identify_return_column(df: pd.DataFrame):\n",
    "    candidates = ['LogReturn_1d', 'log_return_1d', 'Return_1d', 'return_1d', 'daily_return']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def eval_fetch_sp500_returns(start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fetch S&P500 daily simple returns for benchmark comparison.\n",
    "    Primary source: yfinance '^GSPC'.\n",
    "    Fallback: empty series if fetch fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception:\n",
    "        try:\n",
    "            !pip -q install yfinance\n",
    "            import yfinance as yf\n",
    "        except Exception:\n",
    "            print('âš ï¸ Could not install/import yfinance; SP500 benchmark disabled.')\n",
    "            return pd.Series(dtype=float)\n",
    "\n",
    "    try:\n",
    "        df = yf.download('^GSPC', start=str(start_date.date()), end=str((end_date + pd.Timedelta(days=1)).date()), auto_adjust=True, progress=False)\n",
    "        if df is None or df.empty or 'Close' not in df.columns:\n",
    "            print('âš ï¸ SP500 download returned empty data.')\n",
    "            return pd.Series(dtype=float)\n",
    "        close = pd.Series(df['Close']).dropna()\n",
    "        ret = close.pct_change().dropna().astype(float)\n",
    "        ret.index = pd.to_datetime(ret.index)\n",
    "        return ret\n",
    "    except Exception as e:\n",
    "        print(f'âš ï¸ SP500 fetch failed: {type(e).__name__}: {e}')\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "\n",
    "def eval_build_baselines_from_phase1(phase1_data):\n",
    "    test_df = phase1_data.test_df.copy()\n",
    "    if 'Date' not in test_df.columns:\n",
    "        raise ValueError('test_df must contain Date column')\n",
    "\n",
    "    ret_col = eval_identify_return_column(test_df)\n",
    "    if ret_col is None:\n",
    "        raise ValueError('Could not identify return column in test_df')\n",
    "\n",
    "    if 'LogReturn' in ret_col or 'log' in ret_col.lower():\n",
    "        test_df['_simple_ret'] = np.expm1(test_df[ret_col].astype(float))\n",
    "    else:\n",
    "        test_df['_simple_ret'] = test_df[ret_col].astype(float)\n",
    "\n",
    "    # Industry baseline 1: equal-weight over available assets each day\n",
    "    eqw = (\n",
    "        test_df.groupby('Date')['_simple_ret']\n",
    "        .mean()\n",
    "        .sort_index()\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # Industry baseline 2: cash (0% daily return)\n",
    "    cash = pd.Series(np.zeros(len(eqw)), index=pd.to_datetime(eqw.index), name='cash')\n",
    "\n",
    "    # Industry baseline 3: S&P 500 (^GSPC)\n",
    "    dt_index = pd.to_datetime(eqw.index)\n",
    "    sp500_ret = eval_fetch_sp500_returns(dt_index.min(), dt_index.max())\n",
    "    if not sp500_ret.empty:\n",
    "        # align to model dates; missing market holidays become 0 return for alignment stability\n",
    "        sp500_ret = sp500_ret.reindex(dt_index).fillna(0.0)\n",
    "    else:\n",
    "        sp500_ret = pd.Series(dtype=float)\n",
    "\n",
    "    # reset to plain 0..n index for compare_agent_vs_baseline\n",
    "    eqw = eqw.reset_index(drop=True)\n",
    "    cash = cash.reset_index(drop=True)\n",
    "    sp500 = sp500_ret.reset_index(drop=True) if not sp500_ret.empty else pd.Series(dtype=float)\n",
    "    return eqw, cash, sp500\n",
    "\n",
    "\n",
    "eval_baseline_eqw, eval_baseline_cash, eval_baseline_sp500 = eval_build_baselines_from_phase1(eval_phase1_data)\n",
    "print('Baseline lengths | EQW:', len(eval_baseline_eqw), 'Cash:', len(eval_baseline_cash), 'SP500:', len(eval_baseline_sp500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Benchmark each evaluated checkpoint vs baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_rows = []\n",
    "for label, ev in eval_evaluations.items():\n",
    "    try:\n",
    "        cmp_eqw = compare_agent_vs_baseline(ev, eval_baseline_eqw)\n",
    "    except Exception as e:\n",
    "        cmp_eqw = {'error': str(e)}\n",
    "\n",
    "    try:\n",
    "        cmp_cash = compare_agent_vs_baseline(ev, eval_baseline_cash)\n",
    "    except Exception as e:\n",
    "        cmp_cash = {'error': str(e)}\n",
    "\n",
    "    try:\n",
    "        if len(eval_baseline_sp500) > 0:\n",
    "            cmp_sp500 = compare_agent_vs_baseline(ev, eval_baseline_sp500)\n",
    "        else:\n",
    "            cmp_sp500 = {'error': 'SP500 baseline unavailable'}\n",
    "    except Exception as e:\n",
    "        cmp_sp500 = {'error': str(e)}\n",
    "\n",
    "    row = {\n",
    "        'label': label,\n",
    "        'det_sharpe': (ev.deterministic_metrics or {}).get('sharpe_ratio', np.nan),\n",
    "        'det_return': (ev.deterministic_metrics or {}).get('annualized_return', np.nan),\n",
    "        'det_mdd': (ev.deterministic_metrics or {}).get('max_drawdown_abs', np.nan),\n",
    "        'det_turnover': (ev.deterministic_metrics or {}).get('turnover', np.nan),\n",
    "    }\n",
    "\n",
    "    for prefix, comp in [('eqw', cmp_eqw), ('cash', cmp_cash), ('sp500', cmp_sp500)]:\n",
    "        if isinstance(comp, dict) and 'error' not in comp:\n",
    "            for k, v in comp.items():\n",
    "                row[f'{prefix}_{k}'] = v\n",
    "        else:\n",
    "            row[f'{prefix}_error'] = comp.get('error', 'unknown') if isinstance(comp, dict) else 'unknown'\n",
    "\n",
    "    benchmark_rows.append(row)\n",
    "\n",
    "eval_benchmark_df = pd.DataFrame(benchmark_rows)\n",
    "\n",
    "display(eval_benchmark_df.sort_values('det_sharpe', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Champion selection (production candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_benchmark_df.empty:\n",
    "    raise RuntimeError('No benchmark rows available.')\n",
    "\n",
    "# Balanced production-style objective: reward risk-adjusted return, penalize drawdown/turnover.\n",
    "eval_benchmark_df['selection_score'] = (\n",
    "    eval_benchmark_df['det_sharpe'].fillna(-999)\n",
    "    + 0.2 * eval_benchmark_df['det_return'].fillna(0.0)\n",
    "    - 0.7 * eval_benchmark_df['det_mdd'].fillna(1.0)\n",
    "    - 0.1 * eval_benchmark_df['det_turnover'].fillna(1.0)\n",
    ")\n",
    "\n",
    "champion_row = eval_benchmark_df.sort_values('selection_score', ascending=False).iloc[0]\n",
    "EVAL_CHAMPION_LABEL = champion_row['label']\n",
    "EVAL_CHAMPION = eval_evaluations[EVAL_CHAMPION_LABEL]\n",
    "\n",
    "print('ðŸ† Champion label:', EVAL_CHAMPION_LABEL)\n",
    "print(champion_row[['det_sharpe', 'det_return', 'det_mdd', 'det_turnover', 'selection_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Regime-sliced performance (champion vs equal-weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regime_tag(dates: pd.Series):\n",
    "    d = pd.to_datetime(dates)\n",
    "    conds = [\n",
    "        (d <= pd.Timestamp('2020-02-19')),\n",
    "        (d >= pd.Timestamp('2020-02-20')) & (d <= pd.Timestamp('2020-06-30')),\n",
    "        (d >= pd.Timestamp('2020-07-01')) & (d <= pd.Timestamp('2021-12-31')),\n",
    "        (d >= pd.Timestamp('2022-01-01')) & (d <= pd.Timestamp('2023-12-31')),\n",
    "        (d >= pd.Timestamp('2024-01-01')),\n",
    "    ]\n",
    "    labels = ['pre_covid', 'covid_crash', 'post_covid_recovery', 'inflation_rates', 'recent']\n",
    "    out = np.select(conds, labels, default='other')\n",
    "    return pd.Series(out)\n",
    "\n",
    "\n",
    "def eval_sharpe(x):\n",
    "    x = pd.Series(x).dropna()\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "    std = x.std(ddof=1)\n",
    "    if std <= 1e-12:\n",
    "        return np.nan\n",
    "    return np.sqrt(252.0) * x.mean() / std\n",
    "\n",
    "# Build aligned daily return series for champion and baselines\n",
    "champ_port = np.array(EVAL_CHAMPION.deterministic_portfolio)\n",
    "champ_ret = pd.Series(np.diff(champ_port) / champ_port[:-1]).reset_index(drop=True)\n",
    "eqw_ret = eval_baseline_eqw.reset_index(drop=True)\n",
    "sp500_ret = eval_baseline_sp500.reset_index(drop=True) if len(eval_baseline_sp500) > 0 else pd.Series(dtype=float)\n",
    "\n",
    "n_core = min(len(champ_ret), len(eqw_ret), len(eval_phase1_data.test_df['Date'].drop_duplicates()) - 1)\n",
    "if len(sp500_ret) > 0:\n",
    "    n = min(n_core, len(sp500_ret))\n",
    "else:\n",
    "    n = n_core\n",
    "\n",
    "dates = pd.to_datetime(eval_phase1_data.test_df['Date'].drop_duplicates().sort_values()).reset_index(drop=True).iloc[1:n+1]\n",
    "\n",
    "reg_df = pd.DataFrame({\n",
    "    'Date': dates.reset_index(drop=True),\n",
    "    'champion_ret': champ_ret.iloc[:n].reset_index(drop=True),\n",
    "    'eqw_ret': eqw_ret.iloc[:n].reset_index(drop=True),\n",
    "})\n",
    "if len(sp500_ret) > 0:\n",
    "    reg_df['sp500_ret'] = sp500_ret.iloc[:n].reset_index(drop=True)\n",
    "else:\n",
    "    reg_df['sp500_ret'] = np.nan\n",
    "\n",
    "reg_df['regime'] = eval_regime_tag(reg_df['Date'])\n",
    "\n",
    "regime_rows = []\n",
    "for regime, g in reg_df.groupby('regime'):\n",
    "    row = {\n",
    "        'regime': regime,\n",
    "        'n_days': len(g),\n",
    "        'champion_sharpe': eval_sharpe(g['champion_ret']),\n",
    "        'eqw_sharpe': eval_sharpe(g['eqw_ret']),\n",
    "        'champion_total_return': float((1.0 + g['champion_ret']).prod() - 1.0),\n",
    "        'eqw_total_return': float((1.0 + g['eqw_ret']).prod() - 1.0),\n",
    "    }\n",
    "    if g['sp500_ret'].notna().any():\n",
    "        row['sp500_sharpe'] = eval_sharpe(g['sp500_ret'])\n",
    "        row['sp500_total_return'] = float((1.0 + g['sp500_ret'].fillna(0.0)).prod() - 1.0)\n",
    "    else:\n",
    "        row['sp500_sharpe'] = np.nan\n",
    "        row['sp500_total_return'] = np.nan\n",
    "    regime_rows.append(row)\n",
    "\n",
    "eval_regime_df = pd.DataFrame(regime_rows).sort_values('regime').reset_index(drop=True)\n",
    "display(eval_regime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Statistical confidence: bootstrap Sharpe difference (champion - equal-weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_block_bootstrap_sharpe_diff(agent_ret, base_ret, n_boot=2000, block=20, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    a = np.asarray(agent_ret, dtype=float)\n",
    "    b = np.asarray(base_ret, dtype=float)\n",
    "    n = min(len(a), len(b))\n",
    "    a = a[:n]\n",
    "    b = b[:n]\n",
    "\n",
    "    def _sharpe(x):\n",
    "        x = pd.Series(x).dropna()\n",
    "        if len(x) < 2:\n",
    "            return np.nan\n",
    "        s = x.std(ddof=1)\n",
    "        if s <= 1e-12:\n",
    "            return np.nan\n",
    "        return np.sqrt(252.0) * x.mean() / s\n",
    "\n",
    "    diffs = []\n",
    "    n_blocks = int(np.ceil(n / block))\n",
    "    max_start = max(1, n - block + 1)\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = []\n",
    "        for __ in range(n_blocks):\n",
    "            st = int(rng.integers(0, max_start))\n",
    "            idx.extend(range(st, min(st + block, n)))\n",
    "        idx = np.asarray(idx[:n])\n",
    "        d = _sharpe(a[idx]) - _sharpe(b[idx])\n",
    "        if np.isfinite(d):\n",
    "            diffs.append(float(d))\n",
    "\n",
    "    if not diffs:\n",
    "        return {'n_boot_eff': 0, 'mean': np.nan, 'ci_low': np.nan, 'ci_high': np.nan, 'p_le_zero': np.nan}\n",
    "\n",
    "    diffs = np.asarray(diffs)\n",
    "    return {\n",
    "        'n_boot_eff': int(len(diffs)),\n",
    "        'mean': float(np.mean(diffs)),\n",
    "        'ci_low': float(np.quantile(diffs, 0.025)),\n",
    "        'ci_high': float(np.quantile(diffs, 0.975)),\n",
    "        'p_le_zero': float(np.mean(diffs <= 0.0)),\n",
    "    }\n",
    "\n",
    "bootstrap_eqw = eval_block_bootstrap_sharpe_diff(\n",
    "    reg_df['champion_ret'].values,\n",
    "    reg_df['eqw_ret'].values,\n",
    "    n_boot=2000,\n",
    "    block=20,\n",
    "    seed=EVAL_RANDOM_SEED,\n",
    ")\n",
    "\n",
    "if reg_df['sp500_ret'].notna().any():\n",
    "    bootstrap_sp500 = eval_block_bootstrap_sharpe_diff(\n",
    "        reg_df['champion_ret'].values,\n",
    "        reg_df['sp500_ret'].fillna(0.0).values,\n",
    "        n_boot=2000,\n",
    "        block=20,\n",
    "        seed=EVAL_RANDOM_SEED,\n",
    "    )\n",
    "else:\n",
    "    bootstrap_sp500 = {'n_boot_eff': 0, 'mean': np.nan, 'ci_low': np.nan, 'ci_high': np.nan, 'p_le_zero': np.nan}\n",
    "\n",
    "print('Bootstrap Sharpe diff (Champion - EQW):')\n",
    "print(bootstrap_eqw)\n",
    "print('Bootstrap Sharpe diff (Champion - SP500):')\n",
    "print(bootstrap_sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Training-diagnostics quality checks from CSV metrics\n",
    "Uses saved CSVs to report KL stability, turnover drivers, and execution quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_report = {}\n",
    "\n",
    "if eval_latest_episodes_csv and Path(eval_latest_episodes_csv).exists():\n",
    "    ep = pd.read_csv(eval_latest_episodes_csv)\n",
    "    diag_report['episodes_rows'] = len(ep)\n",
    "\n",
    "    if 'approx_kl' in ep.columns:\n",
    "        kl = pd.to_numeric(ep['approx_kl'], errors='coerce').dropna()\n",
    "        if len(kl):\n",
    "            diag_report['approx_kl_mean'] = float(kl.mean())\n",
    "            diag_report['approx_kl_p50'] = float(kl.quantile(0.50))\n",
    "            diag_report['approx_kl_p90'] = float(kl.quantile(0.90))\n",
    "\n",
    "    if {'episode_turnover_pct', 'approx_kl'}.issubset(ep.columns):\n",
    "        x = pd.to_numeric(ep['episode_turnover_pct'], errors='coerce')\n",
    "        y = pd.to_numeric(ep['approx_kl'], errors='coerce')\n",
    "        valid = x.notna() & y.notna()\n",
    "        if valid.any():\n",
    "            diag_report['corr_turnoverpct_kl'] = float(np.corrcoef(x[valid], y[valid])[0, 1])\n",
    "\n",
    "if eval_latest_step_diag_csv and Path(eval_latest_step_diag_csv).exists():\n",
    "    sd = pd.read_csv(eval_latest_step_diag_csv)\n",
    "    diag_report['step_diag_rows'] = len(sd)\n",
    "\n",
    "    for col in ['l1_w_delta', 'turnover_penalty_contrib', 'tx_cost_contrib_reward_pts', 'action_realization_l1']:\n",
    "        if col in sd.columns:\n",
    "            s = pd.to_numeric(sd[col], errors='coerce').dropna()\n",
    "            if len(s):\n",
    "                diag_report[f'{col}_mean'] = float(s.mean())\n",
    "                diag_report[f'{col}_p90'] = float(s.quantile(0.90))\n",
    "\n",
    "print(json.dumps(diag_report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Save final evaluation package\n",
    "Exports leaderboard, benchmark table, regime table, diagnostics, and champion metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out_dir = EVAL_RESULTS_ROOT / 'logs'\n",
    "eval_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "eval_ablation_path = eval_out_dir / f'final_eval_ablation_{ts}.csv'\n",
    "eval_benchmark_path = eval_out_dir / f'final_eval_benchmark_{ts}.csv'\n",
    "eval_regime_path = eval_out_dir / f'final_eval_regime_{ts}.csv'\n",
    "eval_diag_path = eval_out_dir / f'final_eval_diagnostics_{ts}.json'\n",
    "eval_meta_path = eval_out_dir / f'final_eval_champion_{ts}.json'\n",
    "\n",
    "eval_ablation_table.to_csv(eval_ablation_path, index=False)\n",
    "eval_benchmark_df.to_csv(eval_benchmark_path, index=False)\n",
    "eval_regime_df.to_csv(eval_regime_path, index=False)\n",
    "\n",
    "with open(eval_diag_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'bootstrap_sharpe_diff_eqw': bootstrap_eqw,\n",
    "        'bootstrap_sharpe_diff_sp500': bootstrap_sp500,\n",
    "        'diagnostics': diag_report,\n",
    "        'metadata_path': str(EVAL_METADATA_PATH),\n",
    "    }, f, indent=2)\n",
    "\n",
    "with open(eval_meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'champion_label': EVAL_CHAMPION_LABEL,\n",
    "        'selection_row': champion_row.to_dict(),\n",
    "        'deterministic_metrics': EVAL_CHAMPION.deterministic_metrics,\n",
    "        'checkpoint_description': EVAL_CHAMPION.checkpoint_description,\n",
    "    }, f, indent=2, default=str)\n",
    "\n",
    "print('âœ… Saved evaluation package:')\n",
    "print('-', eval_ablation_path)\n",
    "print('-', eval_benchmark_path)\n",
    "print('-', eval_regime_path)\n",
    "print('-', eval_diag_path)\n",
    "print('-', eval_meta_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
