{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Architecture Analysis (Execution-Ready, Updated 2026-02-18)\n",
    "\n",
    "This notebook is aligned with the current TAPE environment updates:\n",
    "- drawdown lambda carry-over + decay\n",
    "- rebalanced penalties with penalty budget cap\n",
    "- intra-step TAPE delta shaping (rolling potential difference)\n",
    "- step-level Sharpe checkpointing\n",
    "- updated episode-length curriculum schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60545e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /content/adaptive_portfolio_rl\n",
    "#!ls -la data\n",
    "#!find . -type d -name \"__pycache__\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /content/adaptive_portfolio_rl\n",
    "#!rm -f data/daily_ohlcv_assets.csv\n",
    "#!rm -f data/master_features_NORMALIZED.csv\n",
    "#!rm -f data/processed_daily_macro_features.csv\n",
    "#!find . -type d -name \"__pycache__\" -prune -exec rm -rf {} +\n",
    "#!ls -la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5877c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/adaptive_portfolio_rl\n",
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (4/4), 2.39 KiB | 816.00 KiB/s, done.\n",
      "From https://github.com/Dave-DKings/tape_tcn_project\n",
      "   b7767d2..3ece882  main       -> origin/main\n",
      "HEAD is now at 3ece882 Update notebook tuning workflow and ignore local fusion artifacts\n"
     ]
    }
   ],
   "source": [
    "# Cell A: sync repo\n",
    "import os\n",
    "if not os.path.exists(\"/content/adaptive_portfolio_rl/.git\"):\n",
    "    !git clone https://github.com/Dave-DKings/tape_tcn_project.git /content/adaptive_portfolio_rl\n",
    "%cd /content/adaptive_portfolio_rl\n",
    "!git fetch origin\n",
    "!git reset --hard origin/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ccabeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/adaptive_portfolio_rl\n"
     ]
    }
   ],
   "source": [
    "%cd /content/adaptive_portfolio_rl\n",
    "!rm -f data/daily_ohlcv_assets.csv\n",
    "!rm -f data/processed_daily_macro_features.csv\n",
    "!rm -f data/master_features_NORMALIZED.csv\n",
    "!rm -rf data/fundamentals\n",
    "!find . -type d -name \"__pycache__\" -prune -exec rm -rf {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407973ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where am I\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ea6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find results folders\n",
    "!find . -maxdepth 3 -type d \\( -name \"tcn_fusion_results\" -o -name \"tcn_results\" -o -name \"output_logs\" \\) -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df99e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files inside results\n",
    "!find ./tcn_fusion_results -maxdepth 3 -type f | head -n 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a12a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old training outputs\n",
    "!rm -rf tcn_fusion_results\n",
    "#!rm -rf tcn_results\n",
    "#!rm -rf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18cf54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell B: install project requirements (Colab-safe pinned stack)\n",
    "%pip install -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f36d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q jedi==0.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d69b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/adaptive_portfolio_rl\n",
      "\tzip warning: name not matched: tcn_fusion_results\n",
      "\tzip warning: name not matched: tcn_results\n",
      "\tzip warning: name not matched: output_logs\n",
      "  adding: data/ (stored 0%)\n",
      "  adding: data/daily_ohlcv_5_assets.csv (deflated 59%)\n",
      "  adding: data/quarterly_fundamentals.csv (deflated 60%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_b34175f2-dd52-4f0a-8897-18b1a1d5e0a1\", \"tcn_artifacts.zip\", 869063)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd /content/adaptive_portfolio_rl\n",
    "!zip -r tcn_artifacts.zip tcn_fusion_results tcn_results output_logs data\n",
    "from google.colab import files\n",
    "files.download(\"tcn_artifacts.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe992e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions: 2.0.2 2.2.2 2.19.0\n",
      "TF GPUs visible: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "ipython 7.34.0 requires jedi, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "import pandas_ta_classic as ta_classic\n",
    "print('Versions:', np.__version__, pd.__version__, tf.__version__)\n",
    "print('TF GPUs visible:', tf.config.list_physical_devices('GPU'))\n",
    "!pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df69df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² Setting all random seeds to: 42\n",
      "   âœ… Deterministic mode enabled (slower but reproducible)\n",
      "   âœ… Python random seed set\n",
      "   âœ… NumPy random seed set\n",
      "   âœ… TensorFlow seed set\n",
      "   âœ… Custom PPO agents seeded\n",
      "TF GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "âœ… Setup complete\n",
      "Project root: /content/adaptive_portfolio_rl\n",
      "Config module path: /content/adaptive_portfolio_rl/src/config.py\n",
      "Active fetch range from module: 2003-09-02 -> 2025-09-01\n",
      "Active analysis range from module: 2003-09-02 -> 2025-09-01\n",
      "Train split end from module: 2021-09-01\n",
      "TensorFlow: 2.19.0\n",
      "NumPy: 2.0.2\n",
      "Pandas: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: PROJECT ROOT, IMPORTS, REPRODUCIBILITY\n",
    "# ============================================================================\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Resolve project root robustly\n",
    "project_root = Path.cwd()\n",
    "if project_root.name != 'adaptive_portfolio_rl':\n",
    "    if (project_root / 'adaptive_portfolio_rl').exists():\n",
    "        project_root = project_root / 'adaptive_portfolio_rl'\n",
    "    elif (project_root.parent / 'adaptive_portfolio_rl').exists():\n",
    "        project_root = project_root.parent / 'adaptive_portfolio_rl'\n",
    "\n",
    "# Ensure imports resolve to this project only\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Scientific stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "# IMPORTANT: force-reload local modules so config edits take effect without stale state\n",
    "import src.config as config_module\n",
    "import src.data_utils as data_utils_module\n",
    "import src.notebook_helpers.tcn_phase1 as tcn_phase1_module\n",
    "importlib.reload(config_module)\n",
    "importlib.reload(data_utils_module)\n",
    "importlib.reload(tcn_phase1_module)\n",
    "\n",
    "# Project imports (from freshly reloaded modules)\n",
    "from src.data_utils import DataProcessor\n",
    "from src.config import get_active_config, PROFILE_BALANCED_GROWTH, ASSET_TICKERS\n",
    "from src.reproducibility_helper import set_all_seeds\n",
    "from src.csv_logger import CSVLogger\n",
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    identify_covariance_columns,\n",
    "    Phase1Dataset,\n",
    "    run_experiment6_tape,\n",
    "    evaluate_experiment6_checkpoint,\n",
    "    create_experiment6_result_stub,\n",
    "    load_training_metadata_into_config,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_all_seeds(RANDOM_SEED, deterministic=True)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"src.environment_tape_rl\").setLevel(logging.WARNING)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"TF GPUs:\", gpus)\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print('âœ… Setup complete')\n",
    "print('Project root:', project_root)\n",
    "print('Config module path:', config_module.__file__)\n",
    "print('Active fetch range from module:', config_module.DATA_FETCH_START_DATE, '->', config_module.DATA_FETCH_END_DATE)\n",
    "print('Active analysis range from module:', config_module.ANALYSIS_START_DATE, '->', config_module.ANALYSIS_END_DATE)\n",
    "print('Train split end from module:', config_module.TRAIN_TEST_SPLIT_DATE)\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('NumPy:', np.__version__)\n",
    "print('Pandas:', pd.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa22329",
   "metadata": {},
   "source": [
    "## 2) Config and Run Controls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b682564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forced notebook date window: 2003-09-02 -> 2025-09-01\n",
      "Forced analysis window: 2003-09-02 -> 2025-09-01\n",
      "Forced train split end: 2021-09-01\n",
      "CONFIG SNAPSHOT\n",
      "Phase: Phase1_Baseline_PPO\n",
      "Tickers: ['MSFT', 'GOOGL', 'JPM', 'JNJ', 'XOM', 'PG', 'NEE', 'LIN', 'CAT', 'UNH']\n",
      "Date range: 2003-09-02 -> 2025-09-01\n",
      "Architecture: TCN\n",
      "TCN filters: [64, 128, 128]\n",
      "Dirichlet activation: elu\n",
      "PPO: epochs= 4 clip= 0.1 actor_lr= 2e-05 critic_lr= 0.0003 target_kl= 0.015\n",
      "\n",
      "REWARD + RISK CONTROLS\n",
      "target_turnover= 0.6 turnover_penalty_scalar= 2.0\n",
      "concentration_penalty_scalar= 2.0 top_weight_penalty_scalar= 1.5\n",
      "action_realization_penalty_scalar= 0.5\n",
      "penalty_budget_ratio= 1.25\n",
      "drawdown: penalty_coef= 1.5 lambda_floor= 0.0 lambda_carry_decay= 0.7\n",
      "drawdown: target= 0.18 tolerance= -0.015 lambda_max= 5.0\n",
      "\n",
      "INTRA-STEP TAPE DELTA\n",
      "enabled= True window= 60 min_history= 20\n",
      "beta= 0.01 clip= 0.2\n",
      "\n",
      "CHECKPOINT RULES\n",
      "tape_checkpoint_threshold= 4.0\n",
      "periodic_checkpoint_every_steps= 10000\n",
      "high_watermark_checkpoint_enabled= True threshold= 0.5\n",
      "step_sharpe_checkpoint_enabled= False threshold= 0.5\n",
      "\n",
      "CURRICULUM\n",
      "episode_length_curriculum_schedule= [{'threshold': 0, 'limit': 1500}, {'threshold': 30000, 'limit': 2000}, {'threshold': 60000, 'limit': 2500}, {'threshold': 90000, 'limit': None}]\n",
      "turnover_penalty_curriculum= {0: 0.75, 30000: 1.25, 60000: 1.5, 90000: 1.75, 120000: 2.0}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD ACTIVE CONFIG + CURRENT CONTROL SNAPSHOT\n",
    "# ============================================================================\n",
    "config = get_active_config('phase1')\n",
    "\n",
    "# Force a single source-of-truth date window for this notebook run\n",
    "# (keeps paper training split, extends test window to ~3 years)\n",
    "config['DATA_FETCH_START_DATE'] = '2003-09-02'\n",
    "config['DATA_FETCH_END_DATE'] = '2025-09-01'\n",
    "config['ANALYSIS_START_DATE'] = '2003-09-02'\n",
    "config['ANALYSIS_END_DATE'] = '2025-09-01'\n",
    "config['TRAIN_TEST_SPLIT_DATE'] = '2021-09-01'\n",
    "\n",
    "print('Forced notebook date window:', config['DATA_FETCH_START_DATE'], '->', config['DATA_FETCH_END_DATE'])\n",
    "print('Forced analysis window:', config['ANALYSIS_START_DATE'], '->', config['ANALYSIS_END_DATE'])\n",
    "print('Forced train split end:', config['TRAIN_TEST_SPLIT_DATE'])\n",
    "\n",
    "# Keep defaults from config unless explicitly changed below\n",
    "config['agent_params']['actor_critic_type'] = 'TCN'\n",
    "config['agent_params']['evaluation_mode'] = config['agent_params'].get('evaluation_mode', 'mode')\n",
    "config['training_params']['update_log_interval'] = 1\n",
    "\n",
    "ppo = config['agent_params'].get('ppo_params', {})\n",
    "env = config.get('environment_params', {})\n",
    "dd = env.get('drawdown_constraint', {})\n",
    "tp = config.get('training_params', {})\n",
    "\n",
    "print('CONFIG SNAPSHOT')\n",
    "print('Phase:', config['phase_name'])\n",
    "print('Tickers:', config['ASSET_TICKERS'])\n",
    "print('Date range:', config['ANALYSIS_START_DATE'], '->', config['ANALYSIS_END_DATE'])\n",
    "print('Architecture:', config['agent_params']['actor_critic_type'])\n",
    "print('TCN filters:', config['agent_params'].get('tcn_filters'))\n",
    "print('Dirichlet activation:', config['agent_params'].get('dirichlet_alpha_activation'))\n",
    "print('PPO: epochs=', ppo.get('num_ppo_epochs'), 'clip=', ppo.get('policy_clip'), 'actor_lr=', ppo.get('actor_lr'), 'critic_lr=', ppo.get('critic_lr'), 'target_kl=', ppo.get('target_kl'))\n",
    "\n",
    "print()\n",
    "print('REWARD + RISK CONTROLS')\n",
    "print('target_turnover=', env.get('target_turnover'), 'turnover_penalty_scalar=', env.get('turnover_penalty_scalar'))\n",
    "print('concentration_penalty_scalar=', env.get('concentration_penalty_scalar'), 'top_weight_penalty_scalar=', env.get('top_weight_penalty_scalar'))\n",
    "print('action_realization_penalty_scalar=', env.get('action_realization_penalty_scalar'))\n",
    "print('penalty_budget_ratio=', env.get('penalty_budget_ratio'))\n",
    "print('drawdown: penalty_coef=', dd.get('penalty_coef'), 'lambda_floor=', dd.get('lambda_floor'), 'lambda_carry_decay=', dd.get('lambda_carry_decay'))\n",
    "print('drawdown: target=', dd.get('target'), 'tolerance=', dd.get('tolerance'), 'lambda_max=', dd.get('lambda_max'))\n",
    "\n",
    "print()\n",
    "print('INTRA-STEP TAPE DELTA')\n",
    "print('enabled=', env.get('intra_step_tape_delta_enabled'), 'window=', env.get('intra_step_tape_delta_window'), 'min_history=', env.get('intra_step_tape_delta_min_history'))\n",
    "print('beta=', env.get('intra_step_tape_delta_beta'), 'clip=', env.get('intra_step_tape_delta_clip'))\n",
    "\n",
    "print()\n",
    "print('CHECKPOINT RULES')\n",
    "print('tape_checkpoint_threshold=', tp.get('tape_checkpoint_threshold'))\n",
    "print('periodic_checkpoint_every_steps=', tp.get('periodic_checkpoint_every_steps'))\n",
    "print('high_watermark_checkpoint_enabled=', tp.get('high_watermark_checkpoint_enabled'), 'threshold=', tp.get('high_watermark_sharpe_threshold'))\n",
    "print('step_sharpe_checkpoint_enabled=', tp.get('step_sharpe_checkpoint_enabled'), 'threshold=', tp.get('step_sharpe_checkpoint_threshold'))\n",
    "\n",
    "print()\n",
    "print('CURRICULUM')\n",
    "print('episode_length_curriculum_schedule=', tp.get('episode_length_curriculum_schedule'))\n",
    "print('turnover_penalty_curriculum=', tp.get('turnover_penalty_curriculum'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL OVERRIDES (SAFE, CURRENT-ALIGNED)\n",
    "# ============================================================================\n",
    "APPLY_OVERRIDES = False\n",
    "\n",
    "if APPLY_OVERRIDES:\n",
    "    # Compact run controls\n",
    "    config['training_params']['max_total_timesteps'] = 30_000\n",
    "    config['training_params']['timesteps_per_ppo_update'] = 504\n",
    "\n",
    "    # PPO stability controls\n",
    "    ppo = config['agent_params']['ppo_params']\n",
    "    ppo.update({\n",
    "        'policy_clip': 0.10,\n",
    "        'num_ppo_epochs': 4,\n",
    "        'actor_lr': 2e-5,\n",
    "        'critic_lr': 3e-4,\n",
    "        'target_kl': 0.015,\n",
    "        'kl_stop_multiplier': 1.2,\n",
    "        'minibatches_before_kl_stop': 1,\n",
    "    })\n",
    "\n",
    "    # Full-horizon episodes (disable episode-length curriculum)\n",
    "    config['training_params']['use_episode_length_curriculum'] = False\n",
    "    config['training_params']['episode_length_curriculum_schedule'] = [\n",
    "        {'threshold': 0, 'limit': None},\n",
    "    ]\n",
    "\n",
    "    # Turnover / reward controls\n",
    "    env = config['environment_params']\n",
    "    env['target_turnover'] = 0.60\n",
    "    env['turnover_target_band'] = 0.20\n",
    "    env['turnover_penalty_scalar'] = 1.5\n",
    "    env['dsr_scalar'] = 2.0\n",
    "    config['training_params']['evaluation_turnover_penalty_scalar'] = 1.5\n",
    "\n",
    "    # Penalty rebalancing\n",
    "    env['concentration_penalty_scalar'] = 2.0\n",
    "    env['concentration_target_hhi'] = 0.14\n",
    "    env['top_weight_penalty_scalar'] = 1.5\n",
    "    env['target_top_weight'] = 0.22\n",
    "    env['action_realization_penalty_scalar'] = 0.5\n",
    "    env['penalty_budget_ratio'] = 1.25\n",
    "\n",
    "    # Drawdown controller (gentler early adaptation)\n",
    "    dd = env['drawdown_constraint']\n",
    "    dd.update({\n",
    "        'enabled': True,\n",
    "        'target': 0.18,\n",
    "        'penalty_coef': 1.5,\n",
    "        'dual_learning_rate': 0.10,\n",
    "        'lambda_init': 0.50,\n",
    "        'lambda_floor': 0.00,\n",
    "        'lambda_max': 5.0,\n",
    "        'lambda_carry_decay': 0.7,\n",
    "        'tolerance': -0.015,\n",
    "        'penalty_reference': 'trigger_boundary',\n",
    "        'cooling_rate': 0.35,\n",
    "    })\n",
    "\n",
    "    # Intra-step TAPE delta shaping (reduced)\n",
    "    env['intra_step_tape_delta_enabled'] = True\n",
    "    env['intra_step_tape_delta_window'] = 60\n",
    "    env['intra_step_tape_delta_min_history'] = 20\n",
    "    env['intra_step_tape_delta_beta'] = 0.01\n",
    "    env['intra_step_tape_delta_clip'] = 0.20\n",
    "\n",
    "    # Step-level Sharpe checkpointing (save any step where Sharpe >= 0.5)\n",
    "    config['training_params']['step_sharpe_checkpoint_enabled'] = True\n",
    "    config['training_params']['step_sharpe_checkpoint_threshold'] = 0.5\n",
    "\n",
    "    print('Overrides applied')\n",
    "else:\n",
    "    print('APPLY_OVERRIDES=False (using config defaults)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0319556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Variant applied: TCN_FUSION\n",
      "results_root: tcn_fusion_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VARIANT SETTINGS (TCN FAMILY)\n",
    "# ============================================================================\n",
    "VARIANT_SETTINGS = {\n",
    "    'TCN': {\n",
    "        'actor_critic_type': 'TCN',\n",
    "        'use_attention': False,\n",
    "        'use_fusion': False,\n",
    "        'results_root': Path('tcn_results'),\n",
    "    },\n",
    "    'TCN_ATTENTION': {\n",
    "        'actor_critic_type': 'TCN_ATTENTION',\n",
    "        'use_attention': True,\n",
    "        'use_fusion': False,\n",
    "        'results_root': Path('tcn_att_results'),\n",
    "    },\n",
    "    'TCN_FUSION': {\n",
    "        'actor_critic_type': 'TCN_FUSION',\n",
    "        'use_attention': False,\n",
    "        'use_fusion': True,\n",
    "        'results_root': Path('tcn_fusion_results'),\n",
    "    },\n",
    "}\n",
    "\n",
    "ACTIVE_VARIANT = 'TCN_FUSION'  # change to: TCN, TCN_ATTENTION, TCN_FUSION\n",
    "\n",
    "if ACTIVE_VARIANT not in VARIANT_SETTINGS:\n",
    "    raise ValueError(f'Unsupported ACTIVE_VARIANT: {ACTIVE_VARIANT}')\n",
    "\n",
    "v = VARIANT_SETTINGS[ACTIVE_VARIANT]\n",
    "config['agent_params']['actor_critic_type'] = v['actor_critic_type']\n",
    "config['agent_params']['use_attention'] = v['use_attention']\n",
    "config['agent_params']['use_fusion'] = v['use_fusion']\n",
    "\n",
    "config['training_params']['use_episode_length_curriculum'] = False\n",
    "config['training_params']['episode_length_curriculum_schedule'] = [\n",
    "    {'threshold': 0, 'limit': None},\n",
    "]\n",
    "\n",
    "\n",
    "LATEST_VARIANT = ACTIVE_VARIANT\n",
    "LATEST_RESULTS_ROOT = str(v['results_root'])\n",
    "\n",
    "print('âœ… Variant applied:', ACTIVE_VARIANT)\n",
    "print('results_root:', LATEST_RESULTS_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a236e",
   "metadata": {},
   "source": [
    "## 3) Data Pipeline (Features + Actuarial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be89b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRED series config: 19 -> 19 (removed legacy invalid codes: 0)\n",
      "Legacy macro disable set already present\n"
     ]
    }
   ],
   "source": [
    "config = get_active_config(\"phase1\")\n",
    "\n",
    "# Optional guard for legacy/invalid macro codes in old configs.\n",
    "# Current config is already updated, so this is usually a no-op.\n",
    "macro_cfg = config[\"feature_params\"][\"macro_data\"]\n",
    "invalid_legacy_codes = {\"NAPM\", \"MOVEINDEX\", \"ISM/MAN_PMI\", \"MOVE\"}\n",
    "before = len(macro_cfg.get(\"fred_series_config\", []))\n",
    "macro_cfg[\"fred_series_config\"] = [\n",
    "    s for s in macro_cfg.get(\"fred_series_config\", [])\n",
    "    if s.get(\"code\") not in invalid_legacy_codes\n",
    "]\n",
    "after = len(macro_cfg.get(\"fred_series_config\", []))\n",
    "print(f\"FRED series config: {before} -> {after} (removed legacy invalid codes: {before - after})\")\n",
    "\n",
    "# Keep legacy engineered-column disables for backward-compatible runs.\n",
    "legacy_macro_columns = {\"ISM_MAN_PMI_level\", \"ISM_MAN_PMI_diff\", \"MOVE_level\", \"MOVE_zscore\"}\n",
    "disabled = set(config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "newly_added = sorted(list(legacy_macro_columns - disabled))\n",
    "disabled.update(legacy_macro_columns)\n",
    "config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"] = sorted(disabled)\n",
    "if newly_added:\n",
    "    print(\"Added legacy macro disables:\", newly_added)\n",
    "else:\n",
    "    print(\"Legacy macro disable set already present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02ef0430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature pruning enabled: True\n",
      "Disabled feature count: 65\n",
      "Sample disabled features: ['ATRr_14', 'BAMLC0A0CMEY_diff', 'BAMLC0A0CMEY_level', 'BAMLC0A0CMEY_zscore', 'BAMLH0A0HYM2_diff', 'BAMLH0A0HYM2_level', 'BAMLH0A0HYM2_zscore', 'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BetaRank', 'BreakevenInf10Y_level', 'BreakevenInf5Y_level', 'CPI_level', 'CPI_mom', 'CPI_yoy', 'CrossSectional_ZScore_LogReturn_1d', 'DAAA_level', 'DAAA_zscore', 'DGS10_level', 'DGS2_level', 'DMN_14', 'DMP_14', 'EFFR_level', 'EMA_12']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FEATURE PRUNING (APPLIED BEFORE NORMALIZATION)\n",
    "# ============================================================================\n",
    "fs = config.setdefault('feature_params', {}).setdefault('feature_selection', {})\n",
    "fs['disable_features'] = True\n",
    "\n",
    "redundant_features = [\n",
    "    # Price-level / highly collinear technicals\n",
    "    'EMA_12', 'EMA_26', 'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'SMA_50',\n",
    "    'DMP_14', 'DMN_14', 'ATRr_14', 'NATR_14', 'VOL_SMA_20',\n",
    "\n",
    "    # Cross-sectional overlaps\n",
    "    'BetaRank', 'VolatilityRank', 'InverseVolRank',\n",
    "    'CrossSectional_ZScore_LogReturn_1d',\n",
    "\n",
    "    # Macro level duplicates (prefer diff/zscore)\n",
    "    'EFFR_level', 'SOFR_level', 'FEDFUNDS_level',\n",
    "    'DGS10_level', 'DGS2_level', 'T10Y2Y_level',\n",
    "    'TIPS10Y_level', 'BreakevenInf10Y_level', 'BreakevenInf5Y_level',\n",
    "    'IG_Credit_level', 'HY_Credit_level',\n",
    "]\n",
    "\n",
    "existing_disabled = set(fs.get('disabled_features', []))\n",
    "fs['disabled_features'] = sorted(existing_disabled.union(redundant_features))\n",
    "\n",
    "print('Feature pruning enabled:', fs.get('disable_features', False))\n",
    "print('Disabled feature count:', len(fs['disabled_features']))\n",
    "print('Sample disabled features:', fs['disabled_features'][:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9283aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING AND PROCESSING DATA\n",
      "================================================================================\n",
      "Raw shape: (55107, 7)\n",
      "Raw dates: 2003-09-02 00:00:00 â†’ 2025-08-29 00:00:00\n",
      "Macro features added: 43\n",
      "Final master_df shape: (54897, 118)\n",
      "Expected feature cols: 66\n",
      "Present feature cols : 66\n",
      "Feature columns with NaN: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADX_14</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealizedSkew_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RollingVolatility_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DownsideSemiVar_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealizedKurtosis_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSI_14</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFI_14</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "MACDs_12_26_9            330\n",
       "MACDh_12_26_9            330\n",
       "ADX_14                   270\n",
       "MACD_12_26_9             250\n",
       "RealizedSkew_21d         200\n",
       "RollingVolatility_21d    200\n",
       "DownsideSemiVar_21d      200\n",
       "RealizedKurtosis_21d     200\n",
       "STOCHd_14_3_3            170\n",
       "RSI_14                   140\n",
       "MFI_14                   130\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING + FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "processor = DataProcessor(config)\n",
    "\n",
    "print('=' * 80)\n",
    "print('LOADING AND PROCESSING DATA')\n",
    "print('=' * 80)\n",
    "\n",
    "FORCE_DATA_REFRESH = True  # Set True once when you want to rebuild cache for new date bounds\n",
    "raw_df = processor.load_ohlcv_data(\n",
    "    start_date=config['DATA_FETCH_START_DATE'],\n",
    "    end_date=config['DATA_FETCH_END_DATE'],\n",
    "    force_download=FORCE_DATA_REFRESH,\n",
    ")\n",
    "print('Raw shape:', raw_df.shape)\n",
    "print('Raw dates:', raw_df['Date'].min(), 'â†’', raw_df['Date'].max())\n",
    "\n",
    "# Core feature pipeline\n",
    "df = processor.calculate_log_returns(raw_df, periods=[1, 5, 10, 21])\n",
    "df = processor.calculate_return_statistics(df, window=21)\n",
    "df = processor.calculate_technical_indicators(df)\n",
    "df = processor.calculate_dynamic_covariance_features(df)\n",
    "df = processor.add_regime_features(df)\n",
    "df = processor.add_fundamental_features(df)\n",
    "\n",
    "macro_cfg = config.get('feature_params', {}).get('macro_data')\n",
    "if macro_cfg is not None:\n",
    "    macro_df, macro_cols = processor._build_macro_feature_frame(macro_cfg, df['Date'].min(), df['Date'].max())\n",
    "    if macro_df is not None and macro_cols:\n",
    "        df = df.merge(macro_df, on='Date', how='left')\n",
    "        print(f'Macro features added: {len(macro_cols)}')\n",
    "\n",
    "df = processor.add_quant_alpha_features(df)\n",
    "df = processor.add_cross_sectional_features(df)\n",
    "df = processor.add_actuarial_features(df)\n",
    "\n",
    "master_df = df.copy()\n",
    "feature_cols = processor.get_feature_columns('phase1')\n",
    "present_feature_cols = [c for c in feature_cols if c in master_df.columns]\n",
    "\n",
    "print('Final master_df shape:', master_df.shape)\n",
    "print('Expected feature cols:', len(feature_cols))\n",
    "print('Present feature cols :', len(present_feature_cols))\n",
    "\n",
    "nan_counts = master_df[present_feature_cols].isna().sum()\n",
    "nan_cols = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "print('Feature columns with NaN:', len(nan_cols))\n",
    "if len(nan_cols) > 0:\n",
    "    display(nan_cols.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "274159b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d',\n",
       "       ...\n",
       "       'LogReturn_1d_ZScore', 'RollingVolatility_21d_ZScore', 'RSI_14_ZScore',\n",
       "       'BetaRank', 'VolatilityRank', 'InverseVolRank',\n",
       "       'Actuarial_Expected_Recovery', 'Actuarial_Prob_30d',\n",
       "       'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f2cdab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuarial columns present: 4\n",
      "['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "                                  mean        std  min    max\n",
      "Actuarial_Expected_Recovery  42.011758  76.714929  0.0  554.5\n",
      "Actuarial_Prob_30d            0.606662   0.369688  0.0    1.0\n",
      "Actuarial_Prob_60d            0.670430   0.338600  0.0    1.0\n",
      "Actuarial_Reserve_Severity    0.718119   0.334310  0.0    1.0\n"
     ]
    }
   ],
   "source": [
    "act_cols = [c for c in master_df.columns if c.startswith(\"Actuarial_\")]\n",
    "print(\"Actuarial columns present:\", len(act_cols))\n",
    "print(act_cols[:10])\n",
    "\n",
    "if act_cols:\n",
    "    print(master_df[act_cols].describe().T[[\"mean\",\"std\",\"min\",\"max\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db599ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis range: 2003-09-02 â†’ 2025-09-01\n",
      "Train split end: 2021-09-01 | Test start: 2021-09-02\n",
      "Train: 2003-10-01 00:00:00 â†’ 2021-09-01 00:00:00 (44,877 rows)\n",
      "Test : 2021-09-02 00:00:00 â†’ 2025-08-29 00:00:00 (10,020 rows)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIXED DATE SPLIT (TRAIN/TEST)\n",
    "# ============================================================================\n",
    "analysis_start = pd.Timestamp(config.get('ANALYSIS_START_DATE', '2003-09-02'))\n",
    "analysis_end = pd.Timestamp(config.get('ANALYSIS_END_DATE', '2025-09-01'))\n",
    "\n",
    "train_end_date = pd.Timestamp(config.get('TRAIN_TEST_SPLIT_DATE', '2021-09-01'))\n",
    "test_start_date = train_end_date + pd.Timedelta(days=1)\n",
    "test_end_date = analysis_end\n",
    "\n",
    "all_dates = pd.to_datetime(master_df['Date'])\n",
    "master_df = master_df[(all_dates >= analysis_start) & (all_dates <= analysis_end)].copy()\n",
    "all_dates = pd.to_datetime(master_df['Date'])\n",
    "\n",
    "train_mask = all_dates <= train_end_date\n",
    "test_mask = (all_dates >= test_start_date) & (all_dates <= test_end_date)\n",
    "\n",
    "train_df = master_df[train_mask].copy()\n",
    "test_df = master_df[test_mask].copy()\n",
    "\n",
    "print('Analysis range:', analysis_start.date(), 'â†’', analysis_end.date())\n",
    "print('Train split end:', train_end_date.date(), '| Test start:', test_start_date.date())\n",
    "print('Train:', train_df['Date'].min(), 'â†’', train_df['Date'].max(), f'({len(train_df):,} rows)')\n",
    "print('Test :', test_df['Date'].min(), 'â†’', test_df['Date'].max(), f'({len(test_df):,} rows)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e66fd48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d',\n",
       "       ...\n",
       "       'LogReturn_1d_ZScore', 'RollingVolatility_21d_ZScore', 'RSI_14_ZScore',\n",
       "       'BetaRank', 'VolatilityRank', 'InverseVolRank',\n",
       "       'Actuarial_Expected_Recovery', 'Actuarial_Prob_30d',\n",
       "       'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e8a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.data_utils:Found 1980 NaN values after normalization, applying forward-fill only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Normalization complete\n",
      "Normalized shape: (54897, 118)\n",
      "Actuarial columns: ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "Normalization strategy counts: {'robust_winsor': 34, 'bounded': 8, 'standard': 24}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NORMALIZATION (TRAIN-FIT, TEST-TRANSFORM)\n",
    "# ============================================================================\n",
    "from collections import Counter\n",
    "\n",
    "feature_cols = processor.get_feature_columns('phase1')\n",
    "\n",
    "master_df_normalized, scalers = processor.normalize_features(\n",
    "    master_df,\n",
    "    feature_cols=feature_cols,\n",
    "    train_end_date=train_end_date,\n",
    "    test_start_date=test_start_date,\n",
    "    existing_scalers=None,\n",
    "    scaler_type='standard',\n",
    ")\n",
    "\n",
    "actuarial_cols = [c for c in master_df_normalized.columns if c.startswith('Actuarial_')]\n",
    "\n",
    "method_counter = Counter()\n",
    "for c in feature_cols:\n",
    "    spec = scalers.get(c)\n",
    "    if isinstance(spec, dict):\n",
    "        method_counter[str(spec.get('method', 'standard'))] += 1\n",
    "    elif spec is None:\n",
    "        method_counter['missing'] += 1\n",
    "    else:\n",
    "        method_counter['legacy_scaler'] += 1\n",
    "\n",
    "print('âœ… Normalization complete')\n",
    "print('Normalized shape:', master_df_normalized.shape)\n",
    "print('Actuarial columns:', actuarial_cols)\n",
    "print('Normalization strategy counts:', dict(method_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a950c63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase1Dataset ready\n",
      "Train shape: (44877, 118)\n",
      "Test shape : (10020, 118)\n",
      "Covariance features: 3\n",
      "Assets: ['CAT', 'GOOGL', 'JNJ', 'JPM', 'LIN', 'MSFT', 'NEE', 'PG', 'UNH', 'XOM']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BUILD PHASE1 DATASET CONTAINER\n",
    "# ============================================================================\n",
    "all_dates_norm = pd.to_datetime(master_df_normalized['Date'])\n",
    "train_df_norm = master_df_normalized[all_dates_norm <= train_end_date].copy()\n",
    "test_df_norm = master_df_normalized[(all_dates_norm >= test_start_date) & (all_dates_norm <= test_end_date)].copy()\n",
    "\n",
    "covariance_columns = identify_covariance_columns(master_df_normalized.columns)\n",
    "\n",
    "phase1_data = Phase1Dataset(\n",
    "    master_df=master_df_normalized,\n",
    "    train_df=train_df_norm,\n",
    "    test_df=test_df_norm,\n",
    "    scalers=scalers,\n",
    "    train_end_date=train_end_date,\n",
    "    test_start_date=test_start_date,\n",
    "    covariance_columns=covariance_columns,\n",
    "    data_processor=processor,\n",
    ")\n",
    "\n",
    "print('âœ… Phase1Dataset ready')\n",
    "print('Train shape:', phase1_data.train_df.shape)\n",
    "print('Test shape :', phase1_data.test_df.shape)\n",
    "print('Covariance features:', len(covariance_columns))\n",
    "print('Assets:', sorted(phase1_data.master_df['Ticker'].dropna().unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6c752a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44877, 73) (10020, 73)\n"
     ]
    }
   ],
   "source": [
    "active_cols = [c for c in phase1_data.data_processor.get_feature_columns(\"phase1\") if c in phase1_data.master_df.columns]\n",
    "core_cols = [c for c in [\"Date\",\"Ticker\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"] if c in phase1_data.master_df.columns]\n",
    "keep = core_cols + active_cols\n",
    "\n",
    "phase1_data.master_df = phase1_data.master_df[keep].copy()\n",
    "phase1_data.train_df = phase1_data.train_df[keep].copy()\n",
    "phase1_data.test_df  = phase1_data.test_df[keep].copy()\n",
    "print(phase1_data.train_df.shape, phase1_data.test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "939dc509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d', 'LogReturn_21d',\n",
       "       'RollingVolatility_21d', 'DownsideSemiVar_21d', 'RealizedSkew_21d',\n",
       "       'RealizedKurtosis_21d', 'MACD_12_26_9', 'MACDh_12_26_9',\n",
       "       'MACDs_12_26_9', 'RSI_14', 'STOCHd_14_3_3', 'ADX_14', 'OBV', 'MFI_14',\n",
       "       'Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1',\n",
       "       'Covariance_Eigenvalue_2', 'Fundamental_FCFE_Delta',\n",
       "       'Fundamental_Revenue_Delta', 'Fundamental_NCFO_Delta',\n",
       "       'Fundamental_FCFE_Sign', 'Fundamental_Staleness_Days',\n",
       "       'Fundamental_Staleness_Quarters', 'Regime_Volatility_Ratio',\n",
       "       'Regime_Price_vs_SMA_Short', 'Regime_SMA_Short_Slope',\n",
       "       'Regime_SMA_Long_Slope', 'Regime_Momentum_Short',\n",
       "       'Regime_Momentum_Long', 'Regime_Breadth_Positive',\n",
       "       'Regime_Corr_to_Market', 'Residual_Momentum_21', 'Volume_Percentile_63',\n",
       "       'YieldCurve_Spread', 'YieldCurve_Inverted_Flag', 'ShortTerm_Reversal_5',\n",
       "       'VolOfVol_63', 'Beta_to_Market', 'OBV_Delta_Norm_21',\n",
       "       'Actuarial_Expected_Recovery', 'Actuarial_Prob_30d',\n",
       "       'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity', 'EFFR_diff',\n",
       "       'EFFR_zscore', 'SOFR_diff', 'FEDFUNDS_diff', 'FEDFUNDS_zscore',\n",
       "       'DGS10_diff', 'DGS10_slope', 'DGS2_diff', 'TIPS10Y_diff',\n",
       "       'BreakevenInf10Y_diff', 'BreakevenInf5Y_diff', 'IG_Credit_diff',\n",
       "       'IG_Credit_zscore', 'HY_Credit_diff', 'HY_Credit_zscore',\n",
       "       'MomentumRank_21d', 'MomentumRank_63d', 'MomentumRank_252d',\n",
       "       'LogReturn_1d_ZScore', 'RollingVolatility_21d_ZScore', 'RSI_14_ZScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase1_data.train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "507c1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "feature_cols = set(phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "print({\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"} & feature_cols)  # should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70adf57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro feature count: 17\n",
      "['YieldCurve_Spread', 'YieldCurve_Inverted_Flag', 'EFFR_diff', 'EFFR_zscore', 'SOFR_diff', 'FEDFUNDS_diff', 'FEDFUNDS_zscore', 'DGS10_diff', 'DGS10_slope', 'DGS2_diff', 'TIPS10Y_diff', 'BreakevenInf10Y_diff', 'BreakevenInf5Y_diff', 'IG_Credit_diff', 'IG_Credit_zscore', 'HY_Credit_diff', 'HY_Credit_zscore']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = phase1_data.data_processor.get_feature_columns(\"phase1\")\n",
    "macro_cols = [c for c in feature_cols if c.startswith((\n",
    "    \"EFFR_\", \"SOFR_\", \"FEDFUNDS_\", \"DGS\", \"T10Y2Y_\", \"TIPS\", \"Breakeven\", \"IG_Credit_\", \"HY_Credit_\", \"YieldCurve_\"\n",
    "))]\n",
    "print(\"macro feature count:\", len(macro_cols))\n",
    "print(macro_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b016baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled âˆ© Active: []\n",
      "Count: 0\n"
     ]
    }
   ],
   "source": [
    "disabled = set(config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "active = set(phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "\n",
    "print(\"Disabled âˆ© Active:\", sorted(disabled & active))\n",
    "print(\"Count:\", len(disabled & active))  # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2d55fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disable_features: True\n",
      "disabled count: 65\n",
      "active count: 66\n",
      "disabled âˆ© active: 0\n",
      "overlap sample: []\n",
      "âœ… Pre-train check passed: pruned features are not in active feature list.\n"
     ]
    }
   ],
   "source": [
    "# PRE-TRAIN ACTIVE FEATURE CHECK\n",
    "disabled = set(config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "active = set(phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "\n",
    "overlap = sorted(disabled & active)\n",
    "print(\"disable_features:\", config[\"feature_params\"][\"feature_selection\"][\"disable_features\"])\n",
    "print(\"disabled count:\", len(disabled))\n",
    "print(\"active count:\", len(active))\n",
    "print(\"disabled âˆ© active:\", len(overlap))\n",
    "print(\"overlap sample:\", overlap[:20])\n",
    "\n",
    "assert config[\"feature_params\"][\"feature_selection\"][\"disable_features\"] is True, \"disable_features is not enabled\"\n",
    "assert len(overlap) == 0, f\"Some disabled features are still active: {overlap[:10]}\"\n",
    "print(\"âœ… Pre-train check passed: pruned features are not in active feature list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01baf8e",
   "metadata": {},
   "source": [
    "## 4) Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional stability tweaks (keep commented unless needed)\n",
    "# config['training_params']['timesteps_per_ppo_update'] = 504\n",
    "# ppo = config['agent_params']['ppo_params']\n",
    "# ppo['batch_size_ppo'] = 512\n",
    "# ppo['num_ppo_epochs'] = 5\n",
    "# ppo['actor_lr'] = 5e-5\n",
    "# ppo['critic_lr'] = 1e-4\n",
    "# ppo['policy_clip'] = 0.15\n",
    "# ppo['target_kl'] = 0.02\n",
    "# ppo['entropy_coef'] = 0.01\n",
    "# config['environment_params']['penalty_budget_ratio'] = 1.25\n",
    "# config['environment_params']['intra_step_tape_delta_beta'] = 0.10\n",
    "# config['environment_params']['intra_step_tape_delta_clip'] = 0.20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248613b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = config[\"agent_params\"]\n",
    "ppo = ap[\"ppo_params\"]\n",
    "tp = config[\"training_params\"]\n",
    "ep = config[\"environment_params\"]\n",
    "\n",
    "# PPO stability\n",
    "ppo[\"actor_lr\"] = 1e-5\n",
    "ppo[\"critic_lr\"] = 2e-4\n",
    "ppo[\"num_ppo_epochs\"] = 2\n",
    "ppo[\"batch_size_ppo\"] = 128\n",
    "ppo[\"target_kl\"] = 0.02\n",
    "ppo[\"entropy_coef\"] = 0.003\n",
    "ppo[\"policy_clip\"] = 0.08\n",
    "\n",
    "# rollout/update cadence\n",
    "tp[\"timesteps_per_ppo_update\"] = 256\n",
    "\n",
    "# model size (reduce volatility + OOM risk)\n",
    "ap[\"sequence_length\"] = 40\n",
    "ap[\"tcn_filters\"] = [32, 64, 64]\n",
    "\n",
    "# reward noise reduction + turnover discipline\n",
    "ep[\"intra_step_tape_delta_enabled\"] = False\n",
    "ep[\"dsr_scalar\"] = 1.0\n",
    "ep[\"target_turnover\"] = 0.50\n",
    "ep[\"turnover_penalty_scalar\"] = 1.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1fd8ae",
   "metadata": {},
   "source": [
    "### Optuna Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c30847",
   "metadata": {},
   "source": [
    "##### Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f701af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = config[\"agent_params\"]\n",
    "ppo = ap[\"ppo_params\"]\n",
    "tp = config[\"training_params\"]\n",
    "ep = config[\"environment_params\"]\n",
    "\n",
    "# PPO stability\n",
    "ppo[\"actor_lr\"] = 1e-5\n",
    "ppo[\"critic_lr\"] = 2e-4\n",
    "ppo[\"num_ppo_epochs\"] = 1\n",
    "ppo[\"policy_clip\"] = 0.06\n",
    "ppo[\"target_kl\"] = 0.02\n",
    "ppo[\"entropy_coef\"] = 0.002\n",
    "ppo[\"max_grad_norm\"] = 0.3\n",
    "\n",
    "# short tuning budget\n",
    "tp[\"timesteps_per_ppo_update\"] = 256\n",
    "tp[\"max_total_timesteps\"] = 20000\n",
    "\n",
    "config[\"training_params\"][\"use_episode_length_curriculum\"] = True\n",
    "config[\"training_params\"][\"episode_length_curriculum_schedule\"] = [\n",
    "    {\"threshold\": 0, \"limit\": 252},\n",
    "    {\"threshold\": 10000, \"limit\": 504},\n",
    "    {\"threshold\": 30000, \"limit\": 1000},\n",
    "    {\"threshold\": 60000, \"limit\": None},\n",
    "]\n",
    "\n",
    "# reduce reward noise, enforce turnover discipline\n",
    "ep[\"intra_step_tape_delta_enabled\"] = False\n",
    "ep[\"dsr_scalar\"] = 1.0\n",
    "ep[\"target_turnover\"] = 0.50\n",
    "ep[\"turnover_penalty_scalar\"] = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179d911",
   "metadata": {},
   "source": [
    "##### Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707edab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied next-run stability-first tuning\n",
      "max_total_timesteps: 100000\n",
      "timesteps_per_ppo_update_schedule: [{'threshold': 0, 'timesteps_per_update': 384}, {'threshold': 30000, 'timesteps_per_update': 512}]\n",
      "batch_size_ppo_schedule: [{'threshold': 0, 'batch_size': 96}, {'threshold': 30000, 'batch_size': 128}]\n",
      "target_kl: 0.012 | kl_stop_multiplier: 1.2 | policy_clip: 0.05\n",
      "actor_lr: 1e-05 | critic_lr: 0.00012\n",
      "turnover_penalty_curriculum: {0: 1.5, 10000: 2.0, 25000: 2.5, 40000: 3.0}\n",
      "terminal gate mdd: 0.23\n",
      "risk_aux: True | sharpe_coef: 0.03 | mvo_coef: 0.001\n",
      "Dirichlet: elu {'max': 0.35, 'min': 0.2} | temp: 1.25 | alpha_cap: 40.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NEXT RUN TUNING OVERRIDES (stability-first + risk-aux + rollout schedule)\n",
    "# ============================================================================\n",
    "from copy import deepcopy\n",
    "\n",
    "config = deepcopy(config)\n",
    "\n",
    "tp = config[\"training_params\"]\n",
    "ppo = config[\"agent_params\"][\"ppo_params\"]\n",
    "env = config[\"environment_params\"]\n",
    "\n",
    "# 1) Train length + PPO rollout schedule\n",
    "tp[\"max_total_timesteps\"] = 100_000\n",
    "\n",
    "# Fallback defaults (used if schedule is missing)\n",
    "tp[\"timesteps_per_ppo_update\"] = 384\n",
    "tp[\"batch_size_ppo\"] = 96\n",
    "\n",
    "# Rollout schedule (less noisy updates than starting at 256)\n",
    "tp[\"timesteps_per_ppo_update_schedule\"] = [\n",
    "    {\"threshold\": 0, \"timesteps_per_update\": 384},\n",
    "    {\"threshold\": 30_000, \"timesteps_per_update\": 512},\n",
    "]\n",
    "\n",
    "# Batch-size schedule (roughly rollout / 4)\n",
    "tp[\"batch_size_ppo_schedule\"] = [\n",
    "    {\"threshold\": 0, \"batch_size\": 96},\n",
    "    {\"threshold\": 30_000, \"batch_size\": 128},\n",
    "]\n",
    "\n",
    "# 2) PPO stability tightening\n",
    "ppo[\"num_ppo_epochs\"] = 1\n",
    "ppo[\"actor_lr\"] = 1.0e-5\n",
    "ppo[\"critic_lr\"] = 1.2e-4\n",
    "ppo[\"target_kl\"] = 0.012\n",
    "ppo[\"kl_stop_multiplier\"] = 1.2\n",
    "ppo[\"entropy_coef\"] = 0.0015\n",
    "ppo[\"max_grad_norm\"] = 0.20\n",
    "ppo[\"policy_clip\"] = 0.05\n",
    "\n",
    "tp[\"actor_lr_schedule\"] = [\n",
    "    {\"threshold\": 0, \"lr\": 1.0e-5},\n",
    "    {\"threshold\": 35_000, \"lr\": 8.0e-6},\n",
    "    {\"threshold\": 70_000, \"lr\": 6.0e-6},\n",
    "]\n",
    "\n",
    "# 3) Episode horizon curriculum\n",
    "tp[\"use_episode_length_curriculum\"] = True\n",
    "tp[\"episode_length_curriculum_schedule\"] = [\n",
    "    {\"threshold\": 0, \"limit\": 252},\n",
    "    {\"threshold\": 10_000, \"limit\": 504},\n",
    "    {\"threshold\": 25_000, \"limit\": 756},\n",
    "    {\"threshold\": 40_000, \"limit\": None},\n",
    "]\n",
    "\n",
    "tp[\"log_step_diagnostics\"] = True\n",
    "\n",
    "# 4) Turnover control (steady but not overly punitive)\n",
    "tp[\"turnover_penalty_curriculum\"] = {\n",
    "    0: 1.5,\n",
    "    10_000: 2.0,\n",
    "    25_000: 2.5,\n",
    "    40_000: 3.0,\n",
    "}\n",
    "tp[\"evaluation_turnover_penalty_scalar\"] = 3.0\n",
    "\n",
    "env[\"target_turnover\"] = 0.35\n",
    "env[\"turnover_penalty_scalar\"] = 1.5\n",
    "env[\"transaction_cost_pct\"] = 0.0005\n",
    "env[\"action_realization_penalty_scalar\"] = 1.0\n",
    "\n",
    "# 5) Signed terminal reward + tighter Gate A\n",
    "env[\"tape_terminal_bonus_mode\"] = \"signed\"\n",
    "env[\"tape_terminal_baseline\"] = 0.20\n",
    "env[\"tape_terminal_scalar\"] = 6.0\n",
    "env[\"tape_terminal_clip\"] = 6.0\n",
    "env[\"tape_terminal_gate_a_enabled\"] = True\n",
    "env[\"tape_terminal_gate_a_sharpe_threshold\"] = 0.0\n",
    "env[\"tape_terminal_gate_a_max_drawdown\"] = 0.23\n",
    "env[\"tape_terminal_neutral_band_halfwidth\"] = 0.003\n",
    "\n",
    "# 6) Risk-aware actor auxiliary objective (moderate strength)\n",
    "ppo[\"use_risk_aux_loss\"] = True\n",
    "ppo[\"risk_aux_return_feature_index\"] = 0\n",
    "ppo[\"risk_aux_cash_return\"] = 0.0\n",
    "ppo[\"risk_aux_sharpe_coef\"] = 0.03\n",
    "ppo[\"risk_aux_mvo_coef\"] = 0.001\n",
    "ppo[\"risk_aux_mvo_cov_ridge\"] = 1e-3\n",
    "ppo[\"risk_aux_mvo_long_only\"] = True\n",
    "ppo[\"risk_aux_mvo_risky_budget\"] = 0.95\n",
    "\n",
    "ap = config[\"agent_params\"]\n",
    "\n",
    "# Keep stable activation\n",
    "ap[\"dirichlet_alpha_activation\"] = \"elu\"\n",
    "\n",
    "# Less noisy sampling than current {max:0.5, min:0.1}\n",
    "ap[\"dirichlet_epsilon\"] = {\"max\": 0.35, \"min\": 0.20}\n",
    "\n",
    "# Flatten logits a bit to reduce extreme weight jumps\n",
    "ap[\"dirichlet_logit_temperature\"] = 1.25\n",
    "\n",
    "# Prevent overconfident alpha spikes\n",
    "ap[\"dirichlet_alpha_cap\"] = 40.0\n",
    "\n",
    "# Keep as-is unless you switch activation to exp_clip\n",
    "ap[\"dirichlet_exp_clip\"] = (-5.0, 3.0)\n",
    "\n",
    "\n",
    "print(\"âœ… Applied next-run stability-first tuning\")\n",
    "print(\"max_total_timesteps:\", tp[\"max_total_timesteps\"])\n",
    "print(\"timesteps_per_ppo_update_schedule:\", tp[\"timesteps_per_ppo_update_schedule\"])\n",
    "print(\"batch_size_ppo_schedule:\", tp[\"batch_size_ppo_schedule\"])\n",
    "print(\"target_kl:\", ppo[\"target_kl\"], \"| kl_stop_multiplier:\", ppo[\"kl_stop_multiplier\"], \"| policy_clip:\", ppo[\"policy_clip\"])\n",
    "print(\"actor_lr:\", ppo[\"actor_lr\"], \"| critic_lr:\", ppo[\"critic_lr\"])\n",
    "print(\"turnover_penalty_curriculum:\", tp[\"turnover_penalty_curriculum\"])\n",
    "print(\"terminal gate mdd:\", env[\"tape_terminal_gate_a_max_drawdown\"])\n",
    "print(\"risk_aux:\", ppo[\"use_risk_aux_loss\"], \"| sharpe_coef:\", ppo[\"risk_aux_sharpe_coef\"], \"| mvo_coef:\", ppo[\"risk_aux_mvo_coef\"])\n",
    "print(\"Dirichlet:\", ap[\"dirichlet_alpha_activation\"], ap[\"dirichlet_epsilon\"],\n",
    "      \"| temp:\", ap[\"dirichlet_logit_temperature\"], \"| alpha_cap:\", ap[\"dirichlet_alpha_cap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5caa6349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting training\n",
      "Variant: TCN_FUSION\n",
      "max_total_timesteps: 100000\n",
      "timesteps_per_ppo_update: 384\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 6: TCN_FUSION Enhanced + TAPE Three-Component\n",
      "================================================================================\n",
      "Architecture: TCN + Fusion\n",
      "Results root: /content/adaptive_portfolio_rl/tcn_fusion_results\n",
      "Working dir: /content/adaptive_portfolio_rl\n",
      "Covariance Features: Yes\n",
      "ðŸŽ¯ REWARD SYSTEM: TAPE (Three-Component v3)\n",
      "   Profile: BalancedGrowth\n",
      "   Daily: Base + DSR/PBRS + Turnover_Proximity\n",
      "   Terminal: mode=signed | baseline=0.20 | scalar=6.0 (clipped Â±6.0)\n",
      "   Gate A: enabled (Sharpe â‰¤ 0.00 or MDD â‰¥ 23.0% -> force non-positive terminal bonus)\n",
      "   Neutral Band: enabled (Â±0.003 around baseline)\n",
      "   ðŸ”„ Profile Manager: disabled (static profile only)\n",
      "ðŸŽ² Experiment Seed: 6042 (Base: 42, Offset: 6000)\n",
      "âœ… Features: Enhanced (includes 3 covariance eigenvalues)\n",
      "   Eigenvalues: ['Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1', 'Covariance_Eigenvalue_2']\n",
      "   Train shape: (44877, 73)\n",
      "   Test shape: (10020, 73)\n",
      "\n",
      "ðŸ—ï¸ Creating THREE-COMPONENT TAPE v3 environments (with curriculum)...\n",
      "   ðŸŽ¯ Reward System: TAPE (Three-Component v3)\n",
      "   ðŸ“Š Profile: BalancedGrowth\n",
      "   âš™ï¸  Component 1: Base Reward (Net Return)\n",
      "   âš™ï¸  Component 2: DSR/PBRS (window=60, scalar=2.00, gamma=0.99)\n",
      "   âš™ï¸  Component 3: Turnover Proximity (target=0.35, band=Â±0.20, scalar=1.50 -> 2.00 â†’ 2.50 â†’ 3.00)\n",
      "      â†³ Schedule: 1.50@0 â†’ 2.00@10,000 â†’ 2.50@25,000 â†’ 3.00@40,000\n",
      "   ðŸŽ Terminal: mode=signed, baseline=0.20, scalar=6.0 (clipped Â±6.0)\n",
      "   ðŸŸ° Neutral Band: enabled (Â±0.003 around baseline)\n",
      "   ðŸš¦ Gate A: enabled (Sharpe â‰¤ 0.00, MDD â‰¥ 23.0%)\n",
      "   ðŸ§  Credit Assignment: step reward is computed at each environment step\n",
      "   ðŸ§¾ Episode-End Handling: terminal TAPE bonus is added at episode completion only\n",
      "   âœ… Retroactive episode-wide reward rescaling: disabled in notebook helper path\n",
      "   ðŸ”’ Drawdown dual controller (requested): target=18.00%, tolerance=-1.50% (trigger boundary â‰ˆ 16.50%), lr=0.100, Î»_init=0.50, Î»_floor=0.00, Î»_max=5.00, penalty_coef=1.50\n",
      "   âœ… Drawdown controller armed in env: target=18.00%, trigger=16.50%, Î»_init=0.500, Î»_floor=0.000, Î»_max=5.00, penalty_coef=1.50\n",
      "âœ… THREE-COMPONENT TAPE v3 Environments created:\n",
      "   Training: 4512 days\n",
      "   Testing: 1002 days\n",
      "\n",
      "ðŸ¤– Creating TCN_FUSION agent with Dirichlet distribution for Exp 6...\n",
      "âœ… Agent created: PPOAgentTF\n",
      "   ðŸŽ² Dirichlet Distribution: ENABLED\n",
      "   ðŸ”§ Actor LR schedule: 0.000010@0 â†’ 0.000008@35,000 â†’ 0.000006@70,000\n",
      "   State dim: 417\n",
      "   Action dim: 10\n",
      "   Actor LR (configured): 1e-05\n",
      "   Actor LR (active): 0.000010\n",
      "   Critic LR (active): 0.000120\n",
      "   PPO update: epochs=1, batch_size=96, target_kl=0.0120, entropy_coef=0.0015\n",
      "   ðŸ“ PPO rollout schedule: 384@0 â†’ 512@30,000\n",
      "   ðŸ§º PPO batch-size schedule: 96@0 â†’ 128@30,000\n",
      "ðŸ“Š Training metrics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_064355_episodes.csv\n",
      "ðŸ§ª Step diagnostics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_064355_step_diagnostics.csv\n",
      "\n",
      "ðŸŽ¯ Starting THREE-COMPONENT TAPE v3 training (with curriculum)...\n",
      "   Total timesteps: 100,000\n",
      "   Timesteps per update: scheduled\n",
      "      0+ steps: timesteps_per_update=384\n",
      "      30,000+ steps: timesteps_per_update=512\n",
      "   Number of updates: 216\n",
      "   PPO batch_size: scheduled\n",
      "      0+ steps: batch_size=96\n",
      "      30,000+ steps: batch_size=128\n",
      "   ðŸ“š Episode Length Curriculum:\n",
      "      0+ steps: limit=252\n",
      "      10,000+ steps: limit=504\n",
      "      25,000+ steps: limit=756\n",
      "      40,000+ steps: limit=full\n",
      "   ðŸ“š Turnover Scalar Curriculum:\n",
      "      0+ steps: scalar=1.50\n",
      "      10,000+ steps: scalar=2.00\n",
      "      25,000+ steps: scalar=2.50\n",
      "      40,000+ steps: scalar=3.00\n",
      "   ðŸ† High-Watermark checkpoints: enabled (save every episode with Sharpe >= 0.50)\n",
      "   ðŸ§· Step-Sharpe checkpoints: disabled\n",
      "ðŸ§¾ Active feature manifest saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_064355_active_feature_manifest.json\n",
      "ðŸ§¾ Training metadata saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_064355_metadata.json\n",
      "   ðŸŽ¯ Episode 1: TAPE Score = 0.1870 (bonus: -0.39 â†’ -0.39)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.090, MDD=24.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.051955 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 1/216 | Step 384/100,000 | Episode 1 | Time: 66.7s\n",
      "   ðŸ“Š Metrics: Return=+1.25% | Sharpe=0.090 | DD=24.24% | Turnover=74.98%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7114 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1590 | critic_loss=15.2615 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=7.6307 | risk_aux_total=-0.0038 | sharpe_proxy=0.1266 | sharpe_loss=-0.0038 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.33% / trig 16.50%) | terminal=0.000 (peak 0.503) | TAPE=0.1870\n",
      "   ðŸŽ¯ Episode 2: TAPE Score = 0.2222 (bonus: +0.17 â†’ +0.17)\n",
      "   ðŸŽ¯ Episode 3: TAPE Score = 0.5287 (bonus: +2.47 â†’ +2.47)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p059_actor.weights.h5 (Sharpe=1.059)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034537 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 2/216 | Step 768/100,000 | Episode 3 | Time: 123.3s\n",
      "   ðŸ“Š Metrics: Return=+13.82% | Sharpe=1.059 | DD=5.36% | Turnover=70.17%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0381 | critic_loss=0.0544 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0272 | risk_aux_total=-0.0001 | sharpe_proxy=0.0029 | sharpe_loss=-0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.22% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5287\n",
      "   ðŸŽ¯ Episode 4: TAPE Score = 0.2059 (bonus: -0.04 â†’ -0.04)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.415, MDD=31.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035701 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 3/216 | Step 1,152/100,000 | Episode 4 | Time: 177.4s\n",
      "   ðŸ“Š Metrics: Return=+10.80% | Sharpe=0.415 | DD=31.52% | Turnover=73.82%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2254 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0473 | critic_loss=0.1140 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0570 | risk_aux_total=-0.0041 | sharpe_proxy=0.1373 | sharpe_loss=-0.0041 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.27% / trig 16.50%) | terminal=0.000 (peak 0.108) | TAPE=0.2059\n",
      "   ðŸŽ¯ Episode 5: TAPE Score = 0.3269 (bonus: +0.95 â†’ +0.95)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp0p639_actor.weights.h5 (Sharpe=0.639)\n",
      "   ðŸŽ¯ Episode 6: TAPE Score = 0.7031 (bonus: +3.77 â†’ +3.77)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp2p561_actor.weights.h5 (Sharpe=2.561)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep6_sh2.561_dd2.3_actor.weights.h5 (Sharpe 2.561, MDD 2.30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036700 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 4/216 | Step 1,536/100,000 | Episode 6 | Time: 232.2s\n",
      "   ðŸ“Š Metrics: Return=+21.15% | Sharpe=2.561 | DD=2.30% | Turnover=71.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7037 | delta_reward=+0.0005\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0638 | critic_loss=0.0660 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0330 | risk_aux_total=-0.0044 | sharpe_proxy=0.1461 | sharpe_loss=-0.0044 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.51% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.7031\n",
      "   ðŸŽ¯ Episode 7: TAPE Score = 0.2423 (bonus: +0.32 â†’ +0.32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.050557 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 5/216 | Step 1,920/100,000 | Episode 7 | Time: 286.6s\n",
      "   ðŸ“Š Metrics: Return=+4.02% | Sharpe=0.226 | DD=11.87% | Turnover=67.98%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2186 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0755 | critic_loss=0.1091 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0545 | risk_aux_total=-0.0036 | sharpe_proxy=0.1212 | sharpe_loss=-0.0036 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 8.62% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.2423\n",
      "   ðŸŽ¯ Episode 8: TAPE Score = 0.1709 (bonus: -0.87 â†’ -0.87)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.657, MDD=38.82%\n",
      "   ðŸŽ¯ Episode 9: TAPE Score = 0.3453 (bonus: +1.09 â†’ +1.09)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00009_shp0p675_actor.weights.h5 (Sharpe=0.675)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.023775 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 6/216 | Step 2,304/100,000 | Episode 9 | Time: 341.0s\n",
      "   ðŸ“Š Metrics: Return=+10.94% | Sharpe=0.675 | DD=7.94% | Turnover=69.76%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2169 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0947 | critic_loss=0.1913 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0957 | risk_aux_total=0.0000 | sharpe_proxy=-0.0001 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.93% / trig 16.50%) | terminal=0.000 (peak 0.519) | TAPE=0.3453\n",
      "   ðŸŽ¯ Episode 10: TAPE Score = 0.2330 (bonus: +0.25 â†’ +0.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015529 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 7/216 | Step 2,688/100,000 | Episode 10 | Time: 396.1s\n",
      "   ðŸ“Š Metrics: Return=+3.23% | Sharpe=0.164 | DD=10.61% | Turnover=73.18%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5738 | delta_reward=-0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1032 | critic_loss=0.0936 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0468 | risk_aux_total=0.0013 | sharpe_proxy=-0.0432 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.2330\n",
      "   ðŸŽ¯ Episode 11: TAPE Score = 0.2547 (bonus: +0.41 â†’ +0.41)\n",
      "   ðŸŽ¯ Episode 12: TAPE Score = 0.1820 (bonus: -0.54 â†’ -0.54)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.405, MDD=24.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019602 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 8/216 | Step 3,072/100,000 | Episode 12 | Time: 450.1s\n",
      "   ðŸ“Š Metrics: Return=-7.13% | Sharpe=-0.405 | DD=24.48% | Turnover=74.07%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7214 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0304 | critic_loss=0.1845 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0922 | risk_aux_total=0.0008 | sharpe_proxy=-0.0268 | sharpe_loss=0.0008 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.138, dd 0.45% / trig 16.50%) | terminal=0.197 (peak 0.197) | TAPE=0.1820\n",
      "   ðŸŽ¯ Episode 13: TAPE Score = 0.3023 (bonus: +0.77 â†’ +0.77)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00013_shp0p610_actor.weights.h5 (Sharpe=0.610)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030225 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 9/216 | Step 3,456/100,000 | Episode 13 | Time: 505.5s\n",
      "   ðŸ“Š Metrics: Return=+9.02% | Sharpe=0.610 | DD=8.21% | Turnover=69.18%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2113 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0110 | critic_loss=0.1287 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0644 | risk_aux_total=-0.0016 | sharpe_proxy=0.0530 | sharpe_loss=-0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.77% / trig 16.50%) | terminal=0.000 (peak 0.138) | TAPE=0.3023\n",
      "   ðŸŽ¯ Episode 14: TAPE Score = 0.1991 (bonus: -0.00 â†’ -0.00)\n",
      "      ðŸŸ° Neutral band applied (Â±0.003)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.230, MDD=16.05%\n",
      "   ðŸŽ¯ Episode 15: TAPE Score = 0.4793 (bonus: +2.10 â†’ +2.10)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00015_shp0p919_actor.weights.h5 (Sharpe=0.919)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.039187 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 10/216 | Step 3,840/100,000 | Episode 15 | Time: 560.0s\n",
      "   ðŸ“Š Metrics: Return=+9.16% | Sharpe=0.919 | DD=4.28% | Turnover=71.06%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3589 | delta_reward=-0.0015\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1045 | critic_loss=0.1151 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0575 | risk_aux_total=0.0002 | sharpe_proxy=-0.0051 | sharpe_loss=0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.72 | std=0.30 | range=[1.06, 2.18]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 3.72% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4793\n",
      "   ðŸŽ¯ Episode 16: TAPE Score = 0.3115 (bonus: +0.84 â†’ +0.84)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00016_shp0p706_actor.weights.h5 (Sharpe=0.706)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.017314 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 11/216 | Step 4,224/100,000 | Episode 16 | Time: 614.7s\n",
      "   ðŸ“Š Metrics: Return=+10.01% | Sharpe=0.706 | DD=8.78% | Turnover=72.02%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2073 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0642 | critic_loss=0.2274 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1137 | risk_aux_total=0.0009 | sharpe_proxy=-0.0299 | sharpe_loss=0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 5.31% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3115\n",
      "   ðŸŽ¯ Episode 17: TAPE Score = 0.2051 (bonus: -0.04 â†’ -0.04)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.302, MDD=15.98%\n",
      "   ðŸŽ¯ Episode 18: TAPE Score = 0.1763 (bonus: -0.71 â†’ -0.71)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.066, MDD=32.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.043616 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 12/216 | Step 4,608/100,000 | Episode 18 | Time: 669.0s\n",
      "   ðŸ“Š Metrics: Return=-1.11% | Sharpe=0.066 | DD=32.05% | Turnover=72.05%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2975 | delta_reward=-0.0021\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1792 | critic_loss=0.3009 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1504 | risk_aux_total=0.0002 | sharpe_proxy=-0.0077 | sharpe_loss=0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.042, dd 2.08% / trig 16.50%) | terminal=0.060 (peak 0.157) | TAPE=0.1763\n",
      "   ðŸŽ¯ Episode 19: TAPE Score = 0.2515 (bonus: +0.39 â†’ +0.39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027971 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 13/216 | Step 4,992/100,000 | Episode 19 | Time: 724.2s\n",
      "   ðŸ“Š Metrics: Return=+8.99% | Sharpe=0.433 | DD=15.88% | Turnover=72.61%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5190 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0767 | critic_loss=0.2225 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1112 | risk_aux_total=-0.0019 | sharpe_proxy=0.0645 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.10% / trig 16.50%) | terminal=0.000 (peak 0.042) | TAPE=0.2515\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-335189549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timesteps_per_ppo_update:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timesteps_per_ppo_update'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     experiment6 = run_experiment6_tape(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mphase1_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphase1_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/adaptive_portfolio_rl/src/notebook_helpers/tcn_phase1.py\u001b[0m in \u001b[0;36mrun_experiment6_tape\u001b[0;34m(phase1_data, config, random_seed, exp_idx, exp_name, architecture, use_covariance, profile, agent_cls, csv_logger_cls, timesteps_per_update, max_total_timesteps)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         \u001b[0msteps_this_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_timestep_rollout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_total_timesteps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_this_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_and_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2437\u001b[0m             \u001b[0mprev_portfolio_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"portfolio_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m             \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/adaptive_portfolio_rl/src/agents/ppo_agent_tf.py\u001b[0m in \u001b[0;36mget_action_and_value\u001b[0;34m(self, state, deterministic, stochastic, evaluation_mode)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# Get value estimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# Squeeze batch dimension if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/adaptive_portfolio_rl/src/agents/actor_critic_tf.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, state, training)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0mx_assets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_assets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0mx_assets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_assets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_assets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfusion_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m         \u001b[0mx_assets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_assets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m         \u001b[0masset_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_assets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/adaptive_portfolio_rl/src/agents/actor_critic_tf.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Split into multiple heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   4019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, grad_a, grad_b, name)\u001b[0m\n\u001b[1;32m   3635\u001b[0m         )\n\u001b[1;32m   3636\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3637\u001b[0;31m         return gen_math_ops.batch_mat_mul_v2(\n\u001b[0m\u001b[1;32m   3638\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3639\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, grad_x, grad_y, name)\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1640\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BatchMatMulV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \"grad_x\", grad_x, \"grad_y\", grad_y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAIN ACTIVE VARIANT\n",
    "# ============================================================================\n",
    "RUN_TRAINING = True\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    train_cfg = config['training_params']\n",
    "    print('ðŸš€ Starting training')\n",
    "    print('Variant:', ACTIVE_VARIANT)\n",
    "    print('max_total_timesteps:', train_cfg['max_total_timesteps'])\n",
    "    print('timesteps_per_ppo_update:', train_cfg['timesteps_per_ppo_update'])\n",
    "\n",
    "    experiment6 = run_experiment6_tape(\n",
    "        phase1_data=phase1_data,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        csv_logger_cls=CSVLogger,\n",
    "        use_covariance=True,\n",
    "        architecture=config['agent_params']['actor_critic_type'],\n",
    "        timesteps_per_update=train_cfg['timesteps_per_ppo_update'],\n",
    "        max_total_timesteps=train_cfg['max_total_timesteps'],\n",
    "    )\n",
    "\n",
    "    print('âœ… Training complete')\n",
    "    print('checkpoint_prefix:', experiment6.checkpoint_path)\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_TRAINING=False (set True to train)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09764b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files inside results\n",
    "!find ./tcn_fusion_results -maxdepth 3 -type f | head -n 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download /content/adaptive_portfolio_rl/tcn_fusion_results as a zip\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "src = Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results\")\n",
    "zip_base = Path(\"/content/tcn_fusion_results_download_new\")\n",
    "\n",
    "if not src.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {src}\")\n",
    "\n",
    "zip_path = shutil.make_archive(str(zip_base), \"zip\", root_dir=str(src.parent), base_dir=src.name)\n",
    "print(\"Created:\", zip_path)\n",
    "\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66784a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp /content/tcn_fusion_results_download_new.zip /content/drive/MyDrive/\n",
    "print(\"Copied to Google Drive: MyDrive/tcn_fusion_results_download_new.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ab856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUICK TRAINING LOG INSPECTION (LATEST)\n",
    "# ============================================================================\n",
    "logs_dir = Path(LATEST_RESULTS_ROOT) / 'logs'\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "episodes_files = sorted(logs_dir.glob('*episodes*.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not episodes_files:\n",
    "    print(f'No episodes CSV found in {logs_dir} yet.')\n",
    "else:\n",
    "    epis_path = episodes_files[0]\n",
    "    episodes_df = pd.read_csv(epis_path)\n",
    "    print('Episodes file:', epis_path)\n",
    "    print('Rows:', len(episodes_df))\n",
    "    display(episodes_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bacaf2",
   "metadata": {},
   "source": [
    "## 5) Evaluation (Unified Multi-Track)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: RELOAD TRAINING METADATA (POST-RESTART)\n",
    "# ============================================================================\n",
    "USE_METADATA_RELOAD = False\n",
    "METADATA_PATH = None  # e.g., Path('tcn_results/logs/Exp6_TCN_Enhanced_TAPE_training_YYYYMMDD_HHMMSS_metadata.json')\n",
    "\n",
    "if USE_METADATA_RELOAD:\n",
    "    if METADATA_PATH is None:\n",
    "        logs_dir = Path(LATEST_RESULTS_ROOT) / 'logs'\n",
    "        cand = sorted(logs_dir.glob('*metadata*.json'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        METADATA_PATH = cand[0] if cand else None\n",
    "\n",
    "    if METADATA_PATH and Path(METADATA_PATH).exists():\n",
    "        config = load_training_metadata_into_config(Path(METADATA_PATH), config, verbose=True)\n",
    "        print('âœ… Metadata reloaded from:', METADATA_PATH)\n",
    "    else:\n",
    "        print('âš ï¸ Metadata file not found; continuing with current config.')\n",
    "else:\n",
    "    print('â„¹ï¸ USE_METADATA_RELOAD=False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UNIFIED EVALUATION: det_mode + det_mean + stochastic\n",
    "# ============================================================================\n",
    "RUN_EVAL = True\n",
    "\n",
    "# Model selection\n",
    "MODEL_FAMILY = 'normal'           # normal | rare | clip\n",
    "NORMAL_MODEL_STRATEGY = 'latest'  # latest | final\n",
    "RARE_MODEL_STRATEGY = 'best'      # best | episode\n",
    "CHECKPOINT_EPISODE = 54           # used when rare_model_strategy='episode'\n",
    "CLIP_EPISODE = 54                 # used when model_family='clip'\n",
    "CHECKPOINT_PREFIX_OVERRIDE = None # e.g., 'tcn_fusion_results/exp6_tape_ep83'\n",
    "\n",
    "if RUN_EVAL:\n",
    "    experiment6_stub = create_experiment6_result_stub(\n",
    "        random_seed=RANDOM_SEED,\n",
    "        use_covariance=True,\n",
    "        architecture=config['agent_params']['actor_critic_type'],\n",
    "        checkpoint_path=None,\n",
    "        base_agent_params=config.get('agent_params'),\n",
    "    )\n",
    "\n",
    "    evaluation_stub = evaluate_experiment6_checkpoint(\n",
    "        experiment6_stub,\n",
    "        phase1_data=phase1_data,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        model_family=MODEL_FAMILY,\n",
    "        normal_model_strategy=NORMAL_MODEL_STRATEGY,\n",
    "        rare_model_strategy=RARE_MODEL_STRATEGY,\n",
    "        checkpoint_episode=CHECKPOINT_EPISODE,\n",
    "        clip_episode=CLIP_EPISODE,\n",
    "        checkpoint_path_override=CHECKPOINT_PREFIX_OVERRIDE,\n",
    "        num_eval_runs=10,\n",
    "        compare_deterministic_modes=['mode', 'mean'],\n",
    "        stochastic_eval_mode='sample',\n",
    "        sample_actions_stochastic=True,\n",
    "        sample_actions=None,\n",
    "        stochastic_episode_length_limit=252,\n",
    "        save_eval_logs=True,\n",
    "        save_eval_artifacts=True,\n",
    "    )\n",
    "\n",
    "    print('âœ… Evaluation complete')\n",
    "    print('Checkpoint:', evaluation_stub.actor_weights_path)\n",
    "    print('Eval CSV  :', evaluation_stub.eval_results_path)\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_EVAL=False (set True to evaluate)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION ARTIFACT EXPORTS (VARIANT-SCOPED)\n",
    "# ============================================================================\n",
    "from datetime import datetime\n",
    "\n",
    "if 'evaluation_stub' not in globals():\n",
    "    print('Run evaluation first (RUN_EVAL=True).')\n",
    "else:\n",
    "    assets = ASSET_TICKERS + ['Cash']\n",
    "\n",
    "    results_root = Path(globals().get('LATEST_RESULTS_ROOT', 'tcn_results'))\n",
    "    stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    out_root = results_root / 'model_outputs' / f'eval_{stamp}'\n",
    "    det_out = out_root / 'deterministic'\n",
    "    sto_out = out_root / 'stochastic'\n",
    "    det_out.mkdir(parents=True, exist_ok=True)\n",
    "    sto_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Deterministic artifacts\n",
    "    det_dates = pd.DatetimeIndex(evaluation_stub.env_test_deterministic.dates)\n",
    "\n",
    "    if len(evaluation_stub.deterministic_alphas) > 0:\n",
    "        df_alpha = pd.DataFrame(evaluation_stub.deterministic_alphas, columns=assets)\n",
    "        df_alpha.index = det_dates[:len(df_alpha)]\n",
    "        df_alpha.index.name = 'date'\n",
    "        df_alpha.to_csv(det_out / 'alphas.csv')\n",
    "\n",
    "    if len(evaluation_stub.deterministic_weights) > 0:\n",
    "        df_w = pd.DataFrame(evaluation_stub.deterministic_weights, columns=assets)\n",
    "        df_w.index = det_dates[:len(df_w)]\n",
    "        df_w.index.name = 'date'\n",
    "        df_w.to_csv(det_out / 'weights.csv')\n",
    "\n",
    "    if len(evaluation_stub.deterministic_actions) > 0:\n",
    "        df_a = pd.DataFrame(evaluation_stub.deterministic_actions, columns=assets)\n",
    "        df_a.index = det_dates[:len(df_a)]\n",
    "        df_a.index.name = 'date'\n",
    "        df_a.to_csv(det_out / 'actions.csv')\n",
    "\n",
    "    # Copy eval summary CSV into output root for traceability\n",
    "    eval_csv_path = Path(evaluation_stub.eval_results_path) if evaluation_stub.eval_results_path else None\n",
    "    if eval_csv_path and eval_csv_path.exists():\n",
    "        df_eval = pd.read_csv(eval_csv_path)\n",
    "        df_eval.to_csv(out_root / 'evaluation_summary.csv', index=False)\n",
    "    else:\n",
    "        df_eval = pd.DataFrame()\n",
    "\n",
    "    # Stochastic artifacts\n",
    "    all_dates = pd.DatetimeIndex(evaluation_stub.env_test_random.dates)\n",
    "    actions_rows, weights_rows, alphas_rows = [], [], []\n",
    "\n",
    "    if isinstance(evaluation_stub.stochastic_results, pd.DataFrame) and not evaluation_stub.stochastic_results.empty:\n",
    "        stochastic_results_df = evaluation_stub.stochastic_results.copy()\n",
    "        stochastic_results_df.to_csv(sto_out / 'stochastic_results.csv', index=False)\n",
    "\n",
    "        for i in range(len(stochastic_results_df)):\n",
    "            run_id = int(stochastic_results_df.iloc[i].get('run', i + 1))\n",
    "            start_date = pd.Timestamp(stochastic_results_df.iloc[i]['start_date'])\n",
    "            start_idx = all_dates.get_loc(start_date)\n",
    "\n",
    "            run_actions = evaluation_stub.stochastic_actions[i] if i < len(evaluation_stub.stochastic_actions) else []\n",
    "            run_weights = evaluation_stub.stochastic_weights[i] if i < len(evaluation_stub.stochastic_weights) else []\n",
    "            run_alphas = evaluation_stub.stochastic_alphas[i] if i < len(evaluation_stub.stochastic_alphas) else []\n",
    "\n",
    "            run_dates = all_dates[start_idx:start_idx + len(run_weights)]\n",
    "\n",
    "            if len(run_actions):\n",
    "                dfa = pd.DataFrame(run_actions, columns=assets)\n",
    "                dfa['run'] = run_id\n",
    "                dfa['date'] = run_dates[:len(dfa)]\n",
    "                actions_rows.append(dfa)\n",
    "\n",
    "            if len(run_weights):\n",
    "                dfw = pd.DataFrame(run_weights, columns=assets)\n",
    "                dfw['run'] = run_id\n",
    "                dfw['date'] = run_dates[:len(dfw)]\n",
    "                weights_rows.append(dfw)\n",
    "\n",
    "            if len(run_alphas):\n",
    "                dfl = pd.DataFrame(run_alphas, columns=assets)\n",
    "                dfl['run'] = run_id\n",
    "                dfl['date'] = run_dates[:len(dfl)]\n",
    "                alphas_rows.append(dfl)\n",
    "\n",
    "    if actions_rows:\n",
    "        pd.concat(actions_rows, ignore_index=True).set_index(['run', 'date']).to_csv(sto_out / 'actions_all_runs.csv')\n",
    "    if weights_rows:\n",
    "        pd.concat(weights_rows, ignore_index=True).set_index(['run', 'date']).to_csv(sto_out / 'weights_all_runs.csv')\n",
    "    if alphas_rows:\n",
    "        pd.concat(alphas_rows, ignore_index=True).set_index(['run', 'date']).to_csv(sto_out / 'alphas_all_runs.csv')\n",
    "\n",
    "    # README with current run context\n",
    "    readme_lines = [\n",
    "        '# Evaluation Artifact Export',\n",
    "        '',\n",
    "        f'- Variant results root: `{results_root}`',\n",
    "        f'- Export root: `{out_root}`',\n",
    "        f'- Checkpoint actor: `{evaluation_stub.actor_weights_path}`',\n",
    "        f'- Checkpoint critic: `{evaluation_stub.critic_weights_path}`',\n",
    "        f'- Eval summary CSV: `{evaluation_stub.eval_results_path}`',\n",
    "        f'- Export timestamp: `{stamp}`',\n",
    "        '',\n",
    "        '## Included Files',\n",
    "        '- `deterministic/weights.csv`',\n",
    "        '- `deterministic/actions.csv`',\n",
    "        '- `deterministic/alphas.csv`',\n",
    "        '- `stochastic/stochastic_results.csv` (if stochastic runs were executed)',\n",
    "        '- `stochastic/weights_all_runs.csv`',\n",
    "        '- `stochastic/actions_all_runs.csv`',\n",
    "        '- `stochastic/alphas_all_runs.csv`',\n",
    "        '- `evaluation_summary.csv`',\n",
    "    ]\n",
    "\n",
    "    if not df_eval.empty:\n",
    "        cols = [\n",
    "            'eval_track', 'evaluation_type', 'start_date', 'market_regime',\n",
    "            'mean_concentration_hhi', 'mean_top_weight',\n",
    "            'mean_action_realization_l1', 'max_action_realization_l1'\n",
    "        ]\n",
    "        present = [c for c in cols if c in df_eval.columns]\n",
    "        readme_lines += ['', '## Key Logged Diagnostics (present in summary CSV)', *(f'- `{c}`' for c in present)]\n",
    "\n",
    "    (out_root / 'README.md').write_text('\\n'.join(readme_lines), encoding='utf-8')\n",
    "\n",
    "    print('âœ… Export complete')\n",
    "    print('Export root:', out_root)\n",
    "    print('Deterministic dir:', det_out)\n",
    "    print('Stochastic dir   :', sto_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c70cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVAL CSV DIAGNOSTIC COLUMN CHECK\n",
    "# ============================================================================\n",
    "required_cols = [\n",
    "    'start_date',\n",
    "    'market_regime',\n",
    "    'mean_concentration_hhi',\n",
    "    'mean_top_weight',\n",
    "    'mean_action_realization_l1',\n",
    "    'max_action_realization_l1',\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "\n",
    "if 'evaluation_stub' in globals() and getattr(evaluation_stub, 'eval_results_path', None):\n",
    "    p = Path(evaluation_stub.eval_results_path)\n",
    "    if p.exists():\n",
    "        csv_path = p\n",
    "\n",
    "if csv_path is None:\n",
    "    root = Path(globals().get('LATEST_RESULTS_ROOT', 'tcn_results'))\n",
    "    logs_dir = root / 'logs'\n",
    "    candidates = sorted(logs_dir.glob('*_eval_*.csv'), key=lambda x: x.stat().st_mtime, reverse=True) if logs_dir.exists() else []\n",
    "    csv_path = candidates[0] if candidates else None\n",
    "\n",
    "if csv_path is None:\n",
    "    print('âš ï¸ No evaluation CSV found. Run evaluation first.')\n",
    "else:\n",
    "    df_eval = pd.read_csv(csv_path)\n",
    "    present = [c for c in required_cols if c in df_eval.columns]\n",
    "    missing = [c for c in required_cols if c not in df_eval.columns]\n",
    "\n",
    "    print('ðŸ“‚ Eval CSV:', csv_path)\n",
    "    print('Rows:', len(df_eval))\n",
    "    print('Required columns present:', len(present), '/', len(required_cols))\n",
    "\n",
    "    if missing:\n",
    "        print('âŒ Missing columns:', missing)\n",
    "    else:\n",
    "        print('âœ… All required diagnostic columns are present.')\n",
    "\n",
    "    show_cols = ['eval_track', 'evaluation_type'] + [c for c in required_cols if c in df_eval.columns]\n",
    "    show_cols = [c for c in show_cols if c in df_eval.columns]\n",
    "    if show_cols:\n",
    "        display(df_eval[show_cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTICS SUMMARY\n",
    "# ============================================================================\n",
    "if 'evaluation_stub' not in globals():\n",
    "    print('Run evaluation first (RUN_EVAL=True).')\n",
    "else:\n",
    "    # stochastic summary\n",
    "    stoch = evaluation_stub.stochastic_results.copy()\n",
    "    if stoch is not None and not stoch.empty:\n",
    "        cols = [\n",
    "            'total_return', 'annualized_return', 'sharpe_ratio', 'sortino_ratio',\n",
    "            'max_drawdown', 'volatility', 'turnover', 'win_rate'\n",
    "        ]\n",
    "        cols = [c for c in cols if c in stoch.columns]\n",
    "        print('Stochastic summary:')\n",
    "        display(stoch[cols].describe().T)\n",
    "\n",
    "    # deterministic diagnostics\n",
    "    acts = np.asarray(evaluation_stub.deterministic_actions)\n",
    "    alps = np.asarray(evaluation_stub.deterministic_alphas)\n",
    "\n",
    "    action_uniques = int(np.unique(np.round(acts, 6), axis=0).shape[0]) if acts.size else 0\n",
    "    alpha_le1_frac = float(np.mean(alps <= 1.0)) if alps.size else 0.0\n",
    "    argmax_uniques = int(np.unique(np.argmax(alps, axis=1)).shape[0]) if (alps.ndim == 2 and len(alps) > 0) else 0\n",
    "\n",
    "    print('Deterministic diagnostics:')\n",
    "    print(' action_uniques      =', action_uniques)\n",
    "    print(' alpha<=1 fraction   =', alpha_le1_frac)\n",
    "    print(' argmax_alpha_uniques=', argmax_uniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIXED STRESS-WINDOW EVALUATION (2 WINDOWS)\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "from dataclasses import replace\n",
    "\n",
    "STRESS_WINDOWS = [\n",
    "    ('2020-02-20', '2020-05-29', 'COVID crash + rebound'),\n",
    "    ('2022-01-03', '2022-12-30', 'Rate-hike bear year'),\n",
    "]\n",
    "\n",
    "def subset_phase1_test_window(phase1_data, start_date, end_date):\n",
    "    s = pd.Timestamp(start_date)\n",
    "    e = pd.Timestamp(end_date)\n",
    "    df = phase1_data.test_df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    win = df[(df['Date'] >= s) & (df['Date'] <= e)].copy()\n",
    "    if win.empty:\n",
    "        raise ValueError(f'No rows in test_df for {start_date} -> {end_date}')\n",
    "    return replace(\n",
    "        phase1_data,\n",
    "        test_df=win,\n",
    "        test_start_date=win['Date'].min(),\n",
    "        train_end_date=win['Date'].max(),\n",
    "    )\n",
    "\n",
    "fixed_rows = []\n",
    "for start, end, label in STRESS_WINDOWS:\n",
    "    phase_win = subset_phase1_test_window(phase1_data, start, end)\n",
    "\n",
    "    ev = evaluate_experiment6_checkpoint(\n",
    "        experiment6_stub,\n",
    "        phase1_data=phase_win,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        checkpoint_path_override=CHECKPOINT_PREFIX_OVERRIDE,\n",
    "        deterministic_eval_mode='mode',\n",
    "        num_eval_runs=0,\n",
    "        stochastic_eval_mode='sample',\n",
    "        save_eval_logs=False,\n",
    "        save_eval_artifacts=False,\n",
    "    )\n",
    "\n",
    "    m = ev.deterministic_metrics or {}\n",
    "    fixed_rows.append({\n",
    "        'window_label': label,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'days_traded': len(ev.deterministic_portfolio) - 1 if len(ev.deterministic_portfolio) else 0,\n",
    "        'total_return': m.get('total_return'),\n",
    "        'annualized_return': m.get('annualized_return'),\n",
    "        'sharpe': m.get('sharpe_ratio'),\n",
    "        'sortino': m.get('sortino_ratio'),\n",
    "        'max_drawdown': m.get('max_drawdown_abs', m.get('max_drawdown')),\n",
    "        'volatility': m.get('volatility'),\n",
    "        'turnover': m.get('turnover'),\n",
    "        'win_rate': m.get('win_rate'),\n",
    "    })\n",
    "\n",
    "fixed_df = pd.DataFrame(fixed_rows)\n",
    "display(fixed_df.sort_values('start'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b0711",
   "metadata": {},
   "source": [
    "## 6) Checkpoint Scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aee0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, socket\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"hostname:\", socket.gethostname())\n",
    "print(\"exists:\", os.path.exists(\"/content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260219_210119_metadata.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "meta = Path(\"tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260219_210119_metadata.json\")\n",
    "config = load_training_metadata_into_config(meta, deepcopy(config), verbose=True)\n",
    "\n",
    "# hard enforce fusion\n",
    "config[\"agent_params\"][\"actor_critic_type\"] = \"TCN_FUSION\"\n",
    "config[\"agent_params\"][\"use_fusion\"] = True\n",
    "config[\"agent_params\"][\"use_attention\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8dfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN CHECKPOINT SCAN (LOCAL + ROBUST)\n",
    "# ============================================================================\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def resolve_results_root():\n",
    "    candidates = [\n",
    "        # Local Windows path (your machine)\n",
    "        #Path(r\"C:\\Users\\Owner\\new_project\\adaptive_portfolio_rl\\tcn_fusion_results\"),\n",
    "        # WSL path to same folder\n",
    "        #Path(\"/mnt/c/Users/Owner/new_project/adaptive_portfolio_rl/tcn_fusion_results\"),\n",
    "        # Relative local fallback\n",
    "        #Path(\"./tcn_fusion_results\"),\n",
    "\n",
    "        # Colab fallbacks (kept just in case)\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results/rare_models\"),\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_results\"),\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results00\"),\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_results00\"),\n",
    "    ]\n",
    "    existing = [p for p in candidates if p.exists()]\n",
    "    if not existing:\n",
    "        raise FileNotFoundError(\"No results root found (local or /content).\")\n",
    "    # Prefer local by candidate order (first match)\n",
    "    return existing[0]\n",
    "\n",
    "def evaluate_checkpoint_range_deterministic_all(\n",
    "    episode_range=(8, 100),\n",
    "    results_root=None,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    deterministic_eval_mode=\"mean\",\n",
    "):\n",
    "    low, high = episode_range\n",
    "    base_root = Path(results_root) if results_root else resolve_results_root()\n",
    "\n",
    "    actor_paths = sorted(base_root.rglob(\"*_actor.weights.h5\"))\n",
    "    print(f\"Found actor files (all subdirs): {len(actor_paths)} under {base_root}\")\n",
    "\n",
    "    rows = []\n",
    "    skipped = 0\n",
    "\n",
    "    for actor_path in actor_paths:\n",
    "        m_ep = re.search(r\"_ep(\\d+)\", actor_path.name)\n",
    "        if not m_ep:\n",
    "            continue\n",
    "        ep = int(m_ep.group(1))\n",
    "        if not (low <= ep <= high):\n",
    "            continue\n",
    "\n",
    "        prefix = str(actor_path).replace(\"_actor.weights.h5\", \"\")\n",
    "        ckpt_group = actor_path.parent.name\n",
    "\n",
    "        try:\n",
    "            stub = create_experiment6_result_stub(\n",
    "                random_seed=RANDOM_SEED,\n",
    "                use_covariance=True,\n",
    "                architecture=arch,\n",
    "                checkpoint_path=prefix,\n",
    "                agent_config=agent_cfg,      # important\n",
    "                base_agent_params=None,      # avoid default drift\n",
    "            )\n",
    "\n",
    "\n",
    "            ev = evaluate_experiment6_checkpoint(\n",
    "                experiment6=stub,\n",
    "                phase1_data=phase1_data,\n",
    "                config=config,\n",
    "                random_seed=random_seed,\n",
    "                checkpoint_path_override=prefix,\n",
    "                model_family=\"normal\",\n",
    "                normal_model_strategy=\"latest\",\n",
    "                num_eval_runs=0,\n",
    "                deterministic_eval_mode=deterministic_eval_mode,\n",
    "                save_eval_logs=False,\n",
    "                save_eval_artifacts=False,\n",
    "            )\n",
    "\n",
    "            m = ev.deterministic_metrics or {}\n",
    "            rows.append({\n",
    "                \"episode\": ep,\n",
    "                \"source_dir\": ckpt_group,\n",
    "                \"checkpoint_prefix\": prefix,\n",
    "                \"sharpe\": m.get(\"sharpe_ratio\", float(\"nan\")),\n",
    "                \"total_return\": m.get(\"total_return\", float(\"nan\")),\n",
    "                \"max_drawdown\": m.get(\"max_drawdown_abs\", m.get(\"max_drawdown\", float(\"nan\"))),\n",
    "                \"turnover\": m.get(\"turnover\", float(\"nan\")),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            print(f\"Skipping incompatible checkpoint: {actor_path.name} | {type(e).__name__}: {e}\")\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"No checkpoints in range {episode_range} under {base_root}\")\n",
    "        return None\n",
    "\n",
    "    df_scores = pd.DataFrame(rows).sort_values(\"sharpe\", ascending=False).reset_index(drop=True)\n",
    "    print(f\"Evaluated: {len(df_scores)} | Skipped: {skipped}\")\n",
    "    return df_scores\n",
    "\n",
    "# Run\n",
    "RUN_SCAN = True\n",
    "\n",
    "if RUN_SCAN:\n",
    "    results_root = resolve_results_root()\n",
    "    print(\"Scanning results root:\", results_root)\n",
    "\n",
    "    scan_df = evaluate_checkpoint_range_deterministic_all(\n",
    "        episode_range=(1, 300),\n",
    "        results_root=results_root,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        deterministic_eval_mode=\"mean\",\n",
    "    )\n",
    "\n",
    "    display(scan_df.head(20) if scan_df is not None else None)\n",
    "\n",
    "    step_dir = results_root / \"step_sharpe_checkpoints\"\n",
    "    if step_dir.exists():\n",
    "        step_files = sorted(step_dir.glob(\"*_actor.weights.h5\"))\n",
    "        print(f\"Step-Sharpe checkpoints found: {len(step_files)}\")\n",
    "        for p in step_files[:10]:\n",
    "            print(\" -\", p.name)\n",
    "    else:\n",
    "        print(\"No step_sharpe_checkpoints directory yet.\")\n",
    "else:\n",
    "    print(\"RUN_SCAN=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a05938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_root = Path(\"tcn_fusion_results\")\n",
    "meta = results_root / \"logs\" / \"Exp6_TCN_FUSION_Enhanced_TAPE_training_20260219_210119_metadata.json\"\n",
    "\n",
    "# 1) align config to run\n",
    "config = load_training_metadata_into_config(meta, deepcopy(config), verbose=True)\n",
    "\n",
    "with open(meta, \"r\", encoding=\"utf-8\") as f:\n",
    "    md = json.load(f)\n",
    "\n",
    "agent_cfg = md[\"Architecture_Settings\"][\"agent_params_effective\"]\n",
    "arch = md[\"Architecture_Settings\"][\"resolved_architecture\"]\n",
    "meta_mtime = meta.stat().st_mtime\n",
    "\n",
    "# 2) filter actor checkpoints to this run window (newer than metadata)\n",
    "all_actor_paths = sorted(results_root.rglob(\"*_actor.weights.h5\"))\n",
    "actor_paths = [p for p in all_actor_paths if p.stat().st_mtime >= meta_mtime - 5]\n",
    "\n",
    "print(\"all:\", len(all_actor_paths), \"filtered:\", len(actor_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHECKPOINT SCANNER (DETERMINISTIC)\n",
    "# ============================================================================\n",
    "import re\n",
    "\n",
    "\n",
    "def evaluate_checkpoint_range_deterministic(\n",
    "    episode_range=(2, 300),\n",
    "    results_root=None,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    deterministic_eval_mode='mode',\n",
    "):\n",
    "    low, high = episode_range\n",
    "    base_root = Path(results_root) if results_root else Path(LATEST_RESULTS_ROOT)\n",
    "\n",
    "    checkpoints = {}\n",
    "    for root in [base_root, base_root / 'rare_models']:\n",
    "        if not root.exists():\n",
    "            continue\n",
    "        for actor_path in root.glob('*_actor.weights.h5'):\n",
    "            m = re.search(r'_ep(\\d+)', actor_path.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            ep = int(m.group(1))\n",
    "            if low <= ep <= high:\n",
    "                checkpoints[ep] = actor_path\n",
    "\n",
    "    if not checkpoints:\n",
    "        print(f'No checkpoints found in {base_root} for range {episode_range}.')\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for ep, actor_path in sorted(checkpoints.items()):\n",
    "        prefix = str(actor_path).replace('_actor.weights.h5', '')\n",
    "\n",
    "        stub = create_experiment6_result_stub(\n",
    "            random_seed=random_seed,\n",
    "            use_covariance=True,\n",
    "            architecture=config['agent_params']['actor_critic_type'],\n",
    "            checkpoint_path=prefix,\n",
    "            base_agent_params=config.get('agent_params'),\n",
    "        )\n",
    "\n",
    "        ev = evaluate_experiment6_checkpoint(\n",
    "            experiment6=stub,\n",
    "            phase1_data=phase1_data,\n",
    "            config=config,\n",
    "            random_seed=random_seed,\n",
    "            checkpoint_path_override=prefix,\n",
    "            model_family='normal',\n",
    "            normal_model_strategy='latest',\n",
    "            num_eval_runs=0,\n",
    "            deterministic_eval_mode=deterministic_eval_mode,\n",
    "            save_eval_logs=False,\n",
    "            save_eval_artifacts=False,\n",
    "        )\n",
    "\n",
    "        m = ev.deterministic_metrics or {}\n",
    "        rows.append({\n",
    "            'episode': ep,\n",
    "            'checkpoint_prefix': prefix,\n",
    "            'sharpe': m.get('sharpe_ratio', float('nan')),\n",
    "            'total_return': m.get('total_return', float('nan')),\n",
    "            'max_drawdown': m.get('max_drawdown_abs', m.get('max_drawdown', float('nan'))),\n",
    "            'turnover': m.get('turnover', float('nan')),\n",
    "        })\n",
    "\n",
    "    df_scores = pd.DataFrame(rows).sort_values('sharpe', ascending=False)\n",
    "    return df_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a68bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN CHECKPOINT SCAN\n",
    "# ============================================================================\n",
    "RUN_SCAN = True\n",
    "\n",
    "if RUN_SCAN:\n",
    "    results_root = Path(\"/content/adaptive_portfolio_rl\") #Path(globals().get('LATEST_RESULTS_ROOT', 'tcn_results'))\n",
    "    print('Scanning:', results_root)\n",
    "    scan_df = evaluate_checkpoint_range_deterministic(\n",
    "        episode_range=(8, 100),\n",
    "        results_root=results_root,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        deterministic_eval_mode='mean',\n",
    "    )\n",
    "    display(scan_df.head(20) if scan_df is not None else None)\n",
    "\n",
    "    step_dir = results_root / 'step_sharpe_checkpoints'\n",
    "    if step_dir.exists():\n",
    "        step_files = sorted(step_dir.glob('*_actor.weights.h5'))\n",
    "        print(f'Step-Sharpe checkpoints found: {len(step_files)}')\n",
    "        for p in step_files[:10]:\n",
    "            print(' -', p.name)\n",
    "    else:\n",
    "        print('No step_sharpe_checkpoints directory yet.')\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_SCAN=False')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03e629",
   "metadata": {},
   "source": [
    "## 7) Overfit Monitor (Train-Test Gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OVERFIT MONITOR HELPERS\n",
    "# ============================================================================\n",
    "import re\n",
    "from dataclasses import replace\n",
    "\n",
    "\n",
    "def _infer_results_root_for_notebook(cfg):\n",
    "    arch = cfg.get('agent_params', {}).get('actor_critic_type', 'TCN').upper()\n",
    "    use_attention = bool(cfg.get('agent_params', {}).get('use_attention', False))\n",
    "    use_fusion = bool(cfg.get('agent_params', {}).get('use_fusion', False))\n",
    "    if arch.startswith('TCN'):\n",
    "        if use_fusion:\n",
    "            return Path('tcn_fusion_results')\n",
    "        if use_attention:\n",
    "            return Path('tcn_att_results')\n",
    "        return Path('tcn_results')\n",
    "    return Path('tcn_results')\n",
    "\n",
    "\n",
    "def _discover_checkpoint_prefixes(results_root, episode_range=(1, 9999), include_rare=True):\n",
    "    lo, hi = episode_range\n",
    "    roots = [Path(results_root)]\n",
    "    if include_rare:\n",
    "        roots.append(Path(results_root) / 'rare_models')\n",
    "\n",
    "    prefixes = {}\n",
    "    for root in roots:\n",
    "        if not root.exists():\n",
    "            continue\n",
    "        for actor in root.glob('*_actor.weights.h5'):\n",
    "            m = re.search(r'_ep(\\d+)', actor.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            ep = int(m.group(1))\n",
    "            if lo <= ep <= hi:\n",
    "                prefixes[ep] = str(actor).replace('_actor.weights.h5', '')\n",
    "\n",
    "    return [(ep, prefixes[ep]) for ep in sorted(prefixes.keys())]\n",
    "\n",
    "\n",
    "def _subset_phase1_for_eval(phase1_data, split='test'):\n",
    "    split = str(split).lower().strip()\n",
    "    if split not in {'train', 'test'}:\n",
    "        raise ValueError(f'split must be train or test, got: {split}')\n",
    "\n",
    "    eval_df = phase1_data.train_df.copy() if split == 'train' else phase1_data.test_df.copy()\n",
    "    start_date = pd.to_datetime(eval_df['Date']).min()\n",
    "    end_date = pd.to_datetime(eval_df['Date']).max()\n",
    "\n",
    "    return replace(\n",
    "        phase1_data,\n",
    "        test_df=eval_df,\n",
    "        test_start_date=start_date,\n",
    "        train_end_date=end_date,\n",
    "    )\n",
    "\n",
    "\n",
    "def _diagnostics_from_eval(ev):\n",
    "    acts = np.asarray(ev.deterministic_actions)\n",
    "    alps = np.asarray(ev.deterministic_alphas)\n",
    "    action_uniques = int(np.unique(np.round(acts, 6), axis=0).shape[0]) if acts.size else 0\n",
    "    alpha_le1_fraction = float(np.mean(alps <= 1.0)) if alps.size else 0.0\n",
    "    argmax_alpha_uniques = int(np.unique(np.argmax(alps, axis=1)).shape[0]) if (alps.ndim == 2 and len(alps) > 0) else 0\n",
    "    return action_uniques, alpha_le1_fraction, argmax_alpha_uniques\n",
    "\n",
    "\n",
    "def run_checkpoint_overfit_monitor(\n",
    "    phase1_data,\n",
    "    config,\n",
    "    random_seed,\n",
    "    episode_range=(1, 300),\n",
    "    deterministic_modes=('mode', 'mean'),\n",
    "    eval_splits=('train', 'test'),\n",
    "    results_root=None,\n",
    "    include_rare=False,\n",
    "    save_csv=True,\n",
    "):\n",
    "    results_root = Path(results_root) if results_root else _infer_results_root_for_notebook(config)\n",
    "    ckpts = _discover_checkpoint_prefixes(results_root, episode_range=episode_range, include_rare=include_rare)\n",
    "    if not ckpts:\n",
    "        raise RuntimeError(f'No checkpoints found in {results_root} for range {episode_range}.')\n",
    "\n",
    "    if isinstance(deterministic_modes, str):\n",
    "        deterministic_modes = (deterministic_modes,)\n",
    "    if isinstance(eval_splits, str):\n",
    "        eval_splits = (eval_splits,)\n",
    "\n",
    "    eval_splits = tuple(str(s).lower().strip() for s in eval_splits)\n",
    "    bad = [s for s in eval_splits if s not in {'train', 'test'}]\n",
    "    if bad:\n",
    "        raise ValueError(f'Invalid eval_splits entries: {bad}. Allowed: train, test')\n",
    "\n",
    "    stub = create_experiment6_result_stub(\n",
    "        random_seed=random_seed,\n",
    "        use_covariance=True,\n",
    "        architecture=config['agent_params']['actor_critic_type'],\n",
    "        checkpoint_path=ckpts[0][1],\n",
    "        base_agent_params=config.get('agent_params'),\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for ep, prefix in ckpts:\n",
    "        for split in eval_splits:\n",
    "            phase_eval = _subset_phase1_for_eval(phase1_data, split=split)\n",
    "            split_start = pd.to_datetime(phase_eval.test_df['Date']).min()\n",
    "            split_end = pd.to_datetime(phase_eval.test_df['Date']).max()\n",
    "\n",
    "            for mode in deterministic_modes:\n",
    "                ev = evaluate_experiment6_checkpoint(\n",
    "                    stub,\n",
    "                    phase1_data=phase_eval,\n",
    "                    config=config,\n",
    "                    random_seed=random_seed,\n",
    "                    checkpoint_path_override=prefix,\n",
    "                    deterministic_eval_mode=mode,\n",
    "                    num_eval_runs=0,\n",
    "                    stochastic_eval_mode='sample',\n",
    "                    save_eval_logs=False,\n",
    "                    save_eval_artifacts=False,\n",
    "                )\n",
    "\n",
    "                m = ev.deterministic_metrics or {}\n",
    "                action_uniques, alpha_le1_fraction, argmax_alpha_uniques = _diagnostics_from_eval(ev)\n",
    "\n",
    "                rows.append({\n",
    "                    'checkpoint_prefix': prefix,\n",
    "                    'episode': ep,\n",
    "                    'architecture': config['agent_params']['actor_critic_type'],\n",
    "                    'split': split,\n",
    "                    'deterministic_mode': mode,\n",
    "                    'seed': random_seed,\n",
    "                    'window_start': split_start,\n",
    "                    'window_end': split_end,\n",
    "                    'days_traded': int(len(ev.deterministic_portfolio) - 1) if len(ev.deterministic_portfolio) else 0,\n",
    "                    'total_return': float(m.get('total_return', np.nan)),\n",
    "                    'annualized_return': float(m.get('annualized_return', np.nan)),\n",
    "                    'sharpe_ratio': float(m.get('sharpe_ratio', np.nan)),\n",
    "                    'sortino_ratio': float(m.get('sortino_ratio', np.nan)),\n",
    "                    'max_drawdown': float(m.get('max_drawdown_abs', m.get('max_drawdown', np.nan))),\n",
    "                    'volatility': float(m.get('volatility', np.nan)),\n",
    "                    'turnover': float(m.get('turnover', np.nan)),\n",
    "                    'win_rate': float(m.get('win_rate', np.nan)),\n",
    "                    'action_uniques': action_uniques,\n",
    "                    'alpha_le1_fraction': alpha_le1_fraction,\n",
    "                    'argmax_alpha_uniques': argmax_alpha_uniques,\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise RuntimeError('Monitor produced no rows.')\n",
    "\n",
    "    left = df[df['split'] == 'train'].copy()\n",
    "    right = df[df['split'] == 'test'].copy()\n",
    "    if left.empty or right.empty:\n",
    "        raise RuntimeError(\"Overfit summary requires BOTH train and test rows. Use eval_splits=('train','test').\")\n",
    "\n",
    "    keys = ['checkpoint_prefix', 'episode', 'architecture', 'deterministic_mode', 'seed']\n",
    "    summary = left.merge(right, on=keys, suffixes=('_train', '_test'))\n",
    "\n",
    "    summary['sharpe_gap'] = summary['sharpe_ratio_train'] - summary['sharpe_ratio_test']\n",
    "    summary['mdd_gap'] = summary['max_drawdown_test'] - summary['max_drawdown_train']\n",
    "    summary['return_gap'] = summary['annualized_return_train'] - summary['annualized_return_test']\n",
    "\n",
    "    summary['flag_overfit'] = (\n",
    "        (summary['sharpe_gap'] > 0.40)\n",
    "        | (summary['mdd_gap'] > 0.05)\n",
    "        | (summary['return_gap'] > 0.10)\n",
    "    )\n",
    "\n",
    "    summary = summary.sort_values(['flag_overfit', 'sharpe_ratio_test'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    out_path = None\n",
    "    if save_csv:\n",
    "        out_dir = Path(results_root) / 'logs'\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        out_path = out_dir / f'checkpoint_overfit_monitor_{ts}.csv'\n",
    "        summary.to_csv(out_path, index=False)\n",
    "        print('ðŸ’¾ Overfit monitor saved:', out_path)\n",
    "\n",
    "    return df, summary, out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ba808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN OVERFIT MONITOR\n",
    "# ============================================================================\n",
    "RUN_OVERFIT_MONITOR = True\n",
    "\n",
    "if RUN_OVERFIT_MONITOR:\n",
    "    results_root = Path(globals().get('LATEST_RESULTS_ROOT', _infer_results_root_for_notebook(config)))\n",
    "    print('Using results root:', results_root)\n",
    "\n",
    "    monitor_rows_df, monitor_summary_df, monitor_csv_path = run_checkpoint_overfit_monitor(\n",
    "        phase1_data=phase1_data,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        episode_range=(79, 100),\n",
    "        deterministic_modes=('mode', 'mean'),\n",
    "        eval_splits=('train', 'test'),\n",
    "        results_root=results_root,\n",
    "        include_rare=True,\n",
    "        save_csv=True,\n",
    "    )\n",
    "\n",
    "    display(monitor_summary_df.head(20))\n",
    "\n",
    "    if not monitor_summary_df.empty:\n",
    "        best = (\n",
    "            monitor_summary_df[monitor_summary_df['flag_overfit'] == False]\n",
    "            .sort_values('sharpe_ratio_test', ascending=False)\n",
    "            .head(10)\n",
    "        )\n",
    "        print('Top non-overfit candidates (by test Sharpe):')\n",
    "        display(best[[\n",
    "            'episode', 'deterministic_mode', 'sharpe_ratio_test',\n",
    "            'max_drawdown_test', 'turnover_test', 'sharpe_gap', 'mdd_gap', 'return_gap'\n",
    "        ]])\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_OVERFIT_MONITOR=False')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Optional Analysis Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: ABLATION TABLE + TRACK SUMMARY\n",
    "# ============================================================================\n",
    "RUN_OPTIONAL_ANALYSIS = False\n",
    "\n",
    "if RUN_OPTIONAL_ANALYSIS:\n",
    "    try:\n",
    "        from src.notebook_helpers.tcn_phase1 import build_ablation_table, build_evaluation_track_summary\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'Optional analysis helpers unavailable: {e}')\n",
    "\n",
    "    available = {k: v for k, v in globals().items() if k.startswith('evaluation_') and hasattr(v, 'deterministic_metrics')}\n",
    "    if 'evaluation_stub' in globals():\n",
    "        available.setdefault('current_eval', evaluation_stub)\n",
    "\n",
    "    if not available:\n",
    "        print('No evaluation objects found. Run evaluation first.')\n",
    "    else:\n",
    "        display(build_ablation_table(available))\n",
    "        if 'evaluation_stub' in globals():\n",
    "            print('Track summary for current evaluation:')\n",
    "            display(build_evaluation_track_summary(evaluation_stub))\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_OPTIONAL_ANALYSIS=False')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Run Checklist\n",
    "\n",
    "Before running heavy jobs:\n",
    "- Confirm `ACTIVE_VARIANT`\n",
    "- Confirm `max_total_timesteps` and `timesteps_per_ppo_update`\n",
    "- Confirm curriculum schedule (1500 -> 2000 -> 2500 -> full)\n",
    "- Confirm step-Sharpe checkpoint rule (`>= 0.5`)\n",
    "- Confirm intra-step TAPE delta settings (`beta`, `clip`, `window`)\n",
    "- Set exactly one expensive toggle at a time (`RUN_TRAINING`, `RUN_EVAL`, `RUN_SCAN`, `RUN_OVERFIT_MONITOR`)\n",
    "- Keep artifact exports on after successful eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15960f6c",
   "metadata": {},
   "source": [
    "## 10) Feature Manifest Audit (Latest Artifacts)\n",
    "\n",
    "Use this section to inspect the latest active-feature manifests without hardcoded timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from src.notebook_helpers.tcn_phase1 import summarize_active_feature_manifest\n",
    "\n",
    "def latest_path(paths):\n",
    "    paths = [p for p in paths if p.exists()]\n",
    "    if not paths:\n",
    "        return None\n",
    "    return sorted(paths, key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
    "\n",
    "trainrl_manifest = latest_path(Path('results').glob('**/active_feature_manifest.json'))\n",
    "notebook_manifest = latest_path(Path(LATEST_RESULTS_ROOT).glob('logs/*_active_feature_manifest.json'))\n",
    "\n",
    "print('Latest train_rl manifest:', trainrl_manifest)\n",
    "print('Latest notebook manifest:', notebook_manifest)\n",
    "\n",
    "if trainrl_manifest:\n",
    "    summarize_active_feature_manifest(str(trainrl_manifest))\n",
    "if notebook_manifest:\n",
    "    summarize_active_feature_manifest(str(notebook_manifest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2203ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect missing requested columns + group counts from latest notebook manifest\n",
    "manifest_path = notebook_manifest\n",
    "if manifest_path is None:\n",
    "    print('No notebook manifest found. Run training first.')\n",
    "else:\n",
    "    m = json.loads(Path(manifest_path).read_text(encoding='utf-8'))\n",
    "    train_env = m.get('train_env', m)\n",
    "    print('Manifest path:', manifest_path)\n",
    "    print('Missing requested columns:', train_env.get('missing_requested_columns', []))\n",
    "    print('Group counts:', train_env.get('group_counts', {}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178280a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print active variable names from latest notebook manifest\n",
    "manifest_path = notebook_manifest\n",
    "if manifest_path is None:\n",
    "    print('No notebook manifest found. Run training first.')\n",
    "else:\n",
    "    m = json.loads(Path(manifest_path).read_text(encoding='utf-8'))\n",
    "    train_env = m.get('train_env', m)\n",
    "    active = train_env.get('active_feature_columns', [])\n",
    "    print(f'Active variable count: {len(active)}')\n",
    "    for v in active:\n",
    "        print(v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
