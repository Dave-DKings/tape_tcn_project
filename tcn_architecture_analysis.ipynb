{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64dd4dbc",
      "metadata": {},
      "source": [
        "# TCN Training Only (Clean)\n",
        "\n",
        "This notebook is for **training only**.\n",
        "It uses isolated `train_*` variables and a Sharpe-based checkpoint policy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d402f683",
      "metadata": {},
      "source": [
        "## 1) Connect to Colab VM and Sync Repo\n",
        "Run this first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7d81df77",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Fresh start complete\n",
            "Repo: /content/adaptive_portfolio_rl\n",
            "Deleted paths: 3\n",
            " - /content/adaptive_portfolio_rl/tcn_fusion_results\n",
            " - /content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv\n",
            " - /content/adaptive_portfolio_rl/data/daily_ohlcv_assets.csv\n"
          ]
        }
      ],
      "source": [
        "# Fresh-start cleanup cell (run before importing project modules)\n",
        "import gc\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "TRAIN_REPO_URL = \"https://github.com/Dave-DKings/tape_tcn_project.git\"\n",
        "TRAIN_REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
        "\n",
        "# 1) Sync repo to latest main\n",
        "if not (TRAIN_REPO_DIR / \".git\").exists():\n",
        "    subprocess.run([\"git\", \"clone\", TRAIN_REPO_URL, str(TRAIN_REPO_DIR)], check=True)\n",
        "\n",
        "subprocess.run([\"git\", \"-C\", str(TRAIN_REPO_DIR), \"fetch\", \"origin\"], check=True)\n",
        "subprocess.run([\"git\", \"-C\", str(TRAIN_REPO_DIR), \"reset\", \"--hard\", \"origin/main\"], check=True)\n",
        "\n",
        "# 2) Remove old experiment outputs/checkpoints/cached data\n",
        "purge_paths = [\n",
        "    TRAIN_REPO_DIR / \"tcn_fusion_results\",\n",
        "    TRAIN_REPO_DIR / \"tcn_results\",\n",
        "    TRAIN_REPO_DIR / \"tcn_att_results\",\n",
        "    TRAIN_REPO_DIR / \"output_logs\",\n",
        "    TRAIN_REPO_DIR / \"data\" / \"phase1_preparation_artifacts\",\n",
        "    TRAIN_REPO_DIR / \"data\" / \"master_features_NORMALIZED.csv\",\n",
        "    TRAIN_REPO_DIR / \"data\" / \"daily_ohlcv_assets.csv\",              # forces fresh OHLCV download\n",
        "    TRAIN_REPO_DIR / \"data\" / \"processed_daily_macro_features.csv\",   # forces fresh macro cache build\n",
        "]\n",
        "\n",
        "deleted = []\n",
        "for p in purge_paths:\n",
        "    if p.is_dir():\n",
        "        shutil.rmtree(p, ignore_errors=True)\n",
        "        deleted.append(str(p))\n",
        "    elif p.is_file():\n",
        "        p.unlink(missing_ok=True)\n",
        "        deleted.append(str(p))\n",
        "\n",
        "# 3) Remove Python/Jupyter cache folders\n",
        "for cache_dir in TRAIN_REPO_DIR.rglob(\"__pycache__\"):\n",
        "    shutil.rmtree(cache_dir, ignore_errors=True)\n",
        "for ckpt_dir in TRAIN_REPO_DIR.rglob(\".ipynb_checkpoints\"):\n",
        "    shutil.rmtree(ckpt_dir, ignore_errors=True)\n",
        "\n",
        "# 4) Clear loaded project modules from kernel memory\n",
        "for mod in list(sys.modules.keys()):\n",
        "    if mod.startswith(\"src.\") or mod.startswith(\"src_\"):\n",
        "        del sys.modules[mod]\n",
        "gc.collect()\n",
        "\n",
        "print(\"âœ… Fresh start complete\")\n",
        "print(f\"Repo: {TRAIN_REPO_DIR}\")\n",
        "print(f\"Deleted paths: {len(deleted)}\")\n",
        "for d in deleted:\n",
        "    print(\" -\", d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9325a176",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exists: True\n",
            "CWD: /content\n",
            "\n",
            "Top-level:\n",
            " - [DIR ] .git\n",
            " - [FILE] .gitignore\n",
            " - [FILE] RL Portfolio Optimization Feature Engineering.md\n",
            " - [FILE] RL_Portfolio_Optimization_Feature_Engineering.ipynb\n",
            " - [FILE] USAGE_GUIDE_ACTUARIAL.py\n",
            " - [FILE] __init__.py\n",
            " - [FILE] convert_md_to_ipynb.py\n",
            " - [DIR ] data\n",
            " - [FILE] data1.zip\n",
            " - [DIR ] data_exports\n",
            " - [FILE] debug_attention_weights.py\n",
            " - [DIR ] eval\n",
            " - [DIR ] paper\n",
            " - [FILE] requirements.txt\n",
            " - [FILE] run_tcn_eval.py\n",
            " - [DIR ] src\n",
            " - [FILE] tcn_architecture_analysis.ipynb\n",
            " - [DIR ] tcn_documentation\n",
            " - [FILE] tcn_evaluation_only.ipynb\n",
            " - [FILE] technical_deep_dive_presentation.ipynb\n",
            " - [DIR ] tests\n",
            " - [FILE] traditional_portfolio_benchmarks.ipynb\n",
            " - [DIR ] training_scripts\n",
            "\n",
            "Target paths:\n",
            " - tcn_fusion_results: MISSING\n",
            " - tcn_results: MISSING\n",
            " - tcn_att_results: MISSING\n",
            " - output_logs: MISSING\n",
            " - data/phase1_preparation_artifacts: MISSING\n",
            " - data/master_features_NORMALIZED.csv: MISSING\n",
            " - data/daily_ohlcv_assets.csv: MISSING\n",
            " - data/processed_daily_macro_features.csv: MISSING\n"
          ]
        }
      ],
      "source": [
        "#from pathlib import Path\n",
        "import os\n",
        "\n",
        "root = Path(\"/content/adaptive_portfolio_rl\")\n",
        "print(\"Exists:\", root.exists())\n",
        "print(\"CWD:\", os.getcwd())\n",
        "\n",
        "print(\"\\nTop-level:\")\n",
        "for p in sorted(root.iterdir()):\n",
        "    kind = \"DIR \" if p.is_dir() else \"FILE\"\n",
        "    print(f\" - [{kind}] {p.name}\")\n",
        "\n",
        "# Quick check for outputs/caches you expected to be deleted\n",
        "targets = [\n",
        "    \"tcn_fusion_results\",\n",
        "    \"tcn_results\",\n",
        "    \"tcn_att_results\",\n",
        "    \"output_logs\",\n",
        "    \"data/phase1_preparation_artifacts\",\n",
        "    \"data/master_features_NORMALIZED.csv\",\n",
        "    \"data/daily_ohlcv_assets.csv\",\n",
        "    \"data/processed_daily_macro_features.csv\",\n",
        "]\n",
        "print(\"\\nTarget paths:\")\n",
        "for t in targets:\n",
        "    p = root / t\n",
        "    print(f\" - {t}: {'EXISTS' if p.exists() else 'MISSING'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c7cda1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#!find /content/adaptive_portfolio_rl -maxdepth 3 | head -n 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09af84a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install project requirements in Colab VM\n",
        "#import subprocess, sys\n",
        "#from pathlib import Path\n",
        "\n",
        "REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
        "REQ_FILE = REPO_DIR / \"requirements.txt\"\n",
        "\n",
        "if not REQ_FILE.exists():\n",
        "    raise FileNotFoundError(f\"Missing requirements file: {REQ_FILE}\")\n",
        "\n",
        "print(\"Using python:\", sys.executable)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REQ_FILE)], check=True)\n",
        "\n",
        "print(\"âœ… Requirements installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "14187b25",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy 2.0.2\n",
            "pandas 2.2.2\n",
            "tensorflow 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import numpy, pandas, tensorflow\n",
        "print(\"numpy\", numpy.__version__)\n",
        "print(\"pandas\", pandas.__version__)\n",
        "print(\"tensorflow\", tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b49d0f2",
      "metadata": {},
      "source": [
        "## 2) Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "641959e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cwd: /content/adaptive_portfolio_rl\n",
            "sys.path[0]: /content/adaptive_portfolio_rl\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    raise FileNotFoundError(f\"Repo not found: {REPO_DIR}\")\n",
        "\n",
        "# Set working directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Add repo root to Python path\n",
        "if str(REPO_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_DIR))\n",
        "\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"sys.path[0]:\", sys.path[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1b477656",
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from src.config import get_active_config\n",
        "from src.csv_logger import CSVLogger\n",
        "from src.notebook_helpers.tcn_phase1 import prepare_phase1_dataset, run_experiment6_tape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e5b538f",
      "metadata": {},
      "source": [
        "## 3) Base Config and Dataset Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b71d4646",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Feature lock from CORE project pipeline (no metadata/manifest)\n",
        "# ------------------------------------------------------------------\n",
        "from src.data_utils import DataProcessor\n",
        "\n",
        "\n",
        "def build_core_active_feature_columns(cfg):\n",
        "    # Active list as defined by core config + current selection rules.\n",
        "    probe = DataProcessor(cfg)\n",
        "    return list(dict.fromkeys(probe.get_feature_columns(\"phase1\")))\n",
        "\n",
        "\n",
        "def apply_core_feature_lock(cfg, active_feature_columns):\n",
        "    # Compute full candidate pool with selection filter temporarily disabled,\n",
        "    # then enforce active-only by setting disabled_features = full - active.\n",
        "    probe_cfg = deepcopy(cfg)\n",
        "    probe_fp = probe_cfg.setdefault(\"feature_params\", {})\n",
        "    probe_fs = probe_fp.setdefault(\"feature_selection\", {})\n",
        "    probe_fs[\"disable_features\"] = False\n",
        "    probe_fs[\"disabled_features\"] = []\n",
        "\n",
        "    probe = DataProcessor(probe_cfg)\n",
        "    core_all_cols = list(dict.fromkeys(probe.get_feature_columns(\"phase1\")))\n",
        "\n",
        "    active_set = set(active_feature_columns)\n",
        "    disabled = sorted([c for c in core_all_cols if c not in active_set])\n",
        "\n",
        "    fp = cfg.setdefault(\"feature_params\", {})\n",
        "    fs = fp.setdefault(\"feature_selection\", {})\n",
        "    fs[\"disable_features\"] = True\n",
        "    fs[\"disabled_features\"] = disabled\n",
        "\n",
        "    return core_all_cols, disabled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d7ca80e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Core feature lock applied\n",
            "   active_feature_columns: 50\n",
            "   disabled_features: 25\n",
            "ğŸ“Š Loading raw market data...\n",
            "   âœ… Raw data shape: (55107, 7)\n",
            "   âœ… Date range: 2003-09-02 00:00:00 â†’ 2025-08-29 00:00:00\n",
            "\n",
            "ğŸ”§ Computing multi-horizon log returns: [1, 5, 10, 21]\n",
            "   âœ… Shape after returns: (54897, 11)\n",
            "\n",
            "ğŸ“ˆ Calculating 21-day rolling statistics\n",
            "\n",
            "ğŸ§® Computing technical indicators\n",
            "\n",
            "ğŸ“Š Computing dynamic covariance features\n",
            "\n",
            "ğŸ¯ Adding regime awareness features\n",
            "   âœ… Master DF shape: (54897, 47)\n",
            "   âœ… Total features: 47\n",
            "\n",
            "ğŸ“Š Integrating fundamental features (if enabled)...\n",
            "   âœ… Fundamental columns in dataset: 6 (enabled=True)\n",
            "   ğŸ§¾ Sample fundamental cols: ['Fundamental_FCFE_Delta', 'Fundamental_Revenue_Delta', 'Fundamental_NCFO_Delta', 'Fundamental_FCFE_Sign', 'Fundamental_Staleness_Days', 'Fundamental_Staleness_Quarters']\n",
            "\n",
            "ğŸ“Š Integrating macroeconomic features (if enabled)...\n",
            "   âœ… Macro features added - 43 columns: ['EFFR_diff', 'EFFR_zscore', 'SOFR_level', 'SOFR_diff', 'FEDFUNDS_diff', 'FEDFUNDS_zscore', 'DGS10_level', 'DGS10_diff', 'DGS10_slope', 'DGS2_level', 'DGS2_diff', 'T10Y2Y_level', 'TIPS10Y_level', 'TIPS10Y_diff', 'BreakevenInf10Y_level', 'BreakevenInf10Y_diff', 'BreakevenInf5Y_level', 'BreakevenInf5Y_diff', 'FedBalanceSheet_level', 'FedBalanceSheet_diff', 'ON_RRP_level', 'ON_RRP_diff', 'CPI_yoy', 'CPI_mom', 'PPI_yoy', 'PPI_mom', 'UNRATE_level', 'UNRATE_diff', 'UNRATE_zscore', 'PAYEMS_level', 'PAYEMS_diff', 'PAYEMS_yoy', 'INDPRO_level', 'INDPRO_diff', 'INDPRO_yoy', 'IG_Credit_level', 'IG_Credit_diff', 'IG_Credit_zscore', 'HY_Credit_level', 'HY_Credit_diff', 'HY_Credit_zscore', 'VIX_level', 'VIX_zscore']\n",
            "\n",
            "ğŸ“Š Integrating Alpha features (if enabled)...\n",
            "\n",
            "âœ… Final master DF shape: (54897, 105)\n",
            "   âœ… Total features: 105\n",
            "\n",
            "================================================================================\n",
            "âœ‚ï¸ FILTERING TO ANALYSIS PERIOD\n",
            "================================================================================\n",
            "   Filtering data to: 2003-09-02 â†’ 2025-09-01\n",
            "   âœ… Dates after filter: 5514 trading days\n",
            "   âœ… Date range: 2003-10-01 00:00:00 to 2025-08-29 00:00:00\n",
            "================================================================================\n",
            "================================================================================\n",
            "âœ‚ï¸  TIME-BASED TRAIN/TEST SPLIT (80/20 split)\n",
            "   Train: 2003-10-01 â†’ 2021-04-09 (4411 days, 17.5 years, 43867 rows)\n",
            "   Test:  2021-04-12 â†’ 2025-08-29 (1103 days, 4.4 years, 11030 rows)\n",
            "================================================================================\n",
            "\n",
            "ğŸ”§ NORMALISING FEATURES (standard scaler)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.data_utils:Found 3171 NaN values after normalization, applying forward-fill only\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ’¾ Saving NORMALISED master dataframe to '/content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv'\n",
            "\n",
            "ğŸ’¾ Saved preparation artifacts:\n",
            "   raw OHLCV: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_raw_ohlcv.csv\n",
            "   full engineered: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_feature_engineered_full.csv\n",
            "   analysis-window engineered: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_feature_engineered_analysis_window.csv\n",
            "   normalized master: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_feature_engineered_normalized.csv\n",
            "   train normalized: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_train_normalized.csv\n",
            "   test normalized: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_test_normalized.csv\n",
            "   scalers: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_scalers.joblib\n",
            "   audit report: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260221_074148_preparation_audit.json\n"
          ]
        }
      ],
      "source": [
        "TRAIN_RANDOM_SEED = 42\n",
        "\n",
        "train_config = deepcopy(get_active_config(\"phase1\"))\n",
        "\n",
        "# Optional: override analysis horizon\n",
        "# train_config[\"ANALYSIS_END_DATE\"] = \"2025-09-01\"\n",
        "\n",
        "# Build active features from core project files/pipeline.\n",
        "train_active_feature_columns = build_core_active_feature_columns(train_config)\n",
        "_, train_disabled_features = apply_core_feature_lock(train_config, train_active_feature_columns)\n",
        "\n",
        "print(\"âœ… Core feature lock applied\")\n",
        "print(\"   active_feature_columns:\", len(train_active_feature_columns))\n",
        "print(\"   disabled_features:\", len(train_disabled_features))\n",
        "\n",
        "# Force fresh dataset build and market data re-download\n",
        "if \"train_phase1_data\" in globals():\n",
        "    del train_phase1_data\n",
        "\n",
        "train_phase1_data = prepare_phase1_dataset(\n",
        "    train_config,\n",
        "    force_download=True,\n",
        "    preparation_artifacts_dir=\"/content/adaptive_portfolio_rl/data_exports\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "32011606",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (43867, 105)\n",
            "Test shape: (11030, 105)\n",
            "Total columns: 105\n",
            "Potential redundant raw/unscaled cols: 0\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train shape:\", train_phase1_data.train_df.shape)\n",
        "print(\"Test shape:\", train_phase1_data.test_df.shape)\n",
        "\n",
        "cols = train_phase1_data.train_df.columns\n",
        "print(\"Total columns:\", len(cols))\n",
        "\n",
        "# quick sanity for common redundant groups\n",
        "dup_like = [c for c in cols if c.endswith(\"_raw\") or c.endswith(\"_unscaled\")]\n",
        "print(\"Potential redundant raw/unscaled cols:\", len(dup_like))\n",
        "print(dup_like[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ee488d70",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
              "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d',\n",
              "       ...\n",
              "       'VIX_zscore', 'CrossSectional_ZScore_LogReturn_1d',\n",
              "       'Residual_Momentum_21', 'Volume_Percentile_63', 'YieldCurve_Spread',\n",
              "       'YieldCurve_Inverted_Flag', 'ShortTerm_Reversal_5', 'VolOfVol_63',\n",
              "       'Beta_to_Market', 'OBV_Delta_Norm_21'],\n",
              "      dtype='object', length=105)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8f32ef47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used feature count: 73\n",
            "Disabled that still in used: []\n",
            "VIX_zscore used? False\n"
          ]
        }
      ],
      "source": [
        "used = set(train_phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
        "disabled = set(train_config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
        "\n",
        "print(\"Used feature count:\", len(used))\n",
        "print(\"Disabled that still in used:\", sorted(disabled & used))  # should be []\n",
        "print(\"VIX_zscore used?\", \"VIX_zscore\" in used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2e85bb7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_cols = [\"Date\", \"Ticker\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "keep = [c for c in base_cols + list(used) if c in train_phase1_data.master_df.columns]\n",
        "\n",
        "train_phase1_data.master_df = train_phase1_data.master_df[keep].copy()\n",
        "train_phase1_data.train_df = train_phase1_data.train_df[keep].copy()\n",
        "train_phase1_data.test_df  = train_phase1_data.test_df[keep].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81e8d0e",
      "metadata": {},
      "source": [
        "## 4) Training Overrides (Sharpe-Only Checkpoint Policy)\n",
        "\n",
        "This policy keeps only Sharpe-threshold high-watermark checkpointing (`>= 0.5`) and disables rare/step/periodic/TAPE checkpoint routes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2720c6fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… KL tuning + Sharpe-only checkpoint policy applied\n",
            "target_kl: 0.02\n",
            "rollout schedule: [{'threshold': 0, 'timesteps_per_update': 384}, {'threshold': 30000, 'timesteps_per_update': 512}]\n",
            "batch schedule: [{'threshold': 0, 'batch_size': 128}, {'threshold': 30000, 'batch_size': 128}]\n",
            "episode_length_curriculum: True [{'threshold': 0, 'limit': 252}, {'threshold': 10000, 'limit': 504}, {'threshold': 25000, 'limit': 756}, {'threshold': 40000, 'limit': None}]\n",
            "actor_lr_schedule: [{'threshold': 0, 'lr': 8e-06}, {'threshold': 40000, 'lr': 7e-06}, {'threshold': 70000, 'lr': 6e-06}]\n",
            "tape_terminal: 6.0 6.0\n",
            "dirichlet: elu 1.2 40.0 {'max': 0.9, 'min': 0.3}\n",
            "high_watermark_sharpe_threshold: 0.5\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "train_config = deepcopy(train_config)  # or deepcopy(config) if that is your active object\n",
        "\n",
        "tp = train_config[\"training_params\"]\n",
        "ap = train_config[\"agent_params\"]\n",
        "ppo = ap[\"ppo_params\"]\n",
        "env = train_config[\"environment_params\"]\n",
        "\n",
        "# Core setup\n",
        "tp[\"max_total_timesteps\"] = 100_000\n",
        "tp[\"timesteps_per_ppo_update\"] = 384  # fallback\n",
        "tp[\"timesteps_per_ppo_update_schedule\"] = [\n",
        "    {\"threshold\": 0, \"timesteps_per_update\": 384},\n",
        "    {\"threshold\": 30_000, \"timesteps_per_update\": 512},\n",
        "]\n",
        "tp[\"batch_size_ppo_schedule\"] = [\n",
        "    {\"threshold\": 0, \"batch_size\": 128},\n",
        "    {\"threshold\": 30_000, \"batch_size\": 128},\n",
        "]\n",
        "\n",
        "# Episode-length curriculum (ENABLE)\n",
        "tp[\"use_episode_length_curriculum\"] = True\n",
        "tp[\"episode_length_curriculum_schedule\"] = [\n",
        "    {\"threshold\": 0, \"limit\": 252},\n",
        "    {\"threshold\": 10_000, \"limit\": 504},\n",
        "    {\"threshold\": 25_000, \"limit\": 756},\n",
        "    {\"threshold\": 40_000, \"limit\": None},\n",
        "]\n",
        "\n",
        "# PPO KL management\n",
        "ppo[\"target_kl\"] = 0.020\n",
        "ppo[\"kl_stop_multiplier\"] = 1.25\n",
        "ppo[\"minibatches_before_kl_stop\"] = 2\n",
        "ppo[\"policy_clip\"] = 0.08\n",
        "ppo[\"num_ppo_epochs\"] = 1\n",
        "ppo[\"max_grad_norm\"] = 0.30\n",
        "\n",
        "# LR + entropy\n",
        "ppo[\"actor_lr\"] = 8e-6\n",
        "ppo[\"critic_lr\"] = 1.2e-4\n",
        "ppo[\"entropy_coef\"] = 0.0015\n",
        "\n",
        "# IMPORTANT: override training-level actor LR schedule (otherwise defaults win)\n",
        "tp[\"actor_lr_schedule\"] = [\n",
        "    {\"threshold\": 0, \"lr\": 8e-6},\n",
        "    {\"threshold\": 40_000, \"lr\": 7e-6},\n",
        "    {\"threshold\": 70_000, \"lr\": 6e-6},\n",
        "]\n",
        "\n",
        "# Dirichlet controls\n",
        "ap[\"dirichlet_alpha_activation\"] = \"elu\"\n",
        "ap[\"dirichlet_logit_temperature\"] = 1.20\n",
        "ap[\"dirichlet_alpha_cap\"] = 40.0\n",
        "ap[\"dirichlet_epsilon\"] = {\"max\": 0.9, \"min\": 0.3}\n",
        "\n",
        "# Keep execution/turnover controls\n",
        "tp[\"action_execution_beta_curriculum\"] = {\n",
        "    0: 0.20,\n",
        "    30_000: 0.35,\n",
        "}\n",
        "tp[\"turnover_penalty_curriculum\"] = {\n",
        "    0: 1.50,\n",
        "    10_000: 2.00,\n",
        "    25_000: 2.50,\n",
        "    40_000: 3.00,\n",
        "}\n",
        "env[\"target_turnover\"] = 0.35\n",
        "env[\"turnover_penalty_scalar\"] = 1.50\n",
        "env[\"transaction_cost_pct\"] = 0.001\n",
        "\n",
        "# Keep terminal reward scale aligned to your intended setup\n",
        "env[\"tape_terminal_scalar\"] = 6.0\n",
        "env[\"tape_terminal_clip\"] = 6.0\n",
        "\n",
        "# Sharpe-only checkpoint policy\n",
        "tp[\"high_watermark_checkpoint_enabled\"] = True\n",
        "tp[\"high_watermark_sharpe_threshold\"] = 0.5\n",
        "tp[\"step_sharpe_checkpoint_enabled\"] = False\n",
        "tp[\"periodic_checkpoint_every_steps\"] = 0\n",
        "tp[\"tape_checkpoint_threshold\"] = 999.0\n",
        "tp[\"rare_checkpoint_params\"] = {\"enable\": False}\n",
        "\n",
        "print(\"âœ… KL tuning + Sharpe-only checkpoint policy applied\")\n",
        "print(\"target_kl:\", ppo[\"target_kl\"])\n",
        "print(\"rollout schedule:\", tp[\"timesteps_per_ppo_update_schedule\"])\n",
        "print(\"batch schedule:\", tp[\"batch_size_ppo_schedule\"])\n",
        "print(\"episode_length_curriculum:\", tp[\"use_episode_length_curriculum\"], tp[\"episode_length_curriculum_schedule\"])\n",
        "print(\"actor_lr_schedule:\", tp[\"actor_lr_schedule\"])\n",
        "print(\"tape_terminal:\", env[\"tape_terminal_scalar\"], env[\"tape_terminal_clip\"])\n",
        "print(\"dirichlet:\", ap[\"dirichlet_alpha_activation\"], ap[\"dirichlet_logit_temperature\"], ap[\"dirichlet_alpha_cap\"], ap[\"dirichlet_epsilon\"])\n",
        "print(\"high_watermark_sharpe_threshold:\", tp[\"high_watermark_sharpe_threshold\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a2441609",
      "metadata": {},
      "outputs": [],
      "source": [
        "#tp = train_config[\"training_params\"]  # or config[\"training_params\"]\n",
        "\n",
        "# Practical logging cadence\n",
        "tp[\"update_log_interval\"] = 5\n",
        "tp[\"alpha_diversity_log_interval\"] = 5\n",
        "\n",
        "# Alpha-stuck warning controls\n",
        "tp[\"alpha_diversity_warning_after_updates\"] = 300\n",
        "tp[\"alpha_diversity_warning_std_threshold\"] = 0.25\n",
        "\n",
        "tp[\"log_step_diagnostics\"] = True  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09063801",
      "metadata": {},
      "source": [
        "## 5) Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a0fd91a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting training\n",
            "Architecture: TCN_FUSION\n",
            "max_total_timesteps: 100000\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT 6: TCN_FUSION Enhanced + TAPE Three-Component\n",
            "================================================================================\n",
            "Architecture: TCN + Fusion\n",
            "Results root: /content/adaptive_portfolio_rl/tcn_fusion_results\n",
            "Working dir: /content/adaptive_portfolio_rl\n",
            "Covariance Features: Yes\n",
            "ğŸ¯ REWARD SYSTEM: TAPE (Three-Component v3)\n",
            "   Profile: BalancedGrowth\n",
            "   Daily: Base + DSR/PBRS + Turnover_Proximity\n",
            "   Terminal: mode=signed | baseline=0.20 | scalar=6.0 (clipped Â±6.0)\n",
            "   Gate A: enabled (Sharpe â‰¤ 0.00 or MDD â‰¥ 25.0% -> force non-positive terminal bonus)\n",
            "   Neutral Band: enabled (Â±0.020 around baseline)\n",
            "   ğŸ”„ Profile Manager: disabled (static profile only)\n",
            "ğŸ² Experiment Seed: 6042 (Base: 42, Offset: 6000)\n",
            "âœ… Features: Enhanced (includes 3 covariance eigenvalues)\n",
            "   Eigenvalues: ['Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1', 'Covariance_Eigenvalue_2']\n",
            "   Train shape: (43867, 80)\n",
            "   Test shape: (11030, 80)\n",
            "\n",
            "ğŸ—ï¸ Creating THREE-COMPONENT TAPE v3 environments (with curriculum)...\n",
            "   ğŸ¯ Reward System: TAPE (Three-Component v3)\n",
            "   ğŸ“Š Profile: BalancedGrowth\n",
            "   âš™ï¸  Component 1: Base Reward (Net Return)\n",
            "   âš™ï¸  Component 2: DSR/PBRS (window=60, scalar=2.00, gamma=0.99)\n",
            "   âš™ï¸  Component 3: Turnover Proximity (target=0.35, band=Â±0.20, scalar=1.50 -> 2.00 â†’ 2.50 â†’ 3.00)\n",
            "      â†³ Schedule: 1.50@0 â†’ 2.00@10,000 â†’ 2.50@25,000 â†’ 3.00@40,000\n",
            "   âš™ï¸  Component 4: Execution Inertia (beta=0.20 -> 0.35, w_exec=(1-Î²)w_prev + Î²w_raw)\n",
            "      â†³ Schedule: 0.20@0 â†’ 0.35@30,000\n",
            "   ğŸ Terminal: mode=signed, baseline=0.20, scalar=6.0 (clipped Â±6.0)\n",
            "   ğŸŸ° Neutral Band: enabled (Â±0.020 around baseline)\n",
            "   ğŸš¦ Gate A: enabled (Sharpe â‰¤ 0.00, MDD â‰¥ 25.0%)\n",
            "   ğŸ§  Credit Assignment: step reward is computed at each environment step\n",
            "   ğŸ§¾ Episode-End Handling: terminal TAPE bonus is added at episode completion only\n",
            "   âœ… Retroactive episode-wide reward rescaling: disabled in notebook helper path\n",
            "   ğŸ”’ Drawdown dual controller (requested): target=18.00%, tolerance=-1.50% (trigger boundary â‰ˆ 16.50%), lr=0.100, Î»_init=0.50, Î»_floor=0.00, Î»_max=5.00, penalty_coef=1.50\n",
            "   âœ… Drawdown controller armed in env: target=18.00%, trigger=16.50%, Î»_init=0.500, Î»_floor=0.000, Î»_max=5.00, penalty_coef=1.50\n",
            "âœ… THREE-COMPONENT TAPE v3 Environments created:\n",
            "   Training: 4411 days\n",
            "   Testing: 1103 days\n",
            "\n",
            "ğŸ¤– Creating TCN_FUSION agent with Dirichlet distribution for Exp 6...\n",
            "âœ… Agent created: PPOAgentTF\n",
            "   ğŸ² Dirichlet Distribution: ENABLED\n",
            "   ğŸ”§ Actor LR schedule: 0.000008@0 â†’ 0.000007@40,000 â†’ 0.000006@70,000\n",
            "   State dim: 406\n",
            "   Action dim: 10\n",
            "   Actor LR (configured): 8e-06\n",
            "   Actor LR (active): 0.000008\n",
            "   Critic LR (active): 0.000120\n",
            "   PPO update: epochs=1, batch_size=128, target_kl=0.0200, entropy_coef=0.0015\n",
            "   ğŸ“ PPO rollout schedule: 384@0 â†’ 512@30,000\n",
            "   ğŸ§º PPO batch-size schedule: 128@0 â†’ 128@30,000\n",
            "ğŸ“Š Training metrics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_episodes.csv\n",
            "ğŸ§ª Step diagnostics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_step_diagnostics.csv\n",
            "\n",
            "ğŸ¯ Starting THREE-COMPONENT TAPE v3 training (with curriculum)...\n",
            "   Total timesteps: 100,000\n",
            "   Timesteps per update: scheduled\n",
            "      0+ steps: timesteps_per_update=384\n",
            "      30,000+ steps: timesteps_per_update=512\n",
            "   Number of updates: 216\n",
            "   PPO batch_size: scheduled\n",
            "      0+ steps: batch_size=128\n",
            "      30,000+ steps: batch_size=128\n",
            "   ğŸ“š Episode Length Curriculum:\n",
            "      0+ steps: limit=252\n",
            "      10,000+ steps: limit=504\n",
            "      25,000+ steps: limit=756\n",
            "      40,000+ steps: limit=full\n",
            "   ğŸ“š Turnover Scalar Curriculum:\n",
            "      0+ steps: scalar=1.50\n",
            "      10,000+ steps: scalar=2.00\n",
            "      25,000+ steps: scalar=2.50\n",
            "      40,000+ steps: scalar=3.00\n",
            "   ğŸ›ï¸ Action Execution Beta Curriculum:\n",
            "      0+ steps: beta=0.20\n",
            "      30,000+ steps: beta=0.35\n",
            "   ğŸ† High-Watermark checkpoints: enabled (save every episode with Sharpe >= 0.50)\n",
            "   ğŸ§· Step-Sharpe checkpoints: disabled\n",
            "ğŸ§¾ Active feature manifest saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_active_feature_manifest.json\n",
            "ğŸ§¾ Training metadata saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_metadata.json\n",
            "   ğŸ¯ Episode 1: TAPE Score = 0.3473 (bonus: +1.10 â†’ +1.10)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p682_actor.weights.h5 (Sharpe=0.682)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.056976 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 2: TAPE Score = 0.5674 (bonus: +2.76 â†’ +2.76)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p209_actor.weights.h5 (Sharpe=1.209)\n",
            "   ğŸ¯ Episode 3: TAPE Score = 0.6686 (bonus: +3.51 â†’ +3.51)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p822_actor.weights.h5 (Sharpe=1.822)\n",
            "   ğŸ¯ Episode 4: TAPE Score = 0.2610 (bonus: -0.46 â†’ -0.46)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.517, MDD=30.36%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p517_actor.weights.h5 (Sharpe=0.517)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.046137 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 5: TAPE Score = 0.5996 (bonus: +3.00 â†’ +3.00)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp1p406_actor.weights.h5 (Sharpe=1.406)\n",
            "   ğŸ¯ Episode 6: TAPE Score = 0.7532 (bonus: +4.15 â†’ +4.15)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p251_actor.weights.h5 (Sharpe=3.251)\n",
            "   ğŸ¯ Episode 7: TAPE Score = 0.4563 (bonus: +1.92 â†’ +1.92)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00007_shp0p778_actor.weights.h5 (Sharpe=0.778)\n",
            "ğŸ”„ Update 5/216 | Step 1,920/100,000 | Episode 7 | Time: 283.5s\n",
            "   ğŸ“Š Metrics: Return=+10.59% | Sharpe=0.778 | DD=10.59% | Turnover=10.55%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2497 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0206 | critic_loss=0.7632 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.3816 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=2.03 | std=0.32 | range=[1.35, 2.91]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 10.16% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4563\n",
            "   ğŸ¯ Episode 8: TAPE Score = 0.2091 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.592, MDD=36.66%\n",
            "   ğŸ¯ Episode 9: TAPE Score = 0.5644 (bonus: +2.73 â†’ +2.73)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00009_shp1p257_actor.weights.h5 (Sharpe=1.257)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.084563 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 10: TAPE Score = 0.3074 (bonus: +0.81 â†’ +0.81)\n",
            "   ğŸ¯ Episode 11: TAPE Score = 0.5608 (bonus: +2.71 â†’ +2.71)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp1p233_actor.weights.h5 (Sharpe=1.233)\n",
            "   ğŸ¯ Episode 12: TAPE Score = 0.2435 (bonus: -0.33 â†’ -0.33)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.176, MDD=17.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033688 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 13: TAPE Score = 0.5226 (bonus: +2.42 â†’ +2.42)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00013_shp1p106_actor.weights.h5 (Sharpe=1.106)\n",
            "   ğŸ¯ Episode 14: TAPE Score = 0.2574 (bonus: +0.43 â†’ +0.43)\n",
            "   ğŸ¯ Episode 15: TAPE Score = 0.6667 (bonus: +3.50 â†’ +3.50)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00015_shp1p810_actor.weights.h5 (Sharpe=1.810)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027681 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 10/216 | Step 3,840/100,000 | Episode 15 | Time: 553.4s\n",
            "   ğŸ“Š Metrics: Return=+16.90% | Sharpe=1.810 | DD=2.68% | Turnover=10.54%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2899 | delta_reward=-0.0011\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=-0.0115 | critic_loss=0.4026 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2013 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.99 | std=0.30 | range=[1.37, 2.74]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.80% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6667\n",
            "   ğŸ¯ Episode 16: TAPE Score = 0.3451 (bonus: +1.09 â†’ +1.09)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00016_shp0p699_actor.weights.h5 (Sharpe=0.699)\n",
            "   ğŸ¯ Episode 17: TAPE Score = 0.3154 (bonus: +0.87 â†’ +0.87)\n",
            "   ğŸ¯ Episode 18: TAPE Score = 0.2888 (bonus: -0.67 â†’ -0.67)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.634, MDD=30.04%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00018_shp0p634_actor.weights.h5 (Sharpe=0.634)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.075446 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 19: TAPE Score = 0.2696 (bonus: +0.52 â†’ +0.52)\n",
            "   ğŸ¯ Episode 20: TAPE Score = 0.5765 (bonus: +2.82 â†’ +2.82)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00020_shp1p247_actor.weights.h5 (Sharpe=1.247)\n",
            "   ğŸ¯ Episode 21: TAPE Score = 0.2722 (bonus: +0.54 â†’ +0.54)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034047 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 22: TAPE Score = 0.2818 (bonus: +0.61 â†’ +0.61)\n",
            "ğŸ”„ Update 15/216 | Step 5,760/100,000 | Episode 22 | Time: 824.1s\n",
            "   ğŸ“Š Metrics: Return=+6.52% | Sharpe=0.373 | DD=11.78% | Turnover=10.28%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7252 | delta_reward=-0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0202 | critic_loss=0.7323 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.3662 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.96 | std=0.30 | range=[1.37, 2.59]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.45% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.2818\n",
            "   ğŸ¯ Episode 23: TAPE Score = 0.4058 (bonus: +1.54 â†’ +1.54)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00023_shp0p659_actor.weights.h5 (Sharpe=0.659)\n",
            "   ğŸ¯ Episode 24: TAPE Score = 0.4410 (bonus: +1.81 â†’ +1.81)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00024_shp0p828_actor.weights.h5 (Sharpe=0.828)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036997 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 25: TAPE Score = 0.4645 (bonus: +1.98 â†’ +1.98)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00025_shp0p991_actor.weights.h5 (Sharpe=0.991)\n",
            "   ğŸ¯ Episode 26: TAPE Score = 0.6484 (bonus: +3.36 â†’ +3.36)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p929_actor.weights.h5 (Sharpe=1.929)\n",
            "   ğŸ¯ Episode 27: TAPE Score = 0.2457 (bonus: -0.34 â†’ -0.34)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.440, MDD=31.86%\n",
            "   ğŸ¯ Episode 28: TAPE Score = 0.5508 (bonus: +2.63 â†’ +2.63)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00028_shp1p133_actor.weights.h5 (Sharpe=1.133)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.069396 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 29: TAPE Score = 0.2405 (bonus: -0.30 â†’ -0.30)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.114, MDD=19.00%\n",
            "   ğŸ¯ Episode 30: TAPE Score = 0.2238 (bonus: -0.18 â†’ -0.18)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.261, MDD=30.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.061816 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 20/216 | Step 7,680/100,000 | Episode 30 | Time: 1095.3s\n",
            "   ğŸ“Š Metrics: Return=+5.35% | Sharpe=0.261 | DD=30.90% | Turnover=10.39%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7616 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0541 | critic_loss=1.1234 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.5617 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=2.03 | std=0.40 | range=[0.95, 3.07]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.10% / trig 16.50%) | terminal=0.000 (peak 0.108) | TAPE=0.2238\n",
            "   ğŸ¯ Episode 31: TAPE Score = 0.7431 (bonus: +4.07 â†’ +4.07)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00031_shp2p546_actor.weights.h5 (Sharpe=2.546)\n",
            "   ğŸ¯ Episode 32: TAPE Score = 0.5603 (bonus: +2.70 â†’ +2.70)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00032_shp1p156_actor.weights.h5 (Sharpe=1.156)\n",
            "   ğŸ¯ Episode 33: TAPE Score = 0.2108 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.104, MDD=34.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.197288 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 34: TAPE Score = 0.6117 (bonus: +3.09 â†’ +3.09)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00034_shp1p560_actor.weights.h5 (Sharpe=1.560)\n",
            "   ğŸ¯ Episode 35: TAPE Score = 0.5748 (bonus: +2.81 â†’ +2.81)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00035_shp1p384_actor.weights.h5 (Sharpe=1.384)\n",
            "   ğŸ¯ Episode 36: TAPE Score = 0.5944 (bonus: +2.96 â†’ +2.96)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00036_shp1p798_actor.weights.h5 (Sharpe=1.798)\n",
            "   ğŸ¯ Episode 37: TAPE Score = 0.3093 (bonus: +0.82 â†’ +0.82)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00037_shp0p504_actor.weights.h5 (Sharpe=0.504)\n",
            "   ğŸ¯ Episode 38: TAPE Score = 0.3046 (bonus: +0.78 â†’ +0.78)\n",
            "ğŸ”„ Update 25/216 | Step 9,600/100,000 | Episode 38 | Time: 1367.0s\n",
            "   ğŸ“Š Metrics: Return=+7.67% | Sharpe=0.455 | DD=12.93% | Turnover=10.30%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2316 | delta_reward=-0.0051\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0291 | critic_loss=0.5723 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2862 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.95 | std=0.30 | range=[1.33, 2.56]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 3.91% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3046\n",
            "   ğŸ¯ Episode 39: TAPE Score = 0.2617 (bonus: +0.46 â†’ +0.46)\n",
            "   ğŸ¯ Episode 40: TAPE Score = 0.3094 (bonus: +0.82 â†’ +0.82)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00040_shp0p558_actor.weights.h5 (Sharpe=0.558)\n",
            "   ğŸ¯ Episode 41: TAPE Score = 0.2482 (bonus: -0.36 â†’ -0.36)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.198, MDD=11.67%\n",
            "\n",
            "ğŸ“š TURNOVER CURRICULUM UPDATE at 10,368 steps:\n",
            "   Turnover penalty scalar: 2.0\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 10,368 steps:\n",
            "   Episode horizon: 504 steps\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.083971 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 42: TAPE Score = 0.3503 (bonus: -1.13 â†’ -1.13)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.808, MDD=31.09%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00042_shp0p808_actor.weights.h5 (Sharpe=0.808)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.046659 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 43: TAPE Score = 0.4407 (bonus: +1.81 â†’ +1.81)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00043_shp0p881_actor.weights.h5 (Sharpe=0.881)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.095843 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 30/216 | Step 11,520/100,000 | Episode 43 | Time: 1636.8s\n",
            "   ğŸ“Š Metrics: Return=+38.15% | Sharpe=0.881 | DD=20.42% | Turnover=10.50%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6682 | delta_reward=-0.0006\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0267 | critic_loss=1.2088 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.6044 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=2.06 | std=0.58 | range=[0.86, 3.47]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.960 (peak 0.976, dd 10.93% / trig 16.50%) | terminal=0.000 (peak 0.012) | TAPE=0.4407\n",
            "   ğŸ¯ Episode 44: TAPE Score = 0.2172 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.029, MDD=36.11%\n",
            "   ğŸ¯ Episode 45: TAPE Score = 0.3505 (bonus: +1.13 â†’ +1.13)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00045_shp0p674_actor.weights.h5 (Sharpe=0.674)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030535 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n",
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.130897 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 46: TAPE Score = 0.2167 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.028, MDD=33.99%\n",
            "   ğŸ¯ Episode 47: TAPE Score = 0.5388 (bonus: +2.54 â†’ +2.54)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00047_shp1p076_actor.weights.h5 (Sharpe=1.076)\n",
            "ğŸ”„ Update 35/216 | Step 13,440/100,000 | Episode 47 | Time: 1906.8s\n",
            "   ğŸ“Š Metrics: Return=+27.34% | Sharpe=1.076 | DD=6.95% | Turnover=10.45%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.4566 | delta_reward=+0.0009\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0230 | critic_loss=0.3489 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1745 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.91 | std=0.30 | range=[1.34, 2.55]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5388\n",
            "   ğŸ¯ Episode 48: TAPE Score = 0.6117 (bonus: +3.09 â†’ +3.09)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00048_shp1p565_actor.weights.h5 (Sharpe=1.565)\n",
            "   ğŸ¯ Episode 49: TAPE Score = 0.6317 (bonus: +3.24 â†’ +3.24)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00049_shp1p567_actor.weights.h5 (Sharpe=1.567)\n",
            "   ğŸ¯ Episode 50: TAPE Score = 0.2474 (bonus: -0.36 â†’ -0.36)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.418, MDD=29.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.054300 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 51: TAPE Score = 0.5228 (bonus: +2.42 â†’ +2.42)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00051_shp1p004_actor.weights.h5 (Sharpe=1.004)\n",
            "ğŸ”„ Update 40/216 | Step 15,360/100,000 | Episode 51 | Time: 2178.2s\n",
            "   ğŸ“Š Metrics: Return=+30.49% | Sharpe=1.004 | DD=10.03% | Turnover=10.30%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7607 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0278 | critic_loss=0.4428 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2214 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.90 | std=0.31 | range=[1.31, 2.61]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034815 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 52: TAPE Score = 0.4163 (bonus: +1.62 â†’ +1.62)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00052_shp0p837_actor.weights.h5 (Sharpe=0.837)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026310 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 53: TAPE Score = 0.3174 (bonus: +0.88 â†’ +0.88)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00053_shp0p547_actor.weights.h5 (Sharpe=0.547)\n",
            "   ğŸ¯ Episode 54: TAPE Score = 0.5070 (bonus: +2.30 â†’ +2.30)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00054_shp1p036_actor.weights.h5 (Sharpe=1.036)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031620 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n",
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.147702 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 45/216 | Step 17,280/100,000 | Episode 54 | Time: 2449.1s\n",
            "   ğŸ“Š Metrics: Return=+32.02% | Sharpe=1.036 | DD=12.70% | Turnover=10.51%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6332 | delta_reward=-0.0003\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0614 | critic_loss=0.8532 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.4266 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=2.05 | std=0.60 | range=[0.80, 3.43]\n",
            "   ğŸ¯ Episode 55: TAPE Score = 0.2168 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.016, MDD=38.39%\n",
            "   ğŸ¯ Episode 56: TAPE Score = 0.5593 (bonus: +2.69 â†’ +2.69)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00056_shp1p105_actor.weights.h5 (Sharpe=1.105)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.037032 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 57: TAPE Score = 0.2649 (bonus: +0.49 â†’ +0.49)\n",
            "   ğŸ¯ Episode 58: TAPE Score = 0.6884 (bonus: +3.66 â†’ +3.66)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00058_shp1p893_actor.weights.h5 (Sharpe=1.893)\n",
            "ğŸ”„ Update 50/216 | Step 19,200/100,000 | Episode 58 | Time: 2720.6s\n",
            "   ğŸ“Š Metrics: Return=+57.51% | Sharpe=1.893 | DD=4.44% | Turnover=10.75%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7481 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0204 | critic_loss=0.5333 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2667 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.88 | std=0.32 | range=[1.25, 2.45]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6884\n",
            "   ğŸ¯ Episode 59: TAPE Score = 0.3335 (bonus: +1.00 â†’ +1.00)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00059_shp0p621_actor.weights.h5 (Sharpe=0.621)\n",
            "   ğŸ¯ Episode 60: TAPE Score = 0.5431 (bonus: +2.57 â†’ +2.57)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p303_actor.weights.h5 (Sharpe=1.303)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031186 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 61: TAPE Score = 0.5552 (bonus: +2.66 â†’ +2.66)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00061_shp1p229_actor.weights.h5 (Sharpe=1.229)\n",
            "   ğŸ¯ Episode 62: TAPE Score = 0.3331 (bonus: +1.00 â†’ +1.00)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00062_shp0p598_actor.weights.h5 (Sharpe=0.598)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034093 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 55/216 | Step 21,120/100,000 | Episode 62 | Time: 2992.6s\n",
            "   ğŸ“Š Metrics: Return=+18.90% | Sharpe=0.598 | DD=13.04% | Turnover=10.81%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6057 | delta_reward=-0.0006\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0245 | critic_loss=0.4722 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2361 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.83 | std=0.28 | range=[1.22, 2.62]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.81% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3331\n",
            "   ğŸ¯ Episode 63: TAPE Score = 0.2664 (bonus: +0.50 â†’ +0.50)\n",
            "   ğŸ¯ Episode 64: TAPE Score = 0.2880 (bonus: +0.66 â†’ +0.66)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.037458 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 65: TAPE Score = 0.5506 (bonus: +2.63 â†’ +2.63)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00065_shp1p173_actor.weights.h5 (Sharpe=1.173)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.142934 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 66: TAPE Score = 0.2155 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.000, MDD=37.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030113 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 60/216 | Step 23,040/100,000 | Episode 66 | Time: 3263.5s\n",
            "   ğŸ“Š Metrics: Return=-4.67% | Sharpe=0.000 | DD=37.28% | Turnover=10.49%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2463 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0258 | critic_loss=0.2519 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1259 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.84 | std=0.28 | range=[1.09, 2.67]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.452, dd 9.39% / trig 16.50%) | terminal=0.645 (peak 1.427) | TAPE=0.2155\n",
            "   ğŸ¯ Episode 67: TAPE Score = 0.2916 (bonus: +0.69 â†’ +0.69)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.052079 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n",
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.161119 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 68: TAPE Score = 0.2146 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.005, MDD=42.03%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035891 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 69: TAPE Score = 0.5346 (bonus: +2.51 â†’ +2.51)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00069_shp1p099_actor.weights.h5 (Sharpe=1.099)\n",
            "   ğŸ¯ Episode 70: TAPE Score = 0.2143 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.013, MDD=41.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.196486 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 65/216 | Step 24,960/100,000 | Episode 70 | Time: 3533.5s\n",
            "   ğŸ“Š Metrics: Return=-5.73% | Sharpe=-0.013 | DD=41.14% | Turnover=10.33%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7426 | delta_reward=+0.0004\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0856 | critic_loss=0.5817 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2908 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.96 | std=0.57 | range=[0.73, 3.26]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.882 (peak 1.351, dd 0.00% / trig 16.50%) | terminal=1.930 (peak 2.136) | TAPE=0.2143\n",
            "\n",
            "ğŸ“š TURNOVER CURRICULUM UPDATE at 25,344 steps:\n",
            "   Turnover penalty scalar: 2.5\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 25,344 steps:\n",
            "   Episode horizon: 756 steps\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029270 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 71: TAPE Score = 0.3165 (bonus: +0.87 â†’ +0.87)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00071_shp0p503_actor.weights.h5 (Sharpe=0.503)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032245 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n",
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030053 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 72: TAPE Score = 0.2202 (bonus: -0.15 â†’ -0.15)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.111, MDD=46.70%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.089330 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n",
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026031 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 70/216 | Step 26,880/100,000 | Episode 72 | Time: 3802.5s\n",
            "   ğŸ“Š Metrics: Return=+4.69% | Sharpe=0.111 | DD=46.70% | Turnover=10.56%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.5878 | delta_reward=-0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0262 | critic_loss=0.2936 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1468 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.77 | std=0.27 | range=[1.18, 2.32]\n",
            "   ğŸ¯ Episode 73: TAPE Score = 0.3868 (bonus: +1.40 â†’ +1.40)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00073_shp0p760_actor.weights.h5 (Sharpe=0.760)\n",
            "   ğŸ¯ Episode 74: TAPE Score = 0.3300 (bonus: +0.98 â†’ +0.98)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00074_shp0p553_actor.weights.h5 (Sharpe=0.553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033399 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 75: TAPE Score = 0.3400 (bonus: +1.05 â†’ +1.05)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00075_shp0p595_actor.weights.h5 (Sharpe=0.595)\n",
            "ğŸ”„ Update 75/216 | Step 28,800/100,000 | Episode 75 | Time: 4074.4s\n",
            "   ğŸ“Š Metrics: Return=+27.38% | Sharpe=0.595 | DD=10.97% | Turnover=10.79%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7275 | delta_reward=+0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0193 | critic_loss=0.3164 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1582 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=384 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.80 | std=0.32 | range=[1.18, 2.42]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.72% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3400\n",
            "   ğŸ¯ Episode 76: TAPE Score = 0.2636 (bonus: -0.48 â†’ -0.48)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.534, MDD=30.08%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00076_shp0p534_actor.weights.h5 (Sharpe=0.534)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.077522 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n",
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030298 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 77: TAPE Score = 0.2874 (bonus: +0.66 â†’ +0.66)\n",
            "\n",
            "ğŸ›ï¸ EXECUTION BETA UPDATE at 30,336 steps:\n",
            "   action_execution_beta: 0.350 (w_exec=(1-Î²)w_prev + Î²w_raw)\n",
            "\n",
            "ğŸ“š PPO ROLLOUT UPDATE at 30,336 steps:\n",
            "   Timesteps per update: 512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030029 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 80/216 | Step 30,848/100,000 | Episode 77 | Time: 4363.3s\n",
            "   ğŸ“Š Metrics: Return=+24.53% | Sharpe=0.418 | DD=15.47% | Turnover=10.95%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6888 | delta_reward=+0.0006\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0058 | critic_loss=0.3238 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1619 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.75 | std=0.29 | range=[1.12, 2.31]\n",
            "   ğŸ¯ Episode 78: TAPE Score = 0.3447 (bonus: +1.09 â†’ +1.09)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00078_shp0p631_actor.weights.h5 (Sharpe=0.631)\n",
            "   ğŸ¯ Episode 79: TAPE Score = 0.4615 (bonus: +1.96 â†’ +1.96)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00079_shp0p858_actor.weights.h5 (Sharpe=0.858)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.120463 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 80: TAPE Score = 0.2656 (bonus: +0.49 â†’ +0.49)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034420 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 81: TAPE Score = 0.2108 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.056, MDD=45.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027938 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 85/216 | Step 33,408/100,000 | Episode 81 | Time: 4723.6s\n",
            "   ğŸ“Š Metrics: Return=-8.88% | Sharpe=-0.056 | DD=45.51% | Turnover=19.64%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6308 | delta_reward=+0.0003\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0201 | critic_loss=0.4055 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.2027 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.72 | std=0.27 | range=[1.18, 2.37]\n",
            "   ğŸ”’ Drawdown Î» snapshot=2.085 (peak 3.097, dd 0.00% / trig 16.50%) | terminal=4.424 (peak 4.443) | TAPE=0.2108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041123 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 82: TAPE Score = 0.3485 (bonus: +1.11 â†’ +1.11)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00082_shp0p602_actor.weights.h5 (Sharpe=0.602)\n",
            "   ğŸ¯ Episode 83: TAPE Score = 0.2747 (bonus: +0.56 â†’ +0.56)\n",
            "   ğŸ¯ Episode 84: TAPE Score = 0.2189 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.045, MDD=33.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.046722 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 90/216 | Step 35,968/100,000 | Episode 84 | Time: 5084.8s\n",
            "   ğŸ“Š Metrics: Return=+3.27% | Sharpe=0.045 | DD=33.20% | Turnover=20.02%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2398 | delta_reward=-0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0209 | critic_loss=0.2880 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1440 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.71 | std=0.28 | range=[0.96, 2.70]\n",
            "   ğŸ¯ Episode 85: TAPE Score = 0.2800 (bonus: +0.60 â†’ +0.60)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040721 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 86: TAPE Score = 0.2835 (bonus: +0.63 â†’ +0.63)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032867 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 87: TAPE Score = 0.3688 (bonus: +1.27 â†’ +1.27)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00087_shp0p675_actor.weights.h5 (Sharpe=0.675)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033104 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 88: TAPE Score = 0.3607 (bonus: +1.21 â†’ +1.21)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00088_shp0p691_actor.weights.h5 (Sharpe=0.691)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034920 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 95/216 | Step 38,528/100,000 | Episode 88 | Time: 5442.8s\n",
            "   ğŸ“Š Metrics: Return=+43.41% | Sharpe=0.691 | DD=15.57% | Turnover=20.05%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6865 | delta_reward=+0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0192 | critic_loss=0.3783 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1891 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.68 | std=0.27 | range=[1.04, 2.24]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.086053 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 89: TAPE Score = 0.2084 (bonus: -0.00 â†’ -0.00)\n",
            "      ğŸŸ° Neutral band applied (Â±0.020)\n",
            "      ğŸš¦ Gate A applied: Sharpe=-0.129, MDD=46.60%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.044886 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 90: TAPE Score = 0.6279 (bonus: +3.21 â†’ +3.21)\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00090_shp1p494_actor.weights.h5 (Sharpe=1.494)\n",
            "   ğŸ”§ Actor learning rate adjusted to 0.000007 at step 40,000\n",
            "\n",
            "ğŸ“š TURNOVER CURRICULUM UPDATE at 40,064 steps:\n",
            "   Turnover penalty scalar: 3.0\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 40,064 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.047472 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 40,576 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040164 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 41,088 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026389 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 100/216 | Step 41,088/100,000 | Episode 90 | Time: 5797.8s\n",
            "   ğŸ“Š Metrics: Return=+75.39% | Sharpe=1.494 | DD=8.91% | Turnover=20.28%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7346 | delta_reward=-0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=-0.0067 | critic_loss=0.2942 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1471 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.67 | std=0.32 | range=[1.11, 2.39]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 41,600 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034302 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 91: TAPE Score = 0.2692 (bonus: -0.52 â†’ -0.52)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.577, MDD=31.96%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00091_shp0p577_actor.weights.h5 (Sharpe=0.577)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 42,112 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.051442 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 42,624 steps:\n",
            "   Episode horizon set to full dataset\n",
            "   ğŸ¯ Episode 92: TAPE Score = 0.2533 (bonus: -0.40 â†’ -0.40)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.489, MDD=30.77%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 43,136 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.068846 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 43,648 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041339 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 105/216 | Step 43,648/100,000 | Episode 92 | Time: 6155.6s\n",
            "   ğŸ“Š Metrics: Return=+38.66% | Sharpe=0.489 | DD=30.77% | Turnover=19.87%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6983 | delta_reward=-0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.1046 | critic_loss=0.2804 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1402 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.62 | std=0.29 | range=[0.99, 2.22]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 44,160 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029594 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 44,672 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 45,184 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033803 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 93: TAPE Score = 0.2676 (bonus: -0.51 â†’ -0.51)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.566, MDD=32.39%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00093_shp0p566_actor.weights.h5 (Sharpe=0.566)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 45,696 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.051225 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 46,208 steps:\n",
            "   Episode horizon set to full dataset\n",
            "ğŸ”„ Update 110/216 | Step 46,208/100,000 | Episode 93 | Time: 6515.1s\n",
            "   ğŸ“Š Metrics: Return=+173.67% | Sharpe=0.566 | DD=32.39% | Turnover=20.21%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2871 | delta_reward=+0.0004\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0230 | critic_loss=0.2645 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1323 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.63 | std=0.33 | range=[0.99, 2.26]\n",
            "   ğŸ¯ Episode 94: TAPE Score = 0.3461 (bonus: -1.10 â†’ -1.10)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.805, MDD=30.21%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00094_shp0p805_actor.weights.h5 (Sharpe=0.805)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 46,720 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040521 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 47,232 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.050321 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 47,744 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.091382 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 48,256 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026807 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 48,768 steps:\n",
            "   Episode horizon set to full dataset\n",
            "ğŸ”„ Update 115/216 | Step 48,768/100,000 | Episode 94 | Time: 6873.1s\n",
            "   ğŸ“Š Metrics: Return=+92.28% | Sharpe=0.805 | DD=30.21% | Turnover=20.16%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.5274 | delta_reward=+0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0229 | critic_loss=0.2439 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1219 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.57 | std=0.29 | range=[1.03, 2.18]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 49,280 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 49,792 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.058241 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 50,304 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.056695 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 95: TAPE Score = 0.2428 (bonus: -0.32 â†’ -0.32)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.405, MDD=47.29%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 50,816 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.028765 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 51,328 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.056756 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 120/216 | Step 51,328/100,000 | Episode 95 | Time: 7230.5s\n",
            "   ğŸ“Š Metrics: Return=+223.03% | Sharpe=0.405 | DD=47.29% | Turnover=20.27%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2347 | delta_reward=-0.0017\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0545 | critic_loss=0.3244 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1622 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.63 | std=0.46 | range=[0.50, 2.94]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 51,840 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.124036 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 52,352 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036469 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 52,864 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036559 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 53,376 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040098 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 53,888 steps:\n",
            "   Episode horizon set to full dataset\n",
            "ğŸ”„ Update 125/216 | Step 53,888/100,000 | Episode 95 | Time: 7588.8s\n",
            "   ğŸ“Š Metrics: Return=+147.28% | Sharpe=0.368 | DD=45.23% | Turnover=20.41%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7162 | delta_reward=-0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0224 | critic_loss=0.2725 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1362 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.56 | std=0.35 | range=[0.92, 2.33]\n",
            "   ğŸ¯ Episode 96: TAPE Score = 0.2459 (bonus: -0.34 â†’ -0.34)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.422, MDD=45.23%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 54,400 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038808 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 54,912 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031649 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 55,424 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030367 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 55,936 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027700 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 56,448 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025296 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 130/216 | Step 56,448/100,000 | Episode 96 | Time: 7945.1s\n",
            "   ğŸ“Š Metrics: Return=+238.89% | Sharpe=0.422 | DD=45.23% | Turnover=20.41%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7491 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0901 | critic_loss=0.2533 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1266 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.52 | std=0.33 | range=[0.94, 2.16]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 56,960 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030447 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 57,472 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.058093 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 97: TAPE Score = 0.2632 (bonus: -0.47 â†’ -0.47)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.533, MDD=31.74%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00097_shp0p533_actor.weights.h5 (Sharpe=0.533)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 57,984 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029004 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 98: TAPE Score = 0.3111 (bonus: -0.83 â†’ -0.83)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.717, MDD=31.67%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00098_shp0p717_actor.weights.h5 (Sharpe=0.717)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 58,496 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.049031 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 59,008 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.057924 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 135/216 | Step 59,008/100,000 | Episode 98 | Time: 8301.0s\n",
            "   ğŸ“Š Metrics: Return=+71.54% | Sharpe=0.717 | DD=31.67% | Turnover=20.57%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2180 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0925 | critic_loss=0.1677 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.0838 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.51 | std=0.35 | range=[0.82, 2.39]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 59,520 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.103592 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 60,032 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029300 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 60,544 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.039157 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 61,056 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 61,568 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.058435 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 140/216 | Step 61,568/100,000 | Episode 98 | Time: 8661.0s\n",
            "   ğŸ“Š Metrics: Return=+108.18% | Sharpe=0.319 | DD=46.30% | Turnover=20.98%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2397 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0272 | critic_loss=0.2288 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1144 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.48 | std=0.33 | range=[0.90, 2.20]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 62,080 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025803 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 99: TAPE Score = 0.2447 (bonus: -0.33 â†’ -0.33)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.408, MDD=46.30%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 62,592 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 63,104 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027426 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 63,616 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033606 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 64,128 steps:\n",
            "   Episode horizon set to full dataset\n",
            "ğŸ”„ Update 145/216 | Step 64,128/100,000 | Episode 99 | Time: 9025.0s\n",
            "   ğŸ“Š Metrics: Return=+208.95% | Sharpe=0.408 | DD=46.30% | Turnover=20.96%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2328 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0215 | critic_loss=0.2748 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1374 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.46 | std=0.33 | range=[0.81, 2.07]\n",
            "   ğŸ¯ Episode 100: TAPE Score = 0.2990 (bonus: -0.74 â†’ -0.74)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.654, MDD=31.05%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00100_shp0p654_actor.weights.h5 (Sharpe=0.654)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 64,640 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.088261 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 65,152 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031876 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 65,664 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.075266 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 66,176 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.084620 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 66,688 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030780 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 150/216 | Step 66,688/100,000 | Episode 100 | Time: 9387.0s\n",
            "   ğŸ“Š Metrics: Return=+181.48% | Sharpe=0.654 | DD=31.05% | Turnover=20.89%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6684 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0137 | critic_loss=0.3144 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1572 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.42 | std=0.28 | range=[0.76, 1.98]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 67,200 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.044023 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 67,712 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.057465 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 68,224 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 68,736 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040599 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 101: TAPE Score = 0.2442 (bonus: -0.33 â†’ -0.33)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.406, MDD=48.94%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 69,248 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038408 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 155/216 | Step 69,248/100,000 | Episode 101 | Time: 9752.3s\n",
            "   ğŸ“Š Metrics: Return=+250.80% | Sharpe=0.406 | DD=48.94% | Turnover=21.07%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2700 | delta_reward=-0.0003\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0237 | critic_loss=0.2404 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1202 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000007 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.42 | std=0.28 | range=[0.77, 2.01]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.69% / trig 16.50%) | terminal=0.000 (peak 5.000) | TAPE=0.2442\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 69,760 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036150 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ”§ Actor learning rate adjusted to 0.000006 at step 70,000\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 70,272 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033302 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 70,784 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027535 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 71,296 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035262 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 102: TAPE Score = 0.2973 (bonus: -0.73 â†’ -0.73)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.633, MDD=29.27%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00102_shp0p633_actor.weights.h5 (Sharpe=0.633)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 71,808 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.053782 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 160/216 | Step 71,808/100,000 | Episode 102 | Time: 10115.6s\n",
            "   ğŸ“Š Metrics: Return=+218.56% | Sharpe=0.633 | DD=29.27% | Turnover=21.11%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2356 | delta_reward=-0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0380 | critic_loss=0.1935 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.0967 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.46 | std=0.35 | range=[0.43, 2.50]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.73% / trig 16.50%) | terminal=0.000 (peak 0.075) | TAPE=0.2973\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 72,320 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029966 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 72,832 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.053522 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 103: TAPE Score = 0.2720 (bonus: -0.54 â†’ -0.54)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.591, MDD=32.12%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00103_shp0p591_actor.weights.h5 (Sharpe=0.591)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 73,344 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040463 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 73,856 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 74,368 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041475 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 165/216 | Step 74,368/100,000 | Episode 103 | Time: 10475.9s\n",
            "   ğŸ“Š Metrics: Return=+83.54% | Sharpe=0.591 | DD=32.12% | Turnover=20.88%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.3706 | delta_reward=+0.0003\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0591 | critic_loss=0.2676 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1338 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.43 | std=0.32 | range=[0.80, 2.06]\n",
            "   ğŸ¯ Episode 104: TAPE Score = 0.2618 (bonus: -0.46 â†’ -0.46)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.556, MDD=30.73%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00104_shp0p556_actor.weights.h5 (Sharpe=0.556)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 74,880 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.059294 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 75,392 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033504 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 75,904 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 76,416 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 76,928 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.061036 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 170/216 | Step 76,928/100,000 | Episode 104 | Time: 10836.0s\n",
            "   ğŸ“Š Metrics: Return=+104.76% | Sharpe=0.556 | DD=30.73% | Turnover=21.28%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.5943 | delta_reward=-0.0003\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=-0.0184 | critic_loss=0.2020 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1010 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.46 | std=0.37 | range=[0.42, 2.50]\n",
            "   ğŸ¯ Episode 105: TAPE Score = 0.2480 (bonus: -0.36 â†’ -0.36)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.491, MDD=32.33%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 77,440 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026737 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 77,952 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 78,464 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033868 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 78,976 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.055704 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 79,488 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029317 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 175/216 | Step 79,488/100,000 | Episode 105 | Time: 11194.9s\n",
            "   ğŸ“Š Metrics: Return=+105.02% | Sharpe=0.491 | DD=32.33% | Turnover=21.36%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2995 | delta_reward=-0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0391 | critic_loss=0.2581 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1290 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.44 | std=0.32 | range=[0.82, 2.11]\n",
            "   ğŸ¯ Episode 106: TAPE Score = 0.2902 (bonus: -0.68 â†’ -0.68)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.630, MDD=31.93%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00106_shp0p630_actor.weights.h5 (Sharpe=0.630)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 80,000 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.113267 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 80,512 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 81,024 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.047054 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 81,536 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.049193 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 82,048 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030544 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 180/216 | Step 82,048/100,000 | Episode 106 | Time: 11552.9s\n",
            "   ğŸ“Š Metrics: Return=+249.41% | Sharpe=0.630 | DD=31.93% | Turnover=21.21%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6794 | delta_reward=+0.0001\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0593 | critic_loss=0.2067 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1033 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.42 | std=0.32 | range=[0.88, 2.12]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 82,560 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029943 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 107: TAPE Score = 0.2685 (bonus: -0.51 â†’ -0.51)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.564, MDD=33.47%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00107_shp0p564_actor.weights.h5 (Sharpe=0.564)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 83,072 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029746 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 83,584 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 84,096 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032390 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 84,608 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.065118 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 185/216 | Step 84,608/100,000 | Episode 107 | Time: 11911.6s\n",
            "   ğŸ“Š Metrics: Return=+219.06% | Sharpe=0.564 | DD=33.47% | Turnover=21.23%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2407 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=-0.0061 | critic_loss=0.2364 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1182 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.46 | std=0.36 | range=[0.42, 2.52]\n",
            "   ğŸ¯ Episode 108: TAPE Score = 0.2659 (bonus: -0.49 â†’ -0.49)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.535, MDD=30.74%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00108_shp0p535_actor.weights.h5 (Sharpe=0.535)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 85,120 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.054906 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 85,632 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.043781 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 109: TAPE Score = 0.3601 (bonus: -1.20 â†’ -1.20)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.807, MDD=28.78%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00109_shp0p807_actor.weights.h5 (Sharpe=0.807)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 86,144 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.051882 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 86,656 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033257 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 87,168 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038062 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 190/216 | Step 87,168/100,000 | Episode 109 | Time: 12269.1s\n",
            "   ğŸ“Š Metrics: Return=+116.49% | Sharpe=0.807 | DD=28.78% | Turnover=21.37%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.4049 | delta_reward=-0.0016\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0221 | critic_loss=0.1884 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.0942 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.42 | std=0.30 | range=[0.89, 2.05]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 87,680 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029920 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 110: TAPE Score = 0.2668 (bonus: -0.50 â†’ -0.50)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.561, MDD=32.00%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00110_shp0p561_actor.weights.h5 (Sharpe=0.561)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 88,192 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.049763 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 88,704 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.050333 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 89,216 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025686 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 89,728 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032822 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 195/216 | Step 89,728/100,000 | Episode 110 | Time: 12627.3s\n",
            "   ğŸ“Š Metrics: Return=+118.23% | Sharpe=0.561 | DD=32.00% | Turnover=21.24%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.4317 | delta_reward=-0.0016\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=-0.0019 | critic_loss=0.2228 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1114 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.43 | std=0.30 | range=[0.83, 2.07]\n",
            "   ğŸ¯ Episode 111: TAPE Score = 0.2812 (bonus: -0.61 â†’ -0.61)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.615, MDD=31.06%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00111_shp0p615_actor.weights.h5 (Sharpe=0.615)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 90,240 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032167 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 90,752 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.048193 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 91,264 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041217 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 91,776 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.028857 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 112: TAPE Score = 0.3116 (bonus: -0.84 â†’ -0.84)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.698, MDD=30.67%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00112_shp0p698_actor.weights.h5 (Sharpe=0.698)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 92,288 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.064799 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 200/216 | Step 92,288/100,000 | Episode 112 | Time: 12984.3s\n",
            "   ğŸ“Š Metrics: Return=+160.17% | Sharpe=0.698 | DD=30.67% | Turnover=21.29%\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0685 | critic_loss=0.1520 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.0760 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.45 | std=0.35 | range=[0.42, 2.49]\n",
            "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.86% / trig 16.50%) | terminal=0.000 (peak 0.104) | TAPE=0.3116\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 92,800 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 93,312 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030427 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 93,824 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 94,336 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.054263 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ğŸ¯ Episode 113: TAPE Score = 0.2810 (bonus: -0.61 â†’ -0.61)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.602, MDD=31.34%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00113_shp0p602_actor.weights.h5 (Sharpe=0.602)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 94,848 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.128885 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 205/216 | Step 94,848/100,000 | Episode 113 | Time: 13342.2s\n",
            "   ğŸ“Š Metrics: Return=+144.68% | Sharpe=0.602 | DD=31.34% | Turnover=21.18%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.6813 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=-0.0037 | critic_loss=0.1946 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.0973 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.54 | std=0.50 | range=[0.36, 2.74]\n",
            "   ğŸ”’ Drawdown Î» snapshot=1.870 (peak 1.870, dd 19.05% / trig 16.50%) | terminal=0.000 (peak 0.109) | TAPE=0.2810\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 95,360 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040477 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 95,872 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 96,384 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.028531 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 96,896 steps:\n",
            "   Episode horizon set to full dataset\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 97,408 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.028197 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 210/216 | Step 97,408/100,000 | Episode 113 | Time: 13701.3s\n",
            "   ğŸ“Š Metrics: Return=+93.12% | Sharpe=0.304 | DD=39.37% | Turnover=21.38%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.2477 | delta_reward=+0.0000\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0234 | critic_loss=0.2130 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1065 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.43 | std=0.30 | range=[0.81, 1.96]\n",
            "   ğŸ¯ Episode 114: TAPE Score = 0.2449 (bonus: -0.34 â†’ -0.34)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.396, MDD=39.37%\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 97,920 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.075642 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 98,432 steps:\n",
            "   Episode horizon set to full dataset\n",
            "   ğŸ¯ Episode 115: TAPE Score = 0.3140 (bonus: -0.86 â†’ -0.86)\n",
            "      ğŸš¦ Gate A applied: Sharpe=0.702, MDD=30.05%\n",
            "      ğŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00115_shp0p702_actor.weights.h5 (Sharpe=0.702)\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 98,944 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.082525 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 99,456 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034443 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 99,968 steps:\n",
            "   Episode horizon set to full dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.053395 exceeded threshold 0.025000 (target_kl 0.020000 Ã— 1.25)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Update 215/216 | Step 99,968/100,000 | Episode 115 | Time: 14058.2s\n",
            "   ğŸ“Š Metrics: Return=+68.15% | Sharpe=0.702 | DD=30.05% | Turnover=21.01%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7037 | delta_reward=+0.0002\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0625 | critic_loss=0.2703 | mean_adv=0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1351 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "   ğŸ”¬ Alpha Diversity: mean=1.47 | std=0.37 | range=[0.42, 2.48]\n",
            "\n",
            "ğŸ“š EPISODE HORIZON UPDATE at 100,000 steps:\n",
            "   Episode horizon set to full dataset\n",
            "ğŸ”„ Update 216/216 | Step 100,000/100,000 | Episode 115 | Time: 14066.5s\n",
            "   ğŸ“Š Metrics: Return=+78.52% | Sharpe=0.650 | DD=30.25% | Turnover=21.05%\n",
            "   ğŸšï¸ Intra-Step TAPE: potential=0.7004 | delta_reward=+0.0002\n",
            "   ğŸ¯ Profile: BalancedGrowth\n",
            "   ğŸ§  Training: actor_loss=0.0201 | critic_loss=0.3658 | mean_adv=-0.0000\n",
            "   ğŸ§® Loss Detail: critic_scaled=0.1829 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
            "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0200 | rollout=512 | batch_size=128\n",
            "\n",
            "âœ… THREE-COMPONENT TAPE v3 training completed!\n",
            "   Total episodes: 115\n",
            "   Total timesteps: 100,000\n",
            "   Training time: 14066.50s (234.44min)\n",
            "ğŸ“Š Training summary saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_summary.csv\n",
            "ğŸ’¾ Final models saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00115_shp0p702_actor.weights.h5, /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00115_shp0p702_critic.weights.h5\n",
            "âœ… Training complete\n",
            "checkpoint_prefix: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00115_shp0p702\n"
          ]
        }
      ],
      "source": [
        "RUN_TRAINING = True\n",
        "\n",
        "if RUN_TRAINING:\n",
        "    tp = train_config[\"training_params\"]\n",
        "    print(\"ğŸš€ Starting training\")\n",
        "    print(\"Architecture:\", train_config[\"agent_params\"].get(\"actor_critic_type\"))\n",
        "    print(\"max_total_timesteps:\", tp[\"max_total_timesteps\"])\n",
        "\n",
        "    train_experiment6 = run_experiment6_tape(\n",
        "        phase1_data=train_phase1_data,\n",
        "        config=train_config,\n",
        "        random_seed=TRAIN_RANDOM_SEED,\n",
        "        csv_logger_cls=CSVLogger,\n",
        "        use_covariance=True,\n",
        "        architecture=train_config[\"agent_params\"].get(\"actor_critic_type\"),\n",
        "        timesteps_per_update=tp.get(\"timesteps_per_ppo_update\", 384),\n",
        "        max_total_timesteps=tp[\"max_total_timesteps\"],\n",
        "    )\n",
        "\n",
        "    print(\"âœ… Training complete\")\n",
        "    print(\"checkpoint_prefix:\", train_experiment6.checkpoint_path)\n",
        "else:\n",
        "    print(\"â„¹ï¸ RUN_TRAINING=False\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ffd0df",
      "metadata": {},
      "source": [
        "## 6) Inspect Latest Training Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "348fd0c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episodes file: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260221_074438_episodes.csv\n",
            "Rows: 44\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-98b024fe-bfc0-42c4-9dee-962bb0fc2f7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>update</th>\n",
              "      <th>timestep</th>\n",
              "      <th>episode</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>episode_return_pct</th>\n",
              "      <th>episode_sharpe</th>\n",
              "      <th>episode_sortino</th>\n",
              "      <th>episode_max_dd</th>\n",
              "      <th>episode_volatility</th>\n",
              "      <th>episode_win_rate</th>\n",
              "      <th>...</th>\n",
              "      <th>actor_grad_norm</th>\n",
              "      <th>critic_grad_norm</th>\n",
              "      <th>alpha_min</th>\n",
              "      <th>alpha_max</th>\n",
              "      <th>alpha_mean</th>\n",
              "      <th>ratio_mean</th>\n",
              "      <th>ratio_std</th>\n",
              "      <th>drawdown_lambda_peak</th>\n",
              "      <th>episode_length</th>\n",
              "      <th>termination_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>125</td>\n",
              "      <td>53888</td>\n",
              "      <td>95</td>\n",
              "      <td>7588.848321</td>\n",
              "      <td>147.280347</td>\n",
              "      <td>0.368493</td>\n",
              "      <td>0.471990</td>\n",
              "      <td>45.234094</td>\n",
              "      <td>0.167654</td>\n",
              "      <td>53.197158</td>\n",
              "      <td>...</td>\n",
              "      <td>0.991537</td>\n",
              "      <td>0.276854</td>\n",
              "      <td>0.917434</td>\n",
              "      <td>2.327151</td>\n",
              "      <td>1.557742</td>\n",
              "      <td>1.022158</td>\n",
              "      <td>0.193112</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3904.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>130</td>\n",
              "      <td>56448</td>\n",
              "      <td>96</td>\n",
              "      <td>7945.142123</td>\n",
              "      <td>238.893770</td>\n",
              "      <td>0.422210</td>\n",
              "      <td>0.528641</td>\n",
              "      <td>45.234094</td>\n",
              "      <td>0.178832</td>\n",
              "      <td>53.352243</td>\n",
              "      <td>...</td>\n",
              "      <td>1.336362</td>\n",
              "      <td>1.444798</td>\n",
              "      <td>0.940221</td>\n",
              "      <td>2.157194</td>\n",
              "      <td>1.522272</td>\n",
              "      <td>0.976395</td>\n",
              "      <td>0.183761</td>\n",
              "      <td>3.610326</td>\n",
              "      <td>3879.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>135</td>\n",
              "      <td>59008</td>\n",
              "      <td>98</td>\n",
              "      <td>8301.014248</td>\n",
              "      <td>71.540151</td>\n",
              "      <td>0.716565</td>\n",
              "      <td>0.834350</td>\n",
              "      <td>31.673584</td>\n",
              "      <td>0.192868</td>\n",
              "      <td>55.942623</td>\n",
              "      <td>...</td>\n",
              "      <td>1.121846</td>\n",
              "      <td>0.524080</td>\n",
              "      <td>0.822288</td>\n",
              "      <td>2.389275</td>\n",
              "      <td>1.506629</td>\n",
              "      <td>1.001624</td>\n",
              "      <td>0.238133</td>\n",
              "      <td>0.118620</td>\n",
              "      <td>977.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>140</td>\n",
              "      <td>61568</td>\n",
              "      <td>98</td>\n",
              "      <td>8660.969729</td>\n",
              "      <td>108.180734</td>\n",
              "      <td>0.318511</td>\n",
              "      <td>0.406986</td>\n",
              "      <td>46.303088</td>\n",
              "      <td>0.169908</td>\n",
              "      <td>52.979066</td>\n",
              "      <td>...</td>\n",
              "      <td>1.659853</td>\n",
              "      <td>0.940132</td>\n",
              "      <td>0.901950</td>\n",
              "      <td>2.202467</td>\n",
              "      <td>1.484410</td>\n",
              "      <td>0.998578</td>\n",
              "      <td>0.192684</td>\n",
              "      <td>0.118620</td>\n",
              "      <td>977.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>145</td>\n",
              "      <td>64128</td>\n",
              "      <td>99</td>\n",
              "      <td>9024.957481</td>\n",
              "      <td>208.949415</td>\n",
              "      <td>0.407927</td>\n",
              "      <td>0.510961</td>\n",
              "      <td>46.303088</td>\n",
              "      <td>0.180258</td>\n",
              "      <td>53.620830</td>\n",
              "      <td>...</td>\n",
              "      <td>1.490246</td>\n",
              "      <td>2.463688</td>\n",
              "      <td>0.806937</td>\n",
              "      <td>2.074920</td>\n",
              "      <td>1.460417</td>\n",
              "      <td>1.012295</td>\n",
              "      <td>0.188959</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3688.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>150</td>\n",
              "      <td>66688</td>\n",
              "      <td>100</td>\n",
              "      <td>9386.984236</td>\n",
              "      <td>181.483281</td>\n",
              "      <td>0.653732</td>\n",
              "      <td>0.821953</td>\n",
              "      <td>31.050019</td>\n",
              "      <td>0.154981</td>\n",
              "      <td>53.283145</td>\n",
              "      <td>...</td>\n",
              "      <td>1.200478</td>\n",
              "      <td>0.395522</td>\n",
              "      <td>0.757536</td>\n",
              "      <td>1.975055</td>\n",
              "      <td>1.417079</td>\n",
              "      <td>0.996568</td>\n",
              "      <td>0.202963</td>\n",
              "      <td>0.105585</td>\n",
              "      <td>2392.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>155</td>\n",
              "      <td>69248</td>\n",
              "      <td>101</td>\n",
              "      <td>9752.312308</td>\n",
              "      <td>250.796114</td>\n",
              "      <td>0.406314</td>\n",
              "      <td>0.510433</td>\n",
              "      <td>48.938057</td>\n",
              "      <td>0.173097</td>\n",
              "      <td>53.635932</td>\n",
              "      <td>...</td>\n",
              "      <td>1.069966</td>\n",
              "      <td>0.180694</td>\n",
              "      <td>0.765731</td>\n",
              "      <td>2.005818</td>\n",
              "      <td>1.420008</td>\n",
              "      <td>1.005967</td>\n",
              "      <td>0.193391</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4209.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>160</td>\n",
              "      <td>71808</td>\n",
              "      <td>102</td>\n",
              "      <td>10115.577685</td>\n",
              "      <td>218.562839</td>\n",
              "      <td>0.632750</td>\n",
              "      <td>0.810252</td>\n",
              "      <td>29.268378</td>\n",
              "      <td>0.156272</td>\n",
              "      <td>53.117025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.910754</td>\n",
              "      <td>0.616523</td>\n",
              "      <td>0.425653</td>\n",
              "      <td>2.499219</td>\n",
              "      <td>1.458250</td>\n",
              "      <td>0.992416</td>\n",
              "      <td>0.238600</td>\n",
              "      <td>0.075213</td>\n",
              "      <td>2744.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>165</td>\n",
              "      <td>74368</td>\n",
              "      <td>103</td>\n",
              "      <td>10475.935310</td>\n",
              "      <td>83.537822</td>\n",
              "      <td>0.591312</td>\n",
              "      <td>0.703680</td>\n",
              "      <td>32.117387</td>\n",
              "      <td>0.172298</td>\n",
              "      <td>54.012561</td>\n",
              "      <td>...</td>\n",
              "      <td>1.559918</td>\n",
              "      <td>1.165193</td>\n",
              "      <td>0.804836</td>\n",
              "      <td>2.058987</td>\n",
              "      <td>1.434285</td>\n",
              "      <td>0.992292</td>\n",
              "      <td>0.228332</td>\n",
              "      <td>0.145043</td>\n",
              "      <td>1434.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>170</td>\n",
              "      <td>76928</td>\n",
              "      <td>104</td>\n",
              "      <td>10836.039549</td>\n",
              "      <td>104.755663</td>\n",
              "      <td>0.556044</td>\n",
              "      <td>0.671867</td>\n",
              "      <td>30.725870</td>\n",
              "      <td>0.160362</td>\n",
              "      <td>53.351064</td>\n",
              "      <td>...</td>\n",
              "      <td>1.423404</td>\n",
              "      <td>1.273925</td>\n",
              "      <td>0.416683</td>\n",
              "      <td>2.497421</td>\n",
              "      <td>1.463326</td>\n",
              "      <td>0.973909</td>\n",
              "      <td>0.262075</td>\n",
              "      <td>0.109403</td>\n",
              "      <td>1881.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>175</td>\n",
              "      <td>79488</td>\n",
              "      <td>105</td>\n",
              "      <td>11194.857169</td>\n",
              "      <td>105.016914</td>\n",
              "      <td>0.491059</td>\n",
              "      <td>0.597881</td>\n",
              "      <td>32.330679</td>\n",
              "      <td>0.155267</td>\n",
              "      <td>53.689095</td>\n",
              "      <td>...</td>\n",
              "      <td>1.491893</td>\n",
              "      <td>0.752600</td>\n",
              "      <td>0.817146</td>\n",
              "      <td>2.106297</td>\n",
              "      <td>1.437509</td>\n",
              "      <td>1.006668</td>\n",
              "      <td>0.182173</td>\n",
              "      <td>0.151463</td>\n",
              "      <td>2156.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>180</td>\n",
              "      <td>82048</td>\n",
              "      <td>106</td>\n",
              "      <td>11552.932506</td>\n",
              "      <td>249.413672</td>\n",
              "      <td>0.630187</td>\n",
              "      <td>0.797070</td>\n",
              "      <td>31.930394</td>\n",
              "      <td>0.155845</td>\n",
              "      <td>53.407184</td>\n",
              "      <td>...</td>\n",
              "      <td>1.148513</td>\n",
              "      <td>0.978653</td>\n",
              "      <td>0.882712</td>\n",
              "      <td>2.124896</td>\n",
              "      <td>1.424873</td>\n",
              "      <td>0.994304</td>\n",
              "      <td>0.211973</td>\n",
              "      <td>0.129592</td>\n",
              "      <td>2980.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>185</td>\n",
              "      <td>84608</td>\n",
              "      <td>107</td>\n",
              "      <td>11911.645464</td>\n",
              "      <td>219.063097</td>\n",
              "      <td>0.563524</td>\n",
              "      <td>0.708176</td>\n",
              "      <td>33.465283</td>\n",
              "      <td>0.158045</td>\n",
              "      <td>53.509061</td>\n",
              "      <td>...</td>\n",
              "      <td>1.149183</td>\n",
              "      <td>1.959135</td>\n",
              "      <td>0.420150</td>\n",
              "      <td>2.519006</td>\n",
              "      <td>1.459295</td>\n",
              "      <td>1.000557</td>\n",
              "      <td>0.276620</td>\n",
              "      <td>0.177292</td>\n",
              "      <td>3036.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>190</td>\n",
              "      <td>87168</td>\n",
              "      <td>109</td>\n",
              "      <td>12269.117805</td>\n",
              "      <td>116.493965</td>\n",
              "      <td>0.806956</td>\n",
              "      <td>0.979883</td>\n",
              "      <td>28.784972</td>\n",
              "      <td>0.168534</td>\n",
              "      <td>54.036364</td>\n",
              "      <td>...</td>\n",
              "      <td>1.194158</td>\n",
              "      <td>0.582249</td>\n",
              "      <td>0.889294</td>\n",
              "      <td>2.053985</td>\n",
              "      <td>1.418738</td>\n",
              "      <td>0.997440</td>\n",
              "      <td>0.196553</td>\n",
              "      <td>0.064523</td>\n",
              "      <td>1376.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>195</td>\n",
              "      <td>89728</td>\n",
              "      <td>110</td>\n",
              "      <td>12627.286321</td>\n",
              "      <td>118.230939</td>\n",
              "      <td>0.560699</td>\n",
              "      <td>0.687758</td>\n",
              "      <td>31.997129</td>\n",
              "      <td>0.155960</td>\n",
              "      <td>52.875785</td>\n",
              "      <td>...</td>\n",
              "      <td>1.784683</td>\n",
              "      <td>0.890284</td>\n",
              "      <td>0.825440</td>\n",
              "      <td>2.067138</td>\n",
              "      <td>1.428147</td>\n",
              "      <td>0.997956</td>\n",
              "      <td>0.182714</td>\n",
              "      <td>0.129763</td>\n",
              "      <td>2070.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>200</td>\n",
              "      <td>92288</td>\n",
              "      <td>112</td>\n",
              "      <td>12984.339746</td>\n",
              "      <td>160.172362</td>\n",
              "      <td>0.698085</td>\n",
              "      <td>0.866149</td>\n",
              "      <td>30.670430</td>\n",
              "      <td>0.152975</td>\n",
              "      <td>52.907531</td>\n",
              "      <td>...</td>\n",
              "      <td>1.145636</td>\n",
              "      <td>0.870696</td>\n",
              "      <td>0.416976</td>\n",
              "      <td>2.490606</td>\n",
              "      <td>1.454391</td>\n",
              "      <td>1.014433</td>\n",
              "      <td>0.329495</td>\n",
              "      <td>0.104402</td>\n",
              "      <td>2099.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>205</td>\n",
              "      <td>94848</td>\n",
              "      <td>113</td>\n",
              "      <td>13342.201170</td>\n",
              "      <td>144.682331</td>\n",
              "      <td>0.602021</td>\n",
              "      <td>0.745132</td>\n",
              "      <td>31.341508</td>\n",
              "      <td>0.153894</td>\n",
              "      <td>52.854594</td>\n",
              "      <td>...</td>\n",
              "      <td>1.130851</td>\n",
              "      <td>0.504859</td>\n",
              "      <td>0.358140</td>\n",
              "      <td>2.738815</td>\n",
              "      <td>1.541263</td>\n",
              "      <td>1.003132</td>\n",
              "      <td>0.482642</td>\n",
              "      <td>0.108881</td>\n",
              "      <td>2243.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>210</td>\n",
              "      <td>97408</td>\n",
              "      <td>113</td>\n",
              "      <td>13701.259389</td>\n",
              "      <td>93.120311</td>\n",
              "      <td>0.304018</td>\n",
              "      <td>0.392391</td>\n",
              "      <td>39.369065</td>\n",
              "      <td>0.172854</td>\n",
              "      <td>52.252252</td>\n",
              "      <td>...</td>\n",
              "      <td>1.224620</td>\n",
              "      <td>1.182268</td>\n",
              "      <td>0.810124</td>\n",
              "      <td>1.960325</td>\n",
              "      <td>1.430809</td>\n",
              "      <td>1.004731</td>\n",
              "      <td>0.192864</td>\n",
              "      <td>0.108881</td>\n",
              "      <td>2243.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>215</td>\n",
              "      <td>99968</td>\n",
              "      <td>115</td>\n",
              "      <td>14058.239728</td>\n",
              "      <td>68.148983</td>\n",
              "      <td>0.702017</td>\n",
              "      <td>0.835756</td>\n",
              "      <td>30.053439</td>\n",
              "      <td>0.193406</td>\n",
              "      <td>54.963427</td>\n",
              "      <td>...</td>\n",
              "      <td>1.300989</td>\n",
              "      <td>2.885931</td>\n",
              "      <td>0.415817</td>\n",
              "      <td>2.477985</td>\n",
              "      <td>1.466220</td>\n",
              "      <td>1.009898</td>\n",
              "      <td>0.325248</td>\n",
              "      <td>0.089567</td>\n",
              "      <td>958.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>216</td>\n",
              "      <td>100000</td>\n",
              "      <td>115</td>\n",
              "      <td>14066.485792</td>\n",
              "      <td>78.524055</td>\n",
              "      <td>0.649932</td>\n",
              "      <td>0.755351</td>\n",
              "      <td>30.247986</td>\n",
              "      <td>0.173939</td>\n",
              "      <td>55.036261</td>\n",
              "      <td>...</td>\n",
              "      <td>2.661150</td>\n",
              "      <td>2.511589</td>\n",
              "      <td>0.728522</td>\n",
              "      <td>1.970628</td>\n",
              "      <td>1.455702</td>\n",
              "      <td>1.007613</td>\n",
              "      <td>0.257829</td>\n",
              "      <td>0.089567</td>\n",
              "      <td>958.0</td>\n",
              "      <td>data_exhausted</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 78 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98b024fe-bfc0-42c4-9dee-962bb0fc2f7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98b024fe-bfc0-42c4-9dee-962bb0fc2f7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98b024fe-bfc0-42c4-9dee-962bb0fc2f7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    update  timestep  episode  elapsed_time  episode_return_pct  \\\n",
              "24     125     53888       95   7588.848321          147.280347   \n",
              "25     130     56448       96   7945.142123          238.893770   \n",
              "26     135     59008       98   8301.014248           71.540151   \n",
              "27     140     61568       98   8660.969729          108.180734   \n",
              "28     145     64128       99   9024.957481          208.949415   \n",
              "29     150     66688      100   9386.984236          181.483281   \n",
              "30     155     69248      101   9752.312308          250.796114   \n",
              "31     160     71808      102  10115.577685          218.562839   \n",
              "32     165     74368      103  10475.935310           83.537822   \n",
              "33     170     76928      104  10836.039549          104.755663   \n",
              "34     175     79488      105  11194.857169          105.016914   \n",
              "35     180     82048      106  11552.932506          249.413672   \n",
              "36     185     84608      107  11911.645464          219.063097   \n",
              "37     190     87168      109  12269.117805          116.493965   \n",
              "38     195     89728      110  12627.286321          118.230939   \n",
              "39     200     92288      112  12984.339746          160.172362   \n",
              "40     205     94848      113  13342.201170          144.682331   \n",
              "41     210     97408      113  13701.259389           93.120311   \n",
              "42     215     99968      115  14058.239728           68.148983   \n",
              "43     216    100000      115  14066.485792           78.524055   \n",
              "\n",
              "    episode_sharpe  episode_sortino  episode_max_dd  episode_volatility  \\\n",
              "24        0.368493         0.471990       45.234094            0.167654   \n",
              "25        0.422210         0.528641       45.234094            0.178832   \n",
              "26        0.716565         0.834350       31.673584            0.192868   \n",
              "27        0.318511         0.406986       46.303088            0.169908   \n",
              "28        0.407927         0.510961       46.303088            0.180258   \n",
              "29        0.653732         0.821953       31.050019            0.154981   \n",
              "30        0.406314         0.510433       48.938057            0.173097   \n",
              "31        0.632750         0.810252       29.268378            0.156272   \n",
              "32        0.591312         0.703680       32.117387            0.172298   \n",
              "33        0.556044         0.671867       30.725870            0.160362   \n",
              "34        0.491059         0.597881       32.330679            0.155267   \n",
              "35        0.630187         0.797070       31.930394            0.155845   \n",
              "36        0.563524         0.708176       33.465283            0.158045   \n",
              "37        0.806956         0.979883       28.784972            0.168534   \n",
              "38        0.560699         0.687758       31.997129            0.155960   \n",
              "39        0.698085         0.866149       30.670430            0.152975   \n",
              "40        0.602021         0.745132       31.341508            0.153894   \n",
              "41        0.304018         0.392391       39.369065            0.172854   \n",
              "42        0.702017         0.835756       30.053439            0.193406   \n",
              "43        0.649932         0.755351       30.247986            0.173939   \n",
              "\n",
              "    episode_win_rate  ...  actor_grad_norm  critic_grad_norm  alpha_min  \\\n",
              "24         53.197158  ...         0.991537          0.276854   0.917434   \n",
              "25         53.352243  ...         1.336362          1.444798   0.940221   \n",
              "26         55.942623  ...         1.121846          0.524080   0.822288   \n",
              "27         52.979066  ...         1.659853          0.940132   0.901950   \n",
              "28         53.620830  ...         1.490246          2.463688   0.806937   \n",
              "29         53.283145  ...         1.200478          0.395522   0.757536   \n",
              "30         53.635932  ...         1.069966          0.180694   0.765731   \n",
              "31         53.117025  ...         0.910754          0.616523   0.425653   \n",
              "32         54.012561  ...         1.559918          1.165193   0.804836   \n",
              "33         53.351064  ...         1.423404          1.273925   0.416683   \n",
              "34         53.689095  ...         1.491893          0.752600   0.817146   \n",
              "35         53.407184  ...         1.148513          0.978653   0.882712   \n",
              "36         53.509061  ...         1.149183          1.959135   0.420150   \n",
              "37         54.036364  ...         1.194158          0.582249   0.889294   \n",
              "38         52.875785  ...         1.784683          0.890284   0.825440   \n",
              "39         52.907531  ...         1.145636          0.870696   0.416976   \n",
              "40         52.854594  ...         1.130851          0.504859   0.358140   \n",
              "41         52.252252  ...         1.224620          1.182268   0.810124   \n",
              "42         54.963427  ...         1.300989          2.885931   0.415817   \n",
              "43         55.036261  ...         2.661150          2.511589   0.728522   \n",
              "\n",
              "    alpha_max  alpha_mean  ratio_mean  ratio_std drawdown_lambda_peak  \\\n",
              "24   2.327151    1.557742    1.022158   0.193112             5.000000   \n",
              "25   2.157194    1.522272    0.976395   0.183761             3.610326   \n",
              "26   2.389275    1.506629    1.001624   0.238133             0.118620   \n",
              "27   2.202467    1.484410    0.998578   0.192684             0.118620   \n",
              "28   2.074920    1.460417    1.012295   0.188959             5.000000   \n",
              "29   1.975055    1.417079    0.996568   0.202963             0.105585   \n",
              "30   2.005818    1.420008    1.005967   0.193391             5.000000   \n",
              "31   2.499219    1.458250    0.992416   0.238600             0.075213   \n",
              "32   2.058987    1.434285    0.992292   0.228332             0.145043   \n",
              "33   2.497421    1.463326    0.973909   0.262075             0.109403   \n",
              "34   2.106297    1.437509    1.006668   0.182173             0.151463   \n",
              "35   2.124896    1.424873    0.994304   0.211973             0.129592   \n",
              "36   2.519006    1.459295    1.000557   0.276620             0.177292   \n",
              "37   2.053985    1.418738    0.997440   0.196553             0.064523   \n",
              "38   2.067138    1.428147    0.997956   0.182714             0.129763   \n",
              "39   2.490606    1.454391    1.014433   0.329495             0.104402   \n",
              "40   2.738815    1.541263    1.003132   0.482642             0.108881   \n",
              "41   1.960325    1.430809    1.004731   0.192864             0.108881   \n",
              "42   2.477985    1.466220    1.009898   0.325248             0.089567   \n",
              "43   1.970628    1.455702    1.007613   0.257829             0.089567   \n",
              "\n",
              "    episode_length  termination_reason  \n",
              "24          3904.0      data_exhausted  \n",
              "25          3879.0      data_exhausted  \n",
              "26           977.0      data_exhausted  \n",
              "27           977.0      data_exhausted  \n",
              "28          3688.0      data_exhausted  \n",
              "29          2392.0      data_exhausted  \n",
              "30          4209.0      data_exhausted  \n",
              "31          2744.0      data_exhausted  \n",
              "32          1434.0      data_exhausted  \n",
              "33          1881.0      data_exhausted  \n",
              "34          2156.0      data_exhausted  \n",
              "35          2980.0      data_exhausted  \n",
              "36          3036.0      data_exhausted  \n",
              "37          1376.0      data_exhausted  \n",
              "38          2070.0      data_exhausted  \n",
              "39          2099.0      data_exhausted  \n",
              "40          2243.0      data_exhausted  \n",
              "41          2243.0      data_exhausted  \n",
              "42           958.0      data_exhausted  \n",
              "43           958.0      data_exhausted  \n",
              "\n",
              "[20 rows x 78 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "TRAIN_RESULTS_ROOT = Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results\")\n",
        "TRAIN_LOGS_DIR = TRAIN_RESULTS_ROOT / \"logs\"\n",
        "\n",
        "episodes_files = sorted(TRAIN_LOGS_DIR.glob(\"*episodes*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "if not episodes_files:\n",
        "    print(f\"No episodes CSV found in {TRAIN_LOGS_DIR}\")\n",
        "else:\n",
        "    train_episodes_path = episodes_files[0]\n",
        "    train_episodes_df = pd.read_csv(train_episodes_path)\n",
        "    print(\"Episodes file:\", train_episodes_path)\n",
        "    print(\"Rows:\", len(train_episodes_df))\n",
        "    display(train_episodes_df.tail(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0fb04a33",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['update', 'timestep', 'episode', 'elapsed_time', 'episode_return_pct',\n",
              "       'episode_sharpe', 'episode_sortino', 'episode_max_dd',\n",
              "       'episode_volatility', 'episode_win_rate', 'episode_turnover',\n",
              "       'episode_turnover_pct', 'episode_return_skew', 'episode_calmar_ratio',\n",
              "       'episode_omega_ratio', 'episode_ulcer_index', 'episode_cvar_5pct',\n",
              "       'profile_name', 'turnover_scalar', 'terminal_drawdown_lambda',\n",
              "       'terminal_drawdown_lambda_peak', 'terminal_drawdown_avg_excess',\n",
              "       'terminal_drawdown_penalty_sum', 'snapshot_drawdown_lambda',\n",
              "       'snapshot_drawdown_lambda_peak', 'snapshot_drawdown_current',\n",
              "       'snapshot_drawdown_avg_excess', 'snapshot_drawdown_penalty_sum',\n",
              "       'snapshot_drawdown_triggered', 'snapshot_drawdown_trigger_boundary',\n",
              "       'snapshot_drawdown_target', 'snapshot_drawdown_tolerance',\n",
              "       'snapshot_intra_step_tape_potential',\n",
              "       'snapshot_intra_step_tape_delta_reward', 'drawdown_lambda',\n",
              "       'tape_score', 'tape_bonus', 'tape_bonus_raw',\n",
              "       'tape_terminal_bonus_mode', 'tape_terminal_baseline',\n",
              "       'tape_terminal_neutral_band_applied',\n",
              "       'tape_terminal_neutral_band_halfwidth', 'tape_gate_a_triggered',\n",
              "       'tape_gate_a_sharpe', 'tape_gate_a_max_drawdown_abs',\n",
              "       'terminal_intra_step_tape_potential',\n",
              "       'terminal_intra_step_tape_delta_reward', 'drawdown_avg_excess',\n",
              "       'drawdown_penalty_sum', 'initial_balance', 'final_balance',\n",
              "       'next_profile_name', 'next_profile_reason', 'actor_loss', 'critic_loss',\n",
              "       'critic_loss_scaled', 'risk_aux_total', 'risk_aux_sharpe_proxy',\n",
              "       'risk_aux_sharpe_loss', 'risk_aux_mvo_loss', 'mean_advantage',\n",
              "       'policy_entropy', 'policy_loss', 'entropy_loss', 'approx_kl',\n",
              "       'clip_fraction', 'value_clip_fraction', 'explained_variance',\n",
              "       'actor_grad_norm', 'critic_grad_norm', 'alpha_min', 'alpha_max',\n",
              "       'alpha_mean', 'ratio_mean', 'ratio_std', 'drawdown_lambda_peak',\n",
              "       'episode_length', 'termination_reason'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_episodes_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46a0e0e1",
      "metadata": {},
      "source": [
        "## 7) Export Results Folder (Optional)\n",
        "Creates a zip for download from Colab VM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "366d8cc2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created: /content/tcn_fusion_results_export.zip\n",
            "Included:\n",
            " - tcn_fusion_results\n",
            " - data/master_features_NORMALIZED.csv\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "EXPORT_RESULTS_ZIP = True\n",
        "EXPORT_PATH = Path(\"/content/tcn_fusion_results_export.zip\")\n",
        "ROOT = Path(\"/content/adaptive_portfolio_rl\")\n",
        "\n",
        "if EXPORT_RESULTS_ZIP:\n",
        "    include_paths = [\n",
        "        ROOT / \"tcn_fusion_results\",\n",
        "        ROOT / \"data\" / \"phase1_preparation_artifacts\",\n",
        "        ROOT / \"data\" / \"master_features_NORMALIZED.csv\",\n",
        "    ]\n",
        "\n",
        "    existing = [p for p in include_paths if p.exists()]\n",
        "    if not existing:\n",
        "        print(\"âš ï¸ Nothing to export.\")\n",
        "    else:\n",
        "        if EXPORT_PATH.exists():\n",
        "            EXPORT_PATH.unlink()\n",
        "\n",
        "        rel_items = [str(p.relative_to(ROOT)) for p in existing]\n",
        "        cmd = f\"cd {ROOT} && zip -qr {EXPORT_PATH} \" + \" \".join(rel_items)\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "        print(f\"âœ… Created: {EXPORT_PATH}\")\n",
        "        print(\"Included:\")\n",
        "        for p in rel_items:\n",
        "            print(\" -\", p)\n",
        "else:\n",
        "    print(\"â„¹ï¸ EXPORT_RESULTS_ZIP=False\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6d3f4d04",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Copied to Drive: /content/drive/MyDrive/tcn_fusion_results_export.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/tcn_fusion_results_export.zip /content/drive/MyDrive/\n",
        "print(\"âœ… Copied to Drive: /content/drive/MyDrive/tcn_fusion_results_export.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33bf11d2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
