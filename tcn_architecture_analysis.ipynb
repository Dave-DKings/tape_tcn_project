{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Architecture Analysis (Execution-Ready, Updated 2026-02-18)\n",
    "\n",
    "This notebook is aligned with the current TAPE environment updates:\n",
    "- drawdown lambda carry-over + decay\n",
    "- rebalanced penalties with penalty budget cap\n",
    "- intra-step TAPE delta shaping (rolling potential difference)\n",
    "- step-level Sharpe checkpointing\n",
    "- updated episode-length curriculum schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60545e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /content/adaptive_portfolio_rl\n",
    "#!ls -la data\n",
    "#!find . -type d -name \"__pycache__\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /content/adaptive_portfolio_rl\n",
    "#!rm -f data/daily_ohlcv_assets.csv\n",
    "#!rm -f data/master_features_NORMALIZED.csv\n",
    "#!rm -f data/processed_daily_macro_features.csv\n",
    "#!find . -type d -name \"__pycache__\" -prune -exec rm -rf {} +\n",
    "#!ls -la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/adaptive_portfolio_rl\n",
      "HEAD is now at 79203cd Add execution-inertia smoothing and beta curriculum for turnover control\n"
     ]
    }
   ],
   "source": [
    "# Cell A: sync repo\n",
    "import os\n",
    "if not os.path.exists(\"/content/adaptive_portfolio_rl/.git\"):\n",
    "    !git clone https://github.com/Dave-DKings/tape_tcn_project.git /content/adaptive_portfolio_rl\n",
    "%cd /content/adaptive_portfolio_rl\n",
    "!git fetch origin\n",
    "!git reset --hard origin/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3c3e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/adaptive_portfolio_rl\n",
      "HEAD is now at 79203cd Add execution-inertia smoothing and beta curriculum for turnover control\n",
      "79203cd\n"
     ]
    }
   ],
   "source": [
    "%cd /content/adaptive_portfolio_rl\n",
    "!git fetch origin\n",
    "!git reset --hard origin/main\n",
    "!git rev-parse --short HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/adaptive_portfolio_rl\n",
    "!rm -f data/daily_ohlcv_assets.csv\n",
    "!rm -f data/processed_daily_macro_features.csv\n",
    "!rm -f data/master_features_NORMALIZED.csv\n",
    "!rm -rf data/fundamentals\n",
    "!find . -type d -name \"__pycache__\" -prune -exec rm -rf {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407973ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where am I\n",
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ea6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find results folders\n",
    "!find . -maxdepth 3 -type d \\( -name \"tcn_fusion_results\" -o -name \"tcn_results\" -o -name \"output_logs\" \\) -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df99e689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: â€˜./tcn_fusion_resultsâ€™: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# list files inside results\n",
    "!find ./tcn_fusion_results -maxdepth 3 -type f | head -n 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a12a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old training outputs\n",
    "!rm -rf tcn_fusion_results\n",
    "#!rm -rf tcn_results\n",
    "#!rm -rf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell B: install project requirements (Colab-safe pinned stack)\n",
    "%pip install -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f36d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q jedi==0.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d69b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/adaptive_portfolio_rl\n",
    "!zip -r tcn_artifacts.zip tcn_fusion_results tcn_results output_logs data\n",
    "from google.colab import files\n",
    "files.download(\"tcn_artifacts.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe992e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "import pandas_ta_classic as ta_classic\n",
    "print('Versions:', np.__version__, pd.__version__, tf.__version__)\n",
    "print('TF GPUs visible:', tf.config.list_physical_devices('GPU'))\n",
    "!pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df69df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² Setting all random seeds to: 42\n",
      "   âœ… Deterministic mode enabled (slower but reproducible)\n",
      "   âœ… Python random seed set\n",
      "   âœ… NumPy random seed set\n",
      "   âœ… TensorFlow seed set\n",
      "   âœ… Custom PPO agents seeded\n",
      "TF GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "âœ… Setup complete\n",
      "Project root: /content/adaptive_portfolio_rl\n",
      "Config module path: /content/adaptive_portfolio_rl/src/config.py\n",
      "Active fetch range from module: 2003-09-02 -> 2025-09-01\n",
      "Active analysis range from module: 2003-09-02 -> 2025-09-01\n",
      "Train split end from module: 2021-09-01\n",
      "TensorFlow: 2.19.0\n",
      "NumPy: 2.0.2\n",
      "Pandas: 2.2.2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: PROJECT ROOT, IMPORTS, REPRODUCIBILITY\n",
    "# ============================================================================\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import inspect\n",
    "\n",
    "# Resolve project root robustly\n",
    "project_root = Path.cwd()\n",
    "if project_root.name != 'adaptive_portfolio_rl':\n",
    "    if (project_root / 'adaptive_portfolio_rl').exists():\n",
    "        project_root = project_root / 'adaptive_portfolio_rl'\n",
    "    elif (project_root.parent / 'adaptive_portfolio_rl').exists():\n",
    "        project_root = project_root.parent / 'adaptive_portfolio_rl'\n",
    "\n",
    "# Ensure imports resolve to this project only\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Scientific stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "# IMPORTANT: force-reload local modules so config edits take effect without stale state\n",
    "import src.config as config_module\n",
    "import src.data_utils as data_utils_module\n",
    "import src.notebook_helpers.tcn_phase1 as tcn_phase1_module\n",
    "import src.environment_tape_rl as env_mod\n",
    "from src.environment_tape_rl import PortfolioEnvTAPE\n",
    "importlib.reload(config_module)\n",
    "importlib.reload(data_utils_module)\n",
    "importlib.reload(tcn_phase1_module)\n",
    "importlib.reload(env_mod)\n",
    "#importlib.reload(phase_mod)\n",
    "\n",
    "# Project imports (from freshly reloaded modules)\n",
    "from src.data_utils import DataProcessor\n",
    "from src.config import get_active_config, PROFILE_BALANCED_GROWTH, ASSET_TICKERS\n",
    "from src.reproducibility_helper import set_all_seeds\n",
    "from src.csv_logger import CSVLogger\n",
    "from src.notebook_helpers.tcn_phase1 import (\n",
    "    identify_covariance_columns,\n",
    "    Phase1Dataset,\n",
    "    run_experiment6_tape,\n",
    "    evaluate_experiment6_checkpoint,\n",
    "    create_experiment6_result_stub,\n",
    "    load_training_metadata_into_config,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_all_seeds(RANDOM_SEED, deterministic=True)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"src.environment_tape_rl\").setLevel(logging.WARNING)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"TF GPUs:\", gpus)\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print('âœ… Setup complete')\n",
    "print('Project root:', project_root)\n",
    "print('Config module path:', config_module.__file__)\n",
    "print('Active fetch range from module:', config_module.DATA_FETCH_START_DATE, '->', config_module.DATA_FETCH_END_DATE)\n",
    "print('Active analysis range from module:', config_module.ANALYSIS_START_DATE, '->', config_module.ANALYSIS_END_DATE)\n",
    "print('Train split end from module:', config_module.TRAIN_TEST_SPLIT_DATE)\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('NumPy:', np.__version__)\n",
    "print('Pandas:', pd.__version__)\n",
    "print(\"action_execution_beta\" in inspect.signature(PortfolioEnvTAPE.__init__).parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa22329",
   "metadata": {},
   "source": [
    "## 2) Config and Run Controls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b682564e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forced notebook date window: 2003-09-02 -> 2025-09-01\n",
      "Forced analysis window: 2003-09-02 -> 2025-09-01\n",
      "Forced train split end: 2021-09-01\n",
      "CONFIG SNAPSHOT\n",
      "Phase: Phase1_Baseline_PPO\n",
      "Tickers: ['MSFT', 'GOOGL', 'JPM', 'JNJ', 'XOM', 'PG', 'NEE', 'LIN', 'CAT', 'UNH']\n",
      "Date range: 2003-09-02 -> 2025-09-01\n",
      "Architecture: TCN\n",
      "TCN filters: [64, 128, 128]\n",
      "Dirichlet activation: elu\n",
      "PPO: epochs= 4 clip= 0.1 actor_lr= 2e-05 critic_lr= 0.0003 target_kl= 0.015\n",
      "\n",
      "REWARD + RISK CONTROLS\n",
      "target_turnover= 0.6 turnover_penalty_scalar= 2.0\n",
      "concentration_penalty_scalar= 2.0 top_weight_penalty_scalar= 1.5\n",
      "action_realization_penalty_scalar= 0.5\n",
      "penalty_budget_ratio= 1.25\n",
      "drawdown: penalty_coef= 1.5 lambda_floor= 0.0 lambda_carry_decay= 0.7\n",
      "drawdown: target= 0.18 tolerance= -0.015 lambda_max= 5.0\n",
      "\n",
      "INTRA-STEP TAPE DELTA\n",
      "enabled= True window= 60 min_history= 20\n",
      "beta= 0.01 clip= 0.2\n",
      "\n",
      "CHECKPOINT RULES\n",
      "tape_checkpoint_threshold= 4.0\n",
      "periodic_checkpoint_every_steps= 10000\n",
      "high_watermark_checkpoint_enabled= True threshold= 0.5\n",
      "step_sharpe_checkpoint_enabled= False threshold= 0.5\n",
      "\n",
      "CURRICULUM\n",
      "episode_length_curriculum_schedule= [{'threshold': 0, 'limit': 1500}, {'threshold': 30000, 'limit': 2000}, {'threshold': 60000, 'limit': 2500}, {'threshold': 90000, 'limit': None}]\n",
      "turnover_penalty_curriculum= {0: 0.75, 30000: 1.25, 60000: 1.5, 90000: 1.75, 120000: 2.0}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD ACTIVE CONFIG + CURRENT CONTROL SNAPSHOT\n",
    "# ============================================================================\n",
    "config = get_active_config('phase1')\n",
    "\n",
    "# Force a single source-of-truth date window for this notebook run\n",
    "# (keeps paper training split, extends test window to ~3 years)\n",
    "config['DATA_FETCH_START_DATE'] = '2003-09-02'\n",
    "config['DATA_FETCH_END_DATE'] = '2025-09-01'\n",
    "config['ANALYSIS_START_DATE'] = '2003-09-02'\n",
    "config['ANALYSIS_END_DATE'] = '2025-09-01'\n",
    "config['TRAIN_TEST_SPLIT_DATE'] = '2021-09-01'\n",
    "\n",
    "print('Forced notebook date window:', config['DATA_FETCH_START_DATE'], '->', config['DATA_FETCH_END_DATE'])\n",
    "print('Forced analysis window:', config['ANALYSIS_START_DATE'], '->', config['ANALYSIS_END_DATE'])\n",
    "print('Forced train split end:', config['TRAIN_TEST_SPLIT_DATE'])\n",
    "\n",
    "# Keep defaults from config unless explicitly changed below\n",
    "config['agent_params']['actor_critic_type'] = 'TCN'\n",
    "config['agent_params']['evaluation_mode'] = config['agent_params'].get('evaluation_mode', 'mode')\n",
    "config['training_params']['update_log_interval'] = 1\n",
    "\n",
    "ppo = config['agent_params'].get('ppo_params', {})\n",
    "env = config.get('environment_params', {})\n",
    "dd = env.get('drawdown_constraint', {})\n",
    "tp = config.get('training_params', {})\n",
    "\n",
    "print('CONFIG SNAPSHOT')\n",
    "print('Phase:', config['phase_name'])\n",
    "print('Tickers:', config['ASSET_TICKERS'])\n",
    "print('Date range:', config['ANALYSIS_START_DATE'], '->', config['ANALYSIS_END_DATE'])\n",
    "print('Architecture:', config['agent_params']['actor_critic_type'])\n",
    "print('TCN filters:', config['agent_params'].get('tcn_filters'))\n",
    "print('Dirichlet activation:', config['agent_params'].get('dirichlet_alpha_activation'))\n",
    "print('PPO: epochs=', ppo.get('num_ppo_epochs'), 'clip=', ppo.get('policy_clip'), 'actor_lr=', ppo.get('actor_lr'), 'critic_lr=', ppo.get('critic_lr'), 'target_kl=', ppo.get('target_kl'))\n",
    "\n",
    "print()\n",
    "print('REWARD + RISK CONTROLS')\n",
    "print('target_turnover=', env.get('target_turnover'), 'turnover_penalty_scalar=', env.get('turnover_penalty_scalar'))\n",
    "print('concentration_penalty_scalar=', env.get('concentration_penalty_scalar'), 'top_weight_penalty_scalar=', env.get('top_weight_penalty_scalar'))\n",
    "print('action_realization_penalty_scalar=', env.get('action_realization_penalty_scalar'))\n",
    "print('penalty_budget_ratio=', env.get('penalty_budget_ratio'))\n",
    "print('drawdown: penalty_coef=', dd.get('penalty_coef'), 'lambda_floor=', dd.get('lambda_floor'), 'lambda_carry_decay=', dd.get('lambda_carry_decay'))\n",
    "print('drawdown: target=', dd.get('target'), 'tolerance=', dd.get('tolerance'), 'lambda_max=', dd.get('lambda_max'))\n",
    "\n",
    "print()\n",
    "print('INTRA-STEP TAPE DELTA')\n",
    "print('enabled=', env.get('intra_step_tape_delta_enabled'), 'window=', env.get('intra_step_tape_delta_window'), 'min_history=', env.get('intra_step_tape_delta_min_history'))\n",
    "print('beta=', env.get('intra_step_tape_delta_beta'), 'clip=', env.get('intra_step_tape_delta_clip'))\n",
    "\n",
    "print()\n",
    "print('CHECKPOINT RULES')\n",
    "print('tape_checkpoint_threshold=', tp.get('tape_checkpoint_threshold'))\n",
    "print('periodic_checkpoint_every_steps=', tp.get('periodic_checkpoint_every_steps'))\n",
    "print('high_watermark_checkpoint_enabled=', tp.get('high_watermark_checkpoint_enabled'), 'threshold=', tp.get('high_watermark_sharpe_threshold'))\n",
    "print('step_sharpe_checkpoint_enabled=', tp.get('step_sharpe_checkpoint_enabled'), 'threshold=', tp.get('step_sharpe_checkpoint_threshold'))\n",
    "\n",
    "print()\n",
    "print('CURRICULUM')\n",
    "print('episode_length_curriculum_schedule=', tp.get('episode_length_curriculum_schedule'))\n",
    "print('turnover_penalty_curriculum=', tp.get('turnover_penalty_curriculum'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL OVERRIDES (SAFE, CURRENT-ALIGNED)\n",
    "# ============================================================================\n",
    "APPLY_OVERRIDES = False\n",
    "\n",
    "if APPLY_OVERRIDES:\n",
    "    # Compact run controls\n",
    "    config['training_params']['max_total_timesteps'] = 30_000\n",
    "    config['training_params']['timesteps_per_ppo_update'] = 504\n",
    "\n",
    "    # PPO stability controls\n",
    "    ppo = config['agent_params']['ppo_params']\n",
    "    ppo.update({\n",
    "        'policy_clip': 0.10,\n",
    "        'num_ppo_epochs': 4,\n",
    "        'actor_lr': 2e-5,\n",
    "        'critic_lr': 3e-4,\n",
    "        'target_kl': 0.015,\n",
    "        'kl_stop_multiplier': 1.2,\n",
    "        'minibatches_before_kl_stop': 1,\n",
    "    })\n",
    "\n",
    "    # Full-horizon episodes (disable episode-length curriculum)\n",
    "    config['training_params']['use_episode_length_curriculum'] = False\n",
    "    config['training_params']['episode_length_curriculum_schedule'] = [\n",
    "        {'threshold': 0, 'limit': None},\n",
    "    ]\n",
    "\n",
    "    # Turnover / reward controls\n",
    "    env = config['environment_params']\n",
    "    env['target_turnover'] = 0.60\n",
    "    env['turnover_target_band'] = 0.20\n",
    "    env['turnover_penalty_scalar'] = 1.5\n",
    "    env['dsr_scalar'] = 2.0\n",
    "    config['training_params']['evaluation_turnover_penalty_scalar'] = 1.5\n",
    "\n",
    "    # Penalty rebalancing\n",
    "    env['concentration_penalty_scalar'] = 2.0\n",
    "    env['concentration_target_hhi'] = 0.14\n",
    "    env['top_weight_penalty_scalar'] = 1.5\n",
    "    env['target_top_weight'] = 0.22\n",
    "    env['action_realization_penalty_scalar'] = 0.5\n",
    "    env['penalty_budget_ratio'] = 1.25\n",
    "\n",
    "    # Drawdown controller (gentler early adaptation)\n",
    "    dd = env['drawdown_constraint']\n",
    "    dd.update({\n",
    "        'enabled': True,\n",
    "        'target': 0.18,\n",
    "        'penalty_coef': 1.5,\n",
    "        'dual_learning_rate': 0.10,\n",
    "        'lambda_init': 0.50,\n",
    "        'lambda_floor': 0.00,\n",
    "        'lambda_max': 5.0,\n",
    "        'lambda_carry_decay': 0.7,\n",
    "        'tolerance': -0.015,\n",
    "        'penalty_reference': 'trigger_boundary',\n",
    "        'cooling_rate': 0.35,\n",
    "    })\n",
    "\n",
    "    # Intra-step TAPE delta shaping (reduced)\n",
    "    env['intra_step_tape_delta_enabled'] = True\n",
    "    env['intra_step_tape_delta_window'] = 60\n",
    "    env['intra_step_tape_delta_min_history'] = 20\n",
    "    env['intra_step_tape_delta_beta'] = 0.01\n",
    "    env['intra_step_tape_delta_clip'] = 0.20\n",
    "\n",
    "    # Step-level Sharpe checkpointing (save any step where Sharpe >= 0.5)\n",
    "    config['training_params']['step_sharpe_checkpoint_enabled'] = True\n",
    "    config['training_params']['step_sharpe_checkpoint_threshold'] = 0.5\n",
    "\n",
    "    print('Overrides applied')\n",
    "else:\n",
    "    print('APPLY_OVERRIDES=False (using config defaults)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0319556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Variant applied: TCN_FUSION\n",
      "results_root: tcn_fusion_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VARIANT SETTINGS (TCN FAMILY)\n",
    "# ============================================================================\n",
    "VARIANT_SETTINGS = {\n",
    "    'TCN': {\n",
    "        'actor_critic_type': 'TCN',\n",
    "        'use_attention': False,\n",
    "        'use_fusion': False,\n",
    "        'results_root': Path('tcn_results'),\n",
    "    },\n",
    "    'TCN_ATTENTION': {\n",
    "        'actor_critic_type': 'TCN_ATTENTION',\n",
    "        'use_attention': True,\n",
    "        'use_fusion': False,\n",
    "        'results_root': Path('tcn_att_results'),\n",
    "    },\n",
    "    'TCN_FUSION': {\n",
    "        'actor_critic_type': 'TCN_FUSION',\n",
    "        'use_attention': False,\n",
    "        'use_fusion': True,\n",
    "        'results_root': Path('tcn_fusion_results'),\n",
    "    },\n",
    "}\n",
    "\n",
    "ACTIVE_VARIANT = 'TCN_FUSION'  # change to: TCN, TCN_ATTENTION, TCN_FUSION\n",
    "\n",
    "if ACTIVE_VARIANT not in VARIANT_SETTINGS:\n",
    "    raise ValueError(f'Unsupported ACTIVE_VARIANT: {ACTIVE_VARIANT}')\n",
    "\n",
    "v = VARIANT_SETTINGS[ACTIVE_VARIANT]\n",
    "config['agent_params']['actor_critic_type'] = v['actor_critic_type']\n",
    "config['agent_params']['use_attention'] = v['use_attention']\n",
    "config['agent_params']['use_fusion'] = v['use_fusion']\n",
    "\n",
    "config['training_params']['use_episode_length_curriculum'] = False\n",
    "config['training_params']['episode_length_curriculum_schedule'] = [\n",
    "    {'threshold': 0, 'limit': None},\n",
    "]\n",
    "\n",
    "\n",
    "LATEST_VARIANT = ACTIVE_VARIANT\n",
    "LATEST_RESULTS_ROOT = str(v['results_root'])\n",
    "\n",
    "print('âœ… Variant applied:', ACTIVE_VARIANT)\n",
    "print('results_root:', LATEST_RESULTS_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a236e",
   "metadata": {},
   "source": [
    "## 3) Data Pipeline (Features + Actuarial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be89b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRED series config: 19 -> 19 (removed legacy invalid codes: 0)\n",
      "Legacy macro disable set already present\n"
     ]
    }
   ],
   "source": [
    "config = get_active_config(\"phase1\")\n",
    "\n",
    "# Optional guard for legacy/invalid macro codes in old configs.\n",
    "# Current config is already updated, so this is usually a no-op.\n",
    "macro_cfg = config[\"feature_params\"][\"macro_data\"]\n",
    "invalid_legacy_codes = {\"NAPM\", \"MOVEINDEX\", \"ISM/MAN_PMI\", \"MOVE\"}\n",
    "before = len(macro_cfg.get(\"fred_series_config\", []))\n",
    "macro_cfg[\"fred_series_config\"] = [\n",
    "    s for s in macro_cfg.get(\"fred_series_config\", [])\n",
    "    if s.get(\"code\") not in invalid_legacy_codes\n",
    "]\n",
    "after = len(macro_cfg.get(\"fred_series_config\", []))\n",
    "print(f\"FRED series config: {before} -> {after} (removed legacy invalid codes: {before - after})\")\n",
    "\n",
    "# Keep legacy engineered-column disables for backward-compatible runs.\n",
    "legacy_macro_columns = {\"ISM_MAN_PMI_level\", \"ISM_MAN_PMI_diff\", \"MOVE_level\", \"MOVE_zscore\"}\n",
    "disabled = set(config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "newly_added = sorted(list(legacy_macro_columns - disabled))\n",
    "disabled.update(legacy_macro_columns)\n",
    "config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"] = sorted(disabled)\n",
    "if newly_added:\n",
    "    print(\"Added legacy macro disables:\", newly_added)\n",
    "else:\n",
    "    print(\"Legacy macro disable set already present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ef0430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature pruning enabled: True\n",
      "Disabled feature count: 65\n",
      "Sample disabled features: ['ATRr_14', 'BAMLC0A0CMEY_diff', 'BAMLC0A0CMEY_level', 'BAMLC0A0CMEY_zscore', 'BAMLH0A0HYM2_diff', 'BAMLH0A0HYM2_level', 'BAMLH0A0HYM2_zscore', 'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BetaRank', 'BreakevenInf10Y_level', 'BreakevenInf5Y_level', 'CPI_level', 'CPI_mom', 'CPI_yoy', 'CrossSectional_ZScore_LogReturn_1d', 'DAAA_level', 'DAAA_zscore', 'DGS10_level', 'DGS2_level', 'DMN_14', 'DMP_14', 'EFFR_level', 'EMA_12']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FEATURE PRUNING (APPLIED BEFORE NORMALIZATION)\n",
    "# ============================================================================\n",
    "fs = config.setdefault('feature_params', {}).setdefault('feature_selection', {})\n",
    "fs['disable_features'] = True\n",
    "\n",
    "redundant_features = [\n",
    "    # Price-level / highly collinear technicals\n",
    "    'EMA_12', 'EMA_26', 'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'SMA_50',\n",
    "    'DMP_14', 'DMN_14', 'ATRr_14', 'NATR_14', 'VOL_SMA_20',\n",
    "\n",
    "    # Cross-sectional overlaps\n",
    "    'BetaRank', 'VolatilityRank', 'InverseVolRank',\n",
    "    'CrossSectional_ZScore_LogReturn_1d',\n",
    "\n",
    "    # Macro level duplicates (prefer diff/zscore)\n",
    "    'EFFR_level', 'SOFR_level', 'FEDFUNDS_level',\n",
    "    'DGS10_level', 'DGS2_level', 'T10Y2Y_level',\n",
    "    'TIPS10Y_level', 'BreakevenInf10Y_level', 'BreakevenInf5Y_level',\n",
    "    'IG_Credit_level', 'HY_Credit_level',\n",
    "]\n",
    "\n",
    "existing_disabled = set(fs.get('disabled_features', []))\n",
    "fs['disabled_features'] = sorted(existing_disabled.union(redundant_features))\n",
    "\n",
    "print('Feature pruning enabled:', fs.get('disable_features', False))\n",
    "print('Disabled feature count:', len(fs['disabled_features']))\n",
    "print('Sample disabled features:', fs['disabled_features'][:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9283aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING AND PROCESSING DATA\n",
      "================================================================================\n",
      "Raw shape: (55107, 7)\n",
      "Raw dates: 2003-09-02 00:00:00 â†’ 2025-08-29 00:00:00\n",
      "Macro features added: 43\n",
      "Final master_df shape: (54897, 118)\n",
      "Expected feature cols: 66\n",
      "Present feature cols : 66\n",
      "Feature columns with NaN: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADX_14</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealizedSkew_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RollingVolatility_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DownsideSemiVar_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealizedKurtosis_21d</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSI_14</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFI_14</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "MACDs_12_26_9            330\n",
       "MACDh_12_26_9            330\n",
       "ADX_14                   270\n",
       "MACD_12_26_9             250\n",
       "RealizedSkew_21d         200\n",
       "RollingVolatility_21d    200\n",
       "DownsideSemiVar_21d      200\n",
       "RealizedKurtosis_21d     200\n",
       "STOCHd_14_3_3            170\n",
       "RSI_14                   140\n",
       "MFI_14                   130\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING + FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "processor = DataProcessor(config)\n",
    "\n",
    "print('=' * 80)\n",
    "print('LOADING AND PROCESSING DATA')\n",
    "print('=' * 80)\n",
    "\n",
    "FORCE_DATA_REFRESH = True  # Set True once when you want to rebuild cache for new date bounds\n",
    "raw_df = processor.load_ohlcv_data(\n",
    "    start_date=config['DATA_FETCH_START_DATE'],\n",
    "    end_date=config['DATA_FETCH_END_DATE'],\n",
    "    force_download=FORCE_DATA_REFRESH,\n",
    ")\n",
    "print('Raw shape:', raw_df.shape)\n",
    "print('Raw dates:', raw_df['Date'].min(), 'â†’', raw_df['Date'].max())\n",
    "\n",
    "# Core feature pipeline\n",
    "df = processor.calculate_log_returns(raw_df, periods=[1, 5, 10, 21])\n",
    "df = processor.calculate_return_statistics(df, window=21)\n",
    "df = processor.calculate_technical_indicators(df)\n",
    "df = processor.calculate_dynamic_covariance_features(df)\n",
    "df = processor.add_regime_features(df)\n",
    "df = processor.add_fundamental_features(df)\n",
    "\n",
    "macro_cfg = config.get('feature_params', {}).get('macro_data')\n",
    "if macro_cfg is not None:\n",
    "    macro_df, macro_cols = processor._build_macro_feature_frame(macro_cfg, df['Date'].min(), df['Date'].max())\n",
    "    if macro_df is not None and macro_cols:\n",
    "        df = df.merge(macro_df, on='Date', how='left')\n",
    "        print(f'Macro features added: {len(macro_cols)}')\n",
    "\n",
    "df = processor.add_quant_alpha_features(df)\n",
    "df = processor.add_cross_sectional_features(df)\n",
    "df = processor.add_actuarial_features(df)\n",
    "\n",
    "master_df = df.copy()\n",
    "feature_cols = processor.get_feature_columns('phase1')\n",
    "present_feature_cols = [c for c in feature_cols if c in master_df.columns]\n",
    "\n",
    "print('Final master_df shape:', master_df.shape)\n",
    "print('Expected feature cols:', len(feature_cols))\n",
    "print('Present feature cols :', len(present_feature_cols))\n",
    "\n",
    "nan_counts = master_df[present_feature_cols].isna().sum()\n",
    "nan_cols = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "print('Feature columns with NaN:', len(nan_cols))\n",
    "if len(nan_cols) > 0:\n",
    "    display(nan_cols.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274159b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d',\n",
       "       ...\n",
       "       'LogReturn_1d_ZScore', 'RollingVolatility_21d_ZScore', 'RSI_14_ZScore',\n",
       "       'BetaRank', 'VolatilityRank', 'InverseVolRank',\n",
       "       'Actuarial_Expected_Recovery', 'Actuarial_Prob_30d',\n",
       "       'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f2cdab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuarial columns present: 4\n",
      "['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "                                  mean        std  min    max\n",
      "Actuarial_Expected_Recovery  42.012050  76.714815  0.0  554.5\n",
      "Actuarial_Prob_30d            0.606652   0.369684  0.0    1.0\n",
      "Actuarial_Prob_60d            0.670421   0.338598  0.0    1.0\n",
      "Actuarial_Reserve_Severity    0.718121   0.334307  0.0    1.0\n"
     ]
    }
   ],
   "source": [
    "act_cols = [c for c in master_df.columns if c.startswith(\"Actuarial_\")]\n",
    "print(\"Actuarial columns present:\", len(act_cols))\n",
    "print(act_cols[:10])\n",
    "\n",
    "if act_cols:\n",
    "    print(master_df[act_cols].describe().T[[\"mean\",\"std\",\"min\",\"max\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db599ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis range: 2003-09-02 â†’ 2025-09-01\n",
      "Train split end: 2021-09-01 | Test start: 2021-09-02\n",
      "Train: 2003-10-01 00:00:00 â†’ 2021-09-01 00:00:00 (44,877 rows)\n",
      "Test : 2021-09-02 00:00:00 â†’ 2025-08-29 00:00:00 (10,020 rows)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIXED DATE SPLIT (TRAIN/TEST)\n",
    "# ============================================================================\n",
    "analysis_start = pd.Timestamp(config.get('ANALYSIS_START_DATE', '2003-09-02'))\n",
    "analysis_end = pd.Timestamp(config.get('ANALYSIS_END_DATE', '2025-09-01'))\n",
    "\n",
    "train_end_date = pd.Timestamp(config.get('TRAIN_TEST_SPLIT_DATE', '2021-09-01'))\n",
    "test_start_date = train_end_date + pd.Timedelta(days=1)\n",
    "test_end_date = analysis_end\n",
    "\n",
    "all_dates = pd.to_datetime(master_df['Date'])\n",
    "master_df = master_df[(all_dates >= analysis_start) & (all_dates <= analysis_end)].copy()\n",
    "all_dates = pd.to_datetime(master_df['Date'])\n",
    "\n",
    "train_mask = all_dates <= train_end_date\n",
    "test_mask = (all_dates >= test_start_date) & (all_dates <= test_end_date)\n",
    "\n",
    "train_df = master_df[train_mask].copy()\n",
    "test_df = master_df[test_mask].copy()\n",
    "\n",
    "print('Analysis range:', analysis_start.date(), 'â†’', analysis_end.date())\n",
    "print('Train split end:', train_end_date.date(), '| Test start:', test_start_date.date())\n",
    "print('Train:', train_df['Date'].min(), 'â†’', train_df['Date'].max(), f'({len(train_df):,} rows)')\n",
    "print('Test :', test_df['Date'].min(), 'â†’', test_df['Date'].max(), f'({len(test_df):,} rows)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e66fd48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d',\n",
       "       ...\n",
       "       'LogReturn_1d_ZScore', 'RollingVolatility_21d_ZScore', 'RSI_14_ZScore',\n",
       "       'BetaRank', 'VolatilityRank', 'InverseVolRank',\n",
       "       'Actuarial_Expected_Recovery', 'Actuarial_Prob_30d',\n",
       "       'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7e8a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.data_utils:Found 1980 NaN values after normalization, applying forward-fill only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Normalization complete\n",
      "Normalized shape: (54897, 118)\n",
      "Actuarial columns: ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "Normalization strategy counts: {'robust_winsor': 34, 'bounded': 8, 'standard': 24}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NORMALIZATION (TRAIN-FIT, TEST-TRANSFORM)\n",
    "# ============================================================================\n",
    "from collections import Counter\n",
    "\n",
    "feature_cols = processor.get_feature_columns('phase1')\n",
    "\n",
    "master_df_normalized, scalers = processor.normalize_features(\n",
    "    master_df,\n",
    "    feature_cols=feature_cols,\n",
    "    train_end_date=train_end_date,\n",
    "    test_start_date=test_start_date,\n",
    "    existing_scalers=None,\n",
    "    scaler_type='standard',\n",
    ")\n",
    "\n",
    "actuarial_cols = [c for c in master_df_normalized.columns if c.startswith('Actuarial_')]\n",
    "\n",
    "method_counter = Counter()\n",
    "for c in feature_cols:\n",
    "    spec = scalers.get(c)\n",
    "    if isinstance(spec, dict):\n",
    "        method_counter[str(spec.get('method', 'standard'))] += 1\n",
    "    elif spec is None:\n",
    "        method_counter['missing'] += 1\n",
    "    else:\n",
    "        method_counter['legacy_scaler'] += 1\n",
    "\n",
    "print('âœ… Normalization complete')\n",
    "print('Normalized shape:', master_df_normalized.shape)\n",
    "print('Actuarial columns:', actuarial_cols)\n",
    "print('Normalization strategy counts:', dict(method_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a950c63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase1Dataset ready\n",
      "Train shape: (44877, 118)\n",
      "Test shape : (10020, 118)\n",
      "Covariance features: 3\n",
      "Assets: ['CAT', 'GOOGL', 'JNJ', 'JPM', 'LIN', 'MSFT', 'NEE', 'PG', 'UNH', 'XOM']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BUILD PHASE1 DATASET CONTAINER\n",
    "# ============================================================================\n",
    "all_dates_norm = pd.to_datetime(master_df_normalized['Date'])\n",
    "train_df_norm = master_df_normalized[all_dates_norm <= train_end_date].copy()\n",
    "test_df_norm = master_df_normalized[(all_dates_norm >= test_start_date) & (all_dates_norm <= test_end_date)].copy()\n",
    "\n",
    "covariance_columns = identify_covariance_columns(master_df_normalized.columns)\n",
    "\n",
    "phase1_data = Phase1Dataset(\n",
    "    master_df=master_df_normalized,\n",
    "    train_df=train_df_norm,\n",
    "    test_df=test_df_norm,\n",
    "    scalers=scalers,\n",
    "    train_end_date=train_end_date,\n",
    "    test_start_date=test_start_date,\n",
    "    covariance_columns=covariance_columns,\n",
    "    data_processor=processor,\n",
    ")\n",
    "\n",
    "print('âœ… Phase1Dataset ready')\n",
    "print('Train shape:', phase1_data.train_df.shape)\n",
    "print('Test shape :', phase1_data.test_df.shape)\n",
    "print('Covariance features:', len(covariance_columns))\n",
    "print('Assets:', sorted(phase1_data.master_df['Ticker'].dropna().unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6c752a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44877, 73) (10020, 73)\n"
     ]
    }
   ],
   "source": [
    "active_cols = [c for c in phase1_data.data_processor.get_feature_columns(\"phase1\") if c in phase1_data.master_df.columns]\n",
    "core_cols = [c for c in [\"Date\",\"Ticker\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"] if c in phase1_data.master_df.columns]\n",
    "keep = core_cols + active_cols\n",
    "\n",
    "phase1_data.master_df = phase1_data.master_df[keep].copy()\n",
    "phase1_data.train_df = phase1_data.train_df[keep].copy()\n",
    "phase1_data.test_df  = phase1_data.test_df[keep].copy()\n",
    "print(phase1_data.train_df.shape, phase1_data.test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "939dc509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
       "       'LogReturn_1d', 'LogReturn_5d', 'LogReturn_10d', 'LogReturn_21d',\n",
       "       'RollingVolatility_21d', 'DownsideSemiVar_21d', 'RealizedSkew_21d',\n",
       "       'RealizedKurtosis_21d', 'MACD_12_26_9', 'MACDh_12_26_9',\n",
       "       'MACDs_12_26_9', 'RSI_14', 'STOCHd_14_3_3', 'ADX_14', 'OBV', 'MFI_14',\n",
       "       'Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1',\n",
       "       'Covariance_Eigenvalue_2', 'Fundamental_FCFE_Delta',\n",
       "       'Fundamental_Revenue_Delta', 'Fundamental_NCFO_Delta',\n",
       "       'Fundamental_FCFE_Sign', 'Fundamental_Staleness_Days',\n",
       "       'Fundamental_Staleness_Quarters', 'Regime_Volatility_Ratio',\n",
       "       'Regime_Price_vs_SMA_Short', 'Regime_SMA_Short_Slope',\n",
       "       'Regime_SMA_Long_Slope', 'Regime_Momentum_Short',\n",
       "       'Regime_Momentum_Long', 'Regime_Breadth_Positive',\n",
       "       'Regime_Corr_to_Market', 'Residual_Momentum_21', 'Volume_Percentile_63',\n",
       "       'YieldCurve_Spread', 'YieldCurve_Inverted_Flag', 'ShortTerm_Reversal_5',\n",
       "       'VolOfVol_63', 'Beta_to_Market', 'OBV_Delta_Norm_21',\n",
       "       'Actuarial_Expected_Recovery', 'Actuarial_Prob_30d',\n",
       "       'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity', 'EFFR_diff',\n",
       "       'EFFR_zscore', 'SOFR_diff', 'FEDFUNDS_diff', 'FEDFUNDS_zscore',\n",
       "       'DGS10_diff', 'DGS10_slope', 'DGS2_diff', 'TIPS10Y_diff',\n",
       "       'BreakevenInf10Y_diff', 'BreakevenInf5Y_diff', 'IG_Credit_diff',\n",
       "       'IG_Credit_zscore', 'HY_Credit_diff', 'HY_Credit_zscore',\n",
       "       'MomentumRank_21d', 'MomentumRank_63d', 'MomentumRank_252d',\n",
       "       'LogReturn_1d_ZScore', 'RollingVolatility_21d_ZScore', 'RSI_14_ZScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase1_data.train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "507c1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "feature_cols = set(phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "print({\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"} & feature_cols)  # should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70adf57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro feature count: 17\n",
      "['YieldCurve_Spread', 'YieldCurve_Inverted_Flag', 'EFFR_diff', 'EFFR_zscore', 'SOFR_diff', 'FEDFUNDS_diff', 'FEDFUNDS_zscore', 'DGS10_diff', 'DGS10_slope', 'DGS2_diff', 'TIPS10Y_diff', 'BreakevenInf10Y_diff', 'BreakevenInf5Y_diff', 'IG_Credit_diff', 'IG_Credit_zscore', 'HY_Credit_diff', 'HY_Credit_zscore']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = phase1_data.data_processor.get_feature_columns(\"phase1\")\n",
    "macro_cols = [c for c in feature_cols if c.startswith((\n",
    "    \"EFFR_\", \"SOFR_\", \"FEDFUNDS_\", \"DGS\", \"T10Y2Y_\", \"TIPS\", \"Breakeven\", \"IG_Credit_\", \"HY_Credit_\", \"YieldCurve_\"\n",
    "))]\n",
    "print(\"macro feature count:\", len(macro_cols))\n",
    "print(macro_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b016baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled âˆ© Active: []\n",
      "Count: 0\n"
     ]
    }
   ],
   "source": [
    "disabled = set(config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "active = set(phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "\n",
    "print(\"Disabled âˆ© Active:\", sorted(disabled & active))\n",
    "print(\"Count:\", len(disabled & active))  # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2d55fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disable_features: True\n",
      "disabled count: 65\n",
      "active count: 66\n",
      "disabled âˆ© active: 0\n",
      "overlap sample: []\n",
      "âœ… Pre-train check passed: pruned features are not in active feature list.\n"
     ]
    }
   ],
   "source": [
    "# PRE-TRAIN ACTIVE FEATURE CHECK\n",
    "disabled = set(config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "active = set(phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "\n",
    "overlap = sorted(disabled & active)\n",
    "print(\"disable_features:\", config[\"feature_params\"][\"feature_selection\"][\"disable_features\"])\n",
    "print(\"disabled count:\", len(disabled))\n",
    "print(\"active count:\", len(active))\n",
    "print(\"disabled âˆ© active:\", len(overlap))\n",
    "print(\"overlap sample:\", overlap[:20])\n",
    "\n",
    "assert config[\"feature_params\"][\"feature_selection\"][\"disable_features\"] is True, \"disable_features is not enabled\"\n",
    "assert len(overlap) == 0, f\"Some disabled features are still active: {overlap[:10]}\"\n",
    "print(\"âœ… Pre-train check passed: pruned features are not in active feature list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01baf8e",
   "metadata": {},
   "source": [
    "## 4) Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional stability tweaks (keep commented unless needed)\n",
    "# config['training_params']['timesteps_per_ppo_update'] = 504\n",
    "# ppo = config['agent_params']['ppo_params']\n",
    "# ppo['batch_size_ppo'] = 512\n",
    "# ppo['num_ppo_epochs'] = 5\n",
    "# ppo['actor_lr'] = 5e-5\n",
    "# ppo['critic_lr'] = 1e-4\n",
    "# ppo['policy_clip'] = 0.15\n",
    "# ppo['target_kl'] = 0.02\n",
    "# ppo['entropy_coef'] = 0.01\n",
    "# config['environment_params']['penalty_budget_ratio'] = 1.25\n",
    "# config['environment_params']['intra_step_tape_delta_beta'] = 0.10\n",
    "# config['environment_params']['intra_step_tape_delta_clip'] = 0.20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248613b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = config[\"agent_params\"]\n",
    "ppo = ap[\"ppo_params\"]\n",
    "tp = config[\"training_params\"]\n",
    "ep = config[\"environment_params\"]\n",
    "\n",
    "# PPO stability\n",
    "ppo[\"actor_lr\"] = 1e-5\n",
    "ppo[\"critic_lr\"] = 2e-4\n",
    "ppo[\"num_ppo_epochs\"] = 2\n",
    "ppo[\"batch_size_ppo\"] = 128\n",
    "ppo[\"target_kl\"] = 0.02\n",
    "ppo[\"entropy_coef\"] = 0.003\n",
    "ppo[\"policy_clip\"] = 0.08\n",
    "\n",
    "# rollout/update cadence\n",
    "tp[\"timesteps_per_ppo_update\"] = 256\n",
    "\n",
    "# model size (reduce volatility + OOM risk)\n",
    "ap[\"sequence_length\"] = 40\n",
    "ap[\"tcn_filters\"] = [32, 64, 64]\n",
    "\n",
    "# reward noise reduction + turnover discipline\n",
    "ep[\"intra_step_tape_delta_enabled\"] = False\n",
    "ep[\"dsr_scalar\"] = 1.0\n",
    "ep[\"target_turnover\"] = 0.50\n",
    "ep[\"turnover_penalty_scalar\"] = 1.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1fd8ae",
   "metadata": {},
   "source": [
    "### Optuna Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c30847",
   "metadata": {},
   "source": [
    "##### Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f701af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = config[\"agent_params\"]\n",
    "ppo = ap[\"ppo_params\"]\n",
    "tp = config[\"training_params\"]\n",
    "ep = config[\"environment_params\"]\n",
    "\n",
    "# PPO stability\n",
    "ppo[\"actor_lr\"] = 1e-5\n",
    "ppo[\"critic_lr\"] = 2e-4\n",
    "ppo[\"num_ppo_epochs\"] = 1\n",
    "ppo[\"policy_clip\"] = 0.06\n",
    "ppo[\"target_kl\"] = 0.02\n",
    "ppo[\"entropy_coef\"] = 0.002\n",
    "ppo[\"max_grad_norm\"] = 0.3\n",
    "\n",
    "# short tuning budget\n",
    "tp[\"timesteps_per_ppo_update\"] = 256\n",
    "tp[\"max_total_timesteps\"] = 20000\n",
    "\n",
    "config[\"training_params\"][\"use_episode_length_curriculum\"] = True\n",
    "config[\"training_params\"][\"episode_length_curriculum_schedule\"] = [\n",
    "    {\"threshold\": 0, \"limit\": 252},\n",
    "    {\"threshold\": 10000, \"limit\": 504},\n",
    "    {\"threshold\": 30000, \"limit\": 1000},\n",
    "    {\"threshold\": 60000, \"limit\": None},\n",
    "]\n",
    "\n",
    "# reduce reward noise, enforce turnover discipline\n",
    "ep[\"intra_step_tape_delta_enabled\"] = False\n",
    "ep[\"dsr_scalar\"] = 1.0\n",
    "ep[\"target_turnover\"] = 0.50\n",
    "ep[\"turnover_penalty_scalar\"] = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179d911",
   "metadata": {},
   "source": [
    "##### Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "707edab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied next-run stability-first tuning\n",
      "max_total_timesteps: 100000\n",
      "timesteps_per_ppo_update_schedule: [{'threshold': 0, 'timesteps_per_update': 384}, {'threshold': 30000, 'timesteps_per_update': 512}]\n",
      "batch_size_ppo_schedule: [{'threshold': 0, 'batch_size': 96}, {'threshold': 30000, 'batch_size': 128}]\n",
      "target_kl: 0.012 | kl_stop_multiplier: 1.2 | policy_clip: 0.05\n",
      "actor_lr: 1e-05 | critic_lr: 0.00012\n",
      "turnover_penalty_curriculum: {0: 1.5, 10000: 2.0, 25000: 2.5, 40000: 3.0}\n",
      "terminal gate mdd: 0.23\n",
      "risk_aux: True | sharpe_coef: 0.03 | mvo_coef: 0.001\n",
      "Dirichlet: elu {'max': 0.35, 'min': 0.2} | temp: 1.25 | alpha_cap: 40.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NEXT RUN TUNING OVERRIDES (stability-first + risk-aux + rollout schedule)\n",
    "# ============================================================================\n",
    "from copy import deepcopy\n",
    "\n",
    "config = deepcopy(config)\n",
    "\n",
    "tp = config[\"training_params\"]\n",
    "ppo = config[\"agent_params\"][\"ppo_params\"]\n",
    "env = config[\"environment_params\"]\n",
    "\n",
    "# 1) Train length + PPO rollout schedule\n",
    "tp[\"max_total_timesteps\"] = 100_000\n",
    "\n",
    "# Fallback defaults (used if schedule is missing)\n",
    "tp[\"timesteps_per_ppo_update\"] = 384\n",
    "tp[\"batch_size_ppo\"] = 96\n",
    "\n",
    "# Rollout schedule (less noisy updates than starting at 256)\n",
    "tp[\"timesteps_per_ppo_update_schedule\"] = [\n",
    "    {\"threshold\": 0, \"timesteps_per_update\": 384},\n",
    "    {\"threshold\": 30_000, \"timesteps_per_update\": 512},\n",
    "]\n",
    "\n",
    "# Batch-size schedule (roughly rollout / 4)\n",
    "tp[\"batch_size_ppo_schedule\"] = [\n",
    "    {\"threshold\": 0, \"batch_size\": 96},\n",
    "    {\"threshold\": 30_000, \"batch_size\": 128},\n",
    "]\n",
    "\n",
    "# 2) PPO stability tightening\n",
    "ppo[\"num_ppo_epochs\"] = 1\n",
    "ppo[\"actor_lr\"] = 1.0e-5\n",
    "ppo[\"critic_lr\"] = 1.2e-4\n",
    "ppo[\"target_kl\"] = 0.012\n",
    "ppo[\"kl_stop_multiplier\"] = 1.2\n",
    "ppo[\"entropy_coef\"] = 0.0015\n",
    "ppo[\"max_grad_norm\"] = 0.20\n",
    "ppo[\"policy_clip\"] = 0.05\n",
    "\n",
    "tp[\"actor_lr_schedule\"] = [\n",
    "    {\"threshold\": 0, \"lr\": 1.0e-5},\n",
    "    {\"threshold\": 35_000, \"lr\": 8.0e-6},\n",
    "    {\"threshold\": 70_000, \"lr\": 6.0e-6},\n",
    "]\n",
    "\n",
    "# 3) Episode horizon curriculum\n",
    "tp[\"use_episode_length_curriculum\"] = True\n",
    "tp[\"episode_length_curriculum_schedule\"] = [\n",
    "    {\"threshold\": 0, \"limit\": 252},\n",
    "    {\"threshold\": 10_000, \"limit\": 504},\n",
    "    {\"threshold\": 25_000, \"limit\": 756},\n",
    "    {\"threshold\": 40_000, \"limit\": None},\n",
    "]\n",
    "\n",
    "tp[\"log_step_diagnostics\"] = True\n",
    "\n",
    "# 4) Turnover control (steady but not overly punitive)\n",
    "tp[\"turnover_penalty_curriculum\"] = {\n",
    "    0: 1.5,\n",
    "    10_000: 2.0,\n",
    "    25_000: 2.5,\n",
    "    40_000: 3.0,\n",
    "}\n",
    "tp[\"evaluation_turnover_penalty_scalar\"] = 3.0\n",
    "\n",
    "env[\"target_turnover\"] = 0.35\n",
    "env[\"turnover_penalty_scalar\"] = 1.5\n",
    "env[\"transaction_cost_pct\"] = 0.0005\n",
    "env[\"action_realization_penalty_scalar\"] = 1.0\n",
    "\n",
    "# 5) Signed terminal reward + tighter Gate A\n",
    "env[\"tape_terminal_bonus_mode\"] = \"signed\"\n",
    "env[\"tape_terminal_baseline\"] = 0.20\n",
    "env[\"tape_terminal_scalar\"] = 6.0\n",
    "env[\"tape_terminal_clip\"] = 6.0\n",
    "env[\"tape_terminal_gate_a_enabled\"] = True\n",
    "env[\"tape_terminal_gate_a_sharpe_threshold\"] = 0.0\n",
    "env[\"tape_terminal_gate_a_max_drawdown\"] = 0.23\n",
    "env[\"tape_terminal_neutral_band_halfwidth\"] = 0.003\n",
    "\n",
    "# 6) Risk-aware actor auxiliary objective (moderate strength)\n",
    "ppo[\"use_risk_aux_loss\"] = True\n",
    "ppo[\"risk_aux_return_feature_index\"] = 0\n",
    "ppo[\"risk_aux_cash_return\"] = 0.0\n",
    "ppo[\"risk_aux_sharpe_coef\"] = 0.03\n",
    "ppo[\"risk_aux_mvo_coef\"] = 0.001\n",
    "ppo[\"risk_aux_mvo_cov_ridge\"] = 1e-3\n",
    "ppo[\"risk_aux_mvo_long_only\"] = True\n",
    "ppo[\"risk_aux_mvo_risky_budget\"] = 0.95\n",
    "\n",
    "ap = config[\"agent_params\"]\n",
    "\n",
    "# Keep stable activation\n",
    "ap[\"dirichlet_alpha_activation\"] = \"elu\"\n",
    "\n",
    "# Less noisy sampling than current {max:0.5, min:0.1}\n",
    "ap[\"dirichlet_epsilon\"] = {\"max\": 0.35, \"min\": 0.20}\n",
    "\n",
    "# Flatten logits a bit to reduce extreme weight jumps\n",
    "ap[\"dirichlet_logit_temperature\"] = 1.25\n",
    "\n",
    "# Prevent overconfident alpha spikes\n",
    "ap[\"dirichlet_alpha_cap\"] = 40.0\n",
    "\n",
    "# Keep as-is unless you switch activation to exp_clip\n",
    "ap[\"dirichlet_exp_clip\"] = (-5.0, 3.0)\n",
    "\n",
    "env[\"action_execution_beta\"] = 0.20\n",
    "tp[\"action_execution_beta_curriculum\"] = {\n",
    "    0: 0.20,\n",
    "    30_000: 0.35,\n",
    "}\n",
    "tp[\"evaluation_action_execution_beta\"] = 0.35\n",
    "\n",
    "\n",
    "\n",
    "print(\"âœ… Applied next-run stability-first tuning\")\n",
    "print(\"max_total_timesteps:\", tp[\"max_total_timesteps\"])\n",
    "print(\"timesteps_per_ppo_update_schedule:\", tp[\"timesteps_per_ppo_update_schedule\"])\n",
    "print(\"batch_size_ppo_schedule:\", tp[\"batch_size_ppo_schedule\"])\n",
    "print(\"target_kl:\", ppo[\"target_kl\"], \"| kl_stop_multiplier:\", ppo[\"kl_stop_multiplier\"], \"| policy_clip:\", ppo[\"policy_clip\"])\n",
    "print(\"actor_lr:\", ppo[\"actor_lr\"], \"| critic_lr:\", ppo[\"critic_lr\"])\n",
    "print(\"turnover_penalty_curriculum:\", tp[\"turnover_penalty_curriculum\"])\n",
    "print(\"terminal gate mdd:\", env[\"tape_terminal_gate_a_max_drawdown\"])\n",
    "print(\"risk_aux:\", ppo[\"use_risk_aux_loss\"], \"| sharpe_coef:\", ppo[\"risk_aux_sharpe_coef\"], \"| mvo_coef:\", ppo[\"risk_aux_mvo_coef\"])\n",
    "print(\"Dirichlet:\", ap[\"dirichlet_alpha_activation\"], ap[\"dirichlet_epsilon\"],\n",
    "      \"| temp:\", ap[\"dirichlet_logit_temperature\"], \"| alpha_cap:\", ap[\"dirichlet_alpha_cap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5caa6349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting training\n",
      "Variant: TCN_FUSION\n",
      "max_total_timesteps: 100000\n",
      "timesteps_per_ppo_update: 384\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 6: TCN_FUSION Enhanced + TAPE Three-Component\n",
      "================================================================================\n",
      "Architecture: TCN + Fusion\n",
      "Results root: /content/adaptive_portfolio_rl/tcn_fusion_results\n",
      "Working dir: /content/adaptive_portfolio_rl\n",
      "Covariance Features: Yes\n",
      "ðŸŽ¯ REWARD SYSTEM: TAPE (Three-Component v3)\n",
      "   Profile: BalancedGrowth\n",
      "   Daily: Base + DSR/PBRS + Turnover_Proximity\n",
      "   Terminal: mode=signed | baseline=0.20 | scalar=6.0 (clipped Â±6.0)\n",
      "   Gate A: enabled (Sharpe â‰¤ 0.00 or MDD â‰¥ 23.0% -> force non-positive terminal bonus)\n",
      "   Neutral Band: enabled (Â±0.003 around baseline)\n",
      "   ðŸ”„ Profile Manager: disabled (static profile only)\n",
      "ðŸŽ² Experiment Seed: 6042 (Base: 42, Offset: 6000)\n",
      "âœ… Features: Enhanced (includes 3 covariance eigenvalues)\n",
      "   Eigenvalues: ['Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1', 'Covariance_Eigenvalue_2']\n",
      "   Train shape: (44877, 73)\n",
      "   Test shape: (10020, 73)\n",
      "\n",
      "ðŸ—ï¸ Creating THREE-COMPONENT TAPE v3 environments (with curriculum)...\n",
      "   ðŸŽ¯ Reward System: TAPE (Three-Component v3)\n",
      "   ðŸ“Š Profile: BalancedGrowth\n",
      "   âš™ï¸  Component 1: Base Reward (Net Return)\n",
      "   âš™ï¸  Component 2: DSR/PBRS (window=60, scalar=2.00, gamma=0.99)\n",
      "   âš™ï¸  Component 3: Turnover Proximity (target=0.35, band=Â±0.20, scalar=1.50 -> 2.00 â†’ 2.50 â†’ 3.00)\n",
      "      â†³ Schedule: 1.50@0 â†’ 2.00@10,000 â†’ 2.50@25,000 â†’ 3.00@40,000\n",
      "   âš™ï¸  Component 4: Execution Inertia (beta=0.20 -> 0.35, w_exec=(1-Î²)w_prev + Î²w_raw)\n",
      "      â†³ Schedule: 0.20@0 â†’ 0.35@30,000\n",
      "   ðŸŽ Terminal: mode=signed, baseline=0.20, scalar=6.0 (clipped Â±6.0)\n",
      "   ðŸŸ° Neutral Band: enabled (Â±0.003 around baseline)\n",
      "   ðŸš¦ Gate A: enabled (Sharpe â‰¤ 0.00, MDD â‰¥ 23.0%)\n",
      "   ðŸ§  Credit Assignment: step reward is computed at each environment step\n",
      "   ðŸ§¾ Episode-End Handling: terminal TAPE bonus is added at episode completion only\n",
      "   âœ… Retroactive episode-wide reward rescaling: disabled in notebook helper path\n",
      "   ðŸ”’ Drawdown dual controller (requested): target=18.00%, tolerance=-1.50% (trigger boundary â‰ˆ 16.50%), lr=0.100, Î»_init=0.50, Î»_floor=0.00, Î»_max=5.00, penalty_coef=1.50\n",
      "   âœ… Drawdown controller armed in env: target=18.00%, trigger=16.50%, Î»_init=0.500, Î»_floor=0.000, Î»_max=5.00, penalty_coef=1.50\n",
      "âœ… THREE-COMPONENT TAPE v3 Environments created:\n",
      "   Training: 4512 days\n",
      "   Testing: 1002 days\n",
      "\n",
      "ðŸ¤– Creating TCN_FUSION agent with Dirichlet distribution for Exp 6...\n",
      "âœ… Agent created: PPOAgentTF\n",
      "   ðŸŽ² Dirichlet Distribution: ENABLED\n",
      "   ðŸ”§ Actor LR schedule: 0.000010@0 â†’ 0.000008@35,000 â†’ 0.000006@70,000\n",
      "   State dim: 417\n",
      "   Action dim: 10\n",
      "   Actor LR (configured): 1e-05\n",
      "   Actor LR (active): 0.000010\n",
      "   Critic LR (active): 0.000120\n",
      "   PPO update: epochs=1, batch_size=96, target_kl=0.0120, entropy_coef=0.0015\n",
      "   ðŸ“ PPO rollout schedule: 384@0 â†’ 512@30,000\n",
      "   ðŸ§º PPO batch-size schedule: 96@0 â†’ 128@30,000\n",
      "ðŸ“Š Training metrics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_episodes.csv\n",
      "ðŸ§ª Step diagnostics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_step_diagnostics.csv\n",
      "\n",
      "ðŸŽ¯ Starting THREE-COMPONENT TAPE v3 training (with curriculum)...\n",
      "   Total timesteps: 100,000\n",
      "   Timesteps per update: scheduled\n",
      "      0+ steps: timesteps_per_update=384\n",
      "      30,000+ steps: timesteps_per_update=512\n",
      "   Number of updates: 216\n",
      "   PPO batch_size: scheduled\n",
      "      0+ steps: batch_size=96\n",
      "      30,000+ steps: batch_size=128\n",
      "   ðŸ“š Episode Length Curriculum:\n",
      "      0+ steps: limit=252\n",
      "      10,000+ steps: limit=504\n",
      "      25,000+ steps: limit=756\n",
      "      40,000+ steps: limit=full\n",
      "   ðŸ“š Turnover Scalar Curriculum:\n",
      "      0+ steps: scalar=1.50\n",
      "      10,000+ steps: scalar=2.00\n",
      "      25,000+ steps: scalar=2.50\n",
      "      40,000+ steps: scalar=3.00\n",
      "   ðŸŽ›ï¸ Action Execution Beta Curriculum:\n",
      "      0+ steps: beta=0.20\n",
      "      30,000+ steps: beta=0.35\n",
      "   ðŸ† High-Watermark checkpoints: enabled (save every episode with Sharpe >= 0.50)\n",
      "   ðŸ§· Step-Sharpe checkpoints: disabled\n",
      "ðŸ§¾ Active feature manifest saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_active_feature_manifest.json\n",
      "ðŸ§¾ Training metadata saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_metadata.json\n",
      "   ðŸŽ¯ Episode 1: TAPE Score = 0.4147 (bonus: -1.61 â†’ -1.61)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.849, MDD=23.45%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_actor.weights.h5 (Sharpe=0.849)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.052154 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 1/216 | Step 384/100,000 | Episode 1 | Time: 66.6s\n",
      "   ðŸ“Š Metrics: Return=+21.33% | Sharpe=0.849 | DD=23.45% | Turnover=11.42%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7406 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0418 | critic_loss=0.6106 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3053 | risk_aux_total=-0.0038 | sharpe_proxy=0.1266 | sharpe_loss=-0.0038 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.44% / trig 16.50%) | terminal=0.000 (peak 0.500) | TAPE=0.4147\n",
      "   ðŸŽ¯ Episode 2: TAPE Score = 0.5335 (bonus: +2.50 â†’ +2.50)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_actor.weights.h5 (Sharpe=1.029)\n",
      "   ðŸŽ¯ Episode 3: TAPE Score = 0.6747 (bonus: +3.56 â†’ +3.56)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841_actor.weights.h5 (Sharpe=1.841)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep3_sh1.841_dd4.4_actor.weights.h5 (Sharpe 1.841, MDD 4.43%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033079 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 2/216 | Step 768/100,000 | Episode 3 | Time: 123.8s\n",
      "   ðŸ“Š Metrics: Return=+23.32% | Sharpe=1.841 | DD=4.43% | Turnover=10.80%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0353 | critic_loss=0.3020 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1510 | risk_aux_total=-0.0001 | sharpe_proxy=0.0028 | sharpe_loss=-0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.13% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6747\n",
      "   ðŸŽ¯ Episode 4: TAPE Score = 0.2654 (bonus: -0.49 â†’ -0.49)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.539, MDD=31.03%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p539_actor.weights.h5 (Sharpe=0.539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035516 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 3/216 | Step 1,152/100,000 | Episode 4 | Time: 178.5s\n",
      "   ðŸ“Š Metrics: Return=+15.27% | Sharpe=0.539 | DD=31.03% | Turnover=11.13%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5203 | delta_reward=-0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0349 | critic_loss=0.8223 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4111 | risk_aux_total=-0.0041 | sharpe_proxy=0.1373 | sharpe_loss=-0.0041 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.48% / trig 16.50%) | terminal=0.000 (peak 0.113) | TAPE=0.2654\n",
      "   ðŸŽ¯ Episode 5: TAPE Score = 0.6310 (bonus: +3.23 â†’ +3.23)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp1p631_actor.weights.h5 (Sharpe=1.631)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep5_sh1.631_dd4.4_actor.weights.h5 (Sharpe 1.631, MDD 4.38%)\n",
      "   ðŸŽ¯ Episode 6: TAPE Score = 0.7520 (bonus: +4.14 â†’ +4.14)\n",
      "      ðŸ’¾ TAPE threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_ep6_actor.weights.h5\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p396_actor.weights.h5 (Sharpe=3.396)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep6_sh3.396_dd2.2_actor.weights.h5 (Sharpe 3.396, MDD 2.23%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036536 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 4/216 | Step 1,536/100,000 | Episode 6 | Time: 233.9s\n",
      "   ðŸ“Š Metrics: Return=+27.23% | Sharpe=3.396 | DD=2.23% | Turnover=10.86%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7396 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0538 | critic_loss=0.3626 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1813 | risk_aux_total=-0.0044 | sharpe_proxy=0.1459 | sharpe_loss=-0.0044 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.71% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.7520\n",
      "   ðŸŽ¯ Episode 7: TAPE Score = 0.5240 (bonus: +2.43 â†’ +2.43)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00007_shp0p953_actor.weights.h5 (Sharpe=0.953)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.050202 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 5/216 | Step 1,920/100,000 | Episode 7 | Time: 288.9s\n",
      "   ðŸ“Š Metrics: Return=+13.12% | Sharpe=0.953 | DD=10.72% | Turnover=10.61%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2500 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0633 | critic_loss=0.8023 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4011 | risk_aux_total=-0.0036 | sharpe_proxy=0.1209 | sharpe_loss=-0.0036 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 8.42% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5240\n",
      "   ðŸŽ¯ Episode 8: TAPE Score = 0.2083 (bonus: -0.06 â†’ -0.06)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.611, MDD=35.82%\n",
      "   ðŸŽ¯ Episode 9: TAPE Score = 0.5841 (bonus: +2.88 â†’ +2.88)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00009_shp1p343_actor.weights.h5 (Sharpe=1.343)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024174 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 6/216 | Step 2,304/100,000 | Episode 9 | Time: 343.7s\n",
      "   ðŸ“Š Metrics: Return=+21.32% | Sharpe=1.343 | DD=7.41% | Turnover=10.66%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2515 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0663 | critic_loss=0.9802 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4901 | risk_aux_total=0.0000 | sharpe_proxy=0.0001 | sharpe_loss=-0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.65% / trig 16.50%) | terminal=0.000 (peak 0.424) | TAPE=0.5841\n",
      "   ðŸŽ¯ Episode 10: TAPE Score = 0.3431 (bonus: +1.07 â†’ +1.07)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00010_shp0p540_actor.weights.h5 (Sharpe=0.540)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015160 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 7/216 | Step 2,688/100,000 | Episode 10 | Time: 399.4s\n",
      "   ðŸ“Š Metrics: Return=+7.72% | Sharpe=0.540 | DD=10.50% | Turnover=11.08%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6887 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1285 | critic_loss=0.4274 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2137 | risk_aux_total=0.0013 | sharpe_proxy=-0.0431 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3431\n",
      "   ðŸŽ¯ Episode 11: TAPE Score = 0.6011 (bonus: +3.01 â†’ +3.01)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp1p485_actor.weights.h5 (Sharpe=1.485)\n",
      "   ðŸŽ¯ Episode 12: TAPE Score = 0.2499 (bonus: +0.37 â†’ +0.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021031 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 8/216 | Step 3,072/100,000 | Episode 12 | Time: 454.2s\n",
      "   ðŸ“Š Metrics: Return=+0.63% | Sharpe=0.010 | DD=17.22% | Turnover=11.16%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7498 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0031 | critic_loss=0.8588 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4294 | risk_aux_total=0.0008 | sharpe_proxy=-0.0260 | sharpe_loss=0.0008 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.16% / trig 16.50%) | terminal=0.000 (peak 0.001) | TAPE=0.2499\n",
      "   ðŸŽ¯ Episode 13: TAPE Score = 0.5365 (bonus: +2.52 â†’ +2.52)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00013_shp1p207_actor.weights.h5 (Sharpe=1.207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030035 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 9/216 | Step 3,456/100,000 | Episode 13 | Time: 509.6s\n",
      "   ðŸ“Š Metrics: Return=+16.36% | Sharpe=1.207 | DD=6.30% | Turnover=10.70%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2452 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0285 | critic_loss=0.6035 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3017 | risk_aux_total=-0.0016 | sharpe_proxy=0.0534 | sharpe_loss=-0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.71% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5365\n",
      "   ðŸŽ¯ Episode 14: TAPE Score = 0.2699 (bonus: +0.52 â†’ +0.52)\n",
      "   ðŸŽ¯ Episode 15: TAPE Score = 0.6911 (bonus: +3.68 â†’ +3.68)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00015_shp2p029_actor.weights.h5 (Sharpe=2.029)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep15_sh2.029_dd2.6_actor.weights.h5 (Sharpe 2.029, MDD 2.59%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036469 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 10/216 | Step 3,840/100,000 | Episode 15 | Time: 564.4s\n",
      "   ðŸ“Š Metrics: Return=+18.42% | Sharpe=2.029 | DD=2.59% | Turnover=11.15%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4699 | delta_reward=-0.0009\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0409 | critic_loss=0.5570 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2785 | risk_aux_total=0.0002 | sharpe_proxy=-0.0050 | sharpe_loss=0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.71 | std=0.30 | range=[1.04, 2.19]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.24% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6911\n",
      "   ðŸŽ¯ Episode 16: TAPE Score = 0.5047 (bonus: +2.29 â†’ +2.29)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00016_shp1p090_actor.weights.h5 (Sharpe=1.090)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016340 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 11/216 | Step 4,224/100,000 | Episode 16 | Time: 619.5s\n",
      "   ðŸ“Š Metrics: Return=+14.48% | Sharpe=1.090 | DD=7.10% | Turnover=10.98%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6656 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1635 | critic_loss=0.9304 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4652 | risk_aux_total=0.0009 | sharpe_proxy=-0.0294 | sharpe_loss=0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5047\n",
      "   ðŸŽ¯ Episode 17: TAPE Score = 0.3353 (bonus: +1.01 â†’ +1.01)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00017_shp0p575_actor.weights.h5 (Sharpe=0.575)\n",
      "   ðŸŽ¯ Episode 18: TAPE Score = 0.2615 (bonus: -0.46 â†’ -0.46)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.536, MDD=31.60%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00018_shp0p536_actor.weights.h5 (Sharpe=0.536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.042058 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 12/216 | Step 4,608/100,000 | Episode 18 | Time: 674.6s\n",
      "   ðŸ“Š Metrics: Return=+14.87% | Sharpe=0.536 | DD=31.60% | Turnover=11.10%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3391 | delta_reward=-0.0021\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1587 | critic_loss=1.5685 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.7843 | risk_aux_total=0.0002 | sharpe_proxy=-0.0074 | sharpe_loss=0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.97% / trig 16.50%) | terminal=0.000 (peak 0.129) | TAPE=0.2615\n",
      "   ðŸŽ¯ Episode 19: TAPE Score = 0.3348 (bonus: +1.01 â†’ +1.01)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00019_shp0p622_actor.weights.h5 (Sharpe=0.622)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029090 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 13/216 | Step 4,992/100,000 | Episode 19 | Time: 730.3s\n",
      "   ðŸ“Š Metrics: Return=+12.90% | Sharpe=0.622 | DD=15.78% | Turnover=11.07%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7109 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0245 | critic_loss=0.7811 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3905 | risk_aux_total=-0.0019 | sharpe_proxy=0.0644 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3348\n",
      "   ðŸŽ¯ Episode 20: TAPE Score = 0.5875 (bonus: +2.91 â†’ +2.91)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00020_shp1p321_actor.weights.h5 (Sharpe=1.321)\n",
      "   ðŸŽ¯ Episode 21: TAPE Score = 0.2753 (bonus: +0.56 â†’ +0.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021867 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 14/216 | Step 5,376/100,000 | Episode 21 | Time: 785.3s\n",
      "   ðŸ“Š Metrics: Return=+6.60% | Sharpe=0.400 | DD=10.47% | Turnover=11.26%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7459 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0304 | critic_loss=0.5466 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2733 | risk_aux_total=-0.0016 | sharpe_proxy=0.0528 | sharpe_loss=-0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.70% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.2753\n",
      "   ðŸŽ¯ Episode 22: TAPE Score = 0.3106 (bonus: +0.83 â†’ +0.83)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00022_shp0p510_actor.weights.h5 (Sharpe=0.510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034112 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 15/216 | Step 5,760/100,000 | Episode 22 | Time: 842.8s\n",
      "   ðŸ“Š Metrics: Return=+8.73% | Sharpe=0.510 | DD=11.24% | Turnover=11.05%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7271 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0251 | critic_loss=0.8815 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4408 | risk_aux_total=0.0001 | sharpe_proxy=-0.0044 | sharpe_loss=0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.07% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3106\n",
      "   ðŸŽ¯ Episode 23: TAPE Score = 0.5224 (bonus: +2.42 â†’ +2.42)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00023_shp0p918_actor.weights.h5 (Sharpe=0.918)\n",
      "   ðŸŽ¯ Episode 24: TAPE Score = 0.6580 (bonus: +3.43 â†’ +3.43)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00024_shp2p128_actor.weights.h5 (Sharpe=2.128)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep24_sh2.128_dd8.1_actor.weights.h5 (Sharpe 2.128, MDD 8.12%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030012 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 16/216 | Step 6,144/100,000 | Episode 24 | Time: 898.9s\n",
      "   ðŸ“Š Metrics: Return=+44.16% | Sharpe=2.128 | DD=8.12% | Turnover=11.40%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4682 | delta_reward=+0.0011\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0820 | critic_loss=0.6882 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3441 | risk_aux_total=0.0018 | sharpe_proxy=-0.0588 | sharpe_loss=0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 6.76% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6580\n",
      "   ðŸŽ¯ Episode 25: TAPE Score = 0.4190 (bonus: +1.64 â†’ +1.64)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00025_shp0p772_actor.weights.h5 (Sharpe=0.772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030438 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 17/216 | Step 6,528/100,000 | Episode 25 | Time: 954.5s\n",
      "   ðŸ“Š Metrics: Return=+12.89% | Sharpe=0.772 | DD=13.29% | Turnover=11.00%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3762 | delta_reward=+0.0009\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0409 | critic_loss=0.7347 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3673 | risk_aux_total=-0.0023 | sharpe_proxy=0.0786 | sharpe_loss=-0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 5.36% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4190\n",
      "   ðŸŽ¯ Episode 26: TAPE Score = 0.5231 (bonus: +2.42 â†’ +2.42)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p237_actor.weights.h5 (Sharpe=1.237)\n",
      "   ðŸŽ¯ Episode 27: TAPE Score = 0.6817 (bonus: +3.61 â†’ +3.61)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00027_shp2p266_actor.weights.h5 (Sharpe=2.266)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep27_sh2.266_dd5.6_actor.weights.h5 (Sharpe 2.266, MDD 5.58%)\n",
      "ðŸ”„ Update 18/216 | Step 6,912/100,000 | Episode 27 | Time: 1012.0s\n",
      "   ðŸ“Š Metrics: Return=+27.98% | Sharpe=2.266 | DD=5.58% | Turnover=11.18%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7513 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0206 | critic_loss=0.6807 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3404 | risk_aux_total=-0.0024 | sharpe_proxy=0.0798 | sharpe_loss=-0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6817\n",
      "   ðŸŽ¯ Episode 28: TAPE Score = 0.2756 (bonus: -0.57 â†’ -0.57)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.582, MDD=30.66%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00028_shp0p582_actor.weights.h5 (Sharpe=0.582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036613 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 19/216 | Step 7,296/100,000 | Episode 28 | Time: 1067.1s\n",
      "   ðŸ“Š Metrics: Return=+16.56% | Sharpe=0.582 | DD=30.66% | Turnover=10.85%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4645 | delta_reward=+0.0008\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0394 | critic_loss=1.3240 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.6620 | risk_aux_total=-0.0065 | sharpe_proxy=0.2169 | sharpe_loss=-0.0065 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.40% / trig 16.50%) | terminal=0.000 (peak 0.099) | TAPE=0.2756\n",
      "   ðŸŽ¯ Episode 29: TAPE Score = 0.5708 (bonus: +2.78 â†’ +2.78)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00029_shp1p252_actor.weights.h5 (Sharpe=1.252)\n",
      "   ðŸŽ¯ Episode 30: TAPE Score = 0.2414 (bonus: -0.31 â†’ -0.31)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.165, MDD=17.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029087 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 20/216 | Step 7,680/100,000 | Episode 30 | Time: 1123.0s\n",
      "   ðŸ“Š Metrics: Return=-2.37% | Sharpe=-0.165 | DD=17.85% | Turnover=11.08%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2028 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0720 | critic_loss=1.6826 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.8413 | risk_aux_total=-0.0001 | sharpe_proxy=0.0039 | sharpe_loss=-0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.65 | std=0.28 | range=[0.91, 2.55]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.099 (peak 0.116, dd 10.46% / trig 16.50%) | terminal=0.000 (peak 0.004) | TAPE=0.2414\n",
      "   ðŸŽ¯ Episode 31: TAPE Score = 0.2383 (bonus: -0.29 â†’ -0.29)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.403, MDD=31.70%\n",
      "   ðŸŽ¯ Episode 32: TAPE Score = 0.7411 (bonus: +4.06 â†’ +4.06)\n",
      "      ðŸ’¾ TAPE threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_ep32_actor.weights.h5\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00032_shp2p639_actor.weights.h5 (Sharpe=2.639)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep32_sh2.639_dd4.3_actor.weights.h5 (Sharpe 2.639, MDD 4.28%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024761 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 21/216 | Step 8,064/100,000 | Episode 32 | Time: 1178.4s\n",
      "   ðŸ“Š Metrics: Return=+34.71% | Sharpe=2.639 | DD=4.28% | Turnover=10.51%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0422 | critic_loss=0.5618 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2809 | risk_aux_total=-0.0003 | sharpe_proxy=0.0102 | sharpe_loss=-0.0003 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.7411\n",
      "   ðŸŽ¯ Episode 33: TAPE Score = 0.6000 (bonus: +3.00 â†’ +3.00)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00033_shp1p429_actor.weights.h5 (Sharpe=1.429)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035126 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 22/216 | Step 8,448/100,000 | Episode 33 | Time: 1233.4s\n",
      "   ðŸ“Š Metrics: Return=+17.80% | Sharpe=1.429 | DD=6.55% | Turnover=10.95%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2285 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0584 | critic_loss=1.4585 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.7292 | risk_aux_total=0.0026 | sharpe_proxy=-0.0878 | sharpe_loss=0.0026 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.268 (peak 0.268, dd 20.91% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6000\n",
      "   ðŸŽ¯ Episode 34: TAPE Score = 0.2131 (bonus: -0.10 â†’ -0.10)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.001, MDD=35.22%\n",
      "   ðŸŽ¯ Episode 35: TAPE Score = 0.6179 (bonus: +3.13 â†’ +3.13)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00035_shp1p583_actor.weights.h5 (Sharpe=1.583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.081014 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 23/216 | Step 8,832/100,000 | Episode 35 | Time: 1288.6s\n",
      "   ðŸ“Š Metrics: Return=+17.59% | Sharpe=1.583 | DD=4.07% | Turnover=11.24%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0691 | critic_loss=0.7771 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3886 | risk_aux_total=-0.0009 | sharpe_proxy=0.0302 | sharpe_loss=-0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 4.77% / trig 16.50%) | terminal=0.000 (peak 0.394) | TAPE=0.6179\n",
      "   ðŸŽ¯ Episode 36: TAPE Score = 0.5920 (bonus: +2.94 â†’ +2.94)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00036_shp1p498_actor.weights.h5 (Sharpe=1.498)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.028170 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 24/216 | Step 9,216/100,000 | Episode 36 | Time: 1343.6s\n",
      "   ðŸ“Š Metrics: Return=+17.73% | Sharpe=1.498 | DD=5.56% | Turnover=11.09%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7473 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0828 | critic_loss=0.4029 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2015 | risk_aux_total=-0.0039 | sharpe_proxy=0.1315 | sharpe_loss=-0.0039 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5920\n",
      "   ðŸŽ¯ Episode 37: TAPE Score = 0.6179 (bonus: +3.13 â†’ +3.13)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00037_shp1p978_actor.weights.h5 (Sharpe=1.978)\n",
      "   ðŸŽ¯ Episode 38: TAPE Score = 0.3165 (bonus: +0.87 â†’ +0.87)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00038_shp0p531_actor.weights.h5 (Sharpe=0.531)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022638 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 25/216 | Step 9,600/100,000 | Episode 38 | Time: 1399.6s\n",
      "   ðŸ“Š Metrics: Return=+9.50% | Sharpe=0.531 | DD=13.31% | Turnover=11.24%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7542 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0750 | critic_loss=0.8972 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4486 | risk_aux_total=-0.0023 | sharpe_proxy=0.0771 | sharpe_loss=-0.0023 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3165\n",
      "   ðŸŽ¯ Episode 39: TAPE Score = 0.6858 (bonus: +3.64 â†’ +3.64)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00039_shp2p205_actor.weights.h5 (Sharpe=2.205)\n",
      "      Rare checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/rare_models/exp6_tape_ep39_sh2.205_dd8.5_actor.weights.h5 (Sharpe 2.205, MDD 8.55%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034812 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 26/216 | Step 9,984/100,000 | Episode 39 | Time: 1455.6s\n",
      "   ðŸ“Š Metrics: Return=+37.03% | Sharpe=2.205 | DD=8.55% | Turnover=10.97%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7498 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0520 | critic_loss=0.5632 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2816 | risk_aux_total=-0.0019 | sharpe_proxy=0.0628 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.13% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6858\n",
      "   ðŸŽ¯ Episode 40: TAPE Score = 0.3471 (bonus: +1.10 â†’ +1.10)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00040_shp0p606_actor.weights.h5 (Sharpe=0.606)\n",
      "   ðŸŽ¯ Episode 41: TAPE Score = 0.3234 (bonus: +0.93 â†’ +0.93)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00041_shp0p553_actor.weights.h5 (Sharpe=0.553)\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step010000_actor.weights.h5\n",
      "\n",
      "ðŸ“š TURNOVER CURRICULUM UPDATE at 10,368 steps:\n",
      "   Turnover penalty scalar: 2.0\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 10,368 steps:\n",
      "   Episode horizon: 504 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020504 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 27/216 | Step 10,368/100,000 | Episode 41 | Time: 1511.6s\n",
      "   ðŸ“Š Metrics: Return=+9.47% | Sharpe=0.553 | DD=10.47% | Turnover=10.93%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7491 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0486 | critic_loss=0.6027 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3013 | risk_aux_total=0.0016 | sharpe_proxy=-0.0537 | sharpe_loss=0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.023638 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 28/216 | Step 10,752/100,000 | Episode 41 | Time: 1566.5s\n",
      "   ðŸ“Š Metrics: Return=+20.68% | Sharpe=0.759 | DD=13.02% | Turnover=11.08%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6100 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0716 | critic_loss=0.7453 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3727 | risk_aux_total=-0.0014 | sharpe_proxy=0.0481 | sharpe_loss=-0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 42: TAPE Score = 0.4135 (bonus: +1.60 â†’ +1.60)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00042_shp0p816_actor.weights.h5 (Sharpe=0.816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022567 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 29/216 | Step 11,136/100,000 | Episode 42 | Time: 1623.3s\n",
      "   ðŸ“Š Metrics: Return=+26.79% | Sharpe=0.816 | DD=13.02% | Turnover=11.09%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6868 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0150 | critic_loss=0.4950 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2475 | risk_aux_total=-0.0007 | sharpe_proxy=0.0227 | sharpe_loss=-0.0007 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.64% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4135\n",
      "   ðŸŽ¯ Episode 43: TAPE Score = 0.5584 (bonus: +2.69 â†’ +2.69)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00043_shp1p129_actor.weights.h5 (Sharpe=1.129)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018431 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 30/216 | Step 11,520/100,000 | Episode 43 | Time: 1678.5s\n",
      "   ðŸ“Š Metrics: Return=+30.80% | Sharpe=1.129 | DD=11.04% | Turnover=10.99%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4594 | delta_reward=-0.0012\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0408 | critic_loss=0.4738 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2369 | risk_aux_total=-0.0005 | sharpe_proxy=0.0163 | sharpe_loss=-0.0005 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.69 | std=0.29 | range=[1.05, 2.22]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.60% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5584\n",
      "   ðŸŽ¯ Episode 44: TAPE Score = 0.5849 (bonus: +2.89 â†’ +2.89)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00044_shp1p375_actor.weights.h5 (Sharpe=1.375)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026257 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 31/216 | Step 11,904/100,000 | Episode 44 | Time: 1733.7s\n",
      "   ðŸ“Š Metrics: Return=+35.93% | Sharpe=1.375 | DD=6.35% | Turnover=10.88%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2482 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0054 | critic_loss=0.6285 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3143 | risk_aux_total=0.0012 | sharpe_proxy=-0.0380 | sharpe_loss=0.0011 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 7.19% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024693 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 32/216 | Step 12,288/100,000 | Episode 44 | Time: 1788.9s\n",
      "   ðŸ“Š Metrics: Return=+25.30% | Sharpe=1.068 | DD=10.71% | Turnover=10.93%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7508 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1762 | critic_loss=0.4692 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2346 | risk_aux_total=-0.0034 | sharpe_proxy=0.1152 | sharpe_loss=-0.0035 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 45: TAPE Score = 0.5454 (bonus: +2.59 â†’ +2.59)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00045_shp1p040_actor.weights.h5 (Sharpe=1.040)\n",
      "ðŸ”„ Update 33/216 | Step 12,672/100,000 | Episode 45 | Time: 1846.5s\n",
      "   ðŸ“Š Metrics: Return=+28.41% | Sharpe=1.040 | DD=10.71% | Turnover=10.91%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2353 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0257 | critic_loss=0.6956 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3478 | risk_aux_total=0.0009 | sharpe_proxy=-0.0286 | sharpe_loss=0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 14.74% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5454\n",
      "   ðŸŽ¯ Episode 46: TAPE Score = 0.2162 (bonus: -0.12 â†’ -0.12)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.121, MDD=37.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035992 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 34/216 | Step 13,056/100,000 | Episode 46 | Time: 1901.6s\n",
      "   ðŸ“Š Metrics: Return=-9.40% | Sharpe=-0.121 | DD=37.82% | Turnover=11.01%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7356 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0620 | critic_loss=1.5616 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.7808 | risk_aux_total=-0.0017 | sharpe_proxy=0.0556 | sharpe_loss=-0.0017 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.297, dd 0.04% / trig 16.50%) | terminal=0.424 (peak 0.424) | TAPE=0.2162\n",
      "   ðŸŽ¯ Episode 47: TAPE Score = 0.3572 (bonus: -1.18 â†’ -1.18)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.822, MDD=30.41%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00047_shp0p822_actor.weights.h5 (Sharpe=0.822)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022892 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 35/216 | Step 13,440/100,000 | Episode 47 | Time: 1956.4s\n",
      "   ðŸ“Š Metrics: Return=+45.87% | Sharpe=0.822 | DD=30.41% | Turnover=11.12%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2311 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0149 | critic_loss=0.9537 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4768 | risk_aux_total=-0.0020 | sharpe_proxy=0.0670 | sharpe_loss=-0.0020 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 12.68% / trig 16.50%) | terminal=0.000 (peak 0.297) | TAPE=0.3572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.155556 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 36/216 | Step 13,824/100,000 | Episode 47 | Time: 2011.5s\n",
      "   ðŸ“Š Metrics: Return=+2.28% | Sharpe=0.137 | DD=39.34% | Turnover=11.42%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2564 | delta_reward=-0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0105 | critic_loss=1.3138 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.6569 | risk_aux_total=0.0015 | sharpe_proxy=-0.0481 | sharpe_loss=0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 48: TAPE Score = 0.2119 (bonus: -0.09 â†’ -0.09)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.027, MDD=39.34%\n",
      "ðŸ”„ Update 37/216 | Step 14,208/100,000 | Episode 48 | Time: 2068.9s\n",
      "   ðŸ“Š Metrics: Return=-7.54% | Sharpe=-0.027 | DD=39.34% | Turnover=11.33%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5369 | delta_reward=-0.0011\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0244 | critic_loss=0.6385 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3192 | risk_aux_total=0.0022 | sharpe_proxy=-0.0719 | sharpe_loss=0.0022 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.288, dd 4.13% / trig 16.50%) | terminal=0.411 (peak 1.318) | TAPE=0.2119\n",
      "   ðŸŽ¯ Episode 49: TAPE Score = 0.3146 (bonus: +0.86 â†’ +0.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021632 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 38/216 | Step 14,592/100,000 | Episode 49 | Time: 2124.1s\n",
      "   ðŸ“Š Metrics: Return=+16.63% | Sharpe=0.498 | DD=11.47% | Turnover=11.01%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6849 | delta_reward=-0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0337 | critic_loss=0.9658 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4829 | risk_aux_total=-0.0025 | sharpe_proxy=0.0840 | sharpe_loss=-0.0025 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.015 (peak 0.120, dd 9.23% / trig 16.50%) | terminal=0.000 (peak 0.288) | TAPE=0.3146\n",
      "   ðŸŽ¯ Episode 50: TAPE Score = 0.3528 (bonus: -1.15 â†’ -1.15)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.815, MDD=31.90%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00050_shp0p815_actor.weights.h5 (Sharpe=0.815)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.147081 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 39/216 | Step 14,976/100,000 | Episode 50 | Time: 2179.4s\n",
      "   ðŸ“Š Metrics: Return=+45.81% | Sharpe=0.815 | DD=31.90% | Turnover=11.36%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7141 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0175 | critic_loss=0.7042 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3521 | risk_aux_total=0.0038 | sharpe_proxy=-0.1249 | sharpe_loss=0.0037 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.018, dd 1.29% / trig 16.50%) | terminal=0.000 (peak 0.120) | TAPE=0.3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021203 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 40/216 | Step 15,360/100,000 | Episode 50 | Time: 2234.5s\n",
      "   ðŸ“Š Metrics: Return=+45.85% | Sharpe=0.977 | DD=21.37% | Turnover=11.50%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7495 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1252 | critic_loss=0.6185 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3093 | risk_aux_total=0.0035 | sharpe_proxy=-0.1165 | sharpe_loss=0.0035 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.64 | std=0.27 | range=[0.97, 2.21]\n",
      "   ðŸŽ¯ Episode 51: TAPE Score = 0.5006 (bonus: +2.25 â†’ +2.25)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00051_shp0p993_actor.weights.h5 (Sharpe=0.993)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.065360 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 41/216 | Step 15,744/100,000 | Episode 51 | Time: 2289.7s\n",
      "   ðŸ“Š Metrics: Return=+47.69% | Sharpe=0.993 | DD=21.37% | Turnover=11.53%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6576 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0971 | critic_loss=1.2486 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.6243 | risk_aux_total=0.0027 | sharpe_proxy=-0.0890 | sharpe_loss=0.0027 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.502 (peak 1.007, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.018) | TAPE=0.5006\n",
      "   ðŸŽ¯ Episode 52: TAPE Score = 0.2199 (bonus: -0.15 â†’ -0.15)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.099, MDD=39.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020099 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 42/216 | Step 16,128/100,000 | Episode 52 | Time: 2344.8s\n",
      "   ðŸ“Š Metrics: Return=-0.08% | Sharpe=0.099 | DD=39.06% | Turnover=11.32%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4783 | delta_reward=-0.0008\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0449 | critic_loss=0.6111 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3056 | risk_aux_total=0.0049 | sharpe_proxy=-0.1624 | sharpe_loss=0.0049 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 6.08% / trig 16.50%) | terminal=0.000 (peak 1.007) | TAPE=0.2199\n",
      "   ðŸŽ¯ Episode 53: TAPE Score = 0.3131 (bonus: +0.85 â†’ +0.85)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00053_shp0p553_actor.weights.h5 (Sharpe=0.553)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016750 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 43/216 | Step 16,512/100,000 | Episode 53 | Time: 2402.5s\n",
      "   ðŸ“Š Metrics: Return=+20.64% | Sharpe=0.553 | DD=14.00% | Turnover=11.19%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2314 | delta_reward=-0.0006\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0259 | critic_loss=0.4249 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2124 | risk_aux_total=-0.0012 | sharpe_proxy=0.0407 | sharpe_loss=-0.0012 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 7.02% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3131\n",
      "   ðŸŽ¯ Episode 54: TAPE Score = 0.4491 (bonus: -1.87 â†’ -1.87)\n",
      "      ðŸš¦ Gate A applied: Sharpe=1.029, MDD=31.16%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00054_shp1p029_actor.weights.h5 (Sharpe=1.029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.050937 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 44/216 | Step 16,896/100,000 | Episode 54 | Time: 2457.9s\n",
      "   ðŸ“Š Metrics: Return=+61.99% | Sharpe=1.029 | DD=31.16% | Turnover=11.21%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0296 | critic_loss=0.8781 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4390 | risk_aux_total=0.0039 | sharpe_proxy=-0.1299 | sharpe_loss=0.0039 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.78% / trig 16.50%) | terminal=0.000 (peak 0.104) | TAPE=0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.092675 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 45/216 | Step 17,280/100,000 | Episode 54 | Time: 2512.9s\n",
      "   ðŸ“Š Metrics: Return=+4.49% | Sharpe=0.196 | DD=37.35% | Turnover=11.56%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2429 | delta_reward=-0.0008\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0327 | critic_loss=1.1307 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.5653 | risk_aux_total=0.0016 | sharpe_proxy=-0.0515 | sharpe_loss=0.0015 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 55: TAPE Score = 0.2171 (bonus: -0.13 â†’ -0.13)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.057, MDD=37.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027018 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 46/216 | Step 17,664/100,000 | Episode 55 | Time: 2568.3s\n",
      "   ðŸ“Š Metrics: Return=-2.47% | Sharpe=0.057 | DD=37.35% | Turnover=11.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7230 | delta_reward=-0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0533 | critic_loss=0.4075 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2037 | risk_aux_total=0.0013 | sharpe_proxy=-0.0435 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.36% / trig 16.50%) | terminal=0.000 (peak 0.893) | TAPE=0.2171\n",
      "   ðŸŽ¯ Episode 56: TAPE Score = 0.5960 (bonus: +2.97 â†’ +2.97)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00056_shp1p425_actor.weights.h5 (Sharpe=1.425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016517 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 47/216 | Step 18,048/100,000 | Episode 56 | Time: 2623.4s\n",
      "   ðŸ“Š Metrics: Return=+36.55% | Sharpe=1.425 | DD=6.99% | Turnover=11.11%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4554 | delta_reward=-0.0010\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0165 | critic_loss=0.2660 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1330 | risk_aux_total=0.0002 | sharpe_proxy=-0.0049 | sharpe_loss=0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.50% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5960\n",
      "   ðŸŽ¯ Episode 57: TAPE Score = 0.6323 (bonus: +3.24 â†’ +3.24)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00057_shp1p714_actor.weights.h5 (Sharpe=1.714)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.047427 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 48/216 | Step 18,432/100,000 | Episode 57 | Time: 2681.3s\n",
      "   ðŸ“Š Metrics: Return=+45.26% | Sharpe=1.714 | DD=8.29% | Turnover=11.13%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7027 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0206 | critic_loss=0.2900 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1450 | risk_aux_total=-0.0018 | sharpe_proxy=0.0601 | sharpe_loss=-0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.59% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6323\n",
      "ðŸ”„ Update 49/216 | Step 18,816/100,000 | Episode 57 | Time: 2739.0s\n",
      "   ðŸ“Š Metrics: Return=+34.45% | Sharpe=1.590 | DD=6.33% | Turnover=10.98%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5759 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0223 | critic_loss=0.3883 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1941 | risk_aux_total=-0.0010 | sharpe_proxy=0.0349 | sharpe_loss=-0.0010 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 58: TAPE Score = 0.6349 (bonus: +3.26 â†’ +3.26)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00058_shp1p589_actor.weights.h5 (Sharpe=1.589)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018710 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 50/216 | Step 19,200/100,000 | Episode 58 | Time: 2795.8s\n",
      "   ðŸ“Š Metrics: Return=+41.14% | Sharpe=1.589 | DD=6.33% | Turnover=10.99%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2364 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0076 | critic_loss=0.3948 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1974 | risk_aux_total=-0.0006 | sharpe_proxy=0.0216 | sharpe_loss=-0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.68 | std=0.29 | range=[0.97, 2.22]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.27% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6349\n",
      "   ðŸŽ¯ Episode 59: TAPE Score = 0.2589 (bonus: -0.44 â†’ -0.44)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.502, MDD=31.07%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00059_shp0p502_actor.weights.h5 (Sharpe=0.502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.056016 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 51/216 | Step 19,584/100,000 | Episode 59 | Time: 2851.1s\n",
      "   ðŸ“Š Metrics: Return=+25.31% | Sharpe=0.502 | DD=31.07% | Turnover=11.17%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7142 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1067 | critic_loss=1.2723 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.6362 | risk_aux_total=0.0038 | sharpe_proxy=-0.1259 | sharpe_loss=0.0038 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.58% / trig 16.50%) | terminal=0.000 (peak 0.099) | TAPE=0.2589\n",
      "   ðŸŽ¯ Episode 60: TAPE Score = 0.5464 (bonus: +2.60 â†’ +2.60)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p136_actor.weights.h5 (Sharpe=1.136)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020376 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 52/216 | Step 19,968/100,000 | Episode 60 | Time: 2906.3s\n",
      "   ðŸ“Š Metrics: Return=+34.69% | Sharpe=1.136 | DD=9.95% | Turnover=11.14%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6962 | delta_reward=+0.0010\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0590 | critic_loss=0.3745 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1872 | risk_aux_total=0.0018 | sharpe_proxy=-0.0589 | sharpe_loss=0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5464\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step020000_actor.weights.h5\n",
      "ðŸ”„ Update 53/216 | Step 20,352/100,000 | Episode 60 | Time: 2964.1s\n",
      "   ðŸ“Š Metrics: Return=+28.44% | Sharpe=1.185 | DD=10.41% | Turnover=11.07%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2402 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0228 | critic_loss=0.4240 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2120 | risk_aux_total=-0.0005 | sharpe_proxy=0.0189 | sharpe_loss=-0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 61: TAPE Score = 0.4702 (bonus: +2.03 â†’ +2.03)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00061_shp0p934_actor.weights.h5 (Sharpe=0.934)\n",
      "ðŸ”„ Update 54/216 | Step 20,736/100,000 | Episode 61 | Time: 3021.6s\n",
      "   ðŸ“Š Metrics: Return=+28.76% | Sharpe=0.934 | DD=12.64% | Turnover=11.07%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7324 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0230 | critic_loss=0.3259 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1630 | risk_aux_total=-0.0002 | sharpe_proxy=0.0063 | sharpe_loss=-0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.78% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4702\n",
      "   ðŸŽ¯ Episode 62: TAPE Score = 0.4532 (bonus: +1.90 â†’ +1.90)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00062_shp0p871_actor.weights.h5 (Sharpe=0.871)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027467 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 55/216 | Step 21,120/100,000 | Episode 62 | Time: 3076.7s\n",
      "   ðŸ“Š Metrics: Return=+27.03% | Sharpe=0.871 | DD=12.17% | Turnover=11.21%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2267 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1056 | critic_loss=0.5073 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2536 | risk_aux_total=0.0024 | sharpe_proxy=-0.0794 | sharpe_loss=0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 11.12% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4532\n",
      "   ðŸŽ¯ Episode 63: TAPE Score = 0.4172 (bonus: -1.63 â†’ -1.63)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.950, MDD=30.61%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00063_shp0p950_actor.weights.h5 (Sharpe=0.950)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020251 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 56/216 | Step 21,504/100,000 | Episode 63 | Time: 3131.9s\n",
      "   ðŸ“Š Metrics: Return=+54.89% | Sharpe=0.950 | DD=30.61% | Turnover=11.16%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2373 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0702 | critic_loss=0.6998 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3499 | risk_aux_total=-0.0037 | sharpe_proxy=0.1242 | sharpe_loss=-0.0037 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.43% / trig 16.50%) | terminal=0.000 (peak 0.100) | TAPE=0.4172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026848 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 57/216 | Step 21,888/100,000 | Episode 63 | Time: 3186.9s\n",
      "   ðŸ“Š Metrics: Return=+51.63% | Sharpe=0.940 | DD=30.55% | Turnover=11.35%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7318 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0603 | critic_loss=0.8910 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4455 | risk_aux_total=-0.0019 | sharpe_proxy=0.0657 | sharpe_loss=-0.0020 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 64: TAPE Score = 0.4026 (bonus: -1.52 â†’ -1.52)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.920, MDD=30.55%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00064_shp0p920_actor.weights.h5 (Sharpe=0.920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016090 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 58/216 | Step 22,272/100,000 | Episode 64 | Time: 3242.1s\n",
      "   ðŸ“Š Metrics: Return=+53.29% | Sharpe=0.920 | DD=30.55% | Turnover=11.37%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6728 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0650 | critic_loss=0.2497 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1249 | risk_aux_total=0.0009 | sharpe_proxy=-0.0297 | sharpe_loss=0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 4.40% / trig 16.50%) | terminal=0.000 (peak 0.095) | TAPE=0.4026\n",
      "   ðŸŽ¯ Episode 65: TAPE Score = 0.5146 (bonus: +2.36 â†’ +2.36)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00065_shp1p063_actor.weights.h5 (Sharpe=1.063)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.055974 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 59/216 | Step 22,656/100,000 | Episode 65 | Time: 3298.0s\n",
      "   ðŸ“Š Metrics: Return=+32.81% | Sharpe=1.063 | DD=12.41% | Turnover=11.04%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2046 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0496 | critic_loss=0.9142 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4571 | risk_aux_total=0.0017 | sharpe_proxy=-0.0551 | sharpe_loss=0.0017 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.591 (peak 0.591, dd 25.43% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5146\n",
      "   ðŸŽ¯ Episode 66: TAPE Score = 0.2148 (bonus: -0.11 â†’ -0.11)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.026, MDD=42.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.126118 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 60/216 | Step 23,040/100,000 | Episode 66 | Time: 3353.2s\n",
      "   ðŸ“Š Metrics: Return=-4.39% | Sharpe=0.026 | DD=42.36% | Turnover=11.57%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7573 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.2074 | critic_loss=0.8487 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4243 | risk_aux_total=0.0007 | sharpe_proxy=-0.0228 | sharpe_loss=0.0007 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.50 | std=0.37 | range=[0.63, 2.37]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.696 (peak 1.260, dd 0.89% / trig 16.50%) | terminal=1.800 (peak 2.084) | TAPE=0.2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018990 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 61/216 | Step 23,424/100,000 | Episode 66 | Time: 3408.2s\n",
      "   ðŸ“Š Metrics: Return=+32.37% | Sharpe=1.049 | DD=9.95% | Turnover=11.04%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2508 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1528 | critic_loss=0.2713 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1356 | risk_aux_total=0.0028 | sharpe_proxy=-0.0913 | sharpe_loss=0.0027 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 67: TAPE Score = 0.5696 (bonus: +2.77 â†’ +2.77)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00067_shp1p185_actor.weights.h5 (Sharpe=1.185)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027140 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 62/216 | Step 23,808/100,000 | Episode 67 | Time: 3463.3s\n",
      "   ðŸ“Š Metrics: Return=+37.87% | Sharpe=1.185 | DD=9.95% | Turnover=11.05%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2610 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1536 | critic_loss=0.3466 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1733 | risk_aux_total=0.0016 | sharpe_proxy=-0.0533 | sharpe_loss=0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.82% / trig 16.50%) | terminal=0.000 (peak 1.260) | TAPE=0.5696\n",
      "   ðŸŽ¯ Episode 68: TAPE Score = 0.2934 (bonus: +0.70 â†’ +0.70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032100 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 63/216 | Step 24,192/100,000 | Episode 68 | Time: 3519.0s\n",
      "   ðŸ“Š Metrics: Return=+13.59% | Sharpe=0.392 | DD=11.57% | Turnover=10.96%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7434 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0558 | critic_loss=0.1936 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0968 | risk_aux_total=-0.0008 | sharpe_proxy=0.0290 | sharpe_loss=-0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.2934\n",
      "   ðŸŽ¯ Episode 69: TAPE Score = 0.6841 (bonus: +3.63 â†’ +3.63)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00069_shp1p922_actor.weights.h5 (Sharpe=1.922)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038037 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 64/216 | Step 24,576/100,000 | Episode 69 | Time: 3574.9s\n",
      "   ðŸ“Š Metrics: Return=+53.88% | Sharpe=1.922 | DD=4.72% | Turnover=10.97%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2313 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0178 | critic_loss=0.5130 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2565 | risk_aux_total=0.0013 | sharpe_proxy=-0.0418 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 7.06% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6841\n",
      "   ðŸŽ¯ Episode 70: TAPE Score = 0.3777 (bonus: +1.33 â†’ +1.33)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00070_shp0p735_actor.weights.h5 (Sharpe=0.735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019074 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 65/216 | Step 24,960/100,000 | Episode 70 | Time: 3630.8s\n",
      "   ðŸ“Š Metrics: Return=+24.02% | Sharpe=0.735 | DD=11.91% | Turnover=11.17%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0471 | critic_loss=0.3687 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1843 | risk_aux_total=0.0016 | sharpe_proxy=-0.0536 | sharpe_loss=0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.16% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3777\n",
      "\n",
      "ðŸ“š TURNOVER CURRICULUM UPDATE at 25,344 steps:\n",
      "   Turnover penalty scalar: 2.5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 25,344 steps:\n",
      "   Episode horizon: 756 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041132 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 66/216 | Step 25,344/100,000 | Episode 70 | Time: 3686.7s\n",
      "   ðŸ“Š Metrics: Return=+30.83% | Sharpe=1.645 | DD=10.66% | Turnover=11.14%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2299 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0260 | critic_loss=0.3172 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1586 | risk_aux_total=-0.0024 | sharpe_proxy=0.0792 | sharpe_loss=-0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 71: TAPE Score = 0.5212 (bonus: +2.41 â†’ +2.41)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00071_shp1p081_actor.weights.h5 (Sharpe=1.081)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.014970 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 67/216 | Step 25,728/100,000 | Episode 71 | Time: 3742.8s\n",
      "   ðŸ“Š Metrics: Return=+51.13% | Sharpe=1.081 | DD=12.76% | Turnover=11.13%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2448 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0739 | critic_loss=0.4306 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2153 | risk_aux_total=0.0022 | sharpe_proxy=-0.0721 | sharpe_loss=0.0022 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.24% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030035 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 68/216 | Step 26,112/100,000 | Episode 71 | Time: 3797.8s\n",
      "   ðŸ“Š Metrics: Return=+26.76% | Sharpe=1.334 | DD=9.03% | Turnover=10.81%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7488 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0433 | critic_loss=0.3314 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1657 | risk_aux_total=-0.0041 | sharpe_proxy=0.1381 | sharpe_loss=-0.0041 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 72: TAPE Score = 0.3714 (bonus: +1.29 â†’ +1.29)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00072_shp0p688_actor.weights.h5 (Sharpe=0.688)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038326 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 69/216 | Step 26,496/100,000 | Episode 72 | Time: 3853.6s\n",
      "   ðŸ“Š Metrics: Return=+34.53% | Sharpe=0.688 | DD=16.66% | Turnover=10.90%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2391 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0348 | critic_loss=0.4229 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2114 | risk_aux_total=0.0009 | sharpe_proxy=-0.0279 | sharpe_loss=0.0008 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.06% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.045198 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 70/216 | Step 26,880/100,000 | Episode 72 | Time: 3909.3s\n",
      "   ðŸ“Š Metrics: Return=+25.57% | Sharpe=1.083 | DD=8.12% | Turnover=11.02%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6439 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0005 | critic_loss=0.3092 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1546 | risk_aux_total=-0.0013 | sharpe_proxy=0.0437 | sharpe_loss=-0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.64 | std=0.30 | range=[0.96, 2.16]\n",
      "   ðŸŽ¯ Episode 73: TAPE Score = 0.2106 (bonus: -0.08 â†’ -0.08)\n",
      "      ðŸš¦ Gate A applied: Sharpe=-0.199, MDD=39.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.125006 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 71/216 | Step 27,264/100,000 | Episode 73 | Time: 3963.4s\n",
      "   ðŸ“Š Metrics: Return=-16.75% | Sharpe=-0.199 | DD=39.96% | Turnover=11.23%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6452 | delta_reward=+0.0009\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1107 | critic_loss=1.1006 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.5503 | risk_aux_total=0.0019 | sharpe_proxy=-0.0612 | sharpe_loss=0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.679 (peak 0.935, dd 0.60% / trig 16.50%) | terminal=1.335 (peak 1.335) | TAPE=0.2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031836 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 72/216 | Step 27,648/100,000 | Episode 73 | Time: 4018.2s\n",
      "   ðŸ“Š Metrics: Return=+29.81% | Sharpe=1.021 | DD=12.07% | Turnover=11.28%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5566 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1250 | critic_loss=0.4321 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2161 | risk_aux_total=-0.0024 | sharpe_proxy=0.0811 | sharpe_loss=-0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 74: TAPE Score = 0.3447 (bonus: +1.09 â†’ +1.09)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00074_shp0p628_actor.weights.h5 (Sharpe=0.628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035563 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 73/216 | Step 28,032/100,000 | Episode 74 | Time: 4073.9s\n",
      "   ðŸ“Š Metrics: Return=+38.13% | Sharpe=0.628 | DD=14.69% | Turnover=11.22%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2477 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0021 | critic_loss=0.4066 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2033 | risk_aux_total=0.0001 | sharpe_proxy=-0.0014 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.85% / trig 16.50%) | terminal=0.000 (peak 0.935) | TAPE=0.3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025218 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 74/216 | Step 28,416/100,000 | Episode 74 | Time: 4128.3s\n",
      "   ðŸ“Š Metrics: Return=+9.65% | Sharpe=0.305 | DD=12.36% | Turnover=11.25%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5767 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1093 | critic_loss=0.3233 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1617 | risk_aux_total=0.0004 | sharpe_proxy=-0.0119 | sharpe_loss=0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 75: TAPE Score = 0.4968 (bonus: +2.23 â†’ +2.23)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00075_shp0p938_actor.weights.h5 (Sharpe=0.938)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.017248 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 75/216 | Step 28,800/100,000 | Episode 75 | Time: 4183.7s\n",
      "   ðŸ“Š Metrics: Return=+44.04% | Sharpe=0.938 | DD=12.36% | Turnover=11.21%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7327 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0409 | critic_loss=0.2362 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1181 | risk_aux_total=-0.0045 | sharpe_proxy=0.1507 | sharpe_loss=-0.0045 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.42% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.055641 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 76/216 | Step 29,184/100,000 | Episode 75 | Time: 4238.2s\n",
      "   ðŸ“Š Metrics: Return=+37.47% | Sharpe=1.575 | DD=6.53% | Turnover=10.96%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7037 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0177 | critic_loss=0.3365 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1682 | risk_aux_total=-0.0030 | sharpe_proxy=0.1009 | sharpe_loss=-0.0030 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 76: TAPE Score = 0.4639 (bonus: +1.98 â†’ +1.98)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00076_shp0p867_actor.weights.h5 (Sharpe=0.867)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.068543 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 77/216 | Step 29,568/100,000 | Episode 76 | Time: 4292.7s\n",
      "   ðŸ“Š Metrics: Return=+43.65% | Sharpe=0.867 | DD=15.89% | Turnover=11.02%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2420 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0774 | critic_loss=0.3867 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1934 | risk_aux_total=0.0013 | sharpe_proxy=-0.0428 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 11.06% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.079839 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 78/216 | Step 29,952/100,000 | Episode 76 | Time: 4347.1s\n",
      "   ðŸ“Š Metrics: Return=-6.22% | Sharpe=-0.009 | DD=42.38% | Turnover=11.61%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2353 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1196 | critic_loss=1.1870 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.5935 | risk_aux_total=0.0054 | sharpe_proxy=-0.1798 | sharpe_loss=0.0054 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸŽ¯ Episode 77: TAPE Score = 0.2267 (bonus: -0.20 â†’ -0.20)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.169, MDD=42.38%\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step030000_actor.weights.h5\n",
      "\n",
      "ðŸŽ›ï¸ EXECUTION BETA UPDATE at 30,336 steps:\n",
      "   action_execution_beta: 0.350 (w_exec=(1-Î²)w_prev + Î²w_raw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034336 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 79/216 | Step 30,336/100,000 | Episode 77 | Time: 4402.9s\n",
      "   ðŸ“Š Metrics: Return=+9.26% | Sharpe=0.169 | DD=42.38% | Turnover=11.53%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2647 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0498 | critic_loss=0.3139 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1570 | risk_aux_total=-0.0006 | sharpe_proxy=0.0209 | sharpe_loss=-0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=384 | batch_size=96\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.295, dd 2.04% / trig 16.50%) | terminal=0.422 (peak 1.962) | TAPE=0.2267\n",
      "\n",
      "ðŸ“š PPO ROLLOUT UPDATE at 30,336 steps:\n",
      "   Timesteps per update: 512\n",
      "\n",
      "ðŸ“š PPO BATCH SIZE UPDATE at 30,336 steps:\n",
      "   Batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030113 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 80/216 | Step 30,848/100,000 | Episode 77 | Time: 4477.3s\n",
      "   ðŸ“Š Metrics: Return=+27.03% | Sharpe=0.708 | DD=12.04% | Turnover=18.88%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7115 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1385 | critic_loss=0.3079 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1540 | risk_aux_total=-0.0028 | sharpe_proxy=0.0937 | sharpe_loss=-0.0028 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.66 | std=0.27 | range=[0.98, 2.09]\n",
      "   ðŸŽ¯ Episode 78: TAPE Score = 0.5319 (bonus: +2.49 â†’ +2.49)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00078_shp1p084_actor.weights.h5 (Sharpe=1.084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.066835 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 81/216 | Step 31,360/100,000 | Episode 78 | Time: 4550.1s\n",
      "   ðŸ“Š Metrics: Return=+50.49% | Sharpe=1.084 | DD=12.04% | Turnover=19.15%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3293 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0639 | critic_loss=1.0767 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.5384 | risk_aux_total=0.0024 | sharpe_proxy=-0.0791 | sharpe_loss=0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=2.583 (peak 2.583, dd 30.18% / trig 16.50%) | terminal=0.000 (peak 0.295) | TAPE=0.5319\n",
      "   ðŸŽ¯ Episode 79: TAPE Score = 0.2133 (bonus: -0.10 â†’ -0.10)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.055, MDD=46.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.082173 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 82/216 | Step 31,872/100,000 | Episode 79 | Time: 4623.7s\n",
      "   ðŸ“Š Metrics: Return=-0.71% | Sharpe=0.055 | DD=46.46% | Turnover=20.75%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6783 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0200 | critic_loss=0.5704 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2852 | risk_aux_total=0.0014 | sharpe_proxy=-0.0455 | sharpe_loss=0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=1.441 (peak 2.069, dd 2.14% / trig 16.50%) | terminal=2.956 (peak 3.299) | TAPE=0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015548 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 83/216 | Step 32,384/100,000 | Episode 79 | Time: 4699.0s\n",
      "   ðŸ“Š Metrics: Return=+21.47% | Sharpe=0.537 | DD=13.24% | Turnover=20.52%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2407 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0037 | critic_loss=0.2744 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1372 | risk_aux_total=0.0003 | sharpe_proxy=-0.0090 | sharpe_loss=0.0003 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 80: TAPE Score = 0.2396 (bonus: +0.30 â†’ +0.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.079069 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 84/216 | Step 32,896/100,000 | Episode 80 | Time: 4772.5s\n",
      "   ðŸ“Š Metrics: Return=+11.65% | Sharpe=0.195 | DD=21.78% | Turnover=20.62%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6800 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0021 | critic_loss=0.9549 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4775 | risk_aux_total=0.0022 | sharpe_proxy=-0.0729 | sharpe_loss=0.0022 | mvo_loss=0.0001\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=2.526 (peak 2.526, dd 20.46% / trig 16.50%) | terminal=0.082 (peak 2.069) | TAPE=0.2396\n",
      "   ðŸŽ¯ Episode 81: TAPE Score = 0.2138 (bonus: -0.10 â†’ -0.10)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.048, MDD=44.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034882 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 85/216 | Step 33,408/100,000 | Episode 81 | Time: 4846.7s\n",
      "   ðŸ“Š Metrics: Return=-1.31% | Sharpe=0.048 | DD=44.51% | Turnover=20.84%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3132 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1120 | critic_loss=0.2974 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1487 | risk_aux_total=-0.0004 | sharpe_proxy=0.0136 | sharpe_loss=-0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.701 (peak 1.448, dd 0.53% / trig 16.50%) | terminal=2.069 (peak 2.577) | TAPE=0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021623 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 86/216 | Step 33,920/100,000 | Episode 81 | Time: 4922.0s\n",
      "   ðŸ“Š Metrics: Return=+19.14% | Sharpe=0.437 | DD=11.02% | Turnover=20.45%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5065 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0608 | critic_loss=0.3530 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1765 | risk_aux_total=0.0014 | sharpe_proxy=-0.0453 | sharpe_loss=0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 82: TAPE Score = 0.3411 (bonus: +1.06 â†’ +1.06)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00082_shp0p589_actor.weights.h5 (Sharpe=0.589)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025557 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 87/216 | Step 34,432/100,000 | Episode 82 | Time: 4995.4s\n",
      "   ðŸ“Š Metrics: Return=+29.12% | Sharpe=0.589 | DD=11.02% | Turnover=20.39%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2664 | delta_reward=-0.0005\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0032 | critic_loss=0.3593 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1796 | risk_aux_total=-0.0004 | sharpe_proxy=0.0129 | sharpe_loss=-0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 9.47% / trig 16.50%) | terminal=0.000 (peak 1.448) | TAPE=0.3411\n",
      "   ðŸŽ¯ Episode 83: TAPE Score = 0.2268 (bonus: -0.20 â†’ -0.20)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.220, MDD=46.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.152659 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 88/216 | Step 34,944/100,000 | Episode 83 | Time: 5068.8s\n",
      "   ðŸ“Š Metrics: Return=+13.76% | Sharpe=0.220 | DD=46.61% | Turnover=20.92%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7533 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0135 | critic_loss=1.2607 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.6303 | risk_aux_total=-0.0020 | sharpe_proxy=0.0667 | sharpe_loss=-0.0020 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000010 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=1.388 (peak 1.967, dd 1.49% / trig 16.50%) | terminal=2.810 (peak 2.825) | TAPE=0.2268\n",
      "   ðŸ”§ Actor learning rate adjusted to 0.000008 at step 35,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015528 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 89/216 | Step 35,456/100,000 | Episode 83 | Time: 5143.2s\n",
      "   ðŸ“Š Metrics: Return=+35.84% | Sharpe=0.711 | DD=17.26% | Turnover=20.50%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6326 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0281 | critic_loss=0.2466 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1233 | risk_aux_total=0.0005 | sharpe_proxy=-0.0173 | sharpe_loss=0.0005 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 84: TAPE Score = 0.3653 (bonus: +1.24 â†’ +1.24)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00084_shp0p723_actor.weights.h5 (Sharpe=0.723)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018697 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 90/216 | Step 35,968/100,000 | Episode 84 | Time: 5216.9s\n",
      "   ðŸ“Š Metrics: Return=+39.90% | Sharpe=0.723 | DD=17.26% | Turnover=20.56%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7024 | delta_reward=+0.0013\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0086 | critic_loss=0.3568 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1784 | risk_aux_total=-0.0010 | sharpe_proxy=0.0351 | sharpe_loss=-0.0011 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.63 | std=0.27 | range=[0.98, 2.17]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.12% / trig 16.50%) | terminal=0.000 (peak 1.967) | TAPE=0.3653\n",
      "   ðŸŽ¯ Episode 85: TAPE Score = 0.3872 (bonus: +1.40 â†’ +1.40)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00085_shp0p712_actor.weights.h5 (Sharpe=0.712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025310 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 91/216 | Step 36,480/100,000 | Episode 85 | Time: 5290.3s\n",
      "   ðŸ“Š Metrics: Return=+34.05% | Sharpe=0.712 | DD=11.34% | Turnover=20.26%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7338 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0021 | critic_loss=0.2457 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1228 | risk_aux_total=-0.0001 | sharpe_proxy=0.0034 | sharpe_loss=-0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.88% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024827 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 92/216 | Step 36,992/100,000 | Episode 85 | Time: 5365.5s\n",
      "   ðŸ“Š Metrics: Return=+34.19% | Sharpe=0.854 | DD=7.30% | Turnover=20.82%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5776 | delta_reward=+0.0011\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0321 | critic_loss=0.4676 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2338 | risk_aux_total=0.0006 | sharpe_proxy=-0.0194 | sharpe_loss=0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 86: TAPE Score = 0.3013 (bonus: +0.76 â†’ +0.76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027340 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 93/216 | Step 37,504/100,000 | Episode 86 | Time: 5438.8s\n",
      "   ðŸ“Š Metrics: Return=+22.49% | Sharpe=0.478 | DD=13.18% | Turnover=20.81%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7340 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0379 | critic_loss=0.3658 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1829 | risk_aux_total=0.0006 | sharpe_proxy=-0.0195 | sharpe_loss=0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.06% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3013\n",
      "   ðŸŽ¯ Episode 87: TAPE Score = 0.2865 (bonus: -0.65 â†’ -0.65)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.633, MDD=31.25%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00087_shp0p633_actor.weights.h5 (Sharpe=0.633)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.060603 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 94/216 | Step 38,016/100,000 | Episode 87 | Time: 5513.3s\n",
      "   ðŸ“Š Metrics: Return=+49.43% | Sharpe=0.633 | DD=31.25% | Turnover=20.88%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6828 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0071 | critic_loss=0.6812 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3406 | risk_aux_total=0.0000 | sharpe_proxy=0.0005 | sharpe_loss=-0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.121) | TAPE=0.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024909 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 95/216 | Step 38,528/100,000 | Episode 87 | Time: 5587.4s\n",
      "   ðŸ“Š Metrics: Return=+13.23% | Sharpe=0.224 | DD=15.93% | Turnover=20.55%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2386 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0183 | critic_loss=0.3479 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1739 | risk_aux_total=0.0014 | sharpe_proxy=-0.0463 | sharpe_loss=0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 88: TAPE Score = 0.2649 (bonus: +0.49 â†’ +0.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034809 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 96/216 | Step 39,040/100,000 | Episode 88 | Time: 5660.8s\n",
      "   ðŸ“Š Metrics: Return=+18.30% | Sharpe=0.307 | DD=15.93% | Turnover=20.53%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5831 | delta_reward=+0.0009\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1009 | critic_loss=0.3652 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1826 | risk_aux_total=-0.0024 | sharpe_proxy=0.0824 | sharpe_loss=-0.0025 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 3.49% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.2649\n",
      "   ðŸŽ¯ Episode 89: TAPE Score = 0.4483 (bonus: +1.86 â†’ +1.86)\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00089_shp0p872_actor.weights.h5 (Sharpe=0.872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041331 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 97/216 | Step 39,552/100,000 | Episode 89 | Time: 5734.2s\n",
      "   ðŸ“Š Metrics: Return=+49.86% | Sharpe=0.872 | DD=14.92% | Turnover=20.83%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3007 | delta_reward=+0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0543 | critic_loss=0.2409 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1205 | risk_aux_total=0.0024 | sharpe_proxy=-0.0804 | sharpe_loss=0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.39% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4483\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step040000_actor.weights.h5\n",
      "\n",
      "ðŸ“š TURNOVER CURRICULUM UPDATE at 40,064 steps:\n",
      "   Turnover penalty scalar: 3.0\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 40,064 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.064406 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 98/216 | Step 40,064/100,000 | Episode 89 | Time: 5808.0s\n",
      "   ðŸ“Š Metrics: Return=+56.90% | Sharpe=0.719 | DD=31.11% | Turnover=20.69%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3289 | delta_reward=+0.0008\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0249 | critic_loss=0.5057 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2529 | risk_aux_total=0.0013 | sharpe_proxy=-0.0444 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 90: TAPE Score = 0.3215 (bonus: -0.91 â†’ -0.91)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.736, MDD=31.11%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00090_shp0p736_actor.weights.h5 (Sharpe=0.736)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 40,576 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035831 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 99/216 | Step 40,576/100,000 | Episode 90 | Time: 5882.2s\n",
      "   ðŸ“Š Metrics: Return=+59.82% | Sharpe=0.736 | DD=31.11% | Turnover=20.70%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2536 | delta_reward=-0.0016\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0069 | critic_loss=0.2561 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1280 | risk_aux_total=-0.0015 | sharpe_proxy=0.0509 | sharpe_loss=-0.0015 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 3.87% / trig 16.50%) | terminal=0.000 (peak 0.106) | TAPE=0.3215\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 41,088 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025706 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 100/216 | Step 41,088/100,000 | Episode 90 | Time: 5957.3s\n",
      "   ðŸ“Š Metrics: Return=+43.34% | Sharpe=0.610 | DD=11.78% | Turnover=20.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2368 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0276 | critic_loss=0.3303 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1652 | risk_aux_total=0.0009 | sharpe_proxy=-0.0308 | sharpe_loss=0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.62 | std=0.26 | range=[0.98, 2.19]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 41,600 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018570 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 101/216 | Step 41,600/100,000 | Episode 90 | Time: 6030.7s\n",
      "   ðŸ“Š Metrics: Return=+114.11% | Sharpe=0.939 | DD=11.78% | Turnover=20.37%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7398 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0366 | critic_loss=0.2226 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1113 | risk_aux_total=-0.0002 | sharpe_proxy=0.0081 | sharpe_loss=-0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 42,112 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.023693 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 102/216 | Step 42,112/100,000 | Episode 90 | Time: 6104.1s\n",
      "   ðŸ“Š Metrics: Return=+163.88% | Sharpe=0.872 | DD=12.93% | Turnover=20.38%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2355 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0639 | critic_loss=0.3727 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1863 | risk_aux_total=0.0009 | sharpe_proxy=-0.0298 | sharpe_loss=0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 91: TAPE Score = 0.3831 (bonus: -1.37 â†’ -1.37)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.861, MDD=30.96%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00091_shp0p861_actor.weights.h5 (Sharpe=0.861)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 42,624 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030887 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 103/216 | Step 42,624/100,000 | Episode 91 | Time: 6178.7s\n",
      "   ðŸ“Š Metrics: Return=+303.78% | Sharpe=0.861 | DD=30.96% | Turnover=20.52%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6981 | delta_reward=-0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0284 | critic_loss=0.3757 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1878 | risk_aux_total=-0.0013 | sharpe_proxy=0.0450 | sharpe_loss=-0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.70% / trig 16.50%) | terminal=0.000 (peak 0.106) | TAPE=0.3831\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 43,136 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.049708 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 104/216 | Step 43,136/100,000 | Episode 91 | Time: 6253.0s\n",
      "   ðŸ“Š Metrics: Return=+29.57% | Sharpe=0.539 | DD=29.07% | Turnover=21.15%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6644 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0083 | critic_loss=0.5231 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2616 | risk_aux_total=0.0002 | sharpe_proxy=-0.0059 | sharpe_loss=0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 92: TAPE Score = 0.3508 (bonus: -1.13 â†’ -1.13)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.798, MDD=29.07%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00092_shp0p798_actor.weights.h5 (Sharpe=0.798)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 43,648 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024622 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 105/216 | Step 43,648/100,000 | Episode 92 | Time: 6325.3s\n",
      "   ðŸ“Š Metrics: Return=+70.27% | Sharpe=0.798 | DD=29.07% | Turnover=21.15%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5215 | delta_reward=+0.0028\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0391 | critic_loss=0.2540 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1270 | risk_aux_total=-0.0028 | sharpe_proxy=0.0929 | sharpe_loss=-0.0028 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.52% / trig 16.50%) | terminal=0.000 (peak 0.074) | TAPE=0.3508\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 44,160 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.052932 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 106/216 | Step 44,160/100,000 | Episode 92 | Time: 6401.0s\n",
      "   ðŸ“Š Metrics: Return=+24.62% | Sharpe=0.498 | DD=12.04% | Turnover=20.59%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2382 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0245 | critic_loss=0.2959 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1480 | risk_aux_total=0.0012 | sharpe_proxy=-0.0403 | sharpe_loss=0.0012 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 44,672 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018886 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 107/216 | Step 44,672/100,000 | Episode 92 | Time: 6473.5s\n",
      "   ðŸ“Š Metrics: Return=+76.58% | Sharpe=0.860 | DD=12.04% | Turnover=20.58%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2837 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0033 | critic_loss=0.2079 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1039 | risk_aux_total=-0.0036 | sharpe_proxy=0.1200 | sharpe_loss=-0.0036 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 45,184 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.055861 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 108/216 | Step 45,184/100,000 | Episode 92 | Time: 6546.0s\n",
      "   ðŸ“Š Metrics: Return=+131.43% | Sharpe=0.678 | DD=31.77% | Turnover=20.69%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6518 | delta_reward=+0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1123 | critic_loss=0.6313 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3157 | risk_aux_total=-0.0037 | sharpe_proxy=0.1237 | sharpe_loss=-0.0037 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 93: TAPE Score = 0.3558 (bonus: -1.17 â†’ -1.17)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.817, MDD=31.77%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00093_shp0p817_actor.weights.h5 (Sharpe=0.817)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 45,696 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020553 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 109/216 | Step 45,696/100,000 | Episode 93 | Time: 6619.2s\n",
      "   ðŸ“Š Metrics: Return=+196.17% | Sharpe=0.817 | DD=31.77% | Turnover=20.69%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7351 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0245 | critic_loss=0.2375 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1188 | risk_aux_total=-0.0012 | sharpe_proxy=0.0403 | sharpe_loss=-0.0012 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.06% / trig 16.50%) | terminal=0.000 (peak 0.121) | TAPE=0.3558\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 46,208 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.054961 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 110/216 | Step 46,208/100,000 | Episode 93 | Time: 6691.0s\n",
      "   ðŸ“Š Metrics: Return=-8.65% | Sharpe=-0.084 | DD=43.38% | Turnover=20.78%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2620 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0733 | critic_loss=0.6257 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3128 | risk_aux_total=0.0044 | sharpe_proxy=-0.1464 | sharpe_loss=0.0044 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.54 | std=0.31 | range=[0.57, 2.28]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 46,720 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.088279 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 111/216 | Step 46,720/100,000 | Episode 93 | Time: 6762.7s\n",
      "   ðŸ“Š Metrics: Return=+34.42% | Sharpe=0.272 | DD=50.31% | Turnover=20.95%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7482 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0180 | critic_loss=0.5962 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2981 | risk_aux_total=-0.0020 | sharpe_proxy=0.0686 | sharpe_loss=-0.0021 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 47,232 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021798 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 112/216 | Step 47,232/100,000 | Episode 93 | Time: 6837.1s\n",
      "   ðŸ“Š Metrics: Return=+52.75% | Sharpe=0.286 | DD=50.31% | Turnover=20.88%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7198 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0198 | critic_loss=0.3332 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1666 | risk_aux_total=0.0004 | sharpe_proxy=-0.0136 | sharpe_loss=0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 47,744 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016942 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 113/216 | Step 47,744/100,000 | Episode 93 | Time: 6908.9s\n",
      "   ðŸ“Š Metrics: Return=+92.28% | Sharpe=0.358 | DD=50.31% | Turnover=20.75%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2447 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0960 | critic_loss=0.2849 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1424 | risk_aux_total=0.0037 | sharpe_proxy=-0.1226 | sharpe_loss=0.0037 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 48,256 steps:\n",
      "   Episode horizon set to full dataset\n",
      "ðŸ”„ Update 114/216 | Step 48,256/100,000 | Episode 93 | Time: 6983.4s\n",
      "   ðŸ“Š Metrics: Return=+136.91% | Sharpe=0.401 | DD=50.31% | Turnover=20.74%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6288 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0250 | critic_loss=0.1982 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0991 | risk_aux_total=-0.0000 | sharpe_proxy=0.0009 | sharpe_loss=-0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 48,768 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020398 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 115/216 | Step 48,768/100,000 | Episode 93 | Time: 7056.1s\n",
      "   ðŸ“Š Metrics: Return=+228.72% | Sharpe=0.486 | DD=50.31% | Turnover=20.71%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7278 | delta_reward=+0.0005\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0128 | critic_loss=0.2844 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1422 | risk_aux_total=-0.0017 | sharpe_proxy=0.0580 | sharpe_loss=-0.0017 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 49,280 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031755 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 116/216 | Step 49,280/100,000 | Episode 93 | Time: 7128.2s\n",
      "   ðŸ“Š Metrics: Return=+381.92% | Sharpe=0.541 | DD=50.31% | Turnover=20.72%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7510 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0182 | critic_loss=0.4867 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2434 | risk_aux_total=0.0050 | sharpe_proxy=-0.1645 | sharpe_loss=0.0049 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 94: TAPE Score = 0.2721 (bonus: -0.54 â†’ -0.54)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.552, MDD=50.31%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00094_shp0p552_actor.weights.h5 (Sharpe=0.552)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 49,792 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.065577 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 117/216 | Step 49,792/100,000 | Episode 94 | Time: 7200.2s\n",
      "   ðŸ“Š Metrics: Return=+409.67% | Sharpe=0.552 | DD=50.31% | Turnover=20.72%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7397 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0362 | critic_loss=0.2417 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1209 | risk_aux_total=0.0011 | sharpe_proxy=-0.0366 | sharpe_loss=0.0011 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.46% / trig 16.50%) | terminal=0.000 (peak 4.862) | TAPE=0.2721\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step050000_actor.weights.h5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 50,304 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029639 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 118/216 | Step 50,304/100,000 | Episode 94 | Time: 7274.8s\n",
      "   ðŸ“Š Metrics: Return=+57.05% | Sharpe=0.730 | DD=15.04% | Turnover=20.72%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7011 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0228 | critic_loss=0.2993 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1496 | risk_aux_total=0.0006 | sharpe_proxy=-0.0186 | sharpe_loss=0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 50,816 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021224 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 119/216 | Step 50,816/100,000 | Episode 94 | Time: 7346.8s\n",
      "   ðŸ“Š Metrics: Return=+93.66% | Sharpe=0.749 | DD=15.04% | Turnover=20.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2466 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0979 | critic_loss=0.2813 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1406 | risk_aux_total=-0.0009 | sharpe_proxy=0.0301 | sharpe_loss=-0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 51,328 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.033676 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 120/216 | Step 51,328/100,000 | Episode 94 | Time: 7418.9s\n",
      "   ðŸ“Š Metrics: Return=+144.69% | Sharpe=0.767 | DD=15.04% | Turnover=20.48%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3851 | delta_reward=-0.0020\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0448 | critic_loss=0.1994 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0997 | risk_aux_total=0.0046 | sharpe_proxy=-0.1514 | sharpe_loss=0.0045 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.62 | std=0.26 | range=[0.92, 2.06]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 51,840 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.023496 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 121/216 | Step 51,840/100,000 | Episode 94 | Time: 7491.7s\n",
      "   ðŸ“Š Metrics: Return=+239.41% | Sharpe=0.848 | DD=15.04% | Turnover=20.48%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7441 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0720 | critic_loss=0.3716 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1858 | risk_aux_total=0.0027 | sharpe_proxy=-0.0879 | sharpe_loss=0.0026 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 52,352 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030923 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 122/216 | Step 52,352/100,000 | Episode 94 | Time: 7566.3s\n",
      "   ðŸ“Š Metrics: Return=+431.81% | Sharpe=0.852 | DD=29.33% | Turnover=20.55%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7339 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0897 | critic_loss=0.5450 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2725 | risk_aux_total=-0.0035 | sharpe_proxy=0.1187 | sharpe_loss=-0.0036 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 95: TAPE Score = 0.3936 (bonus: -1.45 â†’ -1.45)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.867, MDD=29.33%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00095_shp0p867_actor.weights.h5 (Sharpe=0.867)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 52,864 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018606 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 123/216 | Step 52,864/100,000 | Episode 95 | Time: 7638.8s\n",
      "   ðŸ“Š Metrics: Return=+469.91% | Sharpe=0.867 | DD=29.33% | Turnover=20.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2944 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0934 | critic_loss=0.2233 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1116 | risk_aux_total=-0.0012 | sharpe_proxy=0.0394 | sharpe_loss=-0.0012 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.22% / trig 16.50%) | terminal=0.000 (peak 0.079) | TAPE=0.3936\n",
      "   ðŸŽ¯ Episode 96: TAPE Score = 0.3148 (bonus: -0.86 â†’ -0.86)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.726, MDD=31.99%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00096_shp0p726_actor.weights.h5 (Sharpe=0.726)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 53,376 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.075230 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 124/216 | Step 53,376/100,000 | Episode 96 | Time: 7713.0s\n",
      "   ðŸ“Š Metrics: Return=+70.76% | Sharpe=0.726 | DD=31.99% | Turnover=20.86%\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0501 | critic_loss=0.4726 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2363 | risk_aux_total=0.0006 | sharpe_proxy=-0.0186 | sharpe_loss=0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.22% / trig 16.50%) | terminal=0.000 (peak 0.129) | TAPE=0.3148\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 53,888 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029922 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 125/216 | Step 53,888/100,000 | Episode 96 | Time: 7786.9s\n",
      "   ðŸ“Š Metrics: Return=+27.14% | Sharpe=0.679 | DD=16.77% | Turnover=20.70%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6414 | delta_reward=-0.0007\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0195 | critic_loss=0.3293 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1647 | risk_aux_total=0.0000 | sharpe_proxy=-0.0006 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 54,400 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.017178 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 126/216 | Step 54,400/100,000 | Episode 96 | Time: 7862.9s\n",
      "   ðŸ“Š Metrics: Return=+75.69% | Sharpe=0.944 | DD=16.77% | Turnover=20.70%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3414 | delta_reward=-0.0010\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0259 | critic_loss=0.2872 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1436 | risk_aux_total=-0.0008 | sharpe_proxy=0.0280 | sharpe_loss=-0.0008 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 54,912 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015287 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 127/216 | Step 54,912/100,000 | Episode 96 | Time: 7936.4s\n",
      "   ðŸ“Š Metrics: Return=+98.82% | Sharpe=0.758 | DD=16.77% | Turnover=20.68%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5929 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1280 | critic_loss=0.2384 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1192 | risk_aux_total=-0.0021 | sharpe_proxy=0.0711 | sharpe_loss=-0.0021 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 55,424 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022207 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 128/216 | Step 55,424/100,000 | Episode 96 | Time: 8009.9s\n",
      "   ðŸ“Š Metrics: Return=+166.16% | Sharpe=0.845 | DD=16.77% | Turnover=20.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2404 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0863 | critic_loss=0.2899 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1449 | risk_aux_total=0.0004 | sharpe_proxy=-0.0126 | sharpe_loss=0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 55,936 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.032201 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 129/216 | Step 55,936/100,000 | Episode 96 | Time: 8082.8s\n",
      "   ðŸ“Š Metrics: Return=+258.17% | Sharpe=0.744 | DD=30.70% | Turnover=20.71%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7057 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1370 | critic_loss=0.5387 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2693 | risk_aux_total=-0.0013 | sharpe_proxy=0.0447 | sharpe_loss=-0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 97: TAPE Score = 0.3629 (bonus: -1.22 â†’ -1.22)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.821, MDD=30.70%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00097_shp0p821_actor.weights.h5 (Sharpe=0.821)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 56,448 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030928 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 130/216 | Step 56,448/100,000 | Episode 97 | Time: 8155.6s\n",
      "   ðŸ“Š Metrics: Return=+337.57% | Sharpe=0.821 | DD=30.70% | Turnover=20.69%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2258 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0523 | critic_loss=0.2650 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1325 | risk_aux_total=-0.0011 | sharpe_proxy=0.0385 | sharpe_loss=-0.0012 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.59 | std=0.26 | range=[0.94, 2.05]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 8.34% / trig 16.50%) | terminal=0.000 (peak 0.107) | TAPE=0.3629\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 56,960 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.037492 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 131/216 | Step 56,960/100,000 | Episode 97 | Time: 8230.2s\n",
      "   ðŸ“Š Metrics: Return=+43.08% | Sharpe=0.556 | DD=29.64% | Turnover=20.43%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.1995 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0202 | critic_loss=0.3783 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1891 | risk_aux_total=0.0003 | sharpe_proxy=-0.0103 | sharpe_loss=0.0003 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 98: TAPE Score = 0.3988 (bonus: -1.49 â†’ -1.49)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.906, MDD=29.64%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00098_shp0p906_actor.weights.h5 (Sharpe=0.906)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 57,472 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016844 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 132/216 | Step 57,472/100,000 | Episode 98 | Time: 8302.2s\n",
      "   ðŸ“Š Metrics: Return=+120.40% | Sharpe=0.906 | DD=29.64% | Turnover=20.63%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2360 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0184 | critic_loss=0.3097 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1548 | risk_aux_total=-0.0030 | sharpe_proxy=0.1016 | sharpe_loss=-0.0030 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 5.71% / trig 16.50%) | terminal=0.000 (peak 0.087) | TAPE=0.3988\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 57,984 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.039306 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 133/216 | Step 57,984/100,000 | Episode 98 | Time: 8376.1s\n",
      "   ðŸ“Š Metrics: Return=+25.45% | Sharpe=0.562 | DD=16.95% | Turnover=20.52%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2774 | delta_reward=-0.0016\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0716 | critic_loss=0.2508 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1254 | risk_aux_total=0.0005 | sharpe_proxy=-0.0150 | sharpe_loss=0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 58,496 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.249513 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 134/216 | Step 58,496/100,000 | Episode 98 | Time: 8448.0s\n",
      "   ðŸ“Š Metrics: Return=+17.43% | Sharpe=0.177 | DD=48.93% | Turnover=20.89%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2451 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0668 | critic_loss=0.9777 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4888 | risk_aux_total=0.0028 | sharpe_proxy=-0.0935 | sharpe_loss=0.0028 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 59,008 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.040973 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 135/216 | Step 59,008/100,000 | Episode 98 | Time: 8520.2s\n",
      "   ðŸ“Š Metrics: Return=+49.40% | Sharpe=0.293 | DD=48.93% | Turnover=20.86%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2423 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0301 | critic_loss=0.3057 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1529 | risk_aux_total=0.0036 | sharpe_proxy=-0.1186 | sharpe_loss=0.0036 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 59,520 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031141 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 136/216 | Step 59,520/100,000 | Episode 98 | Time: 8592.3s\n",
      "   ðŸ“Š Metrics: Return=+105.53% | Sharpe=0.420 | DD=48.93% | Turnover=20.71%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6884 | delta_reward=-0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0537 | critic_loss=0.2235 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1118 | risk_aux_total=0.0016 | sharpe_proxy=-0.0544 | sharpe_loss=0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step060000_actor.weights.h5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 60,032 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022325 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 137/216 | Step 60,032/100,000 | Episode 98 | Time: 8665.6s\n",
      "   ðŸ“Š Metrics: Return=+131.56% | Sharpe=0.408 | DD=48.93% | Turnover=20.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6775 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0446 | critic_loss=0.2890 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1445 | risk_aux_total=0.0025 | sharpe_proxy=-0.0820 | sharpe_loss=0.0025 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 60,544 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041276 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 138/216 | Step 60,544/100,000 | Episode 98 | Time: 8738.1s\n",
      "   ðŸ“Š Metrics: Return=+217.95% | Sharpe=0.494 | DD=48.93% | Turnover=20.63%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4820 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0506 | critic_loss=0.1955 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0977 | risk_aux_total=-0.0030 | sharpe_proxy=0.1017 | sharpe_loss=-0.0031 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 61,056 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.053136 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 139/216 | Step 61,056/100,000 | Episode 98 | Time: 8810.1s\n",
      "   ðŸ“Š Metrics: Return=+289.98% | Sharpe=0.484 | DD=48.93% | Turnover=20.67%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5709 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1569 | critic_loss=0.4994 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2497 | risk_aux_total=-0.0021 | sharpe_proxy=0.0709 | sharpe_loss=-0.0021 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 99: TAPE Score = 0.2756 (bonus: -0.57 â†’ -0.57)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.554, MDD=48.93%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00099_shp0p554_actor.weights.h5 (Sharpe=0.554)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 61,568 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015165 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 140/216 | Step 61,568/100,000 | Episode 99 | Time: 8883.3s\n",
      "   ðŸ“Š Metrics: Return=+416.00% | Sharpe=0.554 | DD=48.93% | Turnover=20.64%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7333 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0587 | critic_loss=0.2368 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1184 | risk_aux_total=-0.0004 | sharpe_proxy=0.0151 | sharpe_loss=-0.0005 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.58 | std=0.26 | range=[0.92, 2.03]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 3.966) | TAPE=0.2756\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 62,080 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.060716 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 141/216 | Step 62,080/100,000 | Episode 99 | Time: 8955.2s\n",
      "   ðŸ“Š Metrics: Return=-9.39% | Sharpe=-0.124 | DD=42.15% | Turnover=20.43%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2057 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1030 | critic_loss=0.6164 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3082 | risk_aux_total=0.0047 | sharpe_proxy=-0.1564 | sharpe_loss=0.0047 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 62,592 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.175072 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 142/216 | Step 62,592/100,000 | Episode 99 | Time: 9027.3s\n",
      "   ðŸ“Š Metrics: Return=+27.49% | Sharpe=0.237 | DD=47.53% | Turnover=20.71%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7247 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0637 | critic_loss=0.6456 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.3228 | risk_aux_total=-0.0049 | sharpe_proxy=0.1648 | sharpe_loss=-0.0049 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 63,104 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036919 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 143/216 | Step 63,104/100,000 | Episode 99 | Time: 9099.0s\n",
      "   ðŸ“Š Metrics: Return=+50.63% | Sharpe=0.286 | DD=47.53% | Turnover=20.61%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2365 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0193 | critic_loss=0.2727 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1363 | risk_aux_total=-0.0074 | sharpe_proxy=0.2484 | sharpe_loss=-0.0075 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 63,616 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018672 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 144/216 | Step 63,616/100,000 | Episode 99 | Time: 9173.7s\n",
      "   ðŸ“Š Metrics: Return=+102.88% | Sharpe=0.399 | DD=47.53% | Turnover=20.58%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3200 | delta_reward=-0.0032\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0241 | critic_loss=0.3225 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1613 | risk_aux_total=-0.0008 | sharpe_proxy=0.0279 | sharpe_loss=-0.0008 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 64,128 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.025718 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 145/216 | Step 64,128/100,000 | Episode 99 | Time: 9246.0s\n",
      "   ðŸ“Š Metrics: Return=+140.50% | Sharpe=0.417 | DD=47.53% | Turnover=20.55%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7166 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0020 | critic_loss=0.2250 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1125 | risk_aux_total=0.0023 | sharpe_proxy=-0.0743 | sharpe_loss=0.0022 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 64,640 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027842 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 146/216 | Step 64,640/100,000 | Episode 99 | Time: 9318.3s\n",
      "   ðŸ“Š Metrics: Return=+212.75% | Sharpe=0.473 | DD=47.53% | Turnover=20.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2538 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0121 | critic_loss=0.2486 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1243 | risk_aux_total=-0.0034 | sharpe_proxy=0.1139 | sharpe_loss=-0.0034 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 65,152 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.045303 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 147/216 | Step 65,152/100,000 | Episode 99 | Time: 9390.5s\n",
      "   ðŸ“Š Metrics: Return=+361.81% | Sharpe=0.532 | DD=47.53% | Turnover=20.63%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7283 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0176 | critic_loss=0.4662 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2331 | risk_aux_total=-0.0024 | sharpe_proxy=0.0819 | sharpe_loss=-0.0025 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 100: TAPE Score = 0.2795 (bonus: -0.60 â†’ -0.60)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.565, MDD=47.53%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00100_shp0p565_actor.weights.h5 (Sharpe=0.565)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 65,664 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.052760 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 148/216 | Step 65,664/100,000 | Episode 100 | Time: 9462.5s\n",
      "   ðŸ“Š Metrics: Return=+428.49% | Sharpe=0.565 | DD=47.53% | Turnover=20.64%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2414 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0527 | critic_loss=0.3435 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1717 | risk_aux_total=-0.0012 | sharpe_proxy=0.0419 | sharpe_loss=-0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.069, dd 10.12% / trig 16.50%) | terminal=0.000 (peak 3.845) | TAPE=0.2795\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 66,176 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030972 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 149/216 | Step 66,176/100,000 | Episode 100 | Time: 9534.4s\n",
      "   ðŸ“Š Metrics: Return=+54.47% | Sharpe=0.631 | DD=26.70% | Turnover=20.66%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2465 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1482 | critic_loss=0.4095 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2048 | risk_aux_total=-0.0015 | sharpe_proxy=0.0503 | sharpe_loss=-0.0015 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 66,688 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015311 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 150/216 | Step 66,688/100,000 | Episode 100 | Time: 9607.1s\n",
      "   ðŸ“Š Metrics: Return=+120.54% | Sharpe=0.819 | DD=26.70% | Turnover=20.63%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6059 | delta_reward=-0.0006\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0080 | critic_loss=0.2766 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1383 | risk_aux_total=-0.0006 | sharpe_proxy=0.0225 | sharpe_loss=-0.0007 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.61 | std=0.25 | range=[1.01, 2.08]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 67,200 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016589 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 151/216 | Step 67,200/100,000 | Episode 100 | Time: 9679.3s\n",
      "   ðŸ“Š Metrics: Return=+139.84% | Sharpe=0.680 | DD=26.70% | Turnover=20.62%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5250 | delta_reward=+0.0008\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0936 | critic_loss=0.2232 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1116 | risk_aux_total=-0.0017 | sharpe_proxy=0.0588 | sharpe_loss=-0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 67,712 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019214 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 152/216 | Step 67,712/100,000 | Episode 100 | Time: 9751.5s\n",
      "   ðŸ“Š Metrics: Return=+222.85% | Sharpe=0.762 | DD=26.70% | Turnover=20.63%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7450 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0375 | critic_loss=0.1979 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0989 | risk_aux_total=-0.0019 | sharpe_proxy=0.0633 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 68,224 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041906 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 153/216 | Step 68,224/100,000 | Episode 100 | Time: 9823.7s\n",
      "   ðŸ“Š Metrics: Return=+294.31% | Sharpe=0.667 | DD=33.18% | Turnover=20.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7072 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0153 | critic_loss=0.4373 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2186 | risk_aux_total=0.0003 | sharpe_proxy=-0.0089 | sharpe_loss=0.0003 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 101: TAPE Score = 0.3395 (bonus: -1.05 â†’ -1.05)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.755, MDD=33.18%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00101_shp0p755_actor.weights.h5 (Sharpe=0.755)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 68,736 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.035028 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 154/216 | Step 68,736/100,000 | Episode 101 | Time: 9898.8s\n",
      "   ðŸ“Š Metrics: Return=+428.21% | Sharpe=0.755 | DD=33.18% | Turnover=20.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2744 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0192 | critic_loss=0.3039 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1519 | risk_aux_total=-0.0018 | sharpe_proxy=0.0612 | sharpe_loss=-0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 5.48% / trig 16.50%) | terminal=0.000 (peak 0.144) | TAPE=0.3395\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 69,248 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.041616 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 155/216 | Step 69,248/100,000 | Episode 101 | Time: 9971.3s\n",
      "   ðŸ“Š Metrics: Return=+33.81% | Sharpe=0.479 | DD=32.05% | Turnover=20.45%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2241 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0197 | critic_loss=0.3868 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1934 | risk_aux_total=0.0055 | sharpe_proxy=-0.1836 | sharpe_loss=0.0055 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 102: TAPE Score = 0.3409 (bonus: -1.06 â†’ -1.06)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.806, MDD=32.05%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00102_shp0p806_actor.weights.h5 (Sharpe=0.806)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 69,760 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.087350 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 156/216 | Step 69,760/100,000 | Episode 102 | Time: 10043.7s\n",
      "   ðŸ“Š Metrics: Return=+93.57% | Sharpe=0.806 | DD=32.05% | Turnover=20.66%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4933 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1314 | critic_loss=0.2116 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1058 | risk_aux_total=-0.0029 | sharpe_proxy=0.0970 | sharpe_loss=-0.0029 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.14% / trig 16.50%) | terminal=0.000 (peak 0.131) | TAPE=0.3409\n",
      "   ðŸ”§ Actor learning rate adjusted to 0.000006 at step 70,000\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step070000_actor.weights.h5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 70,272 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.118410 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 157/216 | Step 70,272/100,000 | Episode 102 | Time: 10115.8s\n",
      "   ðŸ“Š Metrics: Return=+0.66% | Sharpe=0.072 | DD=46.31% | Turnover=21.10%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7550 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1641 | critic_loss=0.8213 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4107 | risk_aux_total=0.0015 | sharpe_proxy=-0.0489 | sharpe_loss=0.0015 | mvo_loss=0.0001\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 70,784 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.052149 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 158/216 | Step 70,784/100,000 | Episode 102 | Time: 10188.0s\n",
      "   ðŸ“Š Metrics: Return=+27.62% | Sharpe=0.249 | DD=46.31% | Turnover=20.99%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6128 | delta_reward=+0.0005\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1341 | critic_loss=0.2330 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1165 | risk_aux_total=0.0017 | sharpe_proxy=-0.0567 | sharpe_loss=0.0017 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 71,296 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036904 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 159/216 | Step 71,296/100,000 | Episode 102 | Time: 10259.8s\n",
      "   ðŸ“Š Metrics: Return=+59.78% | Sharpe=0.336 | DD=46.31% | Turnover=20.82%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6522 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0835 | critic_loss=0.3558 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1779 | risk_aux_total=0.0035 | sharpe_proxy=-0.1149 | sharpe_loss=0.0034 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 71,808 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019477 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 160/216 | Step 71,808/100,000 | Episode 102 | Time: 10333.0s\n",
      "   ðŸ“Š Metrics: Return=+92.99% | Sharpe=0.379 | DD=46.31% | Turnover=20.70%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2469 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0163 | critic_loss=0.2287 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1143 | risk_aux_total=0.0014 | sharpe_proxy=-0.0447 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.62 | std=0.25 | range=[0.97, 2.09]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 72,320 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.031002 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 161/216 | Step 72,320/100,000 | Episode 102 | Time: 10405.5s\n",
      "   ðŸ“Š Metrics: Return=+165.79% | Sharpe=0.477 | DD=46.31% | Turnover=20.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7351 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0367 | critic_loss=0.2259 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1129 | risk_aux_total=0.0020 | sharpe_proxy=-0.0658 | sharpe_loss=0.0020 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 72,832 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027790 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 162/216 | Step 72,832/100,000 | Episode 102 | Time: 10478.9s\n",
      "   ðŸ“Š Metrics: Return=+249.32% | Sharpe=0.530 | DD=46.31% | Turnover=20.66%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6132 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0872 | critic_loss=0.3015 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1507 | risk_aux_total=-0.0016 | sharpe_proxy=0.0554 | sharpe_loss=-0.0017 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 73,344 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.069347 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 163/216 | Step 73,344/100,000 | Episode 102 | Time: 10551.1s\n",
      "   ðŸ“Š Metrics: Return=+397.89% | Sharpe=0.568 | DD=46.31% | Turnover=20.67%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6990 | delta_reward=+0.0006\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0835 | critic_loss=0.4129 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2064 | risk_aux_total=-0.0012 | sharpe_proxy=0.0423 | sharpe_loss=-0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 103: TAPE Score = 0.2783 (bonus: -0.59 â†’ -0.59)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.569, MDD=46.31%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00103_shp0p569_actor.weights.h5 (Sharpe=0.569)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 73,856 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029482 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 164/216 | Step 73,856/100,000 | Episode 103 | Time: 10624.2s\n",
      "   ðŸ“Š Metrics: Return=+402.16% | Sharpe=0.569 | DD=46.31% | Turnover=20.68%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2442 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0073 | critic_loss=0.1786 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0893 | risk_aux_total=-0.0019 | sharpe_proxy=0.0647 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 4.57% / trig 16.50%) | terminal=0.000 (peak 3.672) | TAPE=0.2783\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 74,368 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019615 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 165/216 | Step 74,368/100,000 | Episode 103 | Time: 10696.6s\n",
      "   ðŸ“Š Metrics: Return=+53.72% | Sharpe=0.774 | DD=11.54% | Turnover=20.59%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2379 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0787 | critic_loss=0.2352 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1176 | risk_aux_total=-0.0011 | sharpe_proxy=0.0358 | sharpe_loss=-0.0011 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 74,880 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019732 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 166/216 | Step 74,880/100,000 | Episode 103 | Time: 10768.8s\n",
      "   ðŸ“Š Metrics: Return=+125.44% | Sharpe=1.048 | DD=11.54% | Turnover=20.61%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7464 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0103 | critic_loss=0.1421 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0710 | risk_aux_total=0.0007 | sharpe_proxy=-0.0243 | sharpe_loss=0.0007 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 75,392 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019070 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 167/216 | Step 75,392/100,000 | Episode 103 | Time: 10841.1s\n",
      "   ðŸ“Š Metrics: Return=+190.07% | Sharpe=0.988 | DD=12.85% | Turnover=20.50%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6548 | delta_reward=+0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0700 | critic_loss=0.2847 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1423 | risk_aux_total=0.0013 | sharpe_proxy=-0.0435 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 104: TAPE Score = 0.3893 (bonus: -1.42 â†’ -1.42)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.875, MDD=31.48%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00104_shp0p875_actor.weights.h5 (Sharpe=0.875)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 75,904 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.051574 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 168/216 | Step 75,904/100,000 | Episode 104 | Time: 10913.4s\n",
      "   ðŸ“Š Metrics: Return=+309.74% | Sharpe=0.875 | DD=31.48% | Turnover=20.55%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7578 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0518 | critic_loss=0.2956 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1478 | risk_aux_total=-0.0013 | sharpe_proxy=0.0452 | sharpe_loss=-0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.117) | TAPE=0.3893\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 76,416 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.023373 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 169/216 | Step 76,416/100,000 | Episode 104 | Time: 10985.4s\n",
      "   ðŸ“Š Metrics: Return=+48.26% | Sharpe=1.542 | DD=9.44% | Turnover=20.58%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7512 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0041 | critic_loss=0.2303 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1152 | risk_aux_total=-0.0044 | sharpe_proxy=0.1460 | sharpe_loss=-0.0044 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 76,928 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.020396 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 170/216 | Step 76,928/100,000 | Episode 104 | Time: 11057.9s\n",
      "   ðŸ“Š Metrics: Return=+25.55% | Sharpe=0.277 | DD=39.13% | Turnover=20.68%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2122 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1477 | critic_loss=0.4289 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2144 | risk_aux_total=0.0046 | sharpe_proxy=-0.1520 | sharpe_loss=0.0046 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.57 | std=0.24 | range=[0.88, 2.03]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 77,440 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.084359 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 171/216 | Step 77,440/100,000 | Episode 104 | Time: 11130.5s\n",
      "   ðŸ“Š Metrics: Return=+72.67% | Sharpe=0.430 | DD=47.39% | Turnover=20.83%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7475 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0855 | critic_loss=0.8999 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.4500 | risk_aux_total=-0.0008 | sharpe_proxy=0.0255 | sharpe_loss=-0.0008 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 77,952 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019727 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 172/216 | Step 77,952/100,000 | Episode 104 | Time: 11203.1s\n",
      "   ðŸ“Š Metrics: Return=+92.08% | Sharpe=0.399 | DD=47.39% | Turnover=20.77%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2499 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1122 | critic_loss=0.2248 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1124 | risk_aux_total=-0.0001 | sharpe_proxy=0.0045 | sharpe_loss=-0.0001 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 78,464 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019538 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 173/216 | Step 78,464/100,000 | Episode 104 | Time: 11275.8s\n",
      "   ðŸ“Š Metrics: Return=+177.43% | Sharpe=0.528 | DD=47.39% | Turnover=20.69%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.4809 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0289 | critic_loss=0.2019 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1010 | risk_aux_total=0.0005 | sharpe_proxy=-0.0146 | sharpe_loss=0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 78,976 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018838 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 174/216 | Step 78,976/100,000 | Episode 104 | Time: 11348.6s\n",
      "   ðŸ“Š Metrics: Return=+227.79% | Sharpe=0.526 | DD=47.39% | Turnover=20.66%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7310 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0614 | critic_loss=0.2103 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1051 | risk_aux_total=-0.0011 | sharpe_proxy=0.0356 | sharpe_loss=-0.0011 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 79,488 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036038 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 175/216 | Step 79,488/100,000 | Episode 104 | Time: 11421.3s\n",
      "   ðŸ“Š Metrics: Return=+313.68% | Sharpe=0.556 | DD=47.39% | Turnover=20.62%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2449 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0662 | critic_loss=0.2391 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1196 | risk_aux_total=-0.0048 | sharpe_proxy=0.1612 | sharpe_loss=-0.0048 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step080000_actor.weights.h5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 80,000 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030460 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 176/216 | Step 80,000/100,000 | Episode 104 | Time: 11494.3s\n",
      "   ðŸ“Š Metrics: Return=+501.01% | Sharpe=0.592 | DD=47.39% | Turnover=20.61%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7277 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1668 | critic_loss=0.3632 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1816 | risk_aux_total=-0.0002 | sharpe_proxy=0.0075 | sharpe_loss=-0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 105: TAPE Score = 0.2953 (bonus: -0.71 â†’ -0.71)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.627, MDD=47.39%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00105_shp0p627_actor.weights.h5 (Sharpe=0.627)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 80,512 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.030316 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 177/216 | Step 80,512/100,000 | Episode 105 | Time: 11569.6s\n",
      "   ðŸ“Š Metrics: Return=+605.94% | Sharpe=0.627 | DD=47.39% | Turnover=20.63%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2340 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0260 | critic_loss=0.2734 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1367 | risk_aux_total=0.0005 | sharpe_proxy=-0.0149 | sharpe_loss=0.0004 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 13.74% / trig 16.50%) | terminal=0.000 (peak 4.111) | TAPE=0.2953\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 81,024 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.037136 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 178/216 | Step 81,024/100,000 | Episode 105 | Time: 11643.0s\n",
      "   ðŸ“Š Metrics: Return=+54.89% | Sharpe=0.805 | DD=15.36% | Turnover=20.69%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2573 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0977 | critic_loss=0.1840 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0920 | risk_aux_total=-0.0042 | sharpe_proxy=0.1394 | sharpe_loss=-0.0042 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 81,536 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019355 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 179/216 | Step 81,536/100,000 | Episode 105 | Time: 11717.3s\n",
      "   ðŸ“Š Metrics: Return=+78.72% | Sharpe=0.694 | DD=15.36% | Turnover=20.57%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2514 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0583 | critic_loss=0.2348 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1174 | risk_aux_total=-0.0001 | sharpe_proxy=0.0056 | sharpe_loss=-0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 82,048 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.034896 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 180/216 | Step 82,048/100,000 | Episode 105 | Time: 11789.9s\n",
      "   ðŸ“Š Metrics: Return=+161.14% | Sharpe=0.900 | DD=15.36% | Turnover=20.49%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7569 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0045 | critic_loss=0.1432 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0716 | risk_aux_total=-0.0019 | sharpe_proxy=0.0628 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.62 | std=0.26 | range=[0.92, 2.02]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 82,560 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018548 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 181/216 | Step 82,560/100,000 | Episode 105 | Time: 11862.4s\n",
      "   ðŸ“Š Metrics: Return=+225.11% | Sharpe=0.862 | DD=15.36% | Turnover=20.49%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7342 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0042 | critic_loss=0.2637 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1318 | risk_aux_total=-0.0038 | sharpe_proxy=0.1264 | sharpe_loss=-0.0038 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 106: TAPE Score = 0.3574 (bonus: -1.18 â†’ -1.18)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.810, MDD=31.35%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00106_shp0p810_actor.weights.h5 (Sharpe=0.810)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 83,072 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.050924 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 182/216 | Step 83,072/100,000 | Episode 106 | Time: 11936.1s\n",
      "   ðŸ“Š Metrics: Return=+351.38% | Sharpe=0.810 | DD=31.35% | Turnover=20.58%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2430 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0822 | critic_loss=0.3622 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1811 | risk_aux_total=-0.0011 | sharpe_proxy=0.0382 | sharpe_loss=-0.0011 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.53% / trig 16.50%) | terminal=0.000 (peak 0.117) | TAPE=0.3574\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 83,584 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.015293 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 183/216 | Step 83,584/100,000 | Episode 106 | Time: 12008.5s\n",
      "   ðŸ“Š Metrics: Return=+43.91% | Sharpe=1.279 | DD=10.37% | Turnover=20.49%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7566 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1289 | critic_loss=0.1541 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0771 | risk_aux_total=0.0003 | sharpe_proxy=-0.0090 | sharpe_loss=0.0003 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 84,096 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027206 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 184/216 | Step 84,096/100,000 | Episode 106 | Time: 12081.8s\n",
      "   ðŸ“Š Metrics: Return=+89.59% | Sharpe=1.105 | DD=12.61% | Turnover=20.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7386 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0456 | critic_loss=0.2280 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1140 | risk_aux_total=0.0000 | sharpe_proxy=-0.0007 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 107: TAPE Score = 0.4042 (bonus: -1.53 â†’ -1.53)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.916, MDD=30.67%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00107_shp0p916_actor.weights.h5 (Sharpe=0.916)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 84,608 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.048160 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 185/216 | Step 84,608/100,000 | Episode 107 | Time: 12154.4s\n",
      "   ðŸ“Š Metrics: Return=+166.13% | Sharpe=0.916 | DD=30.67% | Turnover=20.74%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6531 | delta_reward=-0.0007\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0446 | critic_loss=0.3234 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1617 | risk_aux_total=-0.0035 | sharpe_proxy=0.1171 | sharpe_loss=-0.0035 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.77% / trig 16.50%) | terminal=0.000 (peak 0.092) | TAPE=0.4042\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 85,120 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021552 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 186/216 | Step 85,120/100,000 | Episode 107 | Time: 12226.5s\n",
      "   ðŸ“Š Metrics: Return=+14.75% | Sharpe=0.376 | DD=13.21% | Turnover=20.40%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2474 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1198 | critic_loss=0.2278 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1139 | risk_aux_total=0.0013 | sharpe_proxy=-0.0422 | sharpe_loss=0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 85,632 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.017845 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 187/216 | Step 85,632/100,000 | Episode 107 | Time: 12299.1s\n",
      "   ðŸ“Š Metrics: Return=+67.59% | Sharpe=0.927 | DD=13.21% | Turnover=20.33%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3283 | delta_reward=-0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0395 | critic_loss=0.2050 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1025 | risk_aux_total=-0.0005 | sharpe_proxy=0.0170 | sharpe_loss=-0.0005 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 86,144 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024058 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 188/216 | Step 86,144/100,000 | Episode 107 | Time: 12371.7s\n",
      "   ðŸ“Š Metrics: Return=+90.98% | Sharpe=0.727 | DD=13.87% | Turnover=20.40%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2294 | delta_reward=-0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0656 | critic_loss=0.2139 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1069 | risk_aux_total=0.0042 | sharpe_proxy=-0.1397 | sharpe_loss=0.0042 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 108: TAPE Score = 0.3553 (bonus: -1.16 â†’ -1.16)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.804, MDD=29.86%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00108_shp0p804_actor.weights.h5 (Sharpe=0.804)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 86,656 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.069810 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 189/216 | Step 86,656/100,000 | Episode 108 | Time: 12444.2s\n",
      "   ðŸ“Š Metrics: Return=+189.24% | Sharpe=0.804 | DD=29.86% | Turnover=20.52%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7514 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0307 | critic_loss=0.3569 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1785 | risk_aux_total=-0.0031 | sharpe_proxy=0.1031 | sharpe_loss=-0.0031 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.33% / trig 16.50%) | terminal=0.000 (peak 0.086) | TAPE=0.3553\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 87,168 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022397 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 190/216 | Step 87,168/100,000 | Episode 108 | Time: 12516.3s\n",
      "   ðŸ“Š Metrics: Return=+31.43% | Sharpe=0.877 | DD=7.00% | Turnover=20.48%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2513 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0072 | critic_loss=0.2156 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1078 | risk_aux_total=0.0021 | sharpe_proxy=-0.0711 | sharpe_loss=0.0021 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.62 | std=0.25 | range=[0.95, 2.07]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 87,680 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.024552 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 191/216 | Step 87,680/100,000 | Episode 108 | Time: 12588.1s\n",
      "   ðŸ“Š Metrics: Return=+72.05% | Sharpe=0.920 | DD=11.68% | Turnover=20.28%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6909 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0407 | critic_loss=0.1764 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0882 | risk_aux_total=0.0006 | sharpe_proxy=-0.0187 | sharpe_loss=0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 88,192 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021578 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 192/216 | Step 88,192/100,000 | Episode 108 | Time: 12660.2s\n",
      "   ðŸ“Š Metrics: Return=+132.99% | Sharpe=0.979 | DD=14.79% | Turnover=20.19%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7260 | delta_reward=+0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1176 | critic_loss=0.2160 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1080 | risk_aux_total=0.0007 | sharpe_proxy=-0.0222 | sharpe_loss=0.0007 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 88,704 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.057152 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 193/216 | Step 88,704/100,000 | Episode 108 | Time: 12732.5s\n",
      "   ðŸ“Š Metrics: Return=+255.68% | Sharpe=0.892 | DD=31.16% | Turnover=20.33%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7449 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0396 | critic_loss=0.3638 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1819 | risk_aux_total=-0.0046 | sharpe_proxy=0.1552 | sharpe_loss=-0.0047 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 109: TAPE Score = 0.4047 (bonus: -1.54 â†’ -1.54)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.901, MDD=31.16%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00109_shp0p901_actor.weights.h5 (Sharpe=0.901)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 89,216 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.046846 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 194/216 | Step 89,216/100,000 | Episode 109 | Time: 12805.4s\n",
      "   ðŸ“Š Metrics: Return=+271.83% | Sharpe=0.901 | DD=31.16% | Turnover=20.36%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7021 | delta_reward=-0.0004\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1210 | critic_loss=0.2433 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1216 | risk_aux_total=0.0003 | sharpe_proxy=-0.0085 | sharpe_loss=0.0003 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 2.32% / trig 16.50%) | terminal=0.000 (peak 0.096) | TAPE=0.4047\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 89,728 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.014948 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 195/216 | Step 89,728/100,000 | Episode 109 | Time: 12877.1s\n",
      "   ðŸ“Š Metrics: Return=+47.43% | Sharpe=0.623 | DD=14.58% | Turnover=20.38%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7371 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0065 | critic_loss=0.2473 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1237 | risk_aux_total=0.0022 | sharpe_proxy=-0.0721 | sharpe_loss=0.0022 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step090000_actor.weights.h5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 90,240 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021428 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 196/216 | Step 90,240/100,000 | Episode 109 | Time: 12950.1s\n",
      "   ðŸ“Š Metrics: Return=+80.65% | Sharpe=0.665 | DD=14.58% | Turnover=20.51%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2469 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0550 | critic_loss=0.2050 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1025 | risk_aux_total=0.0021 | sharpe_proxy=-0.0700 | sharpe_loss=0.0021 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 90,752 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.023900 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 197/216 | Step 90,752/100,000 | Episode 109 | Time: 13022.9s\n",
      "   ðŸ“Š Metrics: Return=+126.18% | Sharpe=0.695 | DD=14.58% | Turnover=20.47%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6375 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0658 | critic_loss=0.1867 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0934 | risk_aux_total=0.0006 | sharpe_proxy=-0.0180 | sharpe_loss=0.0005 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 91,264 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016462 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 198/216 | Step 91,264/100,000 | Episode 109 | Time: 13095.1s\n",
      "   ðŸ“Š Metrics: Return=+205.28% | Sharpe=0.772 | DD=14.58% | Turnover=20.43%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7496 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.1091 | critic_loss=0.2686 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1343 | risk_aux_total=-0.0024 | sharpe_proxy=0.0804 | sharpe_loss=-0.0024 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 91,776 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.036138 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 199/216 | Step 91,776/100,000 | Episode 109 | Time: 13168.5s\n",
      "   ðŸ“Š Metrics: Return=+327.69% | Sharpe=0.735 | DD=31.04% | Turnover=20.54%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7493 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0148 | critic_loss=0.3985 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1992 | risk_aux_total=-0.0009 | sharpe_proxy=0.0297 | sharpe_loss=-0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 110: TAPE Score = 0.3357 (bonus: -1.02 â†’ -1.02)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.759, MDD=31.04%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00110_shp0p759_actor.weights.h5 (Sharpe=0.759)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 92,288 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029974 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 200/216 | Step 92,288/100,000 | Episode 110 | Time: 13240.9s\n",
      "   ðŸ“Š Metrics: Return=+361.73% | Sharpe=0.759 | DD=31.04% | Turnover=20.53%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7488 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0256 | critic_loss=0.2902 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1451 | risk_aux_total=-0.0044 | sharpe_proxy=0.1480 | sharpe_loss=-0.0044 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.52 | std=0.30 | range=[0.78, 2.03]\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 3.06% / trig 16.50%) | terminal=0.000 (peak 0.114) | TAPE=0.3357\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 92,800 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.019473 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 201/216 | Step 92,800/100,000 | Episode 110 | Time: 13313.2s\n",
      "   ðŸ“Š Metrics: Return=+71.34% | Sharpe=0.822 | DD=17.19% | Turnover=20.74%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2487 | delta_reward=+0.0001\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1692 | critic_loss=0.2613 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1306 | risk_aux_total=-0.0013 | sharpe_proxy=0.0421 | sharpe_loss=-0.0013 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 93,312 steps:\n",
      "   Episode horizon set to full dataset\n",
      "ðŸ”„ Update 202/216 | Step 93,312/100,000 | Episode 110 | Time: 13388.1s\n",
      "   ðŸ“Š Metrics: Return=+136.44% | Sharpe=0.945 | DD=17.19% | Turnover=20.70%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2765 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0215 | critic_loss=0.2808 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1404 | risk_aux_total=-0.0009 | sharpe_proxy=0.0311 | sharpe_loss=-0.0009 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 93,824 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.021455 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 203/216 | Step 93,824/100,000 | Episode 110 | Time: 13463.1s\n",
      "   ðŸ“Š Metrics: Return=+180.98% | Sharpe=0.856 | DD=17.19% | Turnover=20.65%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7346 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0230 | critic_loss=0.2117 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1059 | risk_aux_total=0.0006 | sharpe_proxy=-0.0194 | sharpe_loss=0.0006 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 94,336 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.026638 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 204/216 | Step 94,336/100,000 | Episode 110 | Time: 13535.4s\n",
      "   ðŸ“Š Metrics: Return=+248.10% | Sharpe=0.839 | DD=17.19% | Turnover=20.58%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2506 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0188 | critic_loss=0.2408 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1204 | risk_aux_total=0.0018 | sharpe_proxy=-0.0588 | sharpe_loss=0.0018 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 94,848 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038856 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 205/216 | Step 94,848/100,000 | Episode 110 | Time: 13608.0s\n",
      "   ðŸ“Š Metrics: Return=+397.86% | Sharpe=0.798 | DD=30.20% | Turnover=20.59%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7495 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.1762 | critic_loss=0.3391 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1696 | risk_aux_total=-0.0027 | sharpe_proxy=0.0901 | sharpe_loss=-0.0027 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 111: TAPE Score = 0.3854 (bonus: -1.39 â†’ -1.39)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.849, MDD=30.20%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00111_shp0p849_actor.weights.h5 (Sharpe=0.849)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 95,360 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.027424 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 206/216 | Step 95,360/100,000 | Episode 111 | Time: 13680.4s\n",
      "   ðŸ“Š Metrics: Return=+485.66% | Sharpe=0.849 | DD=30.20% | Turnover=20.60%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2407 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0736 | critic_loss=0.2777 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1388 | risk_aux_total=-0.0007 | sharpe_proxy=0.0231 | sharpe_loss=-0.0007 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 4.83% / trig 16.50%) | terminal=0.000 (peak 0.086) | TAPE=0.3854\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 95,872 steps:\n",
      "   Episode horizon set to full dataset\n",
      "ðŸ”„ Update 207/216 | Step 95,872/100,000 | Episode 111 | Time: 13755.2s\n",
      "   ðŸ“Š Metrics: Return=+46.67% | Sharpe=0.853 | DD=11.27% | Turnover=20.53%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7430 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0256 | critic_loss=0.2134 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1067 | risk_aux_total=-0.0014 | sharpe_proxy=0.0461 | sharpe_loss=-0.0014 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 96,384 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.028097 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 208/216 | Step 96,384/100,000 | Episode 111 | Time: 13829.2s\n",
      "   ðŸ“Š Metrics: Return=+80.07% | Sharpe=0.778 | DD=13.37% | Turnover=20.50%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6195 | delta_reward=-0.0005\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0172 | critic_loss=0.2337 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1169 | risk_aux_total=0.0005 | sharpe_proxy=-0.0151 | sharpe_loss=0.0005 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 112: TAPE Score = 0.3275 (bonus: -0.96 â†’ -0.96)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.754, MDD=32.04%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00112_shp0p754_actor.weights.h5 (Sharpe=0.754)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 96,896 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.038629 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 209/216 | Step 96,896/100,000 | Episode 112 | Time: 13901.8s\n",
      "   ðŸ“Š Metrics: Return=+158.27% | Sharpe=0.754 | DD=32.04% | Turnover=20.59%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.2540 | delta_reward=-0.0012\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=-0.0167 | critic_loss=0.3511 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1756 | risk_aux_total=-0.0015 | sharpe_proxy=0.0510 | sharpe_loss=-0.0015 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 5.39% / trig 16.50%) | terminal=0.000 (peak 0.133) | TAPE=0.3275\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 97,408 steps:\n",
      "   Episode horizon set to full dataset\n",
      "ðŸ”„ Update 210/216 | Step 97,408/100,000 | Episode 112 | Time: 13976.7s\n",
      "   ðŸ“Š Metrics: Return=+60.97% | Sharpe=1.992 | DD=7.29% | Turnover=20.34%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7545 | delta_reward=-0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0220 | critic_loss=0.2372 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1186 | risk_aux_total=-0.0023 | sharpe_proxy=0.0756 | sharpe_loss=-0.0023 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”¬ Alpha Diversity: mean=1.62 | std=0.27 | range=[0.92, 2.03]\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 97,920 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.029556 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 211/216 | Step 97,920/100,000 | Episode 112 | Time: 14049.0s\n",
      "   ðŸ“Š Metrics: Return=+89.36% | Sharpe=1.182 | DD=12.75% | Turnover=20.32%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6869 | delta_reward=+0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0039 | critic_loss=0.2257 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1129 | risk_aux_total=-0.0002 | sharpe_proxy=0.0058 | sharpe_loss=-0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸŽ¯ Episode 113: TAPE Score = 0.3709 (bonus: -1.28 â†’ -1.28)\n",
      "      ðŸš¦ Gate A applied: Sharpe=0.874, MDD=33.16%\n",
      "      ðŸ’¾ Sharpe-threshold checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00113_shp0p874_actor.weights.h5 (Sharpe=0.874)\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 98,432 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.064165 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 212/216 | Step 98,432/100,000 | Episode 113 | Time: 14121.1s\n",
      "   ðŸ“Š Metrics: Return=+147.52% | Sharpe=0.874 | DD=33.16% | Turnover=20.47%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6203 | delta_reward=+0.0002\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0986 | critic_loss=0.4188 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.2094 | risk_aux_total=-0.0035 | sharpe_proxy=0.1185 | sharpe_loss=-0.0036 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "   ðŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.30% / trig 16.50%) | terminal=0.000 (peak 0.143) | TAPE=0.3709\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 98,944 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.018692 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 213/216 | Step 98,944/100,000 | Episode 113 | Time: 14193.8s\n",
      "   ðŸ“Š Metrics: Return=+32.56% | Sharpe=0.938 | DD=6.99% | Turnover=20.50%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.6057 | delta_reward=+0.0026\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0107 | critic_loss=0.2435 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1217 | risk_aux_total=-0.0001 | sharpe_proxy=0.0050 | sharpe_loss=-0.0002 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 99,456 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.016012 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 214/216 | Step 99,456/100,000 | Episode 113 | Time: 14266.1s\n",
      "   ðŸ“Š Metrics: Return=+81.33% | Sharpe=1.058 | DD=10.81% | Turnover=20.37%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.7292 | delta_reward=+0.0000\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0337 | critic_loss=0.2252 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1126 | risk_aux_total=0.0016 | sharpe_proxy=-0.0528 | sharpe_loss=0.0016 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 99,968 steps:\n",
      "   Episode horizon set to full dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.agents.ppo_agent_tf:âš ï¸ PPO early-stop: approx_kl 0.022923 exceeded threshold 0.014400 (target_kl 0.012000 Ã— 1.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Update 215/216 | Step 99,968/100,000 | Episode 113 | Time: 14338.5s\n",
      "   ðŸ“Š Metrics: Return=+119.10% | Sharpe=0.908 | DD=13.35% | Turnover=20.38%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.5292 | delta_reward=+0.0023\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0543 | critic_loss=0.2628 | mean_adv=0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.1314 | risk_aux_total=-0.0030 | sharpe_proxy=0.0992 | sharpe_loss=-0.0030 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "      ðŸ’¾ Periodic checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_step100000_actor.weights.h5\n",
      "\n",
      "ðŸ“š EPISODE HORIZON UPDATE at 100,000 steps:\n",
      "   Episode horizon set to full dataset\n",
      "ðŸ”„ Update 216/216 | Step 100,000/100,000 | Episode 113 | Time: 14344.3s\n",
      "   ðŸ“Š Metrics: Return=+126.08% | Sharpe=0.927 | DD=13.35% | Turnover=20.40%\n",
      "   ðŸŽšï¸ Intra-Step TAPE: potential=0.3802 | delta_reward=-0.0003\n",
      "   ðŸŽ¯ Profile: BalancedGrowth\n",
      "   ðŸ§  Training: actor_loss=0.0332 | critic_loss=0.1899 | mean_adv=-0.0000\n",
      "   ðŸ§® Loss Detail: critic_scaled=0.0949 | risk_aux_total=-0.0019 | sharpe_proxy=0.0634 | sharpe_loss=-0.0019 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000006 | critic_lr=0.000120 | target_kl=0.0120 | rollout=512 | batch_size=128\n",
      "\n",
      "âœ… THREE-COMPONENT TAPE v3 training completed!\n",
      "   Total episodes: 113\n",
      "   Total timesteps: 100,000\n",
      "   Training time: 14344.35s (239.07min)\n",
      "ðŸ“Š Training summary saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_summary.csv\n",
      "ðŸ’¾ Final models saved: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_ep40_actor.weights.h5, /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_ep40_critic.weights.h5\n",
      "âœ… Training complete\n",
      "checkpoint_prefix: /content/adaptive_portfolio_rl/tcn_fusion_results/exp6_tape_ep40\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAIN ACTIVE VARIANT\n",
    "# ============================================================================\n",
    "RUN_TRAINING = True\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    train_cfg = config['training_params']\n",
    "    print('ðŸš€ Starting training')\n",
    "    print('Variant:', ACTIVE_VARIANT)\n",
    "    print('max_total_timesteps:', train_cfg['max_total_timesteps'])\n",
    "    print('timesteps_per_ppo_update:', train_cfg['timesteps_per_ppo_update'])\n",
    "\n",
    "    experiment6 = run_experiment6_tape(\n",
    "        phase1_data=phase1_data,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        csv_logger_cls=CSVLogger,\n",
    "        use_covariance=True,\n",
    "        architecture=config['agent_params']['actor_critic_type'],\n",
    "        timesteps_per_update=train_cfg['timesteps_per_ppo_update'],\n",
    "        max_total_timesteps=train_cfg['max_total_timesteps'],\n",
    "    )\n",
    "\n",
    "    print('âœ… Training complete')\n",
    "    print('checkpoint_prefix:', experiment6.checkpoint_path)\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_TRAINING=False (set True to train)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d09764b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tcn_fusion_results/exp6_tape_step090000_actor.weights.h5\n",
      "./tcn_fusion_results/exp6_tape_step010000_actor.weights.h5\n",
      "./tcn_fusion_results/exp6_tape_ep32_actor.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep27_sh2.266_dd5.6_critic.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep39_sh2.205_dd8.5_actor.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep32_sh2.639_dd4.3_actor.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep32_sh2.639_dd4.3_critic.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep24_sh2.128_dd8.1_critic.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep39_sh2.205_dd8.5_critic.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep27_sh2.266_dd5.6_actor.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep6_sh3.396_dd2.2_actor.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep24_sh2.128_dd8.1_actor.weights.h5\n",
      "./tcn_fusion_results/rare_models/exp6_tape_ep6_sh3.396_dd2.2_critic.weights.h5\n",
      "./tcn_fusion_results/exp6_tape_ep6_critic.weights.h5\n",
      "./tcn_fusion_results/exp6_tape_step060000_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp1p485_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00101_shp0p755_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00047_shp0p822_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00062_shp0p871_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00105_shp0p627_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00063_shp0p950_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00039_shp2p205_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp1p631_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00010_shp0p540_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00071_shp1p081_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00020_shp1p321_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00094_shp0p552_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00037_shp1p978_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00069_shp1p922_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00063_shp0p950_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00090_shp0p736_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00027_shp2p266_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00006_shp3p396_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00071_shp1p081_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00097_shp0p821_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00033_shp1p429_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00098_shp0p906_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00040_shp0p606_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00110_shp0p759_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00005_shp1p631_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00089_shp0p872_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00107_shp0p916_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00107_shp0p916_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00067_shp1p185_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00082_shp0p589_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00010_shp0p540_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00087_shp0p633_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00015_shp2p029_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00096_shp0p726_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00035_shp1p583_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00112_shp0p754_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00016_shp1p090_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00017_shp0p575_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00018_shp0p536_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p136_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00111_shp0p849_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00095_shp0p867_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00038_shp0p531_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p237_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00059_shp0p502_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00054_shp1p029_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00017_shp0p575_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00102_shp0p806_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00102_shp0p806_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00058_shp1p589_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00082_shp0p589_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00007_shp0p953_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00099_shp0p554_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00084_shp0p723_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00062_shp0p871_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00051_shp0p993_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00036_shp1p498_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00065_shp1p063_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00095_shp0p867_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00059_shp0p502_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00053_shp0p553_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00011_shp1p485_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00075_shp0p938_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00067_shp1p185_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00053_shp0p553_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00061_shp0p934_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00061_shp0p934_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00097_shp0p821_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00084_shp0p723_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00022_shp0p510_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00070_shp0p735_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00074_shp0p628_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00028_shp0p582_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00098_shp0p906_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00091_shp0p861_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00101_shp0p755_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00026_shp1p237_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00108_shp0p804_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00109_shp0p901_critic.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841_actor.weights.h5\n",
      "./tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00024_shp2p128_critic.weights.h5\n"
     ]
    }
   ],
   "source": [
    "# list files inside results\n",
    "!find ./tcn_fusion_results -maxdepth 3 -type f | head -n 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09d9e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /content/data1.zip\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_e1556386-a286-4c37-a10a-9be9f0d9b802\", \"data1.zip\", 3113649)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download /content/adaptive_portfolio_rl/tcn_fusion_results as a zip\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "src = Path(\"/content/adaptive_portfolio_rl/data\")\n",
    "zip_base = Path(\"/content/data1\")\n",
    "\n",
    "if not src.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {src}\")\n",
    "\n",
    "zip_path = shutil.make_archive(str(zip_base), \"zip\", root_dir=str(src.parent), base_dir=src.name)\n",
    "print(\"Created:\", zip_path)\n",
    "\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66784a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Copied to Google Drive: MyDrive/data1.zip\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp /content/data1.zip /content/drive/MyDrive/\n",
    "print(\"Copied to Google Drive: MyDrive/data1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ab856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUICK TRAINING LOG INSPECTION (LATEST)\n",
    "# ============================================================================\n",
    "logs_dir = Path(LATEST_RESULTS_ROOT) / 'logs'\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "episodes_files = sorted(logs_dir.glob('*episodes*.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not episodes_files:\n",
    "    print(f'No episodes CSV found in {logs_dir} yet.')\n",
    "else:\n",
    "    epis_path = episodes_files[0]\n",
    "    episodes_df = pd.read_csv(epis_path)\n",
    "    print('Episodes file:', epis_path)\n",
    "    print('Rows:', len(episodes_df))\n",
    "    display(episodes_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bacaf2",
   "metadata": {},
   "source": [
    "## 5) Evaluation (Unified Multi-Track)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: RELOAD TRAINING METADATA (POST-RESTART)\n",
    "# ============================================================================\n",
    "USE_METADATA_RELOAD = False\n",
    "METADATA_PATH = None  # e.g., Path('tcn_results/logs/Exp6_TCN_Enhanced_TAPE_training_YYYYMMDD_HHMMSS_metadata.json')\n",
    "\n",
    "if USE_METADATA_RELOAD:\n",
    "    if METADATA_PATH is None:\n",
    "        logs_dir = Path(LATEST_RESULTS_ROOT) / 'logs'\n",
    "        cand = sorted(logs_dir.glob('*metadata*.json'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        METADATA_PATH = cand[0] if cand else None\n",
    "\n",
    "    if METADATA_PATH and Path(METADATA_PATH).exists():\n",
    "        config = load_training_metadata_into_config(Path(METADATA_PATH), config, verbose=True)\n",
    "        print('âœ… Metadata reloaded from:', METADATA_PATH)\n",
    "    else:\n",
    "        print('âš ï¸ Metadata file not found; continuing with current config.')\n",
    "else:\n",
    "    print('â„¹ï¸ USE_METADATA_RELOAD=False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UNIFIED EVALUATION: det_mode + det_mean + stochastic\n",
    "# ============================================================================\n",
    "RUN_EVAL = True\n",
    "\n",
    "# Model selection\n",
    "MODEL_FAMILY = 'normal'           # normal | rare | clip\n",
    "NORMAL_MODEL_STRATEGY = 'latest'  # latest | final\n",
    "RARE_MODEL_STRATEGY = 'best'      # best | episode\n",
    "CHECKPOINT_EPISODE = 54           # used when rare_model_strategy='episode'\n",
    "CLIP_EPISODE = 54                 # used when model_family='clip'\n",
    "CHECKPOINT_PREFIX_OVERRIDE = None # e.g., 'tcn_fusion_results/exp6_tape_ep83'\n",
    "\n",
    "if RUN_EVAL:\n",
    "    experiment6_stub = create_experiment6_result_stub(\n",
    "        random_seed=RANDOM_SEED,\n",
    "        use_covariance=True,\n",
    "        architecture=config['agent_params']['actor_critic_type'],\n",
    "        checkpoint_path=None,\n",
    "        base_agent_params=config.get('agent_params'),\n",
    "    )\n",
    "\n",
    "    evaluation_stub = evaluate_experiment6_checkpoint(\n",
    "        experiment6_stub,\n",
    "        phase1_data=phase1_data,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        model_family=MODEL_FAMILY,\n",
    "        normal_model_strategy=NORMAL_MODEL_STRATEGY,\n",
    "        rare_model_strategy=RARE_MODEL_STRATEGY,\n",
    "        checkpoint_episode=CHECKPOINT_EPISODE,\n",
    "        clip_episode=CLIP_EPISODE,\n",
    "        checkpoint_path_override=CHECKPOINT_PREFIX_OVERRIDE,\n",
    "        num_eval_runs=10,\n",
    "        compare_deterministic_modes=['mode', 'mean'],\n",
    "        stochastic_eval_mode='sample',\n",
    "        sample_actions_stochastic=True,\n",
    "        sample_actions=None,\n",
    "        stochastic_episode_length_limit=252,\n",
    "        save_eval_logs=True,\n",
    "        save_eval_artifacts=True,\n",
    "    )\n",
    "\n",
    "    print('âœ… Evaluation complete')\n",
    "    print('Checkpoint:', evaluation_stub.actor_weights_path)\n",
    "    print('Eval CSV  :', evaluation_stub.eval_results_path)\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_EVAL=False (set True to evaluate)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION ARTIFACT EXPORTS (VARIANT-SCOPED)\n",
    "# ============================================================================\n",
    "from datetime import datetime\n",
    "\n",
    "if 'evaluation_stub' not in globals():\n",
    "    print('Run evaluation first (RUN_EVAL=True).')\n",
    "else:\n",
    "    assets = ASSET_TICKERS + ['Cash']\n",
    "\n",
    "    results_root = Path(globals().get('LATEST_RESULTS_ROOT', 'tcn_results'))\n",
    "    stamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    out_root = results_root / 'model_outputs' / f'eval_{stamp}'\n",
    "    det_out = out_root / 'deterministic'\n",
    "    sto_out = out_root / 'stochastic'\n",
    "    det_out.mkdir(parents=True, exist_ok=True)\n",
    "    sto_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Deterministic artifacts\n",
    "    det_dates = pd.DatetimeIndex(evaluation_stub.env_test_deterministic.dates)\n",
    "\n",
    "    if len(evaluation_stub.deterministic_alphas) > 0:\n",
    "        df_alpha = pd.DataFrame(evaluation_stub.deterministic_alphas, columns=assets)\n",
    "        df_alpha.index = det_dates[:len(df_alpha)]\n",
    "        df_alpha.index.name = 'date'\n",
    "        df_alpha.to_csv(det_out / 'alphas.csv')\n",
    "\n",
    "    if len(evaluation_stub.deterministic_weights) > 0:\n",
    "        df_w = pd.DataFrame(evaluation_stub.deterministic_weights, columns=assets)\n",
    "        df_w.index = det_dates[:len(df_w)]\n",
    "        df_w.index.name = 'date'\n",
    "        df_w.to_csv(det_out / 'weights.csv')\n",
    "\n",
    "    if len(evaluation_stub.deterministic_actions) > 0:\n",
    "        df_a = pd.DataFrame(evaluation_stub.deterministic_actions, columns=assets)\n",
    "        df_a.index = det_dates[:len(df_a)]\n",
    "        df_a.index.name = 'date'\n",
    "        df_a.to_csv(det_out / 'actions.csv')\n",
    "\n",
    "    # Copy eval summary CSV into output root for traceability\n",
    "    eval_csv_path = Path(evaluation_stub.eval_results_path) if evaluation_stub.eval_results_path else None\n",
    "    if eval_csv_path and eval_csv_path.exists():\n",
    "        df_eval = pd.read_csv(eval_csv_path)\n",
    "        df_eval.to_csv(out_root / 'evaluation_summary.csv', index=False)\n",
    "    else:\n",
    "        df_eval = pd.DataFrame()\n",
    "\n",
    "    # Stochastic artifacts\n",
    "    all_dates = pd.DatetimeIndex(evaluation_stub.env_test_random.dates)\n",
    "    actions_rows, weights_rows, alphas_rows = [], [], []\n",
    "\n",
    "    if isinstance(evaluation_stub.stochastic_results, pd.DataFrame) and not evaluation_stub.stochastic_results.empty:\n",
    "        stochastic_results_df = evaluation_stub.stochastic_results.copy()\n",
    "        stochastic_results_df.to_csv(sto_out / 'stochastic_results.csv', index=False)\n",
    "\n",
    "        for i in range(len(stochastic_results_df)):\n",
    "            run_id = int(stochastic_results_df.iloc[i].get('run', i + 1))\n",
    "            start_date = pd.Timestamp(stochastic_results_df.iloc[i]['start_date'])\n",
    "            start_idx = all_dates.get_loc(start_date)\n",
    "\n",
    "            run_actions = evaluation_stub.stochastic_actions[i] if i < len(evaluation_stub.stochastic_actions) else []\n",
    "            run_weights = evaluation_stub.stochastic_weights[i] if i < len(evaluation_stub.stochastic_weights) else []\n",
    "            run_alphas = evaluation_stub.stochastic_alphas[i] if i < len(evaluation_stub.stochastic_alphas) else []\n",
    "\n",
    "            run_dates = all_dates[start_idx:start_idx + len(run_weights)]\n",
    "\n",
    "            if len(run_actions):\n",
    "                dfa = pd.DataFrame(run_actions, columns=assets)\n",
    "                dfa['run'] = run_id\n",
    "                dfa['date'] = run_dates[:len(dfa)]\n",
    "                actions_rows.append(dfa)\n",
    "\n",
    "            if len(run_weights):\n",
    "                dfw = pd.DataFrame(run_weights, columns=assets)\n",
    "                dfw['run'] = run_id\n",
    "                dfw['date'] = run_dates[:len(dfw)]\n",
    "                weights_rows.append(dfw)\n",
    "\n",
    "            if len(run_alphas):\n",
    "                dfl = pd.DataFrame(run_alphas, columns=assets)\n",
    "                dfl['run'] = run_id\n",
    "                dfl['date'] = run_dates[:len(dfl)]\n",
    "                alphas_rows.append(dfl)\n",
    "\n",
    "    if actions_rows:\n",
    "        pd.concat(actions_rows, ignore_index=True).set_index(['run', 'date']).to_csv(sto_out / 'actions_all_runs.csv')\n",
    "    if weights_rows:\n",
    "        pd.concat(weights_rows, ignore_index=True).set_index(['run', 'date']).to_csv(sto_out / 'weights_all_runs.csv')\n",
    "    if alphas_rows:\n",
    "        pd.concat(alphas_rows, ignore_index=True).set_index(['run', 'date']).to_csv(sto_out / 'alphas_all_runs.csv')\n",
    "\n",
    "    # README with current run context\n",
    "    readme_lines = [\n",
    "        '# Evaluation Artifact Export',\n",
    "        '',\n",
    "        f'- Variant results root: `{results_root}`',\n",
    "        f'- Export root: `{out_root}`',\n",
    "        f'- Checkpoint actor: `{evaluation_stub.actor_weights_path}`',\n",
    "        f'- Checkpoint critic: `{evaluation_stub.critic_weights_path}`',\n",
    "        f'- Eval summary CSV: `{evaluation_stub.eval_results_path}`',\n",
    "        f'- Export timestamp: `{stamp}`',\n",
    "        '',\n",
    "        '## Included Files',\n",
    "        '- `deterministic/weights.csv`',\n",
    "        '- `deterministic/actions.csv`',\n",
    "        '- `deterministic/alphas.csv`',\n",
    "        '- `stochastic/stochastic_results.csv` (if stochastic runs were executed)',\n",
    "        '- `stochastic/weights_all_runs.csv`',\n",
    "        '- `stochastic/actions_all_runs.csv`',\n",
    "        '- `stochastic/alphas_all_runs.csv`',\n",
    "        '- `evaluation_summary.csv`',\n",
    "    ]\n",
    "\n",
    "    if not df_eval.empty:\n",
    "        cols = [\n",
    "            'eval_track', 'evaluation_type', 'start_date', 'market_regime',\n",
    "            'mean_concentration_hhi', 'mean_top_weight',\n",
    "            'mean_action_realization_l1', 'max_action_realization_l1'\n",
    "        ]\n",
    "        present = [c for c in cols if c in df_eval.columns]\n",
    "        readme_lines += ['', '## Key Logged Diagnostics (present in summary CSV)', *(f'- `{c}`' for c in present)]\n",
    "\n",
    "    (out_root / 'README.md').write_text('\\n'.join(readme_lines), encoding='utf-8')\n",
    "\n",
    "    print('âœ… Export complete')\n",
    "    print('Export root:', out_root)\n",
    "    print('Deterministic dir:', det_out)\n",
    "    print('Stochastic dir   :', sto_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c70cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVAL CSV DIAGNOSTIC COLUMN CHECK\n",
    "# ============================================================================\n",
    "required_cols = [\n",
    "    'start_date',\n",
    "    'market_regime',\n",
    "    'mean_concentration_hhi',\n",
    "    'mean_top_weight',\n",
    "    'mean_action_realization_l1',\n",
    "    'max_action_realization_l1',\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "\n",
    "if 'evaluation_stub' in globals() and getattr(evaluation_stub, 'eval_results_path', None):\n",
    "    p = Path(evaluation_stub.eval_results_path)\n",
    "    if p.exists():\n",
    "        csv_path = p\n",
    "\n",
    "if csv_path is None:\n",
    "    root = Path(globals().get('LATEST_RESULTS_ROOT', 'tcn_results'))\n",
    "    logs_dir = root / 'logs'\n",
    "    candidates = sorted(logs_dir.glob('*_eval_*.csv'), key=lambda x: x.stat().st_mtime, reverse=True) if logs_dir.exists() else []\n",
    "    csv_path = candidates[0] if candidates else None\n",
    "\n",
    "if csv_path is None:\n",
    "    print('âš ï¸ No evaluation CSV found. Run evaluation first.')\n",
    "else:\n",
    "    df_eval = pd.read_csv(csv_path)\n",
    "    present = [c for c in required_cols if c in df_eval.columns]\n",
    "    missing = [c for c in required_cols if c not in df_eval.columns]\n",
    "\n",
    "    print('ðŸ“‚ Eval CSV:', csv_path)\n",
    "    print('Rows:', len(df_eval))\n",
    "    print('Required columns present:', len(present), '/', len(required_cols))\n",
    "\n",
    "    if missing:\n",
    "        print('âŒ Missing columns:', missing)\n",
    "    else:\n",
    "        print('âœ… All required diagnostic columns are present.')\n",
    "\n",
    "    show_cols = ['eval_track', 'evaluation_type'] + [c for c in required_cols if c in df_eval.columns]\n",
    "    show_cols = [c for c in show_cols if c in df_eval.columns]\n",
    "    if show_cols:\n",
    "        display(df_eval[show_cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTICS SUMMARY\n",
    "# ============================================================================\n",
    "if 'evaluation_stub' not in globals():\n",
    "    print('Run evaluation first (RUN_EVAL=True).')\n",
    "else:\n",
    "    # stochastic summary\n",
    "    stoch = evaluation_stub.stochastic_results.copy()\n",
    "    if stoch is not None and not stoch.empty:\n",
    "        cols = [\n",
    "            'total_return', 'annualized_return', 'sharpe_ratio', 'sortino_ratio',\n",
    "            'max_drawdown', 'volatility', 'turnover', 'win_rate'\n",
    "        ]\n",
    "        cols = [c for c in cols if c in stoch.columns]\n",
    "        print('Stochastic summary:')\n",
    "        display(stoch[cols].describe().T)\n",
    "\n",
    "    # deterministic diagnostics\n",
    "    acts = np.asarray(evaluation_stub.deterministic_actions)\n",
    "    alps = np.asarray(evaluation_stub.deterministic_alphas)\n",
    "\n",
    "    action_uniques = int(np.unique(np.round(acts, 6), axis=0).shape[0]) if acts.size else 0\n",
    "    alpha_le1_frac = float(np.mean(alps <= 1.0)) if alps.size else 0.0\n",
    "    argmax_uniques = int(np.unique(np.argmax(alps, axis=1)).shape[0]) if (alps.ndim == 2 and len(alps) > 0) else 0\n",
    "\n",
    "    print('Deterministic diagnostics:')\n",
    "    print(' action_uniques      =', action_uniques)\n",
    "    print(' alpha<=1 fraction   =', alpha_le1_frac)\n",
    "    print(' argmax_alpha_uniques=', argmax_uniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FIXED STRESS-WINDOW EVALUATION (2 WINDOWS)\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "from dataclasses import replace\n",
    "\n",
    "STRESS_WINDOWS = [\n",
    "    ('2020-02-20', '2020-05-29', 'COVID crash + rebound'),\n",
    "    ('2022-01-03', '2022-12-30', 'Rate-hike bear year'),\n",
    "]\n",
    "\n",
    "def subset_phase1_test_window(phase1_data, start_date, end_date):\n",
    "    s = pd.Timestamp(start_date)\n",
    "    e = pd.Timestamp(end_date)\n",
    "    df = phase1_data.test_df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    win = df[(df['Date'] >= s) & (df['Date'] <= e)].copy()\n",
    "    if win.empty:\n",
    "        raise ValueError(f'No rows in test_df for {start_date} -> {end_date}')\n",
    "    return replace(\n",
    "        phase1_data,\n",
    "        test_df=win,\n",
    "        test_start_date=win['Date'].min(),\n",
    "        train_end_date=win['Date'].max(),\n",
    "    )\n",
    "\n",
    "fixed_rows = []\n",
    "for start, end, label in STRESS_WINDOWS:\n",
    "    phase_win = subset_phase1_test_window(phase1_data, start, end)\n",
    "\n",
    "    ev = evaluate_experiment6_checkpoint(\n",
    "        experiment6_stub,\n",
    "        phase1_data=phase_win,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        checkpoint_path_override=CHECKPOINT_PREFIX_OVERRIDE,\n",
    "        deterministic_eval_mode='mode',\n",
    "        num_eval_runs=0,\n",
    "        stochastic_eval_mode='sample',\n",
    "        save_eval_logs=False,\n",
    "        save_eval_artifacts=False,\n",
    "    )\n",
    "\n",
    "    m = ev.deterministic_metrics or {}\n",
    "    fixed_rows.append({\n",
    "        'window_label': label,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'days_traded': len(ev.deterministic_portfolio) - 1 if len(ev.deterministic_portfolio) else 0,\n",
    "        'total_return': m.get('total_return'),\n",
    "        'annualized_return': m.get('annualized_return'),\n",
    "        'sharpe': m.get('sharpe_ratio'),\n",
    "        'sortino': m.get('sortino_ratio'),\n",
    "        'max_drawdown': m.get('max_drawdown_abs', m.get('max_drawdown')),\n",
    "        'volatility': m.get('volatility'),\n",
    "        'turnover': m.get('turnover'),\n",
    "        'win_rate': m.get('win_rate'),\n",
    "    })\n",
    "\n",
    "fixed_df = pd.DataFrame(fixed_rows)\n",
    "display(fixed_df.sort_values('start'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b0711",
   "metadata": {},
   "source": [
    "## 6) Checkpoint Scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aee0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, socket\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"hostname:\", socket.gethostname())\n",
    "print(\"exists:\", os.path.exists(\"/content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260219_210119_metadata.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "meta = Path(\"tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260219_210119_metadata.json\")\n",
    "config = load_training_metadata_into_config(meta, deepcopy(config), verbose=True)\n",
    "\n",
    "# hard enforce fusion\n",
    "config[\"agent_params\"][\"actor_critic_type\"] = \"TCN_FUSION\"\n",
    "config[\"agent_params\"][\"use_fusion\"] = True\n",
    "config[\"agent_params\"][\"use_attention\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8dfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN CHECKPOINT SCAN (LOCAL + ROBUST)\n",
    "# ============================================================================\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def resolve_results_root():\n",
    "    candidates = [\n",
    "        # Local Windows path (your machine)\n",
    "        #Path(r\"C:\\Users\\Owner\\new_project\\adaptive_portfolio_rl\\tcn_fusion_results\"),\n",
    "        # WSL path to same folder\n",
    "        #Path(\"/mnt/c/Users/Owner/new_project/adaptive_portfolio_rl/tcn_fusion_results\"),\n",
    "        # Relative local fallback\n",
    "        #Path(\"./tcn_fusion_results\"),\n",
    "\n",
    "        # Colab fallbacks (kept just in case)\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results/rare_models\"),\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_results\"),\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results00\"),\n",
    "        Path(\"/content/adaptive_portfolio_rl/tcn_results00\"),\n",
    "    ]\n",
    "    existing = [p for p in candidates if p.exists()]\n",
    "    if not existing:\n",
    "        raise FileNotFoundError(\"No results root found (local or /content).\")\n",
    "    # Prefer local by candidate order (first match)\n",
    "    return existing[0]\n",
    "\n",
    "def evaluate_checkpoint_range_deterministic_all(\n",
    "    episode_range=(8, 100),\n",
    "    results_root=None,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    deterministic_eval_mode=\"mean\",\n",
    "):\n",
    "    low, high = episode_range\n",
    "    base_root = Path(results_root) if results_root else resolve_results_root()\n",
    "\n",
    "    actor_paths = sorted(base_root.rglob(\"*_actor.weights.h5\"))\n",
    "    print(f\"Found actor files (all subdirs): {len(actor_paths)} under {base_root}\")\n",
    "\n",
    "    rows = []\n",
    "    skipped = 0\n",
    "\n",
    "    for actor_path in actor_paths:\n",
    "        m_ep = re.search(r\"_ep(\\d+)\", actor_path.name)\n",
    "        if not m_ep:\n",
    "            continue\n",
    "        ep = int(m_ep.group(1))\n",
    "        if not (low <= ep <= high):\n",
    "            continue\n",
    "\n",
    "        prefix = str(actor_path).replace(\"_actor.weights.h5\", \"\")\n",
    "        ckpt_group = actor_path.parent.name\n",
    "\n",
    "        try:\n",
    "            stub = create_experiment6_result_stub(\n",
    "                random_seed=RANDOM_SEED,\n",
    "                use_covariance=True,\n",
    "                architecture=arch,\n",
    "                checkpoint_path=prefix,\n",
    "                agent_config=agent_cfg,      # important\n",
    "                base_agent_params=None,      # avoid default drift\n",
    "            )\n",
    "\n",
    "\n",
    "            ev = evaluate_experiment6_checkpoint(\n",
    "                experiment6=stub,\n",
    "                phase1_data=phase1_data,\n",
    "                config=config,\n",
    "                random_seed=random_seed,\n",
    "                checkpoint_path_override=prefix,\n",
    "                model_family=\"normal\",\n",
    "                normal_model_strategy=\"latest\",\n",
    "                num_eval_runs=0,\n",
    "                deterministic_eval_mode=deterministic_eval_mode,\n",
    "                save_eval_logs=False,\n",
    "                save_eval_artifacts=False,\n",
    "            )\n",
    "\n",
    "            m = ev.deterministic_metrics or {}\n",
    "            rows.append({\n",
    "                \"episode\": ep,\n",
    "                \"source_dir\": ckpt_group,\n",
    "                \"checkpoint_prefix\": prefix,\n",
    "                \"sharpe\": m.get(\"sharpe_ratio\", float(\"nan\")),\n",
    "                \"total_return\": m.get(\"total_return\", float(\"nan\")),\n",
    "                \"max_drawdown\": m.get(\"max_drawdown_abs\", m.get(\"max_drawdown\", float(\"nan\"))),\n",
    "                \"turnover\": m.get(\"turnover\", float(\"nan\")),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            print(f\"Skipping incompatible checkpoint: {actor_path.name} | {type(e).__name__}: {e}\")\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"No checkpoints in range {episode_range} under {base_root}\")\n",
    "        return None\n",
    "\n",
    "    df_scores = pd.DataFrame(rows).sort_values(\"sharpe\", ascending=False).reset_index(drop=True)\n",
    "    print(f\"Evaluated: {len(df_scores)} | Skipped: {skipped}\")\n",
    "    return df_scores\n",
    "\n",
    "# Run\n",
    "RUN_SCAN = True\n",
    "\n",
    "if RUN_SCAN:\n",
    "    results_root = resolve_results_root()\n",
    "    print(\"Scanning results root:\", results_root)\n",
    "\n",
    "    scan_df = evaluate_checkpoint_range_deterministic_all(\n",
    "        episode_range=(1, 300),\n",
    "        results_root=results_root,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        deterministic_eval_mode=\"mean\",\n",
    "    )\n",
    "\n",
    "    display(scan_df.head(20) if scan_df is not None else None)\n",
    "\n",
    "    step_dir = results_root / \"step_sharpe_checkpoints\"\n",
    "    if step_dir.exists():\n",
    "        step_files = sorted(step_dir.glob(\"*_actor.weights.h5\"))\n",
    "        print(f\"Step-Sharpe checkpoints found: {len(step_files)}\")\n",
    "        for p in step_files[:10]:\n",
    "            print(\" -\", p.name)\n",
    "    else:\n",
    "        print(\"No step_sharpe_checkpoints directory yet.\")\n",
    "else:\n",
    "    print(\"RUN_SCAN=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a05938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_root = Path(\"tcn_fusion_results\")\n",
    "meta = results_root / \"logs\" / \"Exp6_TCN_FUSION_Enhanced_TAPE_training_20260219_210119_metadata.json\"\n",
    "\n",
    "# 1) align config to run\n",
    "config = load_training_metadata_into_config(meta, deepcopy(config), verbose=True)\n",
    "\n",
    "with open(meta, \"r\", encoding=\"utf-8\") as f:\n",
    "    md = json.load(f)\n",
    "\n",
    "agent_cfg = md[\"Architecture_Settings\"][\"agent_params_effective\"]\n",
    "arch = md[\"Architecture_Settings\"][\"resolved_architecture\"]\n",
    "meta_mtime = meta.stat().st_mtime\n",
    "\n",
    "# 2) filter actor checkpoints to this run window (newer than metadata)\n",
    "all_actor_paths = sorted(results_root.rglob(\"*_actor.weights.h5\"))\n",
    "actor_paths = [p for p in all_actor_paths if p.stat().st_mtime >= meta_mtime - 5]\n",
    "\n",
    "print(\"all:\", len(all_actor_paths), \"filtered:\", len(actor_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHECKPOINT SCANNER (DETERMINISTIC)\n",
    "# ============================================================================\n",
    "import re\n",
    "\n",
    "\n",
    "def evaluate_checkpoint_range_deterministic(\n",
    "    episode_range=(2, 300),\n",
    "    results_root=None,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    deterministic_eval_mode='mode',\n",
    "):\n",
    "    low, high = episode_range\n",
    "    base_root = Path(results_root) if results_root else Path(LATEST_RESULTS_ROOT)\n",
    "\n",
    "    checkpoints = {}\n",
    "    for root in [base_root, base_root / 'rare_models']:\n",
    "        if not root.exists():\n",
    "            continue\n",
    "        for actor_path in root.glob('*_actor.weights.h5'):\n",
    "            m = re.search(r'_ep(\\d+)', actor_path.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            ep = int(m.group(1))\n",
    "            if low <= ep <= high:\n",
    "                checkpoints[ep] = actor_path\n",
    "\n",
    "    if not checkpoints:\n",
    "        print(f'No checkpoints found in {base_root} for range {episode_range}.')\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for ep, actor_path in sorted(checkpoints.items()):\n",
    "        prefix = str(actor_path).replace('_actor.weights.h5', '')\n",
    "\n",
    "        stub = create_experiment6_result_stub(\n",
    "            random_seed=random_seed,\n",
    "            use_covariance=True,\n",
    "            architecture=config['agent_params']['actor_critic_type'],\n",
    "            checkpoint_path=prefix,\n",
    "            base_agent_params=config.get('agent_params'),\n",
    "        )\n",
    "\n",
    "        ev = evaluate_experiment6_checkpoint(\n",
    "            experiment6=stub,\n",
    "            phase1_data=phase1_data,\n",
    "            config=config,\n",
    "            random_seed=random_seed,\n",
    "            checkpoint_path_override=prefix,\n",
    "            model_family='normal',\n",
    "            normal_model_strategy='latest',\n",
    "            num_eval_runs=0,\n",
    "            deterministic_eval_mode=deterministic_eval_mode,\n",
    "            save_eval_logs=False,\n",
    "            save_eval_artifacts=False,\n",
    "        )\n",
    "\n",
    "        m = ev.deterministic_metrics or {}\n",
    "        rows.append({\n",
    "            'episode': ep,\n",
    "            'checkpoint_prefix': prefix,\n",
    "            'sharpe': m.get('sharpe_ratio', float('nan')),\n",
    "            'total_return': m.get('total_return', float('nan')),\n",
    "            'max_drawdown': m.get('max_drawdown_abs', m.get('max_drawdown', float('nan'))),\n",
    "            'turnover': m.get('turnover', float('nan')),\n",
    "        })\n",
    "\n",
    "    df_scores = pd.DataFrame(rows).sort_values('sharpe', ascending=False)\n",
    "    return df_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a68bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN CHECKPOINT SCAN\n",
    "# ============================================================================\n",
    "RUN_SCAN = True\n",
    "\n",
    "if RUN_SCAN:\n",
    "    results_root = Path(\"/content/adaptive_portfolio_rl\") #Path(globals().get('LATEST_RESULTS_ROOT', 'tcn_results'))\n",
    "    print('Scanning:', results_root)\n",
    "    scan_df = evaluate_checkpoint_range_deterministic(\n",
    "        episode_range=(8, 100),\n",
    "        results_root=results_root,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        deterministic_eval_mode='mean',\n",
    "    )\n",
    "    display(scan_df.head(20) if scan_df is not None else None)\n",
    "\n",
    "    step_dir = results_root / 'step_sharpe_checkpoints'\n",
    "    if step_dir.exists():\n",
    "        step_files = sorted(step_dir.glob('*_actor.weights.h5'))\n",
    "        print(f'Step-Sharpe checkpoints found: {len(step_files)}')\n",
    "        for p in step_files[:10]:\n",
    "            print(' -', p.name)\n",
    "    else:\n",
    "        print('No step_sharpe_checkpoints directory yet.')\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_SCAN=False')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03e629",
   "metadata": {},
   "source": [
    "## 7) Overfit Monitor (Train-Test Gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac1a2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OVERFIT MONITOR HELPERS (VM-safe + scan all checkpoint folders)\n",
    "# ============================================================================\n",
    "import re\n",
    "from dataclasses import replace\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _infer_results_root_for_notebook(cfg):\n",
    "    arch = cfg.get(\"agent_params\", {}).get(\"actor_critic_type\", \"TCN\").upper()\n",
    "    use_attention = bool(cfg.get(\"agent_params\", {}).get(\"use_attention\", False))\n",
    "    use_fusion = bool(cfg.get(\"agent_params\", {}).get(\"use_fusion\", False))\n",
    "\n",
    "    if arch.startswith(\"TCN\"):\n",
    "        if use_fusion:\n",
    "            rel = \"tcn_fusion_results\"\n",
    "        elif use_attention:\n",
    "            rel = \"tcn_att_results\"\n",
    "        else:\n",
    "            rel = \"tcn_results\"\n",
    "    else:\n",
    "        rel = \"tcn_results\"\n",
    "\n",
    "    candidates = [\n",
    "        Path(\"/content/adaptive_portfolio_rl\") / rel,  # Colab VM\n",
    "        Path(rel),                                     # local cwd fallback\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _maybe_load_metadata_into_config(config, results_root, metadata_path=None, auto_latest=True):\n",
    "    cfg = config\n",
    "    chosen = None\n",
    "\n",
    "    if metadata_path:\n",
    "        chosen = Path(metadata_path)\n",
    "    elif auto_latest:\n",
    "        log_dir = Path(results_root) / \"logs\"\n",
    "        metas = sorted(log_dir.glob(\"*_metadata.json\"), key=lambda p: p.stat().st_mtime)\n",
    "        if metas:\n",
    "            chosen = metas[-1]\n",
    "\n",
    "    if chosen is None:\n",
    "        return cfg, None\n",
    "\n",
    "    if \"load_training_metadata_into_config\" not in globals():\n",
    "        print(f\"âš ï¸ metadata loader not found in scope, skipping metadata load: {chosen}\")\n",
    "        return cfg, None\n",
    "\n",
    "    cfg = load_training_metadata_into_config(chosen, cfg, verbose=True)\n",
    "    return cfg, chosen\n",
    "\n",
    "\n",
    "def _discover_checkpoint_prefixes(\n",
    "    results_root,\n",
    "    episode_range=(1, 9999),\n",
    "    include_root=True,\n",
    "    include_rare=True,\n",
    "    include_high_watermark=True,\n",
    "    include_step_sharpe=True,\n",
    "    include_other_subdirs=False,\n",
    "    recursive=True,\n",
    "    require_critic_pair=True,\n",
    "):\n",
    "    results_root = Path(results_root)\n",
    "    lo, hi = episode_range\n",
    "    actor_files = list(results_root.rglob(\"*_actor.weights.h5\") if recursive else results_root.glob(\"*_actor.weights.h5\"))\n",
    "\n",
    "    ckpts = []\n",
    "    for actor in actor_files:\n",
    "        parent = actor.parent\n",
    "        parent_name = parent.name\n",
    "        is_root = parent.resolve() == results_root.resolve()\n",
    "\n",
    "        allowed = False\n",
    "        if is_root and include_root:\n",
    "            allowed = True\n",
    "        elif parent_name == \"rare_models\" and include_rare:\n",
    "            allowed = True\n",
    "        elif parent_name == \"high_watermark_checkpoints\" and include_high_watermark:\n",
    "            allowed = True\n",
    "        elif parent_name == \"step_sharpe_checkpoints\" and include_step_sharpe:\n",
    "            allowed = True\n",
    "        elif include_other_subdirs:\n",
    "            allowed = True\n",
    "\n",
    "        if not allowed:\n",
    "            continue\n",
    "\n",
    "        prefix = str(actor).replace(\"_actor.weights.h5\", \"\")\n",
    "        critic = Path(prefix + \"_critic.weights.h5\")\n",
    "        if require_critic_pair and not critic.exists():\n",
    "            continue\n",
    "\n",
    "        name = actor.name\n",
    "        m_ep = re.search(r\"_ep(\\d+)\", name)\n",
    "        m_step = re.search(r\"_step(\\d+)\", name)\n",
    "\n",
    "        ep = int(m_ep.group(1)) if m_ep else None\n",
    "        step = int(m_step.group(1)) if m_step else None\n",
    "\n",
    "        # Apply episode filter only to episode-tagged checkpoints.\n",
    "        if ep is not None and not (lo <= ep <= hi):\n",
    "            continue\n",
    "\n",
    "        if \"rare_models\" in str(parent):\n",
    "            kind = \"rare\"\n",
    "        elif \"high_watermark_checkpoints\" in str(parent):\n",
    "            kind = \"high_watermark\"\n",
    "        elif \"step_sharpe_checkpoints\" in str(parent):\n",
    "            kind = \"step_sharpe\"\n",
    "        elif step is not None:\n",
    "            kind = \"periodic_step\"\n",
    "        else:\n",
    "            kind = \"root\"\n",
    "\n",
    "        ckpts.append({\n",
    "            \"checkpoint_prefix\": prefix,\n",
    "            \"source_dir\": str(parent),\n",
    "            \"checkpoint_kind\": kind,\n",
    "            \"episode\": ep,\n",
    "            \"step\": step,\n",
    "            \"actor_path\": str(actor),\n",
    "            \"critic_path\": str(critic),\n",
    "        })\n",
    "\n",
    "    # De-dupe by prefix\n",
    "    uniq = {}\n",
    "    for c in ckpts:\n",
    "        uniq[c[\"checkpoint_prefix\"]] = c\n",
    "\n",
    "    ckpts = list(uniq.values())\n",
    "    ckpts.sort(key=lambda x: (\n",
    "        x[\"episode\"] if x[\"episode\"] is not None else 10**9,\n",
    "        x[\"step\"] if x[\"step\"] is not None else 10**12,\n",
    "        x[\"checkpoint_prefix\"],\n",
    "    ))\n",
    "    return ckpts\n",
    "\n",
    "\n",
    "def _subset_phase1_for_eval(phase1_data, split=\"test\"):\n",
    "    split = str(split).lower().strip()\n",
    "    if split not in {\"train\", \"test\"}:\n",
    "        raise ValueError(f\"split must be train or test, got: {split}\")\n",
    "\n",
    "    eval_df = phase1_data.train_df.copy() if split == \"train\" else phase1_data.test_df.copy()\n",
    "    start_date = pd.to_datetime(eval_df[\"Date\"]).min()\n",
    "    end_date = pd.to_datetime(eval_df[\"Date\"]).max()\n",
    "\n",
    "    return replace(\n",
    "        phase1_data,\n",
    "        test_df=eval_df,\n",
    "        test_start_date=start_date,\n",
    "        train_end_date=end_date,\n",
    "    )\n",
    "\n",
    "\n",
    "def _diagnostics_from_eval(ev):\n",
    "    acts = np.asarray(ev.deterministic_actions)\n",
    "    alps = np.asarray(ev.deterministic_alphas)\n",
    "    action_uniques = int(np.unique(np.round(acts, 6), axis=0).shape[0]) if acts.size else 0\n",
    "    alpha_le1_fraction = float(np.mean(alps <= 1.0)) if alps.size else 0.0\n",
    "    argmax_alpha_uniques = int(np.unique(np.argmax(alps, axis=1)).shape[0]) if (alps.ndim == 2 and len(alps) > 0) else 0\n",
    "    return action_uniques, alpha_le1_fraction, argmax_alpha_uniques\n",
    "\n",
    "\n",
    "def run_checkpoint_overfit_monitor(\n",
    "    phase1_data,\n",
    "    config,\n",
    "    random_seed,\n",
    "    episode_range=(1, 300),\n",
    "    deterministic_modes=(\"mode\", \"mean\"),\n",
    "    eval_splits=(\"train\", \"test\"),\n",
    "    results_root=None,\n",
    "    include_root=True,\n",
    "    include_rare=True,\n",
    "    include_high_watermark=True,\n",
    "    include_step_sharpe=True,\n",
    "    include_other_subdirs=False,\n",
    "    recursive=True,\n",
    "    require_critic_pair=True,\n",
    "    metadata_path=None,\n",
    "    auto_load_latest_metadata=True,\n",
    "    save_csv=True,\n",
    "):\n",
    "    cfg = config.copy()\n",
    "    results_root = Path(results_root) if results_root else _infer_results_root_for_notebook(cfg)\n",
    "    if not results_root.exists():\n",
    "        raise RuntimeError(f\"results_root does not exist: {results_root}\")\n",
    "\n",
    "    cfg, used_meta = _maybe_load_metadata_into_config(\n",
    "        cfg, results_root, metadata_path=metadata_path, auto_latest=auto_load_latest_metadata\n",
    "    )\n",
    "    if used_meta:\n",
    "        print(\"ðŸ“„ Using metadata:\", used_meta)\n",
    "\n",
    "    ckpts = _discover_checkpoint_prefixes(\n",
    "        results_root,\n",
    "        episode_range=episode_range,\n",
    "        include_root=include_root,\n",
    "        include_rare=include_rare,\n",
    "        include_high_watermark=include_high_watermark,\n",
    "        include_step_sharpe=include_step_sharpe,\n",
    "        include_other_subdirs=include_other_subdirs,\n",
    "        recursive=recursive,\n",
    "        require_critic_pair=require_critic_pair,\n",
    "    )\n",
    "    if not ckpts:\n",
    "        raise RuntimeError(f\"No checkpoints found under {results_root} with current filters.\")\n",
    "\n",
    "    print(f\"ðŸ”Ž Discovered checkpoints: {len(ckpts)}\")\n",
    "    by_kind = pd.Series([c[\"checkpoint_kind\"] for c in ckpts]).value_counts().to_dict()\n",
    "    print(\"   by kind:\", by_kind)\n",
    "\n",
    "    if isinstance(deterministic_modes, str):\n",
    "        deterministic_modes = (deterministic_modes,)\n",
    "    if isinstance(eval_splits, str):\n",
    "        eval_splits = (eval_splits,)\n",
    "    eval_splits = tuple(str(s).lower().strip() for s in eval_splits)\n",
    "\n",
    "    bad = [s for s in eval_splits if s not in {\"train\", \"test\"}]\n",
    "    if bad:\n",
    "        raise ValueError(f\"Invalid eval_splits entries: {bad}. Allowed: train, test\")\n",
    "\n",
    "    stub = create_experiment6_result_stub(\n",
    "        random_seed=random_seed,\n",
    "        use_covariance=True,\n",
    "        architecture=cfg[\"agent_params\"][\"actor_critic_type\"],\n",
    "        checkpoint_path=ckpts[0][\"checkpoint_prefix\"],\n",
    "        base_agent_params=cfg.get(\"agent_params\"),\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for ck in ckpts:\n",
    "        prefix = ck[\"checkpoint_prefix\"]\n",
    "        ep = ck[\"episode\"]\n",
    "        step = ck[\"step\"]\n",
    "\n",
    "        for split in eval_splits:\n",
    "            phase_eval = _subset_phase1_for_eval(phase1_data, split=split)\n",
    "            split_start = pd.to_datetime(phase_eval.test_df[\"Date\"]).min()\n",
    "            split_end = pd.to_datetime(phase_eval.test_df[\"Date\"]).max()\n",
    "\n",
    "            for mode in deterministic_modes:\n",
    "                try:\n",
    "                    ev = evaluate_experiment6_checkpoint(\n",
    "                        stub,\n",
    "                        phase1_data=phase_eval,\n",
    "                        config=cfg,\n",
    "                        random_seed=random_seed,\n",
    "                        checkpoint_path_override=prefix,\n",
    "                        deterministic_eval_mode=mode,\n",
    "                        num_eval_runs=0,\n",
    "                        stochastic_eval_mode=\"sample\",\n",
    "                        save_eval_logs=False,\n",
    "                        save_eval_artifacts=False,\n",
    "                    )\n",
    "                    m = ev.deterministic_metrics or {}\n",
    "                    action_uniques, alpha_le1_fraction, argmax_alpha_uniques = _diagnostics_from_eval(ev)\n",
    "\n",
    "                    rows.append({\n",
    "                        \"checkpoint_prefix\": prefix,\n",
    "                        \"checkpoint_kind\": ck[\"checkpoint_kind\"],\n",
    "                        \"source_dir\": ck[\"source_dir\"],\n",
    "                        \"episode\": ep,\n",
    "                        \"step\": step,\n",
    "                        \"architecture\": cfg[\"agent_params\"][\"actor_critic_type\"],\n",
    "                        \"split\": split,\n",
    "                        \"deterministic_mode\": mode,\n",
    "                        \"seed\": random_seed,\n",
    "                        \"window_start\": split_start,\n",
    "                        \"window_end\": split_end,\n",
    "                        \"days_traded\": int(len(ev.deterministic_portfolio) - 1) if len(ev.deterministic_portfolio) else 0,\n",
    "                        \"total_return\": float(m.get(\"total_return\", np.nan)),\n",
    "                        \"annualized_return\": float(m.get(\"annualized_return\", np.nan)),\n",
    "                        \"sharpe_ratio\": float(m.get(\"sharpe_ratio\", np.nan)),\n",
    "                        \"sortino_ratio\": float(m.get(\"sortino_ratio\", np.nan)),\n",
    "                        \"max_drawdown\": float(m.get(\"max_drawdown_abs\", m.get(\"max_drawdown\", np.nan))),\n",
    "                        \"volatility\": float(m.get(\"volatility\", np.nan)),\n",
    "                        \"turnover\": float(m.get(\"turnover\", np.nan)),\n",
    "                        \"win_rate\": float(m.get(\"win_rate\", np.nan)),\n",
    "                        \"action_uniques\": action_uniques,\n",
    "                        \"alpha_le1_fraction\": alpha_le1_fraction,\n",
    "                        \"argmax_alpha_uniques\": argmax_alpha_uniques,\n",
    "                        \"eval_error\": \"\",\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    rows.append({\n",
    "                        \"checkpoint_prefix\": prefix,\n",
    "                        \"checkpoint_kind\": ck[\"checkpoint_kind\"],\n",
    "                        \"source_dir\": ck[\"source_dir\"],\n",
    "                        \"episode\": ep,\n",
    "                        \"step\": step,\n",
    "                        \"architecture\": cfg[\"agent_params\"][\"actor_critic_type\"],\n",
    "                        \"split\": split,\n",
    "                        \"deterministic_mode\": mode,\n",
    "                        \"seed\": random_seed,\n",
    "                        \"window_start\": split_start,\n",
    "                        \"window_end\": split_end,\n",
    "                        \"days_traded\": 0,\n",
    "                        \"total_return\": np.nan,\n",
    "                        \"annualized_return\": np.nan,\n",
    "                        \"sharpe_ratio\": np.nan,\n",
    "                        \"sortino_ratio\": np.nan,\n",
    "                        \"max_drawdown\": np.nan,\n",
    "                        \"volatility\": np.nan,\n",
    "                        \"turnover\": np.nan,\n",
    "                        \"win_rate\": np.nan,\n",
    "                        \"action_uniques\": 0,\n",
    "                        \"alpha_le1_fraction\": np.nan,\n",
    "                        \"argmax_alpha_uniques\": 0,\n",
    "                        \"eval_error\": str(e),\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"Monitor produced no rows.\")\n",
    "\n",
    "    ok = df[df[\"eval_error\"] == \"\"].copy()\n",
    "    left = ok[ok[\"split\"] == \"train\"].copy()\n",
    "    right = ok[ok[\"split\"] == \"test\"].copy()\n",
    "\n",
    "    if left.empty or right.empty:\n",
    "        raise RuntimeError(\"Overfit summary requires BOTH successful train and test rows.\")\n",
    "\n",
    "    keys = [\n",
    "        \"checkpoint_prefix\", \"checkpoint_kind\", \"source_dir\",\n",
    "        \"episode\", \"step\", \"architecture\", \"deterministic_mode\", \"seed\"\n",
    "    ]\n",
    "    summary = left.merge(right, on=keys, suffixes=(\"_train\", \"_test\"))\n",
    "\n",
    "    summary[\"sharpe_gap\"] = summary[\"sharpe_ratio_train\"] - summary[\"sharpe_ratio_test\"]\n",
    "    summary[\"mdd_gap\"] = summary[\"max_drawdown_test\"] - summary[\"max_drawdown_train\"]\n",
    "    summary[\"return_gap\"] = summary[\"annualized_return_train\"] - summary[\"annualized_return_test\"]\n",
    "\n",
    "    summary[\"flag_overfit\"] = (\n",
    "        (summary[\"sharpe_gap\"] > 0.40)\n",
    "        | (summary[\"mdd_gap\"] > 0.05)\n",
    "        | (summary[\"return_gap\"] > 0.10)\n",
    "    )\n",
    "\n",
    "    summary = summary.sort_values(\n",
    "        [\"flag_overfit\", \"sharpe_ratio_test\"], ascending=[True, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    out_path = None\n",
    "    if save_csv:\n",
    "        out_dir = Path(results_root) / \"logs\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        out_path = out_dir / f\"checkpoint_overfit_monitor_{ts}.csv\"\n",
    "        summary.to_csv(out_path, index=False)\n",
    "        print(\"ðŸ’¾ Overfit monitor saved:\", out_path)\n",
    "\n",
    "        err_path = out_dir / f\"checkpoint_overfit_monitor_errors_{ts}.csv\"\n",
    "        df[df[\"eval_error\"] != \"\"].to_csv(err_path, index=False)\n",
    "        print(\"ðŸ’¾ Eval errors saved:\", err_path)\n",
    "\n",
    "    return df, summary, out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744f746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied training metadata to config\n",
      "   Metadata: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_metadata.json\n",
      "   Run timestamp: 20260220_072945\n",
      "   Architecture: TCN_FUSION\n",
      "   Turnover target: 0.35\n",
      "   DSR scalar: 2.0\n",
      "   PPO update timesteps: scheduled\n",
      "   Episode length curriculum: True\n",
      "   Profile override loaded: True\n",
      "   Credit assignment mode: step_reward_plus_terminal_bonus\n",
      "   Retroactive episode scaling: False\n",
      "ðŸ“„ Using metadata: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260220_072945_metadata.json\n",
      "ðŸ”Ž Discovered checkpoints: 109\n",
      "   by kind: {'high_watermark': 91, 'periodic_step': 10, 'rare': 5, 'root': 3}\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00001_shp0p849_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00002_shp1p029_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n",
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp1p841_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n",
      "ðŸ”§ Building models before loading weights...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Models built successfully\n",
      "ðŸ“‚ Loading checkpoint weights...\n",
      "\n",
      "================================================================================\n",
      "LOADING CUSTOM CHECKPOINT: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p539\n",
      "================================================================================\n",
      "âœ… Found actor weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p539_actor.weights.h5\n",
      "âœ… Found critic weights: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00004_shp0p539_critic.weights.h5\n",
      "ðŸ—ï¸ Recreating evaluation environments...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mInvalid response: 404 Not Found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results_root = Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results\")\n",
    "\n",
    "df_all, df_summary, out_path = run_checkpoint_overfit_monitor(\n",
    "    phase1_data=phase1_data,\n",
    "    config=config,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    episode_range=(100, 300),\n",
    "    deterministic_modes=(\"mean\",),          # keep stable\n",
    "    eval_splits=(\"test\"),\n",
    "    results_root=results_root,\n",
    "    include_root=True,\n",
    "    include_rare=True,\n",
    "    include_high_watermark=True,\n",
    "    include_step_sharpe=True,               # set True even if empty\n",
    "    include_other_subdirs=False,\n",
    "    recursive=True,\n",
    "    require_critic_pair=True,\n",
    "    metadata_path=None,                     # auto-load latest metadata from logs\n",
    "    auto_load_latest_metadata=True,\n",
    "    save_csv=True,\n",
    ")\n",
    "\n",
    "display(df_summary.head(30))\n",
    "print(\"rows all:\", len(df_all), \"rows summary:\", len(df_summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ba808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN OVERFIT MONITOR\n",
    "# ============================================================================\n",
    "RUN_OVERFIT_MONITOR = True\n",
    "\n",
    "if RUN_OVERFIT_MONITOR:\n",
    "    results_root = Path(globals().get('LATEST_RESULTS_ROOT', _infer_results_root_for_notebook(config)))\n",
    "    print('Using results root:', results_root)\n",
    "\n",
    "    monitor_rows_df, monitor_summary_df, monitor_csv_path = run_checkpoint_overfit_monitor(\n",
    "        phase1_data=phase1_data,\n",
    "        config=config,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        episode_range=(79, 100),\n",
    "        deterministic_modes=('mode', 'mean'),\n",
    "        eval_splits=('train', 'test'),\n",
    "        results_root=results_root,\n",
    "        include_rare=True,\n",
    "        save_csv=True,\n",
    "    )\n",
    "\n",
    "    display(monitor_summary_df.head(20))\n",
    "\n",
    "    if not monitor_summary_df.empty:\n",
    "        best = (\n",
    "            monitor_summary_df[monitor_summary_df['flag_overfit'] == False]\n",
    "            .sort_values('sharpe_ratio_test', ascending=False)\n",
    "            .head(10)\n",
    "        )\n",
    "        print('Top non-overfit candidates (by test Sharpe):')\n",
    "        display(best[[\n",
    "            'episode', 'deterministic_mode', 'sharpe_ratio_test',\n",
    "            'max_drawdown_test', 'turnover_test', 'sharpe_gap', 'mdd_gap', 'return_gap'\n",
    "        ]])\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_OVERFIT_MONITOR=False')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Optional Analysis Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: ABLATION TABLE + TRACK SUMMARY\n",
    "# ============================================================================\n",
    "RUN_OPTIONAL_ANALYSIS = False\n",
    "\n",
    "if RUN_OPTIONAL_ANALYSIS:\n",
    "    try:\n",
    "        from src.notebook_helpers.tcn_phase1 import build_ablation_table, build_evaluation_track_summary\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'Optional analysis helpers unavailable: {e}')\n",
    "\n",
    "    available = {k: v for k, v in globals().items() if k.startswith('evaluation_') and hasattr(v, 'deterministic_metrics')}\n",
    "    if 'evaluation_stub' in globals():\n",
    "        available.setdefault('current_eval', evaluation_stub)\n",
    "\n",
    "    if not available:\n",
    "        print('No evaluation objects found. Run evaluation first.')\n",
    "    else:\n",
    "        display(build_ablation_table(available))\n",
    "        if 'evaluation_stub' in globals():\n",
    "            print('Track summary for current evaluation:')\n",
    "            display(build_evaluation_track_summary(evaluation_stub))\n",
    "else:\n",
    "    print('â„¹ï¸ RUN_OPTIONAL_ANALYSIS=False')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Run Checklist\n",
    "\n",
    "Before running heavy jobs:\n",
    "- Confirm `ACTIVE_VARIANT`\n",
    "- Confirm `max_total_timesteps` and `timesteps_per_ppo_update`\n",
    "- Confirm curriculum schedule (1500 -> 2000 -> 2500 -> full)\n",
    "- Confirm step-Sharpe checkpoint rule (`>= 0.5`)\n",
    "- Confirm intra-step TAPE delta settings (`beta`, `clip`, `window`)\n",
    "- Set exactly one expensive toggle at a time (`RUN_TRAINING`, `RUN_EVAL`, `RUN_SCAN`, `RUN_OVERFIT_MONITOR`)\n",
    "- Keep artifact exports on after successful eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15960f6c",
   "metadata": {},
   "source": [
    "## 10) Feature Manifest Audit (Latest Artifacts)\n",
    "\n",
    "Use this section to inspect the latest active-feature manifests without hardcoded timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from src.notebook_helpers.tcn_phase1 import summarize_active_feature_manifest\n",
    "\n",
    "def latest_path(paths):\n",
    "    paths = [p for p in paths if p.exists()]\n",
    "    if not paths:\n",
    "        return None\n",
    "    return sorted(paths, key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
    "\n",
    "trainrl_manifest = latest_path(Path('results').glob('**/active_feature_manifest.json'))\n",
    "notebook_manifest = latest_path(Path(LATEST_RESULTS_ROOT).glob('logs/*_active_feature_manifest.json'))\n",
    "\n",
    "print('Latest train_rl manifest:', trainrl_manifest)\n",
    "print('Latest notebook manifest:', notebook_manifest)\n",
    "\n",
    "if trainrl_manifest:\n",
    "    summarize_active_feature_manifest(str(trainrl_manifest))\n",
    "if notebook_manifest:\n",
    "    summarize_active_feature_manifest(str(notebook_manifest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2203ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect missing requested columns + group counts from latest notebook manifest\n",
    "manifest_path = notebook_manifest\n",
    "if manifest_path is None:\n",
    "    print('No notebook manifest found. Run training first.')\n",
    "else:\n",
    "    m = json.loads(Path(manifest_path).read_text(encoding='utf-8'))\n",
    "    train_env = m.get('train_env', m)\n",
    "    print('Manifest path:', manifest_path)\n",
    "    print('Missing requested columns:', train_env.get('missing_requested_columns', []))\n",
    "    print('Group counts:', train_env.get('group_counts', {}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178280a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print active variable names from latest notebook manifest\n",
    "manifest_path = notebook_manifest\n",
    "if manifest_path is None:\n",
    "    print('No notebook manifest found. Run training first.')\n",
    "else:\n",
    "    m = json.loads(Path(manifest_path).read_text(encoding='utf-8'))\n",
    "    train_env = m.get('train_env', m)\n",
    "    active = train_env.get('active_feature_columns', [])\n",
    "    print(f'Active variable count: {len(active)}')\n",
    "    for v in active:\n",
    "        print(v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
