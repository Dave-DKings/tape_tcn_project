{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dd4dbc",
   "metadata": {},
   "source": [
    "# TCN Training Only (Clean)\n",
    "\n",
    "This notebook is for **training only**.\n",
    "It uses isolated `train_*` variables and a Sharpe-based checkpoint policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d402f683",
   "metadata": {},
   "source": [
    "## 1) Connect to Colab VM and Sync Repo\n",
    "Run this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d81df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fresh start complete\n",
      "Repo: /content/adaptive_portfolio_rl\n",
      "Deleted paths: 0\n"
     ]
    }
   ],
   "source": [
    "# Fresh-start cleanup cell (run before importing project modules)\n",
    "import gc\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "TRAIN_REPO_URL = \"https://github.com/Dave-DKings/tape_tcn_project.git\"\n",
    "TRAIN_REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
    "\n",
    "# 1) Sync repo to latest main\n",
    "if not (TRAIN_REPO_DIR / \".git\").exists():\n",
    "    subprocess.run([\"git\", \"clone\", TRAIN_REPO_URL, str(TRAIN_REPO_DIR)], check=True)\n",
    "\n",
    "subprocess.run([\"git\", \"-C\", str(TRAIN_REPO_DIR), \"fetch\", \"origin\"], check=True)\n",
    "subprocess.run([\"git\", \"-C\", str(TRAIN_REPO_DIR), \"reset\", \"--hard\", \"origin/main\"], check=True)\n",
    "\n",
    "# 2) Remove old experiment outputs/checkpoints/cached data\n",
    "purge_paths = [\n",
    "    TRAIN_REPO_DIR / \"tcn_fusion_results\",\n",
    "    TRAIN_REPO_DIR / \"tcn_results\",\n",
    "    TRAIN_REPO_DIR / \"tcn_att_results\",\n",
    "    TRAIN_REPO_DIR / \"output_logs\",\n",
    "    TRAIN_REPO_DIR / \"data\" / \"phase1_preparation_artifacts\",\n",
    "    TRAIN_REPO_DIR / \"data\" / \"master_features_NORMALIZED.csv\",\n",
    "    TRAIN_REPO_DIR / \"data\" / \"daily_ohlcv_assets.csv\",              # forces fresh OHLCV download\n",
    "    TRAIN_REPO_DIR / \"data\" / \"processed_daily_macro_features.csv\",   # forces fresh macro cache build\n",
    "]\n",
    "\n",
    "deleted = []\n",
    "for p in purge_paths:\n",
    "    if p.is_dir():\n",
    "        shutil.rmtree(p, ignore_errors=True)\n",
    "        deleted.append(str(p))\n",
    "    elif p.is_file():\n",
    "        p.unlink(missing_ok=True)\n",
    "        deleted.append(str(p))\n",
    "\n",
    "# 3) Remove Python/Jupyter cache folders\n",
    "for cache_dir in TRAIN_REPO_DIR.rglob(\"__pycache__\"):\n",
    "    shutil.rmtree(cache_dir, ignore_errors=True)\n",
    "for ckpt_dir in TRAIN_REPO_DIR.rglob(\".ipynb_checkpoints\"):\n",
    "    shutil.rmtree(ckpt_dir, ignore_errors=True)\n",
    "\n",
    "# 4) Clear loaded project modules from kernel memory\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if mod.startswith(\"src.\") or mod.startswith(\"src_\"):\n",
    "        del sys.modules[mod]\n",
    "gc.collect()\n",
    "\n",
    "print(\"âœ… Fresh start complete\")\n",
    "print(f\"Repo: {TRAIN_REPO_DIR}\")\n",
    "print(f\"Deleted paths: {len(deleted)}\")\n",
    "for d in deleted:\n",
    "    print(\" -\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9325a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: True\n",
      "CWD: /content\n",
      "\n",
      "Top-level:\n",
      " - [DIR ] .git\n",
      " - [FILE] .gitignore\n",
      " - [FILE] RL Portfolio Optimization Feature Engineering.md\n",
      " - [FILE] RL_Portfolio_Optimization_Feature_Engineering.ipynb\n",
      " - [FILE] USAGE_GUIDE_ACTUARIAL.py\n",
      " - [FILE] __init__.py\n",
      " - [FILE] convert_md_to_ipynb.py\n",
      " - [DIR ] data\n",
      " - [FILE] data1.zip\n",
      " - [FILE] debug_attention_weights.py\n",
      " - [DIR ] docs\n",
      " - [DIR ] eval\n",
      " - [DIR ] paper\n",
      " - [DIR ] prompts\n",
      " - [FILE] ra_kl_research_writeup.ipynb\n",
      " - [FILE] rcdcc_research_writeup.ipynb\n",
      " - [FILE] requirements.txt\n",
      " - [FILE] run_tcn_eval.py\n",
      " - [DIR ] src\n",
      " - [FILE] tcn_architecture_analysis.ipynb\n",
      " - [DIR ] tcn_documentation\n",
      " - [FILE] tcn_evaluation_only.ipynb\n",
      " - [FILE] technical_deep_dive_presentation.ipynb\n",
      " - [DIR ] tests\n",
      " - [FILE] traditional_portfolio_benchmarks.ipynb\n",
      " - [DIR ] training_scripts\n",
      "\n",
      "Target paths:\n",
      " - tcn_fusion_results: MISSING\n",
      " - tcn_results: MISSING\n",
      " - tcn_att_results: MISSING\n",
      " - output_logs: MISSING\n",
      " - data/phase1_preparation_artifacts: MISSING\n",
      " - data/master_features_NORMALIZED.csv: MISSING\n",
      " - data/daily_ohlcv_assets.csv: MISSING\n",
      " - data/processed_daily_macro_features.csv: MISSING\n"
     ]
    }
   ],
   "source": [
    "#from pathlib import Path\n",
    "import os\n",
    "\n",
    "root = Path(\"/content/adaptive_portfolio_rl\")\n",
    "print(\"Exists:\", root.exists())\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "print(\"\\nTop-level:\")\n",
    "for p in sorted(root.iterdir()):\n",
    "    kind = \"DIR \" if p.is_dir() else \"FILE\"\n",
    "    print(f\" - [{kind}] {p.name}\")\n",
    "\n",
    "# Quick check for outputs/caches you expected to be deleted\n",
    "targets = [\n",
    "    \"tcn_fusion_results\",\n",
    "    \"tcn_results\",\n",
    "    \"tcn_att_results\",\n",
    "    \"output_logs\",\n",
    "    \"data/phase1_preparation_artifacts\",\n",
    "    \"data/master_features_NORMALIZED.csv\",\n",
    "    \"data/daily_ohlcv_assets.csv\",\n",
    "    \"data/processed_daily_macro_features.csv\",\n",
    "]\n",
    "print(\"\\nTarget paths:\")\n",
    "for t in targets:\n",
    "    p = root / t\n",
    "    print(f\" - {t}: {'EXISTS' if p.exists() else 'MISSING'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!find /content/adaptive_portfolio_rl -maxdepth 3 | head -n 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09af84a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using python: /usr/bin/python3\n",
      "âœ… Requirements installed\n"
     ]
    }
   ],
   "source": [
    "# Install project requirements in Colab VM\n",
    "#import subprocess, sys\n",
    "#from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
    "REQ_FILE = REPO_DIR / \"requirements.txt\"\n",
    "\n",
    "if not REQ_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Missing requirements file: {REQ_FILE}\")\n",
    "\n",
    "print(\"Using python:\", sys.executable)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"], check=True)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(REQ_FILE)], check=True)\n",
    "\n",
    "print(\"âœ… Requirements installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f880e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-80GB (UUID: GPU-1494115c-0190-9a62-5729-2c4708531a57)\n",
      "TF GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Mixed precision policy: <DTypePolicy \"mixed_float16\">\n",
      "Matmul device: /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Default GPU device name: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# --- GPU sanity/setup for TensorFlow ---\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1) Confirm Colab sees an NVIDIA GPU\n",
    "!nvidia-smi -L\n",
    "\n",
    "# 2) Confirm TensorFlow sees GPU(s)\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"TF GPUs:\", gpus)\n",
    "if not gpus:\n",
    "    raise RuntimeError(\"No GPU visible to TensorFlow. In Colab: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# 3) Safer GPU memory behavior\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(g, True)\n",
    "\n",
    "# 4) Optional: speed boost on modern GPUs\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "print(\"Mixed precision policy:\", tf.keras.mixed_precision.global_policy())\n",
    "\n",
    "# 5) Quick proof op runs on GPU\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    a = tf.random.normal((4096, 4096))\n",
    "    b = tf.random.normal((4096, 4096))\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "print(\"Matmul device:\", c.device)\n",
    "print(\"Default GPU device name:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14187b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, pandas, tensorflow\n",
    "print(\"numpy\", numpy.__version__)\n",
    "print(\"pandas\", pandas.__version__)\n",
    "print(\"tensorflow\", tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49d0f2",
   "metadata": {},
   "source": [
    "## 2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641959e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /content/adaptive_portfolio_rl\n",
      "sys.path[0]: /content/adaptive_portfolio_rl\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"/content/adaptive_portfolio_rl\")\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Repo not found: {REPO_DIR}\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# Add repo root to Python path\n",
    "if str(REPO_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b477656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import get_active_config\n",
    "from src.csv_logger import CSVLogger\n",
    "from src.notebook_helpers.tcn_phase1 import prepare_phase1_dataset, run_experiment6_tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b538f",
   "metadata": {},
   "source": [
    "## 3) Base Config and Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71d4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Global feature-audit plan enforcement (49 + 4 actuarial = 53)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def enforce_feature_audit_plan(cfg):\n",
    "    fs = cfg.setdefault(\"feature_params\", {}).setdefault(\"feature_selection\", {})\n",
    "    fs[\"enforce_allowlist\"] = True\n",
    "    fs[\"allowlist_apply_to_phase2\"] = False\n",
    "\n",
    "    allowlist = list(dict.fromkeys(fs.get(\"active_features_allowlist\", []) or []))\n",
    "    fs[\"active_features_allowlist\"] = allowlist\n",
    "\n",
    "    plan_name = fs.get(\"feature_audit_plan_name\", \"feature_audit_allowlist\")\n",
    "    expected_total = int(fs.get(\"feature_audit_expected_total_count\", len(allowlist)))\n",
    "    act_cols = [c for c in allowlist if str(c).startswith(\"Actuarial_\")]\n",
    "\n",
    "    print(\"âœ… Feature audit plan configured\")\n",
    "    print(\"   plan:\", plan_name)\n",
    "    print(\"   allowlist count:\", len(allowlist))\n",
    "    print(\"   expected total:\", expected_total)\n",
    "    print(\"   actuarial in allowlist:\", len(act_cols), act_cols)\n",
    "\n",
    "    if len(allowlist) != expected_total:\n",
    "        print(\"âš ï¸ Allowlist count differs from expected total. Check src/config.py\")\n",
    "\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ca80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature audit plan configured\n",
      "   plan: exp6_feature_audit_20260221_v2\n",
      "   allowlist count: 53\n",
      "   expected total: 53\n",
      "   actuarial in allowlist: 4 ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "ğŸ“Š Loading raw market data...\n",
      "   âœ… Raw data shape: (55107, 7)\n",
      "   âœ… Date range: 2003-09-02 00:00:00 â†’ 2025-08-29 00:00:00\n",
      "\n",
      "ğŸ”§ Computing multi-horizon log returns: [1, 5, 10, 21]\n",
      "   âœ… Shape after returns: (54897, 11)\n",
      "\n",
      "ğŸ“ˆ Calculating 21-day rolling statistics\n",
      "\n",
      "ğŸ§® Computing technical indicators\n",
      "\n",
      "ğŸ“Š Computing dynamic covariance features\n",
      "\n",
      "ğŸ¯ Adding regime awareness features\n",
      "   âœ… Master DF shape: (54897, 47)\n",
      "   âœ… Total features: 47\n",
      "\n",
      "ğŸ“Š Integrating fundamental features (if enabled)...\n",
      "   âœ… Fundamental columns in dataset: 6 (enabled=True)\n",
      "   ğŸ§¾ Sample fundamental cols: ['Fundamental_FCFE_Delta', 'Fundamental_Revenue_Delta', 'Fundamental_NCFO_Delta', 'Fundamental_FCFE_Sign', 'Fundamental_Staleness_Days', 'Fundamental_Staleness_Quarters']\n",
      "\n",
      "ğŸ“Š Integrating macroeconomic features (if enabled)...\n",
      "   âœ… Macro features added - 43 columns: ['EFFR_diff', 'EFFR_zscore', 'SOFR_level', 'SOFR_diff', 'FEDFUNDS_diff', 'FEDFUNDS_zscore', 'DGS10_level', 'DGS10_diff', 'DGS10_slope', 'DGS2_level', 'DGS2_diff', 'T10Y2Y_level', 'TIPS10Y_level', 'TIPS10Y_diff', 'BreakevenInf10Y_level', 'BreakevenInf10Y_diff', 'BreakevenInf5Y_level', 'BreakevenInf5Y_diff', 'FedBalanceSheet_level', 'FedBalanceSheet_diff', 'ON_RRP_level', 'ON_RRP_diff', 'CPI_yoy', 'CPI_mom', 'PPI_yoy', 'PPI_mom', 'UNRATE_level', 'UNRATE_diff', 'UNRATE_zscore', 'PAYEMS_level', 'PAYEMS_diff', 'PAYEMS_yoy', 'INDPRO_level', 'INDPRO_diff', 'INDPRO_yoy', 'IG_Credit_level', 'IG_Credit_diff', 'IG_Credit_zscore', 'HY_Credit_level', 'HY_Credit_diff', 'HY_Credit_zscore', 'VIX_level', 'VIX_zscore']\n",
      "\n",
      "ğŸ“Š Integrating Alpha features (if enabled)...\n",
      "\n",
      "ğŸ“Š Integrating actuarial features (if enabled)...\n",
      "   âœ… Actuarial columns in dataset: 4 (enabled=True)\n",
      "   ğŸ“‹ Non-null counts: {'Actuarial_Expected_Recovery': 54897, 'Actuarial_Prob_30d': 54897, 'Actuarial_Prob_60d': 54897, 'Actuarial_Reserve_Severity': 54897}\n",
      "\n",
      "âœ… Final master DF shape: (54897, 109)\n",
      "   âœ… Total features: 109\n",
      "ğŸ§­ Feature audit plan: exp6_feature_audit_20260221_v2 (allowlist enabled)\n",
      "   active feature count (phase1): 53\n",
      "   âœ… expected active features: 53\n",
      "\n",
      "================================================================================\n",
      "âœ‚ï¸ FILTERING TO ANALYSIS PERIOD\n",
      "================================================================================\n",
      "   Filtering data to: 2003-09-02 â†’ 2025-09-01\n",
      "   âœ… Dates after filter: 5514 trading days\n",
      "   âœ… Date range: 2003-10-01 00:00:00 to 2025-08-29 00:00:00\n",
      "================================================================================\n",
      "================================================================================\n",
      "âœ‚ï¸  TIME-BASED TRAIN/TEST SPLIT (80/20 split)\n",
      "   Train: 2003-10-01 â†’ 2021-04-09 (4411 days, 17.5 years, 43867 rows)\n",
      "   Test:  2021-04-12 â†’ 2025-08-29 (1103 days, 4.4 years, 11030 rows)\n",
      "================================================================================\n",
      "\n",
      "ğŸ”§ NORMALISING FEATURES (standard scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.data_utils:Found 1566 NaN values after normalization, applying forward-fill only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Saving NORMALISED master dataframe to '/content/adaptive_portfolio_rl/data/master_features_NORMALIZED.csv'\n",
      "\n",
      "ğŸ’¾ Saved preparation artifacts:\n",
      "   raw OHLCV: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_raw_ohlcv.csv\n",
      "   full engineered: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_feature_engineered_full.csv\n",
      "   analysis-window engineered: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_feature_engineered_analysis_window.csv\n",
      "   normalized master: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_feature_engineered_normalized.csv\n",
      "   train normalized: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_train_normalized.csv\n",
      "   test normalized: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_test_normalized.csv\n",
      "   scalers: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_scalers.joblib\n",
      "   audit report: /content/adaptive_portfolio_rl/data_exports/phase1_prep_20260224_024125_preparation_audit.json\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RANDOM_SEED = 42\n",
    "\n",
    "train_config = deepcopy(get_active_config(\"phase1\"))\n",
    "\n",
    "# Optional: override analysis horizon\n",
    "# train_config[\"ANALYSIS_END_DATE\"] = \"2025-09-01\"\n",
    "\n",
    "train_config = enforce_feature_audit_plan(train_config)\n",
    "\n",
    "# Force fresh dataset build and market data re-download\n",
    "if \"train_phase1_data\" in globals():\n",
    "    del train_phase1_data\n",
    "\n",
    "train_phase1_data = prepare_phase1_dataset(\n",
    "    train_config,\n",
    "    force_download=True,\n",
    "    preparation_artifacts_dir=\"/content/adaptive_portfolio_rl/data_exports\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32011606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (43867, 109)\n",
      "Test shape: (11030, 109)\n",
      "Total columns: 109\n",
      "Potential redundant raw/unscaled cols: 0\n",
      "[]\n",
      "Model feature count (phase1): 53\n",
      "Actuarial feature count: 4 ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", train_phase1_data.train_df.shape)\n",
    "print(\"Test shape:\", train_phase1_data.test_df.shape)\n",
    "\n",
    "cols = train_phase1_data.train_df.columns\n",
    "print(\"Total columns:\", len(cols))\n",
    "\n",
    "# quick sanity for common redundant groups\n",
    "dup_like = [c for c in cols if c.endswith(\"_raw\") or c.endswith(\"_unscaled\")]\n",
    "print(\"Potential redundant raw/unscaled cols:\", len(dup_like))\n",
    "print(dup_like[:20])\n",
    "\n",
    "used_now = list(dict.fromkeys(train_phase1_data.data_processor.get_feature_columns(\"phase1\")))\n",
    "act_now = [c for c in used_now if c.startswith(\"Actuarial_\")]\n",
    "print(\"Model feature count (phase1):\", len(used_now))\n",
    "print(\"Actuarial feature count:\", len(act_now), act_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee488d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f32ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used feature count: 53\n",
      "Actuarial used: 4 ['Actuarial_Expected_Recovery', 'Actuarial_Prob_30d', 'Actuarial_Prob_60d', 'Actuarial_Reserve_Severity']\n",
      "Disabled that still in used: []\n",
      "VIX_zscore used? True\n"
     ]
    }
   ],
   "source": [
    "used = set(train_phase1_data.data_processor.get_feature_columns(\"phase1\"))\n",
    "disabled = set(train_config[\"feature_params\"][\"feature_selection\"][\"disabled_features\"])\n",
    "act_used = sorted([c for c in used if c.startswith(\"Actuarial_\")])\n",
    "\n",
    "print(\"Used feature count:\", len(used))\n",
    "print(\"Actuarial used:\", len(act_used), act_used)\n",
    "print(\"Disabled that still in used:\", sorted(disabled & used))  # should be []\n",
    "print(\"VIX_zscore used?\", \"VIX_zscore\" in used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e85bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = [\"Date\", \"Ticker\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "keep = [c for c in base_cols + list(used) if c in train_phase1_data.master_df.columns]\n",
    "\n",
    "train_phase1_data.master_df = train_phase1_data.master_df[keep].copy()\n",
    "train_phase1_data.train_df = train_phase1_data.train_df[keep].copy()\n",
    "train_phase1_data.test_df  = train_phase1_data.test_df[keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e8d0e",
   "metadata": {},
   "source": [
    "## 4) Training Overrides (Sharpe-Only Checkpoint Policy)\n",
    "\n",
    "This policy keeps only Sharpe-threshold high-watermark checkpointing (`>= 0.5`) and disables rare/step/periodic/TAPE checkpoint routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied next-run override (KL-stable + smoother execution + moderate turnover control)\n",
      "num_ppo_epochs: 1\n",
      "target_kl: 0.05 | kl_stop_multiplier: 1.25\n",
      "RA-KL: {'ra_kl_enabled': True, 'ra_kl_gain': 0.03, 'ra_kl_deadband': 0.2, 'ra_kl_max_change_fraction': 0.05, 'ra_kl_min_target_kl': 0.016, 'ra_kl_max_target_kl': 0.03}\n",
      "action_execution_beta_curriculum: {0: 0.15, 30000: 0.25}\n",
      "turnover_penalty_curriculum: {0: 0.0, 10000: 0.0, 25000: 0.0, 40000: 0.2}\n",
      "concentration: 3.0 0.12 2.0\n",
      "TCN stack: [64, 96, 128, 128, 128] | dilations: [1, 2, 4, 8, 16] | dropout: 0.15\n",
      "Fusion mixer: {'fusion_cross_asset_mixer_enabled': True, 'fusion_cross_asset_mixer_layers': 2, 'fusion_cross_asset_mixer_expansion': 2.0, 'fusion_cross_asset_mixer_dropout': 0.1}\n",
      "Fusion alpha head: [128, 64] | dropout: 0.05\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NEXT RUN OVERRIDES (post-mortem tuned: KL stability + turnover control)\n",
    "# ============================================================================\n",
    "from copy import deepcopy\n",
    "\n",
    "train_config = deepcopy(train_config)  # or deepcopy(config) if that's your active object\n",
    "\n",
    "tp = train_config[\"training_params\"]\n",
    "ap = train_config[\"agent_params\"]\n",
    "ppo = ap[\"ppo_params\"]\n",
    "env = train_config[\"environment_params\"]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) Core run shape\n",
    "# ----------------------------------------------------------------------------\n",
    "tp[\"max_total_timesteps\"] = 20_000\n",
    "tp[\"timesteps_per_ppo_update\"] = 384  # fallback\n",
    "\n",
    "tp[\"timesteps_per_ppo_update_schedule\"] = [\n",
    "    {\"threshold\": 0, \"timesteps_per_update\": 384},\n",
    "    {\"threshold\": 50_000, \"timesteps_per_update\": 448},\n",
    "]\n",
    "\n",
    "tp[\"batch_size_ppo_schedule\"] = [\n",
    "    {\"threshold\": 0, \"batch_size\": 96},\n",
    "    {\"threshold\": 50_000, \"batch_size\": 112},\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) A2: deeper temporal receptive field (1D TCN only; 2D variant skipped)\n",
    "# ----------------------------------------------------------------------------\n",
    "ap[\"tcn_filters\"] = [64, 96, 128, 128, 128]\n",
    "ap[\"tcn_kernel_size\"] = 5\n",
    "ap[\"tcn_dilations\"] = [1, 2, 4, 8, 16]\n",
    "ap[\"tcn_dropout\"] = 0.15\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) PPO stability (reduce aggressiveness)\n",
    "# ----------------------------------------------------------------------------\n",
    "ppo[\"num_ppo_epochs\"] = 1\n",
    "ppo[\"policy_clip\"] = 0.08\n",
    "ppo[\"target_kl\"] = 0.050\n",
    "ppo[\"kl_stop_multiplier\"] = 1.25\n",
    "ppo[\"minibatches_before_kl_stop\"] = 2\n",
    "ppo[\"max_grad_norm\"] = 0.30\n",
    "\n",
    "ppo[\"actor_lr\"] = 2e-5\n",
    "ppo[\"critic_lr\"] = 1.2e-4\n",
    "ppo[\"entropy_coef\"] = 0.0020\n",
    "\n",
    "tp[\"actor_lr_schedule\"] = [\n",
    "    {\"threshold\": 0, \"lr\": 8e-6},\n",
    "    {\"threshold\": 30_000, \"lr\": 7e-6},\n",
    "    {\"threshold\": 60_000, \"lr\": 6e-6},\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) RA-KL (less aggressive, prevent floor lock)\n",
    "# ----------------------------------------------------------------------------\n",
    "tp[\"ra_kl_enabled\"] = True\n",
    "tp[\"ra_kl_target_ratio\"] = 1.0\n",
    "tp[\"ra_kl_ema_alpha\"] = 0.25\n",
    "tp[\"ra_kl_gain\"] = 0.03\n",
    "tp[\"ra_kl_deadband\"] = 0.20\n",
    "tp[\"ra_kl_max_change_fraction\"] = 0.05\n",
    "tp[\"ra_kl_min_target_kl\"] = 0.016\n",
    "tp[\"ra_kl_max_target_kl\"] = 0.030\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) Dirichlet + concentration controls\n",
    "# ----------------------------------------------------------------------------\n",
    "ap[\"dirichlet_alpha_activation\"] = \"softplus\"\n",
    "ap[\"dirichlet_logit_temperature\"] = 1.0 # Keep static temperature neutral when adaptive is on\n",
    "ap[\"dirichlet_alpha_cap\"] = 20.0\n",
    "ap[\"dirichlet_epsilon\"] = {\"max\": 0.2, \"min\": 0.02}\n",
    "\n",
    "ap[\"dirichlet_adaptive_temperature_enabled\"] = True\n",
    "ap[\"dirichlet_adaptive_temperature_base\"] = 0.9\n",
    "ap[\"dirichlet_adaptive_temperature_slope\"] = 0.6\n",
    "ap[\"dirichlet_adaptive_temperature_min\"] = 0.8\n",
    "ap[\"dirichlet_adaptive_temperature_max\"] = 2.5\n",
    "\n",
    "\n",
    "# A3/A4: richer alpha head + optional cross-asset mixer\n",
    "ap[\"fusion_cross_asset_mixer_enabled\"] = True\n",
    "ap[\"fusion_cross_asset_mixer_layers\"] = 2\n",
    "ap[\"fusion_cross_asset_mixer_expansion\"] = 2.0\n",
    "ap[\"fusion_cross_asset_mixer_dropout\"] = 0.10\n",
    "ap[\"fusion_alpha_head_hidden_dims\"] = [128, 64]\n",
    "ap[\"fusion_alpha_head_dropout\"] = 0.05\n",
    "\n",
    "env[\"concentration_penalty_scalar\"] = 3.0\n",
    "env[\"concentration_target_hhi\"] = 0.12\n",
    "env[\"top_weight_penalty_scalar\"] = 2.0\n",
    "env[\"action_realization_penalty_scalar\"] = 0.5\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) Turnover + execution smoothing\n",
    "# ----------------------------------------------------------------------------\n",
    "env[\"target_turnover\"] = 0.35\n",
    "env[\"turnover_penalty_scalar\"] = 0.00\n",
    "env[\"transaction_cost_pct\"] = 0.001\n",
    "\n",
    "tp[\"action_execution_beta_curriculum\"] = {\n",
    "    0: 0.15,\n",
    "    30_000: 0.25,\n",
    "}\n",
    "tp[\"evaluation_action_execution_beta\"] = 0.15\n",
    "\n",
    "tp[\"turnover_penalty_curriculum\"] = {\n",
    "    0: 0.00,\n",
    "    10_000: 0.0,\n",
    "    25_000: 0.0,\n",
    "    40_000: 0.2,\n",
    "}\n",
    "tp[\"evaluation_turnover_penalty_scalar\"] = 0.2\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7) Episode horizon curriculum (keep cap late)\n",
    "# ----------------------------------------------------------------------------\n",
    "tp[\"use_episode_length_curriculum\"] = True\n",
    "tp[\"episode_length_curriculum_schedule\"] = [\n",
    "    {\"threshold\": 0, \"limit\": 252},\n",
    "    {\"threshold\": 10_000, \"limit\": 504},\n",
    "    {\"threshold\": 25_000, \"limit\": 756},\n",
    "    {\"threshold\": 90_000, \"limit\": 1008},\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 8) Logging + checkpoints\n",
    "# ----------------------------------------------------------------------------\n",
    "tp[\"log_step_diagnostics\"] = True\n",
    "tp[\"update_log_interval\"] = 5\n",
    "tp[\"alpha_diversity_log_interval\"] = 1\n",
    "tp[\"alpha_diversity_warning_after_updates\"] = 120\n",
    "tp[\"alpha_diversity_warning_std_threshold\"] = 0.25\n",
    "\n",
    "tp[\"deterministic_validation_checkpointing_enabled\"] = True\n",
    "tp[\"deterministic_validation_eval_every_episodes\"] = 3\n",
    "tp[\"deterministic_validation_mode\"] = \"mean\"\n",
    "tp[\"deterministic_validation_episode_length_limit\"] = 504\n",
    "tp[\"deterministic_validation_sharpe_min\"] = 0.5\n",
    "tp[\"deterministic_validation_sharpe_min_delta\"] = 0.005\n",
    "tp[\"deterministic_validation_seed_offset\"] = 10_000\n",
    "tp[\"deterministic_validation_log_alpha_stats\"] = True\n",
    "tp[\"deterministic_validation_checkpointing_only\"] = True\n",
    "\n",
    "tp[\"high_watermark_checkpoint_enabled\"] = False\n",
    "tp[\"high_watermark_sharpe_threshold\"] = 0.5\n",
    "tp[\"step_sharpe_checkpoint_enabled\"] = False\n",
    "tp[\"periodic_checkpoint_every_steps\"] = 0\n",
    "tp[\"rare_checkpoint_params\"] = {\"enable\": False}\n",
    "tp[\"tape_checkpoint_threshold\"] = 999.0\n",
    "\n",
    "print(\"âœ… Applied next-run override (KL-stable + smoother execution + moderate turnover control)\")\n",
    "print(\"num_ppo_epochs:\", ppo[\"num_ppo_epochs\"])\n",
    "print(\"target_kl:\", ppo[\"target_kl\"], \"| kl_stop_multiplier:\", ppo[\"kl_stop_multiplier\"])\n",
    "print(\"RA-KL:\", {k: tp[k] for k in [\n",
    "    \"ra_kl_enabled\", \"ra_kl_gain\", \"ra_kl_deadband\",\n",
    "    \"ra_kl_max_change_fraction\", \"ra_kl_min_target_kl\", \"ra_kl_max_target_kl\"\n",
    "]})\n",
    "print(\"action_execution_beta_curriculum:\", tp[\"action_execution_beta_curriculum\"])\n",
    "print(\"turnover_penalty_curriculum:\", tp[\"turnover_penalty_curriculum\"])\n",
    "print(\"concentration:\", env[\"concentration_penalty_scalar\"], env[\"concentration_target_hhi\"], env[\"top_weight_penalty_scalar\"])\n",
    "\n",
    "\n",
    "print(\"TCN stack:\", ap[\"tcn_filters\"], \"| dilations:\", ap[\"tcn_dilations\"], \"| dropout:\", ap[\"tcn_dropout\"])\n",
    "print(\"Fusion mixer:\", {k: ap[k] for k in [\"fusion_cross_asset_mixer_enabled\", \"fusion_cross_asset_mixer_layers\", \"fusion_cross_asset_mixer_expansion\", \"fusion_cross_asset_mixer_dropout\"]})\n",
    "print(\"Fusion alpha head:\", ap[\"fusion_alpha_head_hidden_dims\"], \"| dropout:\", ap[\"fusion_alpha_head_dropout\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1706d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ EXPERIMENT_DISABLE_KL_GUARDS=True (non-default experimental mode)\n"
     ]
    }
   ],
   "source": [
    "# Optional experimental override (OFF by default)\n",
    "# Keep this OFF for the aligned default pipeline.\n",
    "EXPERIMENT_DISABLE_KL_GUARDS = True\n",
    "\n",
    "if EXPERIMENT_DISABLE_KL_GUARDS:\n",
    "    tp = train_config[\"training_params\"]\n",
    "    ppo = train_config[\"agent_params\"][\"ppo_params\"]\n",
    "\n",
    "    # Disable RA-KL controller (otherwise it keeps adjusting target_kl)\n",
    "    tp[\"ra_kl_enabled\"] = False\n",
    "\n",
    "    # Disable KL early-stop gate in PPOAgentTF\n",
    "    ppo[\"target_kl\"] = 0.0\n",
    "\n",
    "    # Optional (irrelevant once target_kl=0, but explicit)\n",
    "    ppo[\"kl_stop_multiplier\"] = 999.0\n",
    "    ppo[\"minibatches_before_kl_stop\"] = 9999\n",
    "    print(\"âš ï¸ EXPERIMENT_DISABLE_KL_GUARDS=True (non-default experimental mode)\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ EXPERIMENT_DISABLE_KL_GUARDS=False (keeping RA-KL + KL safeguards)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09063801",
   "metadata": {},
   "source": [
    "## 5) Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0fd91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting training\n",
      "Architecture: TCN_FUSION\n",
      "max_total_timesteps: 20000\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT 6: TCN_FUSION Enhanced + TAPE Three-Component\n",
      "================================================================================\n",
      "Architecture: TCN + Fusion\n",
      "Results root: /content/adaptive_portfolio_rl/tcn_fusion_results\n",
      "Working dir: /content/adaptive_portfolio_rl\n",
      "Covariance Features: Yes\n",
      "ğŸ¯ REWARD SYSTEM: TAPE (Three-Component v3)\n",
      "   Profile: BalancedGrowth\n",
      "   Daily: Base + DSR/PBRS + Turnover_Proximity\n",
      "   Terminal: mode=signed | baseline=0.20 | scalar=10.0 (clipped Â±10.0)\n",
      "   Gate A: enabled (Sharpe â‰¤ 0.00 or MDD â‰¥ 25.0% -> force non-positive terminal bonus)\n",
      "   Neutral Band: enabled (Â±0.020 around baseline)\n",
      "   ğŸ”„ Profile Manager: disabled (static profile only)\n",
      "ğŸ² Experiment Seed: 6042 (Base: 42, Offset: 6000)\n",
      "âœ… Features: Enhanced (includes 3 covariance eigenvalues)\n",
      "   Eigenvalues: ['Covariance_Eigenvalue_0', 'Covariance_Eigenvalue_1', 'Covariance_Eigenvalue_2']\n",
      "   Train shape: (43867, 60)\n",
      "   Test shape: (11030, 60)\n",
      "   ğŸ§® Actuarial columns: 4 detected (enabled=True) | total non-null=219588\n",
      "      {'Actuarial_Expected_Recovery': 54897, 'Actuarial_Prob_30d': 54897, 'Actuarial_Prob_60d': 54897, 'Actuarial_Reserve_Severity': 54897}\n",
      "\n",
      "ğŸ—ï¸ Creating THREE-COMPONENT TAPE v3 environments (with curriculum)...\n",
      "   ğŸ¯ Reward System: TAPE (Three-Component v3)\n",
      "   ğŸ“Š Profile: BalancedGrowth\n",
      "   âš™ï¸  Component 1: Base Reward (Net Return)\n",
      "   âš™ï¸  Component 2: DSR/PBRS (window=60, scalar=2.00, gamma=0.99)\n",
      "   âš™ï¸  Component 3: Turnover Proximity (target=0.35, band=Â±0.20, scalar=0.00 -> 0.00 â†’ 0.00 â†’ 0.20)\n",
      "      â†³ Schedule: 0.00@0 â†’ 0.00@10,000 â†’ 0.00@25,000 â†’ 0.20@40,000\n",
      "   âš™ï¸  Component 4: Execution Inertia (beta=0.15 -> 0.25, w_exec=(1-Î²)w_prev + Î²w_raw)\n",
      "      â†³ Schedule: 0.15@0 â†’ 0.25@30,000\n",
      "   ğŸ Terminal: mode=signed, baseline=0.20, scalar=10.0 (clipped Â±10.0)\n",
      "   ğŸŸ° Neutral Band: enabled (Â±0.020 around baseline)\n",
      "   ğŸš¦ Gate A: enabled (Sharpe â‰¤ 0.00, MDD â‰¥ 25.0%)\n",
      "   ğŸ§  Credit Assignment: step reward is computed at each environment step\n",
      "   ğŸ§¾ Episode-End Handling: terminal TAPE bonus is added at episode completion only\n",
      "   âœ… Retroactive episode-wide reward rescaling: disabled in notebook helper path\n",
      "   ğŸ”’ Drawdown dual controller (requested): target=18.00%, tolerance=-1.50% (trigger boundary â‰ˆ 16.50%), lr=0.100, Î»_init=0.50, Î»_floor=0.00, Î»_max=5.00, penalty_coef=1.50\n",
      "   âœ… Drawdown controller armed in env: target=18.00%, trigger=16.50%, Î»_init=0.500, Î»_floor=0.000, Î»_max=5.00, penalty_coef=1.50\n",
      "âœ… THREE-COMPONENT TAPE v3 Environments created:\n",
      "   Training: 4411 days\n",
      "   Testing: 1103 days\n",
      "\n",
      "ğŸ¤– Creating TCN_FUSION agent with Dirichlet distribution for Exp 6...\n",
      "âœ… Agent created: PPOAgentTF\n",
      "   ğŸ² Dirichlet Distribution: ENABLED\n",
      "   ğŸ”§ Actor LR schedule: 0.000008@0 â†’ 0.000007@30,000 â†’ 0.000006@60,000\n",
      "   State dim: 341\n",
      "   Action dim: 10\n",
      "   Actor LR (configured): 2e-05\n",
      "   Actor LR (active): 0.000008\n",
      "   Critic LR (active): 0.000120\n",
      "   ğŸ§± TCN stack: filters=[64, 96, 128, 128, 128] | kernel=5 | dilations=[1, 2, 4, 8, 16] | dropout=0.15\n",
      "   ğŸ§© Fusion core: embed=128 | heads=4 | dropout=0.1\n",
      "   ğŸ”€ Cross-Asset Mixer (A4): enabled=True | layers=2 | expansion=2.0 | dropout=0.1\n",
      "   ğŸ¯ Alpha head (A3): dims=[128, 64] | dropout=0.05\n",
      "   ğŸ›ï¸ Dirichlet controls: activation=softplus | temperature=0.09 | alpha_cap=20.0 | epsilon={'max': 0.2, 'min': 0.02}\n",
      "   PPO update: epochs=1, batch_size=96, target_kl=0.0000, entropy_coef=0.0020\n",
      "   ğŸ“ PPO rollout schedule: 384@0 â†’ 448@50,000\n",
      "   ğŸ§º PPO batch-size schedule: 96@0 â†’ 112@50,000\n",
      "ğŸ“Š Training metrics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260224_024645_episodes.csv\n",
      "ğŸ§ª Step diagnostics will stream to /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260224_024645_step_diagnostics.csv\n",
      "\n",
      "ğŸ¯ Starting THREE-COMPONENT TAPE v3 training (with curriculum)...\n",
      "   Total timesteps: 20,000\n",
      "   Timesteps per update: scheduled\n",
      "      0+ steps: timesteps_per_update=384\n",
      "      50,000+ steps: timesteps_per_update=448\n",
      "   Number of updates: 53\n",
      "   PPO batch_size: scheduled\n",
      "      0+ steps: batch_size=96\n",
      "      50,000+ steps: batch_size=112\n",
      "   ğŸ“š Episode Length Curriculum:\n",
      "      0+ steps: limit=252\n",
      "      10,000+ steps: limit=504\n",
      "      25,000+ steps: limit=756\n",
      "      90,000+ steps: limit=1008\n",
      "   ğŸ“š Turnover Scalar Curriculum:\n",
      "      0+ steps: scalar=0.00\n",
      "      10,000+ steps: scalar=0.00\n",
      "      25,000+ steps: scalar=0.00\n",
      "      40,000+ steps: scalar=0.20\n",
      "   ğŸ›ï¸ Action Execution Beta Curriculum:\n",
      "      0+ steps: beta=0.15\n",
      "      30,000+ steps: beta=0.25\n",
      "   ğŸ† Deterministic-validation checkpoints: enabled (every 3 episodes | mode=mean | min_sharpe=0.50 | min_delta=0.005 | alpha_diag=True | horizon=504)\n",
      "   ğŸ§· Legacy checkpoint routes: disabled (high-watermark/step/periodic/tape/rare)\n",
      "   âœ… Checkpoint selector default: deterministic validation Sharpe improvement\n",
      "ğŸ§¾ Active feature manifest saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260224_024645_active_feature_manifest.json\n",
      "ğŸ§¾ Training metadata saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260224_024645_metadata.json\n",
      "   ğŸ¯ Episode 1: TAPE Score = 0.3875 (bonus: +2.34 â†’ +2.34)\n",
      "   ğŸ¯ Episode 2: TAPE Score = 0.5346 (bonus: +4.18 â†’ +4.18)\n",
      "   ğŸ¯ Episode 3: TAPE Score = 0.6253 (bonus: +5.32 â†’ +5.32)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.798 | Return=+30.96% | DD=13.82%\n",
      "      ğŸ’¾ Deterministic-validation checkpoint saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p798_actor.weights.h5 (val_sharpe=0.798)\n",
      "   ğŸ¯ Episode 4: TAPE Score = 0.2872 (bonus: -1.09 â†’ -1.09)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.587, MDD=30.63%\n",
      "   ğŸ¯ Episode 5: TAPE Score = 0.6283 (bonus: +5.35 â†’ +5.35)\n",
      "   ğŸ¯ Episode 6: TAPE Score = 0.7490 (bonus: +6.86 â†’ +6.86)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.776 | Return=+30.07% | DD=13.37%\n",
      "   ğŸ¯ Episode 7: TAPE Score = 0.4605 (bonus: +3.26 â†’ +3.26)\n",
      "ğŸ”„ Update 5/53 | Step 1,920/20,000 | Episode 7 | Time: 1055.3s\n",
      "   ğŸ“Š Metrics: Return=+10.59% | Sharpe=0.780 | DD=9.37% | Turnover=4.15%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.2474 | delta_reward=+0.0000\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0535 | critic_loss=0.5106 | mean_adv=-0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2553 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=5.68 | std=4.02 | range=[0.23, 17.24]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 7.87% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.4605\n",
      "   ğŸ¯ Episode 8: TAPE Score = 0.2084 (bonus: -0.00 â†’ -0.00)\n",
      "      ğŸŸ° Neutral band applied (Â±0.020)\n",
      "      ğŸš¦ Gate A applied: Sharpe=-0.539, MDD=36.40%\n",
      "   ğŸ¯ Episode 9: TAPE Score = 0.5291 (bonus: +4.11 â†’ +4.11)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.769 | Return=+29.86% | DD=13.15%\n",
      "   ğŸ¯ Episode 10: TAPE Score = 0.3829 (bonus: +2.29 â†’ +2.29)\n",
      "   ğŸ¯ Episode 11: TAPE Score = 0.5754 (bonus: +4.69 â†’ +4.69)\n",
      "   ğŸ¯ Episode 12: TAPE Score = 0.2822 (bonus: +1.03 â†’ +1.03)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.762 | Return=+29.37% | DD=13.00%\n",
      "   ğŸ¯ Episode 13: TAPE Score = 0.5670 (bonus: +4.59 â†’ +4.59)\n",
      "   ğŸ¯ Episode 14: TAPE Score = 0.2707 (bonus: +0.88 â†’ +0.88)\n",
      "   ğŸ¯ Episode 15: TAPE Score = 0.6463 (bonus: +5.58 â†’ +5.58)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.767 | Return=+29.24% | DD=12.72%\n",
      "ğŸ”„ Update 10/53 | Step 3,840/20,000 | Episode 15 | Time: 2298.1s\n",
      "   ğŸ“Š Metrics: Return=+15.77% | Sharpe=1.660 | DD=2.80% | Turnover=4.14%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.6204 | delta_reward=-0.0004\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0500 | critic_loss=0.4430 | mean_adv=-0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2215 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=6.39 | std=3.75 | range=[0.33, 17.17]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.87% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6463\n",
      "   ğŸ¯ Episode 16: TAPE Score = 0.5300 (bonus: +4.12 â†’ +4.12)\n",
      "   ğŸ¯ Episode 17: TAPE Score = 0.4473 (bonus: +3.09 â†’ +3.09)\n",
      "   ğŸ¯ Episode 18: TAPE Score = 0.3134 (bonus: -1.42 â†’ -1.42)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.687, MDD=30.72%\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.773 | Return=+29.35% | DD=12.64%\n",
      "   ğŸ¯ Episode 19: TAPE Score = 0.3625 (bonus: +2.03 â†’ +2.03)\n",
      "   ğŸ¯ Episode 20: TAPE Score = 0.5976 (bonus: +4.97 â†’ +4.97)\n",
      "   ğŸ¯ Episode 21: TAPE Score = 0.3171 (bonus: +1.46 â†’ +1.46)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.770 | Return=+29.11% | DD=12.56%\n",
      "   ğŸ¯ Episode 22: TAPE Score = 0.3365 (bonus: +1.71 â†’ +1.71)\n",
      "ğŸ”„ Update 15/53 | Step 5,760/20,000 | Episode 22 | Time: 3327.3s\n",
      "   ğŸ“Š Metrics: Return=+10.30% | Sharpe=0.592 | DD=11.54% | Turnover=4.23%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.6687 | delta_reward=-0.0001\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0441 | critic_loss=0.4961 | mean_adv=0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2481 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=6.64 | std=3.16 | range=[0.79, 15.29]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 1.34% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3365\n",
      "   ğŸ¯ Episode 23: TAPE Score = 0.4968 (bonus: +3.71 â†’ +3.71)\n",
      "   ğŸ¯ Episode 24: TAPE Score = 0.4479 (bonus: +3.10 â†’ +3.10)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.762 | Return=+28.75% | DD=12.46%\n",
      "   ğŸ¯ Episode 25: TAPE Score = 0.5196 (bonus: +4.00 â†’ +4.00)\n",
      "   ğŸ¯ Episode 26: TAPE Score = 0.6690 (bonus: +5.86 â†’ +5.86)\n",
      "   ğŸ¯ Episode 27: TAPE Score = 0.2767 (bonus: -0.96 â†’ -0.96)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.578, MDD=30.83%\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.760 | Return=+28.65% | DD=12.33%\n",
      "   ğŸ¯ Episode 28: TAPE Score = 0.5641 (bonus: +4.55 â†’ +4.55)\n",
      "   ğŸ¯ Episode 29: TAPE Score = 0.2616 (bonus: +0.77 â†’ +0.77)\n",
      "   ğŸ¯ Episode 30: TAPE Score = 0.2464 (bonus: -0.58 â†’ -0.58)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.412, MDD=30.85%\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.754 | Return=+28.26% | DD=12.24%\n",
      "ğŸ”„ Update 20/53 | Step 7,680/20,000 | Episode 30 | Time: 4570.4s\n",
      "   ğŸ“Š Metrics: Return=+10.54% | Sharpe=0.412 | DD=30.85% | Turnover=4.17%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.7531 | delta_reward=-0.0000\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0444 | critic_loss=0.5066 | mean_adv=-0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2533 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=6.77 | std=2.90 | range=[0.93, 13.02]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.09% / trig 16.50%) | terminal=0.000 (peak 0.102) | TAPE=0.2464\n",
      "   ğŸ¯ Episode 31: TAPE Score = 0.7026 (bonus: +6.28 â†’ +6.28)\n",
      "   ğŸ¯ Episode 32: TAPE Score = 0.5776 (bonus: +4.72 â†’ +4.72)\n",
      "   ğŸ¯ Episode 33: TAPE Score = 0.2116 (bonus: -0.00 â†’ -0.00)\n",
      "      ğŸŸ° Neutral band applied (Â±0.020)\n",
      "      ğŸš¦ Gate A applied: Sharpe=-0.174, MDD=37.97%\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.742 | Return=+27.69% | DD=12.23%\n",
      "   ğŸ¯ Episode 34: TAPE Score = 0.6112 (bonus: +5.14 â†’ +5.14)\n",
      "   ğŸ¯ Episode 35: TAPE Score = 0.5717 (bonus: +4.65 â†’ +4.65)\n",
      "   ğŸ¯ Episode 36: TAPE Score = 0.6173 (bonus: +5.22 â†’ +5.22)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.729 | Return=+27.21% | DD=12.37%\n",
      "   ğŸ¯ Episode 37: TAPE Score = 0.3482 (bonus: +1.85 â†’ +1.85)\n",
      "   ğŸ¯ Episode 38: TAPE Score = 0.3228 (bonus: +1.53 â†’ +1.53)\n",
      "ğŸ”„ Update 25/53 | Step 9,600/20,000 | Episode 38 | Time: 5603.7s\n",
      "   ğŸ“Š Metrics: Return=+8.96% | Sharpe=0.535 | DD=13.26% | Turnover=4.17%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.2337 | delta_reward=-0.0052\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0432 | critic_loss=0.4831 | mean_adv=0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2415 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=7.33 | std=2.69 | range=[2.10, 12.85]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 3.75% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.3228\n",
      "   ğŸ¯ Episode 39: TAPE Score = 0.2981 (bonus: +1.23 â†’ +1.23)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.718 | Return=+26.76% | DD=12.52%\n",
      "   ğŸ¯ Episode 40: TAPE Score = 0.3281 (bonus: +1.60 â†’ +1.60)\n",
      "   ğŸ¯ Episode 41: TAPE Score = 0.2488 (bonus: -0.61 â†’ -0.61)\n",
      "      ğŸš¦ Gate A applied: Sharpe=-0.327, MDD=12.87%\n",
      "\n",
      "ğŸ“š EPISODE HORIZON UPDATE at 10,368 steps:\n",
      "   Episode horizon: 504 steps\n",
      "   ğŸ¯ Episode 42: TAPE Score = 0.4155 (bonus: -2.69 â†’ -2.69)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.934, MDD=31.07%\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.715 | Return=+26.58% | DD=12.52%\n",
      "   ğŸ¯ Episode 43: TAPE Score = 0.5269 (bonus: +4.09 â†’ +4.09)\n",
      "ğŸ”„ Update 30/53 | Step 11,520/20,000 | Episode 43 | Time: 6651.7s\n",
      "   ğŸ“Š Metrics: Return=+54.95% | Sharpe=1.106 | DD=19.91% | Turnover=4.32%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.6054 | delta_reward=-0.0009\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0517 | critic_loss=0.5451 | mean_adv=-0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2726 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=6.37 | std=3.19 | range=[0.31, 13.91]\n",
      "   ğŸ”’ Drawdown Î» snapshot=1.189 (peak 1.206, dd 10.41% / trig 16.50%) | terminal=0.000 (peak 0.011) | TAPE=0.5269\n",
      "   ğŸ¯ Episode 44: TAPE Score = 0.2227 (bonus: -0.28 â†’ -0.28)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.110, MDD=37.97%\n",
      "   ğŸ¯ Episode 45: TAPE Score = 0.3707 (bonus: +2.13 â†’ +2.13)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.712 | Return=+26.42% | DD=12.35%\n",
      "   ğŸ¯ Episode 46: TAPE Score = 0.2182 (bonus: -0.00 â†’ -0.00)\n",
      "      ğŸŸ° Neutral band applied (Â±0.020)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.000, MDD=38.28%\n",
      "   ğŸ¯ Episode 47: TAPE Score = 0.5671 (bonus: +4.59 â†’ +4.59)\n",
      "ğŸ”„ Update 35/53 | Step 13,440/20,000 | Episode 47 | Time: 7471.5s\n",
      "   ğŸ“Š Metrics: Return=+32.20% | Sharpe=1.249 | DD=7.36% | Turnover=4.07%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.6021 | delta_reward=+0.0003\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0464 | critic_loss=0.3768 | mean_adv=0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.1884 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=7.41 | std=2.41 | range=[1.81, 12.04]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.122) | TAPE=0.5671\n",
      "   ğŸ¯ Episode 48: TAPE Score = 0.6572 (bonus: +5.71 â†’ +5.71)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.712 | Return=+26.43% | DD=12.15%\n",
      "   ğŸ¯ Episode 49: TAPE Score = 0.6410 (bonus: +5.51 â†’ +5.51)\n",
      "   ğŸ¯ Episode 50: TAPE Score = 0.2605 (bonus: -0.76 â†’ -0.76)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.486, MDD=30.89%\n",
      "   ğŸ¯ Episode 51: TAPE Score = 0.5490 (bonus: +4.36 â†’ +4.36)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.722 | Return=+26.82% | DD=12.05%\n",
      "ğŸ”„ Update 40/53 | Step 15,360/20,000 | Episode 51 | Time: 8505.1s\n",
      "   ğŸ“Š Metrics: Return=+35.03% | Sharpe=1.137 | DD=10.19% | Turnover=4.02%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.7626 | delta_reward=+0.0000\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0417 | critic_loss=0.3101 | mean_adv=-0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.1551 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=7.59 | std=2.34 | range=[3.48, 11.75]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.07% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.5490\n",
      "   ğŸ¯ Episode 52: TAPE Score = 0.4573 (bonus: +3.22 â†’ +3.22)\n",
      "   ğŸ¯ Episode 53: TAPE Score = 0.3506 (bonus: +1.88 â†’ +1.88)\n",
      "   ğŸ¯ Episode 54: TAPE Score = 0.5273 (bonus: +4.09 â†’ +4.09)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.740 | Return=+27.48% | DD=11.96%\n",
      "ğŸ”„ Update 45/53 | Step 17,280/20,000 | Episode 54 | Time: 9324.2s\n",
      "   ğŸ“Š Metrics: Return=+35.25% | Sharpe=1.120 | DD=13.66% | Turnover=4.19%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.5971 | delta_reward=-0.0002\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0517 | critic_loss=0.5514 | mean_adv=0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.2757 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=6.27 | std=2.89 | range=[0.39, 13.00]\n",
      "   ğŸ¯ Episode 55: TAPE Score = 0.2186 (bonus: -0.00 â†’ -0.00)\n",
      "      ğŸŸ° Neutral band applied (Â±0.020)\n",
      "      ğŸš¦ Gate A applied: Sharpe=0.011, MDD=42.90%\n",
      "   ğŸ¯ Episode 56: TAPE Score = 0.5595 (bonus: +4.49 â†’ +4.49)\n",
      "   ğŸ¯ Episode 57: TAPE Score = 0.3030 (bonus: +1.29 â†’ +1.29)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.738 | Return=+27.35% | DD=11.95%\n",
      "   ğŸ¯ Episode 58: TAPE Score = 0.6548 (bonus: +5.68 â†’ +5.68)\n",
      "ğŸ”„ Update 50/53 | Step 19,200/20,000 | Episode 58 | Time: 10141.7s\n",
      "   ğŸ“Š Metrics: Return=+48.12% | Sharpe=1.755 | DD=4.51% | Turnover=4.32%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.7503 | delta_reward=+0.0000\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0412 | critic_loss=0.2630 | mean_adv=0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.1315 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=7.01 | std=2.06 | range=[2.22, 11.89]\n",
      "   ğŸ”’ Drawdown Î» snapshot=0.000 (peak 0.000, dd 0.00% / trig 16.50%) | terminal=0.000 (peak 0.000) | TAPE=0.6548\n",
      "   ğŸ¯ Episode 59: TAPE Score = 0.3725 (bonus: +2.16 â†’ +2.16)\n",
      "   ğŸ¯ Episode 60: TAPE Score = 0.5718 (bonus: +4.65 â†’ +4.65)\n",
      "      ğŸ§ª Deterministic validation: Sharpe=0.713 | Return=+26.37% | DD=12.39%\n",
      "ğŸ”„ Update 53/53 | Step 20,000/20,000 | Episode 60 | Time: 10621.0s\n",
      "   ğŸ“Š Metrics: Return=+38.26% | Sharpe=1.456 | DD=10.59% | Turnover=4.31%\n",
      "   ğŸšï¸ Intra-Step TAPE: potential=0.6558 | delta_reward=+0.0003\n",
      "   ğŸ¯ Profile: BalancedGrowth\n",
      "   ğŸ§  Training: actor_loss=0.0415 | critic_loss=0.8920 | mean_adv=0.0000\n",
      "   ğŸ§® Loss Detail: critic_scaled=0.4460 | risk_aux_total=0.0000 | sharpe_proxy=0.0000 | sharpe_loss=0.0000 | mvo_loss=0.0000\n",
      "   âš™ï¸ Optimizer: actor_lr=0.000008 | critic_lr=0.000120 | target_kl=0.0000 | rollout=384 | batch_size=96\n",
      "   ğŸ”¬ Alpha Diversity: mean=6.42 | std=1.83 | range=[4.12, 10.28]\n",
      "\n",
      "âœ… THREE-COMPONENT TAPE v3 training completed!\n",
      "   Total episodes: 60\n",
      "   Total timesteps: 20,000\n",
      "   Training time: 10621.02s (177.02min)\n",
      "ğŸ“Š Training summary saved: /content/adaptive_portfolio_rl/tcn_fusion_results/logs/Exp6_TCN_FUSION_Enhanced_TAPE_training_20260224_024645_summary.csv\n",
      "ğŸ’¾ Final models saved: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p456_actor.weights.h5, /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00060_shp1p456_critic.weights.h5\n",
      "ğŸ¯ Default selected checkpoint (best deterministic validation): /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p798\n",
      "   â†³ Selection basis: deterministic validation Sharpe 0.798 at episode 3\n",
      "âœ… Training complete\n",
      "checkpoint_prefix: /content/adaptive_portfolio_rl/tcn_fusion_results/high_watermark_checkpoints/exp6_tape_hw_ep00003_shp0p798\n"
     ]
    }
   ],
   "source": [
    "RUN_TRAINING = True\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    tp = train_config[\"training_params\"]\n",
    "    print(\"ğŸš€ Starting training\")\n",
    "    print(\"Architecture:\", train_config[\"agent_params\"].get(\"actor_critic_type\"))\n",
    "    print(\"max_total_timesteps:\", tp[\"max_total_timesteps\"])\n",
    "\n",
    "    train_experiment6 = run_experiment6_tape(\n",
    "        phase1_data=train_phase1_data,\n",
    "        config=train_config,\n",
    "        random_seed=TRAIN_RANDOM_SEED,\n",
    "        csv_logger_cls=CSVLogger,\n",
    "        use_covariance=True,\n",
    "        architecture=train_config[\"agent_params\"].get(\"actor_critic_type\"),\n",
    "        timesteps_per_update=tp.get(\"timesteps_per_ppo_update\", 384),\n",
    "        max_total_timesteps=tp[\"max_total_timesteps\"],\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Training complete\")\n",
    "    print(\"checkpoint_prefix:\", train_experiment6.checkpoint_path)\n",
    "else:\n",
    "    print(\"â„¹ï¸ RUN_TRAINING=False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffd0df",
   "metadata": {},
   "source": [
    "## 6) Inspect Latest Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348fd0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RESULTS_ROOT = Path(\"/content/adaptive_portfolio_rl/tcn_fusion_results\")\n",
    "TRAIN_LOGS_DIR = TRAIN_RESULTS_ROOT / \"logs\"\n",
    "\n",
    "episodes_files = sorted(TRAIN_LOGS_DIR.glob(\"*episodes*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not episodes_files:\n",
    "    print(f\"No episodes CSV found in {TRAIN_LOGS_DIR}\")\n",
    "else:\n",
    "    train_episodes_path = episodes_files[0]\n",
    "    train_episodes_df = pd.read_csv(train_episodes_path)\n",
    "    print(\"Episodes file:\", train_episodes_path)\n",
    "    print(\"Rows:\", len(train_episodes_df))\n",
    "    display(train_episodes_df.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb04a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0e0e1",
   "metadata": {},
   "source": [
    "## 7) Export Results Folder (Optional)\n",
    "Creates a zip for download from Colab VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "EXPORT_RESULTS_ZIP = True\n",
    "EXPORT_PATH = Path(\"/content/tcn_fusion_results_run4.zip\")\n",
    "ROOT = Path(\"/content/adaptive_portfolio_rl\")\n",
    "\n",
    "if EXPORT_RESULTS_ZIP:\n",
    "    # Core items\n",
    "    include_paths = [\n",
    "        ROOT / \"tcn_fusion_results\",\n",
    "        ROOT / \"data\" / \"phase1_preparation_artifacts\",\n",
    "        ROOT / \"data\" / \"master_features_NORMALIZED.csv\",\n",
    "        ROOT / \"data_exports\",  # include all prep exports like phase1_prep_* artifacts\n",
    "    ]\n",
    "\n",
    "    # Also include latest phase1_prep_* files (explicitly, if present)\n",
    "    data_exports_dir = ROOT / \"data_exports\"\n",
    "    if data_exports_dir.exists():\n",
    "        latest_prep_files = sorted(\n",
    "            data_exports_dir.glob(\"phase1_prep_*\"),\n",
    "            key=lambda p: p.stat().st_mtime,\n",
    "            reverse=True,\n",
    "        )\n",
    "        include_paths.extend(latest_prep_files)\n",
    "\n",
    "    # De-dup + existence check\n",
    "    seen = set()\n",
    "    existing = []\n",
    "    for p in include_paths:\n",
    "        p = p.resolve()\n",
    "        if p.exists() and p not in seen:\n",
    "            seen.add(p)\n",
    "            existing.append(p)\n",
    "\n",
    "    if not existing:\n",
    "        print(\"âš ï¸ Nothing to export.\")\n",
    "    else:\n",
    "        if EXPORT_PATH.exists():\n",
    "            EXPORT_PATH.unlink()\n",
    "\n",
    "        rel_items = [str(p.relative_to(ROOT)) for p in existing if str(p).startswith(str(ROOT))]\n",
    "        if not rel_items:\n",
    "            print(\"âš ï¸ No export items are under ROOT.\")\n",
    "        else:\n",
    "            cmd = f\"cd {ROOT} && zip -qr {EXPORT_PATH} \" + \" \".join(f'\"{x}\"' for x in rel_items)\n",
    "            subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "            print(f\"âœ… Created: {EXPORT_PATH}\")\n",
    "            print(\"Included:\")\n",
    "            for p in rel_items:\n",
    "                print(\" -\", p)\n",
    "else:\n",
    "    print(\"â„¹ï¸ EXPORT_RESULTS_ZIP=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp /content/tcn_fusion_results_run4.zip /content/drive/MyDrive/\n",
    "print(\"âœ… Copied to Drive: /content/drive/MyDrive/tcn_fusion_results_run4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf11d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
