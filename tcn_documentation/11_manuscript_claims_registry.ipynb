{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manuscript Claims Registry (Evidence Control)\n",
        "\n",
        "**Objective**: enforce one-to-one traceability between each paper claim and concrete evidence artifacts (logs, tables, figures, checkpoints, code references).\n",
        "\n",
        "Use this notebook as the single source of truth for what you can safely claim in the paper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Why This Exists\n",
        "\n",
        "A claim is publishable only when it has:\n",
        "1. exact metric definition,\n",
        "2. exact data split,\n",
        "3. exact model/config/checkpoint,\n",
        "4. exact artifact path proving it,\n",
        "5. reproducible extraction route.\n",
        "\n",
        "If any of these is missing, the claim remains **Draft** and must not be promoted to final manuscript language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Claim Quality Levels\n",
        "\n",
        "- **Draft**: idea-level claim, evidence not yet locked.\n",
        "- **Supported**: evidence exists, but reproducibility check not completed.\n",
        "- **Verified**: evidence + reproducibility + consistency checks passed.\n",
        "- **Rejected**: claim contradicted by current evidence.\n",
        "\n",
        "Only **Verified** claims should appear as definitive results in the paper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Required Registry Fields\n",
        "\n",
        "Each claim row must include:\n",
        "\n",
        "- `claim_id` (stable unique key)\n",
        "- `paper_section` (e.g., Introduction, Methods, Results)\n",
        "- `claim_text` (exact sentence-level claim)\n",
        "- `claim_type` (`method`, `performance`, `robustness`, `implementation`, `risk`)\n",
        "- `model_variant` (`TCN`, `TCN_ATTENTION`, `TCN_FUSION`)\n",
        "- `data_split` (`train`, `test_oos`, `stochastic_oos`)\n",
        "- `eval_track` (`det_mode`, `det_mean`, `stochastic`)\n",
        "- `metric_name`, `metric_value`, `metric_unit`\n",
        "- `comparator_name`, `comparator_value` (if relative claim)\n",
        "- `checkpoint_ref` (episode/checkpoint prefix)\n",
        "- `run_metadata_json`\n",
        "- `evidence_paths` (semicolon-separated artifact paths)\n",
        "- `code_refs` (source files/functions used to compute metric)\n",
        "- `repro_steps` (brief extraction instructions)\n",
        "- `status` (`Draft`, `Supported`, `Verified`, `Rejected`)\n",
        "- `owner`, `last_updated`, `notes`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Recommended Folder Convention\n",
        "\n",
        "- Registry CSV: `tcn_documentation/claims_registry/claims_registry.csv`\n",
        "- Snapshots: `tcn_documentation/claims_registry/snapshots/`\n",
        "- Derived tables for paper: `tcn_documentation/claims_registry/exports/`\n",
        "\n",
        "Keep artifact paths relative to project root where possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if PROJECT_ROOT.name != 'adaptive_portfolio_rl':\n",
        "    # If running from repo root or elsewhere, try to resolve explicitly\n",
        "    candidate = PROJECT_ROOT / 'adaptive_portfolio_rl'\n",
        "    if candidate.exists():\n",
        "        PROJECT_ROOT = candidate\n",
        "\n",
        "REGISTRY_DIR = PROJECT_ROOT / 'tcn_documentation' / 'claims_registry'\n",
        "SNAPSHOT_DIR = REGISTRY_DIR / 'snapshots'\n",
        "EXPORT_DIR = REGISTRY_DIR / 'exports'\n",
        "\n",
        "for d in [REGISTRY_DIR, SNAPSHOT_DIR, EXPORT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "REGISTRY_CSV = REGISTRY_DIR / 'claims_registry.csv'\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('Registry CSV:', REGISTRY_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "CLAIM_COLUMNS = [\n",
        "    'claim_id',\n",
        "    'paper_section',\n",
        "    'claim_text',\n",
        "    'claim_type',\n",
        "    'model_variant',\n",
        "    'data_split',\n",
        "    'eval_track',\n",
        "    'metric_name',\n",
        "    'metric_value',\n",
        "    'metric_unit',\n",
        "    'comparator_name',\n",
        "    'comparator_value',\n",
        "    'checkpoint_ref',\n",
        "    'run_metadata_json',\n",
        "    'evidence_paths',\n",
        "    'code_refs',\n",
        "    'repro_steps',\n",
        "    'status',\n",
        "    'owner',\n",
        "    'last_updated',\n",
        "    'notes',\n",
        "]\n",
        "\n",
        "def init_registry(path=REGISTRY_CSV):\n",
        "    if path.exists():\n",
        "        df = pd.read_csv(path)\n",
        "        for c in CLAIM_COLUMNS:\n",
        "            if c not in df.columns:\n",
        "                df[c] = ''\n",
        "        df = df[CLAIM_COLUMNS]\n",
        "    else:\n",
        "        df = pd.DataFrame(columns=CLAIM_COLUMNS)\n",
        "    return df\n",
        "\n",
        "claims_df = init_registry()\n",
        "print('Rows:', len(claims_df))\n",
        "claims_df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def upsert_claim(df, row_dict):\n",
        "    row = {c: row_dict.get(c, '') for c in CLAIM_COLUMNS}\n",
        "    row['last_updated'] = datetime.now().isoformat(timespec='seconds')\n",
        "    claim_id = row['claim_id']\n",
        "    if not claim_id:\n",
        "        raise ValueError('claim_id is required')\n",
        "\n",
        "    mask = df['claim_id'] == claim_id\n",
        "    if mask.any():\n",
        "        df.loc[mask, CLAIM_COLUMNS] = [row[c] for c in CLAIM_COLUMNS]\n",
        "    else:\n",
        "        df.loc[len(df)] = [row[c] for c in CLAIM_COLUMNS]\n",
        "    return df\n",
        "\n",
        "# Example placeholder claim\n",
        "claims_df = upsert_claim(claims_df, {\n",
        "    'claim_id': 'RES-TCN-001',\n",
        "    'paper_section': 'Results',\n",
        "    'claim_text': 'TCN outperforms baseline on OOS Sharpe in det_mean evaluation.',\n",
        "    'claim_type': 'performance',\n",
        "    'model_variant': 'TCN',\n",
        "    'data_split': 'test_oos',\n",
        "    'eval_track': 'det_mean',\n",
        "    'metric_name': 'sharpe_ratio',\n",
        "    'metric_value': '',\n",
        "    'metric_unit': 'ratio',\n",
        "    'comparator_name': 'baseline_sharpe',\n",
        "    'comparator_value': '',\n",
        "    'checkpoint_ref': '',\n",
        "    'run_metadata_json': '',\n",
        "    'evidence_paths': '',\n",
        "    'code_refs': 'src/notebook_helpers/tcn_phase1.py::evaluate_experiment6_checkpoint',\n",
        "    'repro_steps': 'Load checkpoint, run deterministic mean eval, extract summary metrics.',\n",
        "    'status': 'Draft',\n",
        "    'owner': 'Owner',\n",
        "    'notes': 'Fill after full variant campaign.'\n",
        "})\n",
        "claims_df.tail(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def validate_evidence_paths(df, project_root=PROJECT_ROOT):\n",
        "    rows = []\n",
        "    for _, r in df.iterrows():\n",
        "        claim_id = str(r.get('claim_id', ''))\n",
        "        evidence = str(r.get('evidence_paths', '')).strip()\n",
        "        if not evidence:\n",
        "            rows.append({'claim_id': claim_id, 'path': '', 'exists': False, 'note': 'missing evidence_paths'})\n",
        "            continue\n",
        "        for p in [x.strip() for x in evidence.split(';') if x.strip()]:\n",
        "            path = Path(p)\n",
        "            if not path.is_absolute():\n",
        "                path = project_root / path\n",
        "            rows.append({'claim_id': claim_id, 'path': str(path), 'exists': path.exists(), 'note': ''})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "validation_df = validate_evidence_paths(claims_df)\n",
        "validation_df.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Persist registry + timestamped snapshot\n",
        "claims_df = claims_df[CLAIM_COLUMNS].copy()\n",
        "claims_df.to_csv(REGISTRY_CSV, index=False)\n",
        "\n",
        "snapshot_path = SNAPSHOT_DIR / f\"claims_registry_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "claims_df.to_csv(snapshot_path, index=False)\n",
        "\n",
        "print('Saved registry:', REGISTRY_CSV)\n",
        "print('Saved snapshot:', snapshot_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Export manuscript-ready views\n",
        "verified = claims_df[claims_df['status'].str.lower() == 'verified'].copy()\n",
        "draft = claims_df[claims_df['status'].str.lower() == 'draft'].copy()\n",
        "\n",
        "verified_out = EXPORT_DIR / 'verified_claims.csv'\n",
        "draft_out = EXPORT_DIR / 'draft_claims.csv'\n",
        "\n",
        "verified.to_csv(verified_out, index=False)\n",
        "draft.to_csv(draft_out, index=False)\n",
        "\n",
        "print('Verified export:', verified_out)\n",
        "print('Draft export:', draft_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Operating Rule for Writing\n",
        "\n",
        "Before adding any numeric statement to the manuscript:\n",
        "1. Add/Update a claim row here.\n",
        "2. Attach evidence artifacts.\n",
        "3. Mark as `Verified` only after rerun/repro check.\n",
        "4. Use `claim_id` as inline comment in paper drafting notes.\n",
        "\n",
        "This process prevents accidental over-claiming and keeps results publication-defensible.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}