@article{markowitz1952portfolio,
  title     = {Portfolio selection},
  author    = {Markowitz, Harry},
  journal   = {The Journal of Finance},
  volume    = {7},
  number    = {1},
  pages     = {77--91},
  year      = {1952},
  publisher = {Wiley Online Library}
}

@article{andre2021dirichlet,
  title   = {Dirichlet policies for reinforced factor portfolios},
  author  = {Andr{\'e}, E and Coqueret, Guillaume},
  journal = {arXiv preprint arXiv:2011.05381v3},
  year    = {2021}
}

@inproceedings{bengio2009curriculum,
  title     = {Curriculum learning},
  author    = {Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle = {Proceedings of the 26th International Conference on Machine Learning},
  pages     = {41--48},
  year      = {2009}
}

@article{canonaco2024sample,
  title   = {On the sample efficiency of abstractions and potential-based reward shaping in reinforcement learning},
  author  = {Canonaco, G and Ardon, L and Pozanco, A and Borrajo, D},
  journal = {arXiv preprint arXiv:2404.14876},
  year    = {2024}
}

@mastersthesis{castagno2024portfolio,
  title  = {Portfolio optimization with artificial intelligence: A neural network approach to maximizing risk-adjusted returns},
  author = {Castagno, G},
  school = {Politecnico di Torino},
  year   = {2024}
}

@article{choudhary2025risk,
  title   = {Risk-adjusted deep reinforcement learning for portfolio optimization: A multi-reward approach},
  author  = {Choudhary, H and Orra, A and Sahoo, K and Thakur, M},
  journal = {International Journal of Computational Intelligence Systems},
  volume  = {18},
  number  = {1},
  pages   = {126},
  year    = {2025}
}

@inproceedings{devidze2022exploration,
  title     = {Exploration-guided reward shaping for reinforcement learning under sparse rewards},
  author    = {Devidze, Rati and Kamalaruban, P and Singla, A},
  booktitle = {36th Conference on Neural Information Processing Systems (NeurIPS 2022)},
  year      = {2022}
}

@inproceedings{hu2020learning,
  title     = {Learning to utilize shaping rewards: A new approach of reward shaping},
  author    = {Hu, Y and others},
  booktitle = {34th Conference on Neural Information Processing Systems (NeurIPS 2020)},
  year      = {2020}
}

@article{huang2024self,
  title   = {A self-rewarding mechanism in deep reinforcement learning for trading strategy optimization},
  author  = {Huang, Y and Zhou, C and Zhang, L and Lu, X},
  journal = {Mathematics},
  volume  = {12},
  number  = {24},
  pages   = {4020},
  year    = {2024}
}

@inproceedings{jeon2023benchmarking,
  title     = {Benchmarking Potential Based Rewards for Learning Humanoid Locomotion},
  author    = {Jeon, Se Hwan and others},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2023}
}

@article{kaishev2009dirichlet,
  title   = {Dirichlet bridge sampling for the Variance Gamma process: pricing path-dependent options},
  author  = {Kaishev, Vladimir K and Dimitrova, D S},
  journal = {Management Science},
  volume  = {55},
  number  = {3},
  pages   = {483--496},
  year    = {2009}
}

@article{koratamaddi2021market,
  title   = {Market sentiment-aware deep reinforcement learning approach for stock portfolio allocation},
  author  = {Koratamaddi, P and Wadhwani, K and Gupta, M and Sanjeevi, S G},
  journal = {Engineering Science and Technology, an International Journal},
  volume  = {24},
  number  = {4},
  pages   = {848--859},
  year    = {2021}
}

@article{li2018deep,
  title   = {Deep reinforcement learning: An overview},
  author  = {Li, Y},
  journal = {arXiv preprint arXiv:1701.07274v6},
  year    = {2018}
}

@article{li2025ttsnet,
  title   = {TTSNet: Transformer–Temporal Convolutional Network–Self-Attention with Feature Fusion for Prediction of Remaining Useful Life of Aircraft Engines},
  author  = {Li, Z and Luo, S and Liu, H and Tang, C and Miao, J},
  journal = {Sensors},
  volume  = {25},
  number  = {2},
  pages   = {432},
  year    = {2025}
}

@inproceedings{marom2018belief,
  title     = {Belief reward shaping in reinforcement learning},
  author    = {Marom, O and Rosman, B},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2018}
}

@inproceedings{muller2025improving,
  title     = {Improving the effectiveness of potential-based reward shaping in reinforcement learning},
  author    = {M{\"u}ller, H and Kudenko, D},
  booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  pages     = {2684--2686},
  year      = {2025}
}

@article{ng1999policy,
  title  = {Policy invariance under reward transformations: Theory and application to reward shaping},
  author = {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  year   = {1999}
}

@article{sami2022graph,
  title   = {Graph convolutional recurrent networks for reward shaping in reinforcement learning},
  author  = {Sami, H and Bentahar, J and Mourad, A and Otrok, H and Damiani, E},
  journal = {Information Sciences},
  volume  = {608},
  pages   = {337--352},
  year    = {2022}
}

@inproceedings{sood2023deep,
  title     = {Deep reinforcement learning for optimal portfolio allocation: A comparative study with mean-variance optimization},
  author    = {Sood, S and Papasotiriou, K and Vaiciulis, M and Balch, T},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2023}
}

@article{tian2022prescriptive,
  title   = {A prescriptive Dirichlet power allocation policy with deep reinforcement learning},
  author  = {Tian, Y and Han, M and Kulkarni, C and Fink, O},
  journal = {Engineering Applications of Artificial Intelligence},
  volume  = {112},
  pages   = {104882},
  year    = {2022}
}

@article{wang2025risk,
  title   = {Risk-sensitive deep reinforcement learning for portfolio optimization},
  author  = {Wang, X and Liu, L},
  journal = {Journal of Risk and Financial Management},
  volume  = {18},
  number  = {7},
  pages   = {347},
  year    = {2025}
}

@article{wong2025portfolio,
  title   = {Portfolio optimization through a multi-modal deep reinforcement learning framework},
  author  = {Wong, J and Liu, L L},
  journal = {Engineering: Open Access},
  volume  = {3},
  number  = {4},
  pages   = {1-8},
  year    = {2025}
}

@mastersthesis{xu2024portfolio,
  title  = {Portfolio optimization with reinforcement learning},
  author = {Xu, Y},
  school = {University of North Carolina at Chapel Hill},
  type   = {Senior honors thesis},
  year   = {2024}
}

@article{yang2022selective,
  title   = {A selective portfolio management algorithm with off-policy reinforcement learning using Dirichlet distribution},
  author  = {Yang, H and Park, H and Lee, K},
  journal = {Axioms},
  volume  = {11},
  number  = {12},
  pages   = {664},
  year    = {2022}
}

@inproceedings{yang2020ensemble,
  title     = {Deep reinforcement learning for automated stock trading: An ensemble strategy},
  author    = {Yang, H and Liu, X-Y and Zhong, S and Walid, A},
  booktitle = {ACM International Conference on AI in Finance (ICAIF '20)},
  pages     = {8 pages},
  year      = {2020}
}

@techreport{zhang2020deep,
  title       = {Deep learning for portfolio optimization},
  author      = {Zhang, Z and Zohren, S and Roberts, S},
  institution = {Oxford-Man Institute of Quantitative Finance, University of Oxford},
  year        = {2020}
}

@inproceedings{bai2018tcn,
  title     = {An empirical evaluation of generic convolutional and recurrent networks for sequence modeling},
  author    = {Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  booktitle = {arXiv preprint arXiv:1803.01271},
  year      = {2018}
}

@article{jiang2017deep,
  title   = {A deep reinforcement learning framework for the financial portfolio management problem},
  author  = {Jiang, Zhengyao and Xu, Dixing and Liang, Jinjun},
  journal = {arXiv preprint arXiv:1706.10059},
  year    = {2017}
}

@inproceedings{liang2018adversarial,
  title     = {Adversarial deep reinforcement learning in portfolio management},
  author    = {Liang, Zhipeng and Chen, Hao and Zhu, Junhao and Jiang, Kangkang and Li, Yanran},
  booktitle = {arXiv preprint arXiv:1808.09940},
  year      = {2018}
}

@article{xu2021portfolio,
  title   = {DP-TCN: Differential privacy-inspired TCN for stock prediction using financial news},
  author  = {Xu, Xinyi and Zhang, Yanqing},
  journal = {arXiv preprint arXiv:2106.09121},
  year    = {2021}
}

@book{embrechts2013modelling,
  title     = {Modelling extremal events: for insurance and finance},
  author    = {Embrechts, Paul and Kl{\"u}ppelberg, Claudia and Mikosch, Thomas},
  year      = {2013},
  publisher = {Springer Science \& Business Media}
}

@article{kaplan1958nonparametric,
  title     = {Nonparametric estimation from incomplete observations},
  author    = {Kaplan, Edward L and Meier, Paul},
  journal   = {Journal of the American statistical association},
  volume    = {53},
  number    = {282},
  pages     = {457--481},
  year      = {1958},
  publisher = {Taylor \& Francis}
}

@article{schulman2017proximal,
  title   = {Proximal policy optimization algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017}
}

@article{mack1993distribution,
  title     = {Distribution-free calculation of the standard error of chain ladder reserve estimates},
  author    = {Mack, Thomas},
  journal   = {ASTIN Bulletin: The Journal of the IAA},
  volume    = {23},
  number    = {2},
  pages     = {213--225},
  year      = {1993},
  publisher = {Cambridge University Press}
}

@book{taylor2000loss,
  title     = {Loss reserving: an actuarial perspective},
  author    = {Taylor, Gregory C},
  volume    = {21},
  year      = {2000},
  publisher = {Springer Science \& Business Media}
}

